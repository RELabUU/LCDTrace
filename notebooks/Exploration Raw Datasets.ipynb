{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "local-paintball",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "#Import Python Libraries\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "#Import Self-written Functions\n",
    "import os\n",
    "import sys\n",
    "src_dir = os.path.join(os.getcwd(), '..', 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from d00_utils.calculateTimeDifference import calculateTimeDifference #Function to calc time difference\n",
    "from d01_data.loadCommits import loadCommits #Function to load SVN data\n",
    "from d02_intermediate.cleanCommitData import cleanCommitData #Function to clean commit data\n",
    "from d02_intermediate.cleanJiraData import cleanJiraData #Function to clean JIRA data\n",
    "\n",
    "from d03_processing.createFittedTF_IDF import createFittedTF_IDF #Function to see if a trace is valid\n",
    "from d03_processing.createCorpusFromDocumentList import createCorpusFromDocumentList #Function to create a corpus\n",
    "from d03_processing.checkValidityTrace import checkValidityTrace #Function to see if a trace is valid\n",
    "from d03_processing.calculateTimeDif import calculateTimeDif #Calculate the time difference between 2 dates in seconds\n",
    "from d03_processing.checkFullnameEqualsEmail import checkFullnameEqualsEmail #Check if fullName is equal to the email\n",
    "from d03_processing.calculateCosineSimilarity import calculateCosineSimilarity #Calculate the cos similarity\n",
    "from d03_processing.calculateDocumentStatistics import calculateUniqueWordCount\n",
    "from d03_processing.calculateDocumentStatistics import calculateTotalWordCount\n",
    "from d03_processing.calculateDocumentStatistics import calculateOverlapBetweenDocuments\n",
    "\n",
    "from d04_modelling.summariseClassDistribution import summariseClassDistribution #Visualize the class distribution\n",
    "from d04_modelling.showModelPerformance import showModelPerformance # Show several performance measures\n",
    "\n",
    "#Display full value of a column\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "#Display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adverse-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import raw JIRA dataset\n",
    "rawData_JIRA_dataProcessing = pd.read_csv('../data/01_raw/JIRA Mendix.csv')\n",
    "rawData_JIRA_academy = pd.read_excel('../data/01_raw/JIRA Mendix Academy export.xlsx')\n",
    "rawData_JIRA_academyMay = pd.read_excel('../data/01_raw/JIRA Mendix Academy export_15_05_2021.xlsx')\n",
    "rawData_JIRA_dealService = pd.read_csv('../data/01_raw/deal-service.csv')\n",
    "rawData_JIRA_mxShop = pd.read_excel('../data/01_raw/JIRA Mendix Engagement export_22_06_2021.xlsx')\n",
    "\n",
    "#import SVN\n",
    "rawData_SVN_dataProcessing = loadCommits(\"../data/01_raw/data-processing-svn-dump.txt\")\n",
    "rawData_SVN_academy = loadCommits(\"../data/01_raw/academy-svn-dump.txt\")\n",
    "rawData_SVN_dealService = loadCommits('../data/01_raw/dealservice-dump.txt')\n",
    "rawData_SVN_mxShop = loadCommits(\"../data/01_raw/mxshop-dump.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "federal-petersburg",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Description</th>\n",
       "      <th>Epic Link</th>\n",
       "      <th>Fix versions</th>\n",
       "      <th>Story Points</th>\n",
       "      <th>Updated</th>\n",
       "      <th>Assignee</th>\n",
       "      <th>Created</th>\n",
       "      <th>Creator</th>\n",
       "      <th>External issue ID</th>\n",
       "      <th>Issue Type</th>\n",
       "      <th>Last Viewed</th>\n",
       "      <th>Linked Issues</th>\n",
       "      <th>Parent Link</th>\n",
       "      <th>Project</th>\n",
       "      <th>RCA Comments</th>\n",
       "      <th>Reporter</th>\n",
       "      <th>Resolved</th>\n",
       "      <th>Status Category</th>\n",
       "      <th>Design Review Comments</th>\n",
       "      <th>Mitigation Status and Comments</th>\n",
       "      <th>Key</th>\n",
       "      <th>Description.1</th>\n",
       "      <th>Issue Description</th>\n",
       "      <th>Watchers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Datalake sending Learning Path Progress bug</td>\n",
       "      <td>Medium</td>\n",
       "      <td>a issue occured with sending data to datalake, it seemed that somehow a record was not found when processing the first batch of learning path progress.\\nIt can be caused as seen in the logs when duplicated learning path progress been removed (could be caused by the after commit on learning path progress microflow that cleans up duplicated learning path progress), since we now update each learning path progress object with the value 'is processed to datalake' when it is being retrieved in the batch, before it is send to datalake. It causes that the process of sending data to datalake has been stopped. and currently 420 learning path progress objects have been marked as 'processed to datalake', but have not been send to datalake since the process is stopped by the system.\\n\\n!Screenshot 2021-05-11 at 21.36.20.png|width=1401,height=674!\\n\\n\\n\\nas seen in this image, there are no learning path progress records in Datalake\\n\\n!image (4).png|width=3360,height=2100!\\n\\nSeen here the admin panel amount of learning path progress objects that been marked as 'processed to datalake'. but not been send to datalake\\n\\n!image-20210512-074254.png|width=3360,height=4039!\\n\\n\\n\\n*Acceptance Criteria* \\n\\n* Create Microflow to reset the learning path progress objects that have {{ProcessedToDatalake = true}} since all these records should all be set on _false_ again before performing the send historical data to datalake\\n* Find a solution how to handle the error.\\n\\n----\\n\\n\\n\\n{color:#00B8D9}*[ BEFORE RELEASE ]*{color}\\n\\n# Make sure datalake producer ‘enable sending data’ is *disabled*\\nAdmin pages → Dataproducer overview → open datalake config - Checked, it is disabled. \\n!image-20210511-153413.png|width=1880,height=244!\\n\\n{color:#FF991F}*[ AFTER RELEASE ]*{color} \\n\\n*Datalake Setup - All done* (/)\\n\\n# Delete the currently configuration of datalake producer, to reset it again to send all data over again\\nAdmin pages → Dataproducer overview → open datalake config → delete\\n# Create the configuration again by clicking the button 'open datalake config', *with the settings below*, and click save.\\n## *Send historical data:* true\\n## *Enable:* false\\n## *Batch Size limit:* 3000\\n# Make sure academy production datalake sending data is *disabled* (can be managed in the frontend Admin pages → Dataproducer overview → open datalake config → disable send data to datalake → save) \\n# in datalake portal production ([https://portal.datalake.mendix.com/tables|https://portal.datalake.mendix.com/tables]) all the tables in academy need to be removed and re-assigned again. this triggers that all data will be removed and can have a clean setup. \\n# Make sure academy production datalake sending data is *enabled* again</td>\n",
       "      <td>LRN-1092</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-05-12 08:37:12.805</td>\n",
       "      <td>Huibert de Haas</td>\n",
       "      <td>2021-05-12 07:40:15.145</td>\n",
       "      <td>Berend Scheffers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bug</td>\n",
       "      <td>2021-05-12 07:51:13.208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Learn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Berend Scheffers</td>\n",
       "      <td>NaT</td>\n",
       "      <td>To Do</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LRN-1243</td>\n",
       "      <td>*Goals:-*_x000D_\\n_x000D_\\n*Non Goals:-*_x000D_\\n_x000D_\\n*Documentation:-*_x000D_\\n_x000D_\\n*Acceptance Criteria:-*</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Summary Priority  \\\n",
       "0  Datalake sending Learning Path Progress bug   Medium   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Description  \\\n",
       "0  a issue occured with sending data to datalake, it seemed that somehow a record was not found when processing the first batch of learning path progress.\\nIt can be caused as seen in the logs when duplicated learning path progress been removed (could be caused by the after commit on learning path progress microflow that cleans up duplicated learning path progress), since we now update each learning path progress object with the value 'is processed to datalake' when it is being retrieved in the batch, before it is send to datalake. It causes that the process of sending data to datalake has been stopped. and currently 420 learning path progress objects have been marked as 'processed to datalake', but have not been send to datalake since the process is stopped by the system.\\n\\n!Screenshot 2021-05-11 at 21.36.20.png|width=1401,height=674!\\n\\n\\n\\nas seen in this image, there are no learning path progress records in Datalake\\n\\n!image (4).png|width=3360,height=2100!\\n\\nSeen here the admin panel amount of learning path progress objects that been marked as 'processed to datalake'. but not been send to datalake\\n\\n!image-20210512-074254.png|width=3360,height=4039!\\n\\n\\n\\n*Acceptance Criteria* \\n\\n* Create Microflow to reset the learning path progress objects that have {{ProcessedToDatalake = true}} since all these records should all be set on _false_ again before performing the send historical data to datalake\\n* Find a solution how to handle the error.\\n\\n----\\n\\n\\n\\n{color:#00B8D9}*[ BEFORE RELEASE ]*{color}\\n\\n# Make sure datalake producer ‘enable sending data’ is *disabled*\\nAdmin pages → Dataproducer overview → open datalake config - Checked, it is disabled. \\n!image-20210511-153413.png|width=1880,height=244!\\n\\n{color:#FF991F}*[ AFTER RELEASE ]*{color} \\n\\n*Datalake Setup - All done* (/)\\n\\n# Delete the currently configuration of datalake producer, to reset it again to send all data over again\\nAdmin pages → Dataproducer overview → open datalake config → delete\\n# Create the configuration again by clicking the button 'open datalake config', *with the settings below*, and click save.\\n## *Send historical data:* true\\n## *Enable:* false\\n## *Batch Size limit:* 3000\\n# Make sure academy production datalake sending data is *disabled* (can be managed in the frontend Admin pages → Dataproducer overview → open datalake config → disable send data to datalake → save) \\n# in datalake portal production ([https://portal.datalake.mendix.com/tables|https://portal.datalake.mendix.com/tables]) all the tables in academy need to be removed and re-assigned again. this triggers that all data will be removed and can have a clean setup. \\n# Make sure academy production datalake sending data is *enabled* again   \n",
       "\n",
       "  Epic Link Fix versions  Story Points                 Updated  \\\n",
       "0  LRN-1092          NaN           NaN 2021-05-12 08:37:12.805   \n",
       "\n",
       "          Assignee                 Created           Creator  \\\n",
       "0  Huibert de Haas 2021-05-12 07:40:15.145  Berend Scheffers   \n",
       "\n",
       "   External issue ID Issue Type             Last Viewed Linked Issues  \\\n",
       "0                NaN        Bug 2021-05-12 07:51:13.208           NaN   \n",
       "\n",
       "   Parent Link Project  RCA Comments          Reporter Resolved  \\\n",
       "0          NaN   Learn           NaN  Berend Scheffers      NaT   \n",
       "\n",
       "  Status Category  Design Review Comments  Mitigation Status and Comments  \\\n",
       "0           To Do                     NaN                             NaN   \n",
       "\n",
       "        Key  \\\n",
       "0  LRN-1243   \n",
       "\n",
       "                                                                                                          Description.1  \\\n",
       "0  *Goals:-*_x000D_\\n_x000D_\\n*Non Goals:-*_x000D_\\n_x000D_\\n*Documentation:-*_x000D_\\n_x000D_\\n*Acceptance Criteria:-*   \n",
       "\n",
       "   Issue Description  Watchers  \n",
       "0                NaN         1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData_JIRA_academyMay.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-ecology",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
