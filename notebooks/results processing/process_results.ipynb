{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import pacakges\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "Parameters to configure\n",
    "'''\n",
    "#Set file path\n",
    "dataset = 'example'\n",
    "\n",
    "# top-X to compute for feature importance\n",
    "top_n = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-normalised datsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "df = pd.DataFrame(columns=['algorithm', 'Balancing', 'Accuracy (mean)', 'Accuracy (std)', 'Precision (mean)', 'Precision (std)', 'Recall (mean)','Recall (std)','F1 (mean)','F1 (std)', 'F2 (mean)','F2 (std)', 'F0.5 (mean)','F0.5 (std)', 'Average Precision (mean)', 'Average Precision (std)'])\n",
    "\n",
    "none_rf = pd.read_csv('../../results/2. Non-Normalised Results/random_forests/none_results.csv')\n",
    "over_rf = pd.read_csv('../../results/2. Non-Normalised Results/random_forests/over_results.csv')\n",
    "under_rf = pd.read_csv('../../results/2. Non-Normalised Results/random_forests/under_results.csv')\n",
    "half_rf = pd.read_csv('../../results/2. Non-Normalised Results/random_forests/5050_results.csv')\n",
    "\n",
    "\n",
    "file_list_string = ['none', 'over', 'under',' 5050']\n",
    "file_list = [none_rf, over_rf, under_rf, half_rf]\n",
    "\n",
    "count = 0\n",
    "for file in file_list:\n",
    "    temp_list_mean = file.mean(axis=0)\n",
    "    temp_list_mean = temp_list_mean[1:].reset_index(drop=True)\n",
    "    temp_list_std = file[['Accuracy', 'Precision', 'Recall', 'F1', 'F2', 'F0.5', 'Average Precision']].std()\n",
    "    total_list = []\n",
    "    for mean, std in zip(temp_list_mean, temp_list_std):\n",
    "        total_list.append(mean)\n",
    "        total_list.append(std)\n",
    "    total_list = ['random_forests'] + [file_list_string[count]] + total_list\n",
    "    df.loc[len(df)] = total_list\n",
    "    count += 1\n",
    "\n",
    "# XGBoost\n",
    "none_xgb = pd.read_csv('../../results/2. Non-Normalised Results/xg_boost/none_results.csv')\n",
    "over_xgb = pd.read_csv('../../results/2. Non-Normalised Results/xg_boost/over_results.csv')\n",
    "under_xgb = pd.read_csv('../../results/2. Non-Normalised Results/xg_boost/under_results.csv')\n",
    "half_xgb = pd.read_csv('../../results/2. Non-Normalised Results/xg_boost/5050_results.csv')\n",
    "\n",
    "file_list = [none_xgb, over_xgb, under_xgb, half_xgb]\n",
    "\n",
    "count = 0\n",
    "for file in file_list:\n",
    "    temp_list_mean = file.mean(axis=0)\n",
    "    temp_list_mean = temp_list_mean[1:].reset_index(drop=True)\n",
    "    temp_list_std = file[['Accuracy', 'Precision', 'Recall', 'F1', 'F2', 'F0.5', 'Average Precision']].std()\n",
    "    total_list = []\n",
    "    for mean, std in zip(temp_list_mean, temp_list_std):\n",
    "        total_list.append(mean)\n",
    "        total_list.append(std)\n",
    "    total_list = ['xgboost'] + [file_list_string[count]] + total_list\n",
    "    df.loc[len(df)] = total_list\n",
    "    count += 1\n",
    "\n",
    "# LightGBM\n",
    "none_lgbm = pd.read_csv('../../results/2. Non-Normalised Results/light_gbm/none_results.csv')\n",
    "over_lgbm = pd.read_csv('../../results/2. Non-Normalised Results/light_gbm/over_results.csv')\n",
    "under_lgbm = pd.read_csv('../../results/2. Non-Normalised Results/light_gbm/under_results.csv')\n",
    "half_lgbm = pd.read_csv('../../results/2. Non-Normalised Results/light_gbm/5050_results.csv')\n",
    "\n",
    "file_list = [none_lgbm, over_lgbm, under_lgbm, half_lgbm]\n",
    "\n",
    "count = 0\n",
    "for file in file_list:\n",
    "    temp_list_mean = file.mean(axis=0)\n",
    "    temp_list_mean = temp_list_mean[1:].reset_index(drop=True)\n",
    "    temp_list_std = file[['Accuracy', 'Precision', 'Recall', 'F1', 'F2', 'F0.5', 'Average Precision']].std()\n",
    "    total_list = []\n",
    "    for mean, std in zip(temp_list_mean, temp_list_std):\n",
    "        total_list.append(mean)\n",
    "        total_list.append(std)\n",
    "    total_list = ['lightgbm'] + [file_list_string[count]] + total_list\n",
    "    df.loc[len(df)] = total_list\n",
    "    count += 1\n",
    "\n",
    "df.to_excel(excel_writer = f\"../../results/Evaluation/{dataset}_F-metrics_non-normalized.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "none_rf = pd.read_csv('../../results/4. Feature Importance Results/random_forests/none_results.csv')\n",
    "over_rf = pd.read_csv('../../results/4. Feature Importance Results/random_forests/over_results.csv')\n",
    "under_rf = pd.read_csv('../../results/4. Feature Importance Results/random_forests/under_results.csv')\n",
    "half_rf = pd.read_csv('../../results/4. Feature Importance Results/random_forests/5050_results.csv')\n",
    "\n",
    "feature_names = none_rf.columns.values.tolist()\n",
    "feature_names = feature_names[1:]\n",
    "df_columns = ['algorithm'] + ['Balancing'] + feature_names\n",
    "\n",
    "df = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "file_list_string = ['none', 'over', 'under',' 5050']\n",
    "file_list = [none_rf, over_rf, under_rf, half_rf]\n",
    "\n",
    "count = 0\n",
    "for file in file_list:\n",
    "    temp_list = file.mean(axis=0)\n",
    "    temp_list = temp_list[1:].reset_index(drop=True)\n",
    "    temp_list = temp_list.tolist()\n",
    "    temp_list = ['random_forests'] + [file_list_string[count]] + temp_list\n",
    "    df.loc[len(df)] = temp_list\n",
    "    count += 1\n",
    "\n",
    "# XGBoost\n",
    "none_xgb = pd.read_csv('../../results/4. Feature Importance Results/xg_boost/none_results.csv')\n",
    "over_xgb = pd.read_csv('../../results/4. Feature Importance Results/xg_boost/over_results.csv')\n",
    "under_xgb = pd.read_csv('../../results/4. Feature Importance Results/xg_boost/under_results.csv')\n",
    "half_xgb = pd.read_csv('../../results/4. Feature Importance Results/xg_boost/5050_results.csv')\n",
    "\n",
    "file_list = [none_xgb, over_xgb, under_xgb, half_xgb]\n",
    "\n",
    "count = 0\n",
    "for file in file_list:\n",
    "    temp_list = file.mean(axis=0)\n",
    "    temp_list = temp_list[1:].reset_index(drop=True)\n",
    "    temp_list = temp_list.tolist()\n",
    "    temp_list = ['xg_boost'] + [file_list_string[count]] + temp_list\n",
    "    df.loc[len(df)] = temp_list\n",
    "    count += 1\n",
    "\n",
    "# LightGBM\n",
    "none_lgbm = pd.read_csv('../../results/4. Feature Importance Results/light_gbm/none_results.csv')\n",
    "over_lgbm = pd.read_csv('../../results/4. Feature Importance Results/light_gbm/over_results.csv')\n",
    "under_lgbm = pd.read_csv('../../results/4. Feature Importance Results/light_gbm/under_results.csv')\n",
    "half_lgbm = pd.read_csv('../../results/4. Feature Importance Results/light_gbm/5050_results.csv')\n",
    "\n",
    "file_list = [none_lgbm, over_lgbm, under_lgbm, half_lgbm]\n",
    "\n",
    "count = 0\n",
    "for file in file_list:\n",
    "    temp_list = file.mean(axis=0)\n",
    "    temp_list = temp_list[1:].reset_index(drop=True)\n",
    "    temp_list = temp_list.tolist()\n",
    "    temp_list = ['light_gbm'] + [file_list_string[count]] + temp_list\n",
    "    df.loc[len(df)] = temp_list\n",
    "    count += 1\n",
    "\n",
    "df.to_excel(excel_writer = f\"../../results/Evaluation/{dataset}_feature_importance.xlsx\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
