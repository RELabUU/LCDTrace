{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Python Libraries\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "#Import Self-written Functions\n",
    "import os\n",
    "import sys\n",
    "src_dir = os.path.join(os.getcwd(), '..', 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from d00_utils.calculateTimeDifference import calculateTimeDifference #Function to calc time difference\n",
    "from d01_data.loadCommits import loadCommits #Function to load SVN data\n",
    "from d02_intermediate.cleanCommitData import cleanCommitData #Function to clean commit data\n",
    "from d02_intermediate.cleanJiraData import cleanJiraData #Function to clean JIRA data\n",
    "\n",
    "from d03_processing.createFittedTF_IDF import createFittedTF_IDF #Function to see if a trace is valid\n",
    "from d03_processing.createCorpusFromDocumentList import createCorpusFromDocumentList #Function to create a corpus\n",
    "from d03_processing.checkValidityTrace import checkValidityTrace #Function to see if a trace is valid\n",
    "from d03_processing.calculateTimeDif import calculateTimeDif #Calculate the time difference between 2 dates in seconds\n",
    "from d03_processing.checkFullnameEqualsEmail import checkFullnameEqualsEmail #Check if fullName is equal to the email\n",
    "from d03_processing.calculateCosineSimilarity import calculateCosineSimilarity #Calculate the cos similarity\n",
    "from d03_processing.calculateDocumentStatistics import calculateUniqueWordCount\n",
    "from d03_processing.calculateDocumentStatistics import calculateTotalWordCount\n",
    "from d03_processing.calculateDocumentStatistics import calculateOverlapBetweenDocuments\n",
    "\n",
    "from d04_modelling.summariseClassDistribution import summariseClassDistribution #Visualize the class distribution\n",
    "from d04_modelling.showModelPerformance import showModelPerformance # Show several performance measures\n",
    "\n",
    "#Display full value of a column\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "#Display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-sellers",
   "metadata": {},
   "source": [
    "# 1. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set dataset\n",
    "\n",
    "datasetDirectory = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import raw JIRA dataset\n",
    "rawData_JIRA_academy = pd.read_excel('../data/01_raw/JIRA Mendix Academy export_15_05_2021.xlsx')\n",
    "\n",
    "\n",
    "#import\n",
    "rawData_SVN_academy = loadCommits('../data/01_raw/academy-svn-dump.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-utility",
   "metadata": {},
   "source": [
    "# 2. Clean Raw Data\n",
    "## 2.1 Clean Raw Data - SVN Data\n",
    "Clean the raw data of the SVN files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "#nltk for NLP \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.util import ngrams\n",
    "\n",
    "#Function to transform natural text into unigram tokens\n",
    "def preprocessNaturalLanguage(text, porterStemmer, cachedStopWords):\n",
    "    string_text = str(text)\n",
    "    #lowercase the string\n",
    "    lower_case_string = string_text.lower()\n",
    "    \n",
    "    #Remove interpunction\n",
    "    no_interpunction = lower_case_string.translate(str.maketrans('','',string.punctuation))\n",
    "    \n",
    "    #Remove numbers\n",
    "    no_numbers = ''.join([i for i in no_interpunction if not i.isdigit()])\n",
    "    \n",
    "    #tokenize string\n",
    "    tokens = word_tokenize(no_interpunction)\n",
    "    \n",
    "    #remove stopwords\n",
    "    tokens_without_sw = [word for word in tokens if not word in cachedStopWords]\n",
    "    \n",
    "    #Stem the tokens\n",
    "    stemmedToken = list(map(porterStemmer.stem, tokens_without_sw))\n",
    "\n",
    "    return(stemmedToken)\n",
    "\n",
    "#Function to transform natural text into n-gram tokens\n",
    "def preprocessNGrams(text, porterStemmer, cachedStopWords, nGramSize):\n",
    "    string_text = str(text)\n",
    "    \n",
    "    #lowercase the string\n",
    "    lower_case_string = string_text.lower()\n",
    "    \n",
    "    #Remove interpunction\n",
    "    no_interpunction = lower_case_string.translate(str.maketrans('','',string.punctuation))\n",
    "    \n",
    "    #Remove numbers\n",
    "    no_numbers = ''.join([i for i in no_interpunction if not i.isdigit()])\n",
    "    \n",
    "    #tokenize string\n",
    "    tokens = word_tokenize(no_interpunction)\n",
    "    \n",
    "    #Create the ngrams\n",
    "    ngrams = list(nltk.ngrams(tokens, nGramSize))\n",
    "    \n",
    "    #remove all the n-grams containing a stopword\n",
    "    cleanNGrams = [ngram for ngram in ngrams if not any(stop in ngram for stop in cachedStopWords)]\n",
    "    \n",
    "    #Stem the tokens\n",
    "    stemmedNGrams = []\n",
    "    for ngram in cleanNGrams:\n",
    "        stemmed = list(map(porterStemmer.stem, ngram))\n",
    "        stemmedNGrams.append(stemmed)\n",
    "    return(stemmedNGrams)\n",
    "\n",
    "#Function to transform date into a date object\n",
    "def preprocessCommitDate(date_string):\n",
    "    date_time_obj = datetime.strptime(date_string, '%Y-%m-%dT%H:%M:%S.%fZ')  \n",
    "    return(date_time_obj)\n",
    "    \n",
    "#Remove the found Issue key from the log\n",
    "def removeIssueKey(log_message):\n",
    "    issue_keys = re.findall(r\"LRN+.[0-9]+|AFM+.[0-9]+|MA+.[0-9]+|AFI+.[0-9]+|EM+.[0-9]+|OE+.[0-9]+|EM+.[0-9]+\", log_message)\n",
    "    log_message_without_key = log_message\n",
    "    for issue_key in issue_keys:\n",
    "        log_message_without_key = log_message_without_key.replace(issue_key, \"\")\n",
    "    return(log_message_without_key)\n",
    "\n",
    "def unitNamesLambdaFunc(unitName, stemmer):\n",
    "    #Lower case\n",
    "    unitNameLowered = unitName.lower()\n",
    "    \n",
    "    #Remove interpunction\n",
    "    noInterpunction = unitNameLowered.translate(str.maketrans('','',string.punctuation))\n",
    "    \n",
    "    #Remove numbers\n",
    "    noNumbers = ''.join([i for i in noInterpunction if not i.isdigit()])\n",
    "    \n",
    "    stemmendUnitName = stemmer.stem(noInterpunction)\n",
    "    \n",
    "    \n",
    "    return(stemmendUnitName)\n",
    "    \n",
    "\n",
    "def preprocessUnitNames(unitName, porterStemmer, cachedStopWords):\n",
    "    if (isinstance(unitName, str)):\n",
    "        #Split camelCasing\n",
    "        unitNameSplitList = re.sub('([A-Z][a-z]+)', r' \\1', re.sub('([A-Z]+)', r' \\1', unitName)).split()\n",
    "        \n",
    "        porterStemmer = PorterStemmer() #create an object of class PorterStemmer\n",
    "        \n",
    "        #Preprocess each split found.\n",
    "        unitNameLowered = list(map(lambda unitName: unitNamesLambdaFunc(unitName, porterStemmer), \n",
    "                                   unitNameSplitList))\n",
    "        \n",
    "        #Check for stopwords\n",
    "        tokensWithoutSW = [word for word in unitNameLowered if not word in cachedStopWords]\n",
    "\n",
    "        return(tokensWithoutSW)\n",
    "\n",
    "def preprocessNGramsUnitNames(unitName, porterStemmer, cachedStopWords, nGramSize):\n",
    "    if (isinstance(unitName, str)):\n",
    "        #Split camelCasing\n",
    "        unitNameSplitList = re.sub('([A-Z][a-z]+)', r' \\1', re.sub('([A-Z]+)', r' \\1', unitName)).split()\n",
    "        \n",
    "        cleanedUnitNames = []\n",
    "        for unitNameSplit in unitNameSplitList:\n",
    "            #Lower case unit names\n",
    "            lowerCased = unitNameSplit.lower()\n",
    "\n",
    "            #Remove interpunction\n",
    "            removedInterpunction = lowerCased.translate(str.maketrans('','',string.punctuation))\n",
    "            cleanedUnitNames.append(removedInterpunction)\n",
    "            \n",
    "        #Transform to string (needed for tokenizer\n",
    "        unitNameString = ' '.join(cleanedUnitNames)\n",
    "\n",
    "        #Tokenzize words\n",
    "        tokenized = word_tokenize(unitNameString)\n",
    "        \n",
    "        #Create the ngrams\n",
    "        ngrams = list(nltk.ngrams(tokenized, nGramSize))\n",
    "        \n",
    "        porterStemmer = PorterStemmer() #create an object of class PorterStemmer\n",
    "        \n",
    "        #remove all the n-grams containing a stopword\n",
    "        cleanNGrams = [ngram for ngram in ngrams if not any(stop in ngram for stop in cachedStopWords)]\n",
    "    \n",
    "        #Stem the tokens\n",
    "        stemmedNGrams = []\n",
    "        for ngram in cleanNGrams:\n",
    "            stemmed = list(map(porterStemmer.stem, ngram))\n",
    "            stemmedNGrams.append(stemmed)\n",
    "            \n",
    "        return(stemmedNGrams)\n",
    "\n",
    "#Method to clean all columns of the provided data\n",
    "def cleanCommitData(rawCommitData): \n",
    "    #create an object of class PorterStemmer\n",
    "    porterStemmer = PorterStemmer()\n",
    "    \n",
    "    #Find all stopwords\n",
    "    cachedStopWords = stopwords.words(\"english\")\n",
    "    \n",
    "    #Remove all revisions without an issue key in the log message\n",
    "    commit_df = rawCommitData[rawCommitData[\"related_issue_key\"].notna()]\n",
    "\n",
    "    #Execute cleaning methods on dataset\n",
    "    cleaned_commit_logs = commit_df['log'].apply(lambda x: removeIssueKey(x))\n",
    "    processed_commit_logs = cleaned_commit_logs.apply(lambda x: preprocessNaturalLanguage(x, porterStemmer, cachedStopWords))\n",
    "    processed_commit_logs_2grams = cleaned_commit_logs.apply(lambda x: preprocessNGrams(x, porterStemmer, cachedStopWords, 2))\n",
    "    processed_commit_logs_3grams = cleaned_commit_logs.apply(lambda x: preprocessNGrams(x, porterStemmer, cachedStopWords, 3))\n",
    "    processed_date_times = commit_df['date'].apply(lambda x: preprocessCommitDate(x))\n",
    "    processed_unit_names = commit_df['impacted_unit_names'].apply(lambda x: preprocessUnitNames(x, porterStemmer, cachedStopWords))\n",
    "    processed_unit_names_2grams = commit_df['impacted_unit_names'].apply(lambda x: preprocessNGramsUnitNames(x, porterStemmer, cachedStopWords, 2))\n",
    "    processed_unit_names_3grams = commit_df['impacted_unit_names'].apply(lambda x: preprocessNGramsUnitNames(x, porterStemmer, cachedStopWords, 3))\n",
    "    \n",
    "\n",
    "    #Put all data together into a new dataframe\n",
    "    commit_data = {'Revision': commit_df[\"revision\"],\n",
    "               'Email' : commit_df[\"email\"],\n",
    "               'Commit_date': processed_date_times,\n",
    "               \"Issue_key_commit\": commit_df[\"related_issue_key\"],\n",
    "               'Logs': processed_commit_logs, \n",
    "               'Logs_2grams': processed_commit_logs_2grams, \n",
    "               'Logs_3grams': processed_commit_logs_3grams, \n",
    "               'Unit_names': processed_unit_names,\n",
    "               'Unit_names_2grams': processed_unit_names_2grams,\n",
    "               'Unit_names_3grams': processed_unit_names_3grams,\n",
    "               'Commit_natural_text': processed_commit_logs + processed_unit_names,\n",
    "               'Commit_natural_text_2grams': processed_commit_logs_2grams + processed_unit_names_2grams,\n",
    "               'Commit_natural_text_3grams': processed_commit_logs_3grams + processed_unit_names_3grams\n",
    "               }\n",
    "               \n",
    "    commit_processed_df = pd.DataFrame(data=commit_data)\n",
    "\n",
    "    return(commit_processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-knowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "intermediateData_SVN_academy = cleanCommitData(rawData_SVN_academy)\n",
    "\n",
    "#Create a temp XLSX file for all intermediate datasets\n",
    "intermediateData_SVN_academy.to_excel(excel_writer = \"../data/02_intermediate/intermediateData_SVN_academy.xlsx\", index = False)\n",
    "\n",
    "#Create a pickle file for all intermediate datasets\n",
    "intermediateData_SVN_academy.to_pickle(path= \"../data/02_intermediate/intermediateData_SVN_academy.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished cleaning after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import string\n",
    "#nltk for NLP \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag  import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "#Function to clean the comments\n",
    "def clean_comments(comment):\n",
    "    try:\n",
    "        commentDates = re.findall(r\"[0-9]{2} [A-Z][a-z]{2} [0-9]{4} [0-9]{2}:[0-9]{2};[a-zA-Z0-9_]{24};\", comment)\n",
    "        accountIds = re.findall(r\"\\[~accountid:[a-zA-Z0-9]{24}\\]\", comment)\n",
    "               \n",
    "        \n",
    "        cleanedComment = comment.replace(\"nan\",'')\n",
    "        for commentDate in commentDates:\n",
    "            cleanedComment = cleanedComment.replace(commentDate,'')\n",
    "        \n",
    "        for accountId in accountIds: \n",
    "            cleanedComment = cleanedComment.replace(accountId,'')\n",
    "        \n",
    "        return(cleanedComment)\n",
    "    except:\n",
    "        return(\"\")\n",
    "\n",
    "def preprocess(text, porterStemmer, cachedStopwords):\n",
    "    string_text = str(text)\n",
    "    #lowercase the string\n",
    "    lower_case_string = string_text.lower()\n",
    "    \n",
    "    #Remove interpunction\n",
    "    no_interpunction = lower_case_string.translate(str.maketrans('','',string.punctuation))\n",
    "    \n",
    "    #Remove numbers\n",
    "    no_numbers = ''.join([i for i in no_interpunction if not i.isdigit()])\n",
    "    \n",
    "    #tokenize string\n",
    "    tokens = word_tokenize(no_numbers)\n",
    "    \n",
    "    #remove stopwords\n",
    "    tokens_without_sw = [word for word in tokens if not word in cachedStopwords]\n",
    "    \n",
    "    #Stem the tokens\n",
    "    stemmedToken = list(map(porterStemmer.stem, tokens_without_sw))\n",
    "\n",
    "    return(stemmedToken)\n",
    "\n",
    "def preprocessNGrams(text, porterStemmer, cachedStopWords, nGramSize):\n",
    "    string_text = str(text)\n",
    "    \n",
    "    #lowercase the string\n",
    "    lower_case_string = string_text.lower()\n",
    "    \n",
    "    #Remove interpunction\n",
    "    no_interpunction = lower_case_string.translate(str.maketrans('','',string.punctuation))\n",
    "    \n",
    "    #Remove numbers\n",
    "    no_numbers = ''.join([i for i in no_interpunction if not i.isdigit()])\n",
    "    \n",
    "    #tokenize string\n",
    "    tokens = word_tokenize(no_numbers)\n",
    "    \n",
    "    #Create the ngrams\n",
    "    ngrams = list(nltk.ngrams(tokens, nGramSize))\n",
    "    \n",
    "    #remove all the n-grams containing a stopword\n",
    "    cleanNGrams = [ngram for ngram in ngrams if not any(stop in ngram for stop in cachedStopWords)]\n",
    "    \n",
    "    #Stem the tokens\n",
    "    stemmedNGrams = []\n",
    "    for ngram in cleanNGrams:\n",
    "        stemmed = list(map(porterStemmer.stem, ngram))\n",
    "        stemmedNGrams.append(stemmed)\n",
    "    return(stemmedNGrams)\n",
    "\n",
    "#Function to transform date into a date object\n",
    "def preprocess_jira_date(date_string):\n",
    "    if(isinstance(date_string, str)):\n",
    "        try:\n",
    "            date_time_obj = datetime.strptime(date_string, '%d %b %Y %H:%M')\n",
    "        except:\n",
    "            date_time_obj = datetime.strptime(date_string, '%Y-%m-%d %H:%M:%S:%f')\n",
    "        return(date_time_obj)\n",
    "    elif(isinstance(date_string, datetime)): \n",
    "        return(date_string)\n",
    "    else:\n",
    "        return(np.nan)\n",
    "    \n",
    "    \n",
    "def findVerbs(tokenList):\n",
    "    posTags = pos_tag(tokenList)\n",
    "    verbAbrList = ['VBP', 'VBG', 'VBN', 'VBP', 'VBZ', 'RB', 'RBR', 'RBS']\n",
    "    verbList = []\n",
    "    for posTag in posTags:\n",
    "        if posTag[1] in verbAbrList:\n",
    "            verbList.append(posTag[0])\n",
    "    return(verbList)\n",
    "\n",
    "#Preprocess all the features and transform to the format needed for further processing.\n",
    "def preprocessJiraData(cleanDataFrame, preprocessComments, porterStemmer, cachedStopWords, startTime):\n",
    "    if (preprocessComments == True):\n",
    "        nOfSteps = '4'\n",
    "    else:\n",
    "        nOfSteps = '3'\n",
    "\n",
    "    #preprocess Summaries\n",
    "    jira_summaries = cleanDataFrame['Summary'].apply(lambda x: preprocess(x, porterStemmer, cachedStopWords))\n",
    "    jira_summaries_2grams = cleanDataFrame['Summary'].apply(lambda x: preprocessNGrams(x, porterStemmer, cachedStopWords, 2))\n",
    "    jira_summaries_3grams = cleanDataFrame['Summary'].apply(lambda x: preprocessNGrams(x, porterStemmer, cachedStopWords, 3))\n",
    "    \n",
    "    endTimeCleaningSummaries = time.time() - startTime\n",
    "    print(\"1/\" + nOfSteps + \") Finished Cleaning Summaries after \" + str(endTimeCleaningSummaries) + \" sec\")\n",
    "\n",
    "    #preprocess Descriptions\n",
    "    jira_descriptions = cleanDataFrame['Description'].apply(lambda x: preprocess(x, porterStemmer, cachedStopWords))\n",
    "    jira_descriptions_2grams = cleanDataFrame['Description'].apply(lambda x: preprocessNGrams(x, porterStemmer, cachedStopWords, 2))\n",
    "    jira_descriptions_3grams = cleanDataFrame['Description'].apply(lambda x: preprocessNGrams(x, porterStemmer, cachedStopWords, 2))\n",
    "    \n",
    "    endTimeCleaningDescriptions = time.time() - startTime\n",
    "    print(\"2/\" + nOfSteps + \") Finished Cleaning Description after \" + str(endTimeCleaningDescriptions) + \" sec\")\n",
    "\n",
    "    #preprocess Dates\n",
    "    jira_creation = cleanDataFrame['Created'].apply(lambda x: preprocess_jira_date(x))\n",
    "    jira_updated = cleanDataFrame['Updated'].apply(lambda x: preprocess_jira_date(x))\n",
    "    jira_resolved = cleanDataFrame['Resolved'].apply(lambda x: preprocess_jira_date(x))\n",
    "    endTimeCleaningDates = time.time() - startTime\n",
    "    print(\"3/\" + nOfSteps + \") Finished Cleaning Dates after \" + str(endTimeCleaningDates) + \" sec\")\n",
    "\n",
    "    #Comments take too long for a test run.\n",
    "    if (preprocessComments == True):\n",
    "        jira_comments = cleanDataFrame['Comments'].apply(lambda x: preprocess(x, porterStemmer, cachedStopWords))\n",
    "        jira_comments_2grams = cleanDataFrame['Comments'].apply(lambda x: preprocessNGrams(x, porterStemmer, cachedStopWords, 2))\n",
    "        jira_comments_3grams = cleanDataFrame['Comments'].apply(lambda x: preprocessNGrams(x, porterStemmer, cachedStopWords, 2))\n",
    "        endTimeCleaningComments = time.time() - startTime\n",
    "        print(\"4/\" + nOfSteps + \") Finished Cleaning Comments after \" + str(endTimeCleaningComments) + \" sec\")\n",
    "\n",
    "         #create JIRA corpus by merging Summary and Description\n",
    "        jira_data = {'Issue_key_jira': cleanDataFrame['Issue key'], \n",
    "             'Assignee': cleanDataFrame['Assignee'],\n",
    "             'Jira_created_date': jira_creation, \n",
    "             'Jira_updated_date': jira_updated, \n",
    "             'Jira_resolved_date': jira_resolved, \n",
    "             'Summary': jira_summaries, \n",
    "             'Summary_2grams': jira_summaries_2grams,\n",
    "             'Summary_3grams': jira_summaries_3grams, \n",
    "             'Description': jira_descriptions,\n",
    "             'Description_2grams': jira_descriptions_2grams,\n",
    "             'Description_3grams': jira_descriptions_3grams,\n",
    "             'Comments': jira_comments,\n",
    "             'Comments_2grams': jira_comments_2grams,\n",
    "             'Comments_3grams': jira_comments_3grams,\n",
    "             'Jira_natural_text': jira_summaries +  jira_descriptions + jira_comments,\n",
    "             'Jira_natural_text_2grams': jira_summaries_2grams +  jira_descriptions_2grams + jira_comments_2grams,\n",
    "             'Jira_natural_text_3grams': jira_summaries_3grams +  jira_descriptions_3grams + jira_comments_3grams}\n",
    "    else:\n",
    "         #create JIRA corpus by merging Summary and Description\n",
    "        jira_data = {'Issue_key_jira': cleanDataFrame['Issue key'], \n",
    "             'Assignee': cleanDataFrame['Assignee'],\n",
    "             'Jira_created_date': jira_creation, \n",
    "             'Jira_updated_date': jira_updated, \n",
    "             'Jira_resolved_date': jira_resolved, \n",
    "             'Summary': jira_summaries,\n",
    "             'Summary_2grams': jira_summaries_2grams,\n",
    "             'Summary_3grams': jira_summaries_3grams,\n",
    "             'Description': jira_descriptions,\n",
    "             'Description_2grams': jira_descriptions_2grams,\n",
    "             'Description_3grams': jira_descriptions_3grams,\n",
    "             'Jira_natural_text': jira_summaries +  jira_descriptions,\n",
    "             'Jira_natural_text_2grams': jira_summaries_2grams +  jira_descriptions_2grams,\n",
    "             'Jira_natural_text_3grams': jira_summaries_3grams +  jira_descriptions_3grams}\n",
    "\n",
    "    jira_processed_df = pd.DataFrame(data=jira_data)\n",
    "    \n",
    "    #Find verbs\n",
    "    jira_processed_df['verbs'] = jira_processed_df['Jira_natural_text'].apply(lambda x: findVerbs(x))\n",
    "    \n",
    "    return(jira_processed_df)\n",
    "\n",
    "#Input dataframe and num of_comments, and bool to determine if comments need to be cleaned\n",
    "def cleanJiraData(dataFrame, cleanComments, commentAmount):\n",
    "    startTime = time.time()\n",
    "\n",
    "    #create an object of class PorterStemmer\n",
    "    porterStemmer = PorterStemmer()\n",
    "    \n",
    "    #Find all stopwords\n",
    "    cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "    if (cleanComments == True):\n",
    "        #Subset only all comments \n",
    "        loc_first_comment = dataFrame.columns.get_loc('Comment') # Variable storing the col location of the 1st comment\n",
    "    \n",
    "        dataFrame[\"Comments\"] = dataFrame.iloc[:,loc_first_comment:loc_first_comment+commentAmount].apply(\n",
    "            lambda x: \" \".join(x.astype(str)), axis=1)\n",
    "    \n",
    "        #First remove the date and comment string from the comments\n",
    "        dataFrame[\"Comments\"] = dataFrame[\"Comments\"].apply(lambda x: clean_comments(x))\n",
    "\n",
    "        #Subset JIRA ID, Summary, Description, comments\n",
    "        jira_issues_subset = dataFrame[[\"Issue key\", \"Assignee\", \"Summary\", \"Description\", \"Comments\", \"Created\", \"Resolved\", \"Updated\"]]\n",
    "        cleanedAndProcessedJiraData = preprocessJiraData(jira_issues_subset, preprocessComments = True, porterStemmer = porterStemmer, cachedStopWords = cachedStopWords, startTime = startTime)\n",
    "        return(cleanedAndProcessedJiraData)\n",
    "    else: \n",
    "        jira_issues_subset = dataFrame[[\"Issue key\", \"Assignee\", \"Summary\", \"Description\", \"Created\", \"Resolved\", \"Updated\"]]\n",
    "        cleanedAndProcessedJiraData = preprocessJiraData(jira_issues_subset, preprocessComments = False, porterStemmer = porterStemmer, cachedStopWords = cachedStopWords, startTime = startTime)\n",
    "        return(cleanedAndProcessedJiraData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-zambia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename key to Issue key\n",
    "rawData_JIRA_academy = rawData_JIRA_academy.rename({'Key': 'Issue key'}, axis=1)\n",
    "\n",
    "#Clean Data sets\n",
    "intermediateData_JIRA_academy = cleanJiraData(dataFrame = rawData_JIRA_academy, cleanComments = False, commentAmount = 39)\n",
    "\n",
    "#Create a temp XLSX file for all intermediate datasets\n",
    "intermediateData_JIRA_academy.to_excel(excel_writer = \"../data/02_intermediate/intermediateData_JIRA_academy.xlsx\", index = False)\n",
    "\n",
    "#Create a pickle file for all intermediate datasets\n",
    "intermediateData_JIRA_academy.to_pickle(path= \"../data/02_intermediate/intermediateData_JIRA_academy.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-bankruptcy",
   "metadata": {},
   "source": [
    "## 2.4 Clean Raw Data - Create JIRA Corpora\n",
    "Create the corpora for JIRA UNIGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCorpusFromDocumentList(token_column):\n",
    "    token_list = token_column.tolist()\n",
    "    corpus_list = []\n",
    "    \n",
    "    for document in token_list:\n",
    "        #Only join to the string when a list. When it is not a list, then it is np.NaN, thus no changes\n",
    "        if(isinstance(document, list)):\n",
    "            #Transform list to a string for SKLEARN to accept the input.\n",
    "            token_string = ' '.join(document)\n",
    "        \n",
    "            #Add string to the corpus list\n",
    "            corpus_list.append(token_string)\n",
    "    return(corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-corrections",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create JIRA corpus for academy dataset\n",
    "intermediateData_JIRA_academyCorpusSummary = createCorpusFromDocumentList(intermediateData_JIRA_academy.Summary)\n",
    "intermediateData_JIRA_academyCorpusDescription = createCorpusFromDocumentList(intermediateData_JIRA_academy.Description)\n",
    "\n",
    "#Merge all JIRA Corpora into 1 corpus\n",
    "intermediateData_JIRA_academyCorpus = [i+\" \"+j for i,j in zip(intermediateData_JIRA_academyCorpusSummary,\n",
    "                                                                             intermediateData_JIRA_academyCorpusDescription\n",
    "                                                                            )]\n",
    "\n",
    "#Save intermediate pickles\n",
    "with open('../data/02_intermediate/intermediateData_JIRA_academyCorpus.pkl', 'wb') as f:\n",
    "    pickle.dump(intermediateData_JIRA_academyCorpus, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-tanzania",
   "metadata": {},
   "source": [
    "Bigram corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCorpusNGrams(tokenColumn):\n",
    "    tokenList = tokenColumn.tolist()\n",
    "    corpusList = []\n",
    "    \n",
    "    #Transform to strings\n",
    "    for document in tokenList:\n",
    "        if(isinstance(document, list)):\n",
    "            for ngram in document:\n",
    "                ngramString = ' '.join(ngram)\n",
    "                corpusList.append(ngramString)         \n",
    "    return(corpusList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create JIRA corpus for academy dataset\n",
    "intermediateData_JIRA_academyCorpusSummary_2grams = createCorpusNGrams(intermediateData_JIRA_academy.Summary_2grams)\n",
    "intermediateData_JIRA_academyCorpusDescription_2grams = createCorpusNGrams(intermediateData_JIRA_academy.Description_2grams)\n",
    "\n",
    "#Merge all JIRA Corpora into 1 corpus\n",
    "intermediateData_JIRA_academyCorpus_2gram = [i+\" \"+j for i,j in zip(intermediateData_JIRA_academyCorpusSummary_2grams,\n",
    "                                                                             intermediateData_JIRA_academyCorpusDescription_2grams\n",
    "                                                                             )]\n",
    "\n",
    "\n",
    "#Save intermediate pickles\n",
    "with open('../data/02_intermediate/intermediateData_JIRA_academyCorpus_2gram.pkl', 'wb') as f:\n",
    "    pickle.dump(intermediateData_JIRA_academyCorpus_2gram, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-syntax",
   "metadata": {},
   "source": [
    "## 2.4 Clean Raw Data - Create SVN Corpora\n",
    "Create the corpora for SVN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediateData_SVN_academy = pd.read_pickle(\"../data/02_intermediate/intermediateData_SVN_academy.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create corpus for log messages\n",
    "intermediateData_SVNLogs_academyCorpus = createCorpusFromDocumentList(intermediateData_SVN_academy.Logs)\n",
    "\n",
    "#Create corpus for unit names\n",
    "intermediateData_SVNUnitNames_academyCorpus = createCorpusFromDocumentList(intermediateData_SVN_academy.Unit_names)\n",
    "\n",
    "#Create corpus for entire commit (log message + model)\n",
    "intermediateData_SVN_academyCorpus = createCorpusFromDocumentList(intermediateData_SVN_academy.Logs + intermediateData_SVN_academy.Unit_names)\n",
    "intermediateData_SVN_academyCorpusAll = createCorpusFromDocumentList(intermediateData_SVN_academy.Logs + intermediateData_SVN_academy.Unit_names)\n",
    "#Save intermediate pickles\n",
    "with open('../data/02_intermediate/intermediateData_SVNLogs_academyCorpus.pkl', 'wb') as f:\n",
    "    pickle.dump(intermediateData_SVNLogs_academyCorpus, f)\n",
    "\n",
    "with open('../data/02_intermediate/intermediateData_SVNUnitNames_academyCorpus.pkl', 'wb') as f:\n",
    "    pickle.dump(intermediateData_SVNUnitNames_academyCorpus, f)\n",
    "\n",
    "with open('../data/02_intermediate/intermediateData_SVN_academyCorpus.pkl', 'wb') as f:\n",
    "    pickle.dump(intermediateData_SVN_academyCorpus, f)\n",
    "    \n",
    "with open('../data/02_intermediate/intermediateData_SVN_academyCorpusAll.pkl', 'wb') as f:\n",
    "    pickle.dump(intermediateData_SVN_academyCorpusAll, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-tactics",
   "metadata": {},
   "source": [
    "bigram corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediateData_SVNLogs_academyCorpus_2gram = createCorpusNGrams(intermediateData_SVN_academy.Logs_2grams)\n",
    "intermediateData_SVNUnitNames_academyCorpus_2gram = createCorpusNGrams(intermediateData_SVN_academy.Unit_names_2grams)\n",
    "with open('../data/02_intermediate/intermediateData_SVNLogs_academyCorpus_2gram.pkl', 'wb') as f:\n",
    "    pickle.dump(intermediateData_SVNLogs_academyCorpus_2gram, f)\n",
    "    \n",
    "    \n",
    "with open('../data/02_intermediate/intermediateData_SVNUnitNames_academyCorpus_2gram.pkl', 'wb') as f:\n",
    "    pickle.dump(intermediateData_SVNUnitNames_academyCorpus_2gram, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-collaboration",
   "metadata": {},
   "source": [
    "# 3. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this code block when you've restarted the kernel, and want to use previously gained results.\n",
    "intermediateData_JIRA_academy = pd.read_pickle(\"../data/02_intermediate/intermediateData_JIRA_academy.pkl\")\n",
    "\n",
    "intermediateData_SVN_academy = pd.read_pickle(\"../data/02_intermediate/intermediateData_SVN_academy.pkl\")\n",
    "\n",
    "intermediateData_JIRA_academyCorpus = pd.read_pickle(r'../data/02_intermediate/intermediateData_JIRA_academyCorpus.pkl')\n",
    "intermediateData_JIRA_academyCorpus = pd.read_pickle(r'../data/02_intermediate/intermediateData_JIRA_academyCorpus.pkl')\n",
    "#intermediateData_SVN_academyCorpusAll = pd.read_pickle(r'../data/02_intermediate/intermediateData_SVN_academyCorpusAll.pkl')\n",
    "#intermediateData_SVN_academyCorpusModel = pd.read_pickle(r'../data/02_intermediate/intermediateData_SVN_academyCorpusModel.pkl')\n",
    "intermediateData_SVN_academyCorpus = pd.read_pickle(r'../data/02_intermediate/intermediateData_SVN_academyCorpus.pkl')\n",
    "\n",
    "############# Bigrams\n",
    "\n",
    "\n",
    "############# Trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-mouse",
   "metadata": {},
   "source": [
    "## 3.0 Preprocess Data - Create cartesian product JIRA x Commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create cartesian products JIRA x Commits\n",
    "processedData_academyCartesian = intermediateData_JIRA_academy.merge(intermediateData_SVN_academy, how='cross')\n",
    "\n",
    "processedData_academyCartesian = processedData_academyCartesian.drop(processedData_academyCartesian[processedData_academyCartesian.Jira_created_date > processedData_academyCartesian.Commit_date].index)\n",
    "\n",
    "#Create a pickle file for all intermediate datasets\n",
    "processedData_academyCartesian.to_pickle(path= \"../data/03_processed/processedData_academyCartesian.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-texas",
   "metadata": {},
   "source": [
    "## 3.1 Preprocess Data - Create Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new dataFrames for the time features\n",
    "processedData_academyLabels = pd.DataFrame() \n",
    "\n",
    "\n",
    "#Create a column, which indicates which traces are valid.\n",
    "processedData_academyLabels[\"is_valid\"] = processedData_academyCartesian.apply(lambda x: checkValidityTrace(x.Issue_key_jira, x.Issue_key_commit), axis=1)\n",
    "print(\"Finished creating labels for academy\")\n",
    "\n",
    "#Save intermediate results\n",
    "processedData_academyLabels.to_pickle(path= \"../data/03_processed/processedData_academyLabels.pkl\")\n",
    "\n",
    "processedData_academyLabels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-november",
   "metadata": {},
   "outputs": [],
   "source": [
    "#processedData_academyLabels[processedData_academyLabels.is_valid == True].count()\n",
    "processedData_academyLabels[processedData_academyLabels.is_valid == True].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-helicopter",
   "metadata": {},
   "source": [
    "## 3.2 Preprocess Data - Create Time-Related Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new dataFrames for the time features\n",
    "processedData_academyFeaturesTime = pd.DataFrame() \n",
    "\n",
    "\n",
    "#Calculate the time features for data Processing Dataset\n",
    "processedData_academyFeaturesTime['Creation_commit_date_dif'] = processedData_academyCartesian.apply(lambda x: calculateTimeDif(x.Jira_created_date, x.Commit_date), axis=1)\n",
    "processedData_academyFeaturesTime['Updated_commit_date_dif'] = processedData_academyCartesian.apply(lambda x: calculateTimeDif(x.Jira_updated_date, x.Commit_date), axis=1)\n",
    "processedData_academyFeaturesTime['Resolved_commit_date_dif'] = processedData_academyCartesian.apply(lambda x: calculateTimeDif(x.Jira_resolved_date, x.Commit_date), axis=1)\n",
    "print(\"Finished data Processing\")\n",
    "\n",
    "#Create a pickle file for all intermediate datasets\n",
    "processedData_academyFeaturesTime.to_pickle(path= \"../data/03_processed/processedData_academyFeaturesTime.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-exchange",
   "metadata": {},
   "source": [
    "## 3.3 Preprocess Data - Create Stakeholder-Related Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new dataFrames for the Stakeholder features\n",
    "processedData_academyFeaturesStakeholder = pd.DataFrame() \n",
    "\n",
    "processedData_academyFeaturesStakeholder['Assignee_is_commiter'] = processedData_academyCartesian.apply(lambda x: checkFullnameEqualsEmail(x.Assignee, x.Email), axis=1)\n",
    "print(\"Finished academy\")\n",
    "\n",
    "#Create a pickle file for all intermediate datasets\n",
    "processedData_academyFeaturesStakeholder.to_pickle(path= \"../data/03_processed/processedData_academyFeaturesStakeholder.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-marijuana",
   "metadata": {},
   "source": [
    "## 3.4 Preprocess Data - Create Cosine Similarity Features\n",
    "### 3.4.1 academy - Cosine Similarity UniGrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-imagination",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "import pandas as pd\n",
    "\n",
    "def calc_vector_representation(document, cv, fittedTF_IDF):        \n",
    "    #Transform document type to a string\n",
    "    documentString = document\n",
    "    \n",
    "    #Calculate the Term Frequency of the document\n",
    "    inputDocs = [documentString] \n",
    "\n",
    "    # count matrix \n",
    "    count_vector = cv.transform(inputDocs) \n",
    " \n",
    "    #tf-idf scores \n",
    "    tf_idf_vector = fittedTF_IDF.transform(count_vector)\n",
    "\n",
    "    feature_names = cv.get_feature_names() \n",
    " \n",
    "    #get tfidf vector for first document \n",
    "    document_vector=tf_idf_vector[0] \n",
    " \n",
    "    #print the scores \n",
    "    \n",
    "    # place tf-idf values in a pandas data frame \n",
    "    df = pd.DataFrame(document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"]) \n",
    "    df.sort_values(by=[\"tfidf\"],ascending=False)\n",
    "\n",
    "    return(document_vector.T.todense())\n",
    "\n",
    "def calculateCosineSimilarity(document1, document2, cv, fittedTF_IDF):\n",
    "\n",
    "    #If both doc1 and doc2 are lists\n",
    "    if (isinstance(document1, list) & isinstance(document2, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ' '.join(document1)\n",
    "        document2String = ' '.join(document2)\n",
    "\n",
    "    #Only document1 is a list\n",
    "    elif(isinstance(document1, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ' '.join(document1)\n",
    "        document2String = ''\n",
    "\n",
    "    #Only document2 is a list\n",
    "    elif(isinstance(document2, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ''\n",
    "        document2String = ' '.join(document2)\n",
    "        \n",
    "    else:\n",
    "        document1String = ''\n",
    "        document2String = ''\n",
    "\n",
    "    vector1 = calc_vector_representation(document1String, cv, fittedTF_IDF)\n",
    "    vector2 = calc_vector_representation(document2String, cv, fittedTF_IDF)\n",
    "    \n",
    "    #The cosine similarity. Produces NaN if no terms are found in the corpus.\n",
    "    result = 1 - spatial.distance.cosine(vector1, vector2)\n",
    "    \n",
    "    return(result)\n",
    "\n",
    "def calculateCosineSimilarityNGrams(document1, document2, cv, fittedTF_IDF):\n",
    "\n",
    "    #If both doc1 and doc2 are lists\n",
    "    if (isinstance(document1, list) & isinstance(document2, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ' '.join(document1)\n",
    "        document2String = ' '.join(document2)\n",
    "\n",
    "    #Only document1 is a list\n",
    "    elif(isinstance(document1, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ' '.join(document1)\n",
    "        document2String = ''\n",
    "\n",
    "    #Only document2 is a list\n",
    "    elif(isinstance(document2, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ''\n",
    "        document2String = ' '.join(document2)\n",
    "        \n",
    "    else:\n",
    "        document1String = ''\n",
    "        document2String = ''\n",
    "\n",
    "    vector1 = calc_vector_representation(document1String, cv, fittedTF_IDF)\n",
    "    vector2 = calc_vector_representation(document2String, cv, fittedTF_IDF)\n",
    "    \n",
    "    #The cosine similarity. Produces NaN if no terms are found in the corpus.\n",
    "    result = 1 - spatial.distance.cosine(vector1, vector2)\n",
    "    \n",
    "    return(result)\n",
    "\n",
    "\n",
    "def calculateCosineSimilarityWithPOSPruning(document1, document2, cv, fittedTF_IDF, verbList):\n",
    "\n",
    "    #If both doc1 and doc2 are lists\n",
    "    if (isinstance(document1, list) & isinstance(document2, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ' '.join(document1)\n",
    "        document2String = ' '.join(document2)\n",
    "\n",
    "    #Only document1 is a list\n",
    "    elif(isinstance(document1, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ' '.join(document1)\n",
    "        document2String = ''\n",
    "\n",
    "    #Only document2 is a list\n",
    "    elif(isinstance(document2, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ''\n",
    "        document2String = ' '.join(document2)\n",
    "        \n",
    "    else:\n",
    "        document1String = ''\n",
    "        document2String = ''\n",
    "\n",
    "    vector1 = calc_vector_representation(document1String, cv, fittedTF_IDF)\n",
    "    vector2 = calc_vector_representation(document2String, cv, fittedTF_IDF)\n",
    "    \n",
    "    #The cosine similarity. Produces NaN if no terms are found in the corpus.\n",
    "    result = 1 - spatial.distance.cosine(vector1, vector2)\n",
    "    \n",
    "    verbCounter = 0\n",
    "    if(isinstance(document2, list)):\n",
    "        for token in document2:\n",
    "            if token in verbList:\n",
    "                verbCounter = verbCounter + 1\n",
    "    \n",
    "    if verbCounter > 0:\n",
    "        result = result * (1 + (0.1 * verbCounter))\n",
    "    else:\n",
    "        result = 0\n",
    "    \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the count vectorizer and tfidf for the corpus\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "######################################################\n",
    "#                       academy              #\n",
    "######################################################\n",
    "\n",
    "################# Unigrams ###############\n",
    "#instantiate CountVectorizer() for SVN\n",
    "processedData_SVN_academyCountVectorizer = CountVectorizer()\n",
    "processedData_SVN_academyCountTF_IDF = createFittedTF_IDF(processedData_SVN_academyCountVectorizer, intermediateData_SVN_academyCorpus)\n",
    "\n",
    "processedData_SVNLogs_academyCountVectorizer = CountVectorizer()\n",
    "processedData_SVNLogs_academyCountTF_IDF = createFittedTF_IDF(processedData_SVNLogs_academyCountVectorizer, intermediateData_SVNLogs_academyCorpus)\n",
    "\n",
    "processedData_SVNUnitNames_academyCountVectorizer = CountVectorizer()\n",
    "processedData_SVNUnitNames_academyCountTF_IDF = createFittedTF_IDF(processedData_SVNUnitNames_academyCountVectorizer, intermediateData_SVNUnitNames_academyCorpus)\n",
    "\n",
    "#instantiate CountVectorizer() for JIRA - unigram\n",
    "processedData_JIRA_academyCountVectorizer = CountVectorizer()\n",
    "processedData_JIRA_academyCountTF_IDF = createFittedTF_IDF(processedData_JIRA_academyCountVectorizer, intermediateData_JIRA_academyCorpus)\n",
    "\n",
    "processedData_JIRASummaries_academyCountVectorizer = CountVectorizer()\n",
    "processedData_JIRASummaries_academyCountTF_IDF = createFittedTF_IDF(processedData_JIRASummaries_academyCountVectorizer, intermediateData_JIRA_academyCorpusSummary)\n",
    "\n",
    "processedData_JIRADescriptions_academyCountVectorizer = CountVectorizer()\n",
    "processedData_JIRADescriptions_academyCountTF_IDF = createFittedTF_IDF(processedData_JIRADescriptions_academyCountVectorizer, intermediateData_JIRA_academyCorpusDescription)\n",
    "\n",
    "#processedData_JIRAComments_academyCountVectorizer = CountVectorizer()\n",
    "#processedData_JIRAComments_academyCountTF_IDF = createFittedTF_IDF(processedData_JIRAComments_academyCountVectorizer, intermediateData_JIRA_academyCorpusComments)\n",
    "\n",
    "\n",
    "################# Bigrams ###############\n",
    "#instantiate CountVectorizer() for SVN - bigrams\n",
    "processedData_SVNLogs_academyCountVectorizer_2gram = CountVectorizer(ngram_range=(2, 2))\n",
    "processedData_SVNLogs_academyCountTF_IDF_2gram = createFittedTF_IDF(processedData_SVNLogs_academyCountVectorizer_2gram, intermediateData_SVNLogs_academyCorpus_2gram)\n",
    "\n",
    "processedData_SVNUnitNames_academyCountVectorizer_2gram = CountVectorizer()\n",
    "processedData_SVNUnitNames_academyCountTF_IDF_2gram = createFittedTF_IDF(processedData_SVNUnitNames_academyCountVectorizer_2gram, intermediateData_SVNUnitNames_academyCorpus_2gram)\n",
    "\n",
    "\n",
    "#instantiate CountVectorizer() for JIRA - biigram\n",
    "processedData_JIRA_academyCountVectorizer_2gram = CountVectorizer(ngram_range=(2, 2))\n",
    "processedData_JIRA_academyCountTF_IDF_2gram = createFittedTF_IDF(processedData_JIRA_academyCountVectorizer_2gram, intermediateData_JIRA_academyCorpus_2gram)\n",
    "\n",
    "processedData_JIRASummaries_academyCountVectorizer_2gram = CountVectorizer(ngram_range=(2, 2))\n",
    "processedData_JIRASummaries_academyCountTF_IDF_2gram = createFittedTF_IDF(processedData_JIRASummaries_academyCountVectorizer_2gram, intermediateData_JIRA_academyCorpusSummary_2grams)\n",
    "\n",
    "processedData_JIRADescriptions_academyCountVectorizer_2gram = CountVectorizer(ngram_range=(2, 2))\n",
    "processedData_JIRADescriptions_academyCountTF_IDF_2gram = createFittedTF_IDF(processedData_JIRADescriptions_academyCountVectorizer_2gram, intermediateData_JIRA_academyCorpusDescription_2grams)\n",
    "\n",
    "#processedData_JIRAComments_academyCountVectorizer_2gram = CountVectorizer(ngram_range=(2, 2))\n",
    "#processedData_JIRAComments_academyCountTF_IDF_2gram = createFittedTF_IDF(processedData_JIRAComments_academyCountVectorizer_2gram, intermediateData_JIRA_academyCorpusComments_2grams)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-audience",
   "metadata": {},
   "source": [
    "#### 3.4.1 [VSM unigram] Similarity between JIRA issue and Commit Log - Jira As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-replication",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmLogsJiraAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmLogsJiraAsQuery[\"vsm_logs_jira_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Logs, processedData_JIRA_academyCountVectorizer, processedData_JIRA_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmLogsJiraAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmLogsJiraAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-september",
   "metadata": {},
   "source": [
    "#### 3.4.2 [VSM unigram] Similarity between JIRA issue and Commit Log - Log As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-stretch",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmLogsLogAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmLogsLogAsQuery[\"vsm_logs_log_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Logs, processedData_SVNLogs_academyCountVectorizer, processedData_SVNLogs_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmLogsLogAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmLogsLogAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-basic",
   "metadata": {},
   "source": [
    "#### 3.4.3 [VSM unigram] Similarity between JIRA issue and Unit Names - JIRA As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-commodity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmUnitNamesJiraAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmUnitNamesJiraAsQuery[\"vsm_unit_names_jira_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Unit_names, processedData_JIRA_academyCountVectorizer, processedData_JIRA_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmUnitNamesJiraAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmUnitNamesJiraAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-drink",
   "metadata": {},
   "source": [
    "#### 3.4.1 [VSM unigram] Similarity between JIRA Summary and Commit Log - Jira As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-classics",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmSummaryLogsSummaryAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmSummaryLogsSummaryAsQuery[\"vsm_summary_logs_summary_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Summary, x.Logs, processedData_JIRASummaries_academyCountVectorizer, processedData_JIRASummaries_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmSummaryLogsSummaryAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmSummaryLogsSummaryAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-victor",
   "metadata": {},
   "source": [
    "#### 3.4.1 [VSM unigram] Similarity between JIRA Summary and Commit Log - Log As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmSummaryLogsLogsAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmSummaryLogsLogsAsQuery[\"vsm_summary_logs_logs_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Summary, x.Logs, processedData_SVNLogs_academyCountVectorizer, processedData_SVNLogs_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmSummaryLogsLogsAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmSummaryLogsLogsAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-receiver",
   "metadata": {},
   "source": [
    "#### 3.4.1 [VSM unigram] Similarity between JIRA Summary and UnitNames - Summary As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmSummaryUnitNamesSummaryAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmSummaryUnitNamesSummaryAsQuery[\"vsm_summary_unitNames_summary_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Summary, x.Unit_names, processedData_JIRASummaries_academyCountVectorizer, processedData_JIRASummaries_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmSummaryUnitNamesSummaryAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmSummaryUnitNamesSummaryAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-guinea",
   "metadata": {},
   "source": [
    "#### 3.4.1 [VSM unigram] Similarity between JIRA Summary and UnitNames - UnitNames As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmSummaryUnitNamesUnitNamesAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmSummaryUnitNamesUnitNamesAsQuery[\"vsm_summary_unitNames_unitNames_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Summary, x.Unit_names, processedData_SVNUnitNames_academyCountVectorizer, processedData_SVNUnitNames_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmSummaryUnitNamesSummaryAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmSummaryUnitNamesUnitNamesAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-greek",
   "metadata": {},
   "source": [
    "#### 3.4.3 [VSM unigram - verb pruning] Similarity between JIRA issue and Unit Names - JIRA As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmVerbPruningUnitNamesJiraAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmVerbPruningUnitNamesJiraAsQuery[\"vsm_verb_pruning_unit_names_jira_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarityWithPOSPruning(x.Jira_natural_text, x.Unit_names, processedData_JIRA_academyCountVectorizer, processedData_JIRA_academyCountTF_IDF, x.verbs), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmVerbPruningUnitNamesJiraAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmVerbPruningUnitNamesJiraAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query and verb pruning' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-jungle",
   "metadata": {},
   "source": [
    "#### 3.4.4 [VSM unigram] Similarity between JIRA issue and Unit Names  - Unit Names As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmUnitNamesUnitNamesAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmUnitNamesUnitNamesAsQuery[\"vsm_unit_names_log_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Unit_names, processedData_SVNUnitNames_academyCountVectorizer, processedData_SVNUnitNames_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmUnitNamesUnitNamesAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmUnitNamesUnitNamesAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-hearts",
   "metadata": {},
   "source": [
    "#### 3.4.5 [VSM unigram] Similarity between JIRA description and commit log - Description as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmDescriptionDescriptionAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmDescriptionDescriptionAsQuery[\"vsm_description_description_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Description, x.Logs, processedData_JIRADescriptions_academyCountVectorizer, processedData_JIRADescriptions_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmDescriptionDescriptionAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmDescriptionDescriptionAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-trash",
   "metadata": {},
   "source": [
    "#### 3.4.5 [VSM unigram Silarity between JIRA description and commit log - Log as descrintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmDescriptionLogsAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmDescriptionLogsAsQuery[\"vsm_description_log_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Description, x.Unit_names, processedData_SVNUnitNames_academyCountVectorizer, processedData_SVNUnitNames_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmDescriptionLogsAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmDescriptionLogsAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-landing",
   "metadata": {},
   "source": [
    "#### 3.4.5 [VSM unigram Silarity between JIRA Comment and unitnames - Comment as query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-beginning",
   "metadata": {},
   "source": [
    "#### 3.4.5 [VSM unigram Silarity between JIRA Comment and unitnames - Comment as query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-accused",
   "metadata": {},
   "source": [
    "#### 3.4.5 [VSM unigram Silarity between JIRA Comment and commit log - Comment as description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-medicaid",
   "metadata": {},
   "source": [
    "#### 3.4.5 [VSM unigram Silarity between JIRA description and commit log - Log as description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-romantic",
   "metadata": {},
   "source": [
    "#### [VSM bigram] Similarity between JIRA comments and Commit Logs - Logs as query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-festival",
   "metadata": {},
   "source": [
    "#### 3.4.5 [VSM bigram] Silarity between JIRA Comment and commit log - Comment as query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-fairy",
   "metadata": {},
   "source": [
    "#### [VSM Unigram] Similarity between Unit Names and Description - Unit Names as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmUnitNamesDescriptionUnitNamesAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmUnitNamesDescriptionUnitNamesAsQuery[\"vsm_unitnames_description_unitnames_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Description, x.Unit_names, processedData_SVNUnitNames_academyCountVectorizer, processedData_SVNUnitNames_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmUnitNamesDescriptionUnitNamesAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmUnitNamesDescriptionUnitNamesAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-patio",
   "metadata": {},
   "source": [
    "#### [VSM Unigram] Similarity between Unit Names and Description - Description as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmUnitNamesDescriptionDescriptionAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmUnitNamesDescriptionDescriptionAsQuery[\"vsm_unitnames_description_description_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Description, x.Unit_names, processedData_JIRADescriptions_academyCountVectorizer, processedData_JIRADescriptions_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmUnitNamesDescriptionDescriptionAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmUnitNamesDescriptionDescriptionAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-schedule",
   "metadata": {},
   "source": [
    "#### [VSM Unigram] Similarity between Unit Names and Comments - Unit Names as query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-council",
   "metadata": {},
   "source": [
    "#### [VSM Unigram] Similarity between Unit Names and Comments - Comments as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [VSM Unigram] Similarity between SVN (entirely) and JIRA (entirely)- JIRA as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmSvnJiraJiraAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmSvnJiraJiraAsQuery[\"vsm_svn_jira_jira_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Commit_natural_text, processedData_JIRA_academyCountVectorizer, processedData_JIRA_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmSvnJiraJiraAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmSvnJiraJiraAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [VSM Unigram] Similarity between SVN (entirely) and JIRA (entirely) - SVN as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmSvnJiraSvnAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmSvnJiraSvnAsQuery[\"vsm_svn_jira_svn_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Commit_natural_text, processedData_SVN_academyCountVectorizer, processedData_SVN_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmSvnJiraSvnAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmSvnJiraSvnAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [VSM Unigram] Similarity between SVN (entirely) and Summary - SVN as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-amazon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmSvnSummarySvnAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmSvnSummarySvnAsQuery[\"vsm_svn_summary_svn_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Commit_natural_text, x.Summary, processedData_SVN_academyCountVectorizer, processedData_SVN_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmSvnSummarySvnAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmSvnSummarySvnAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [VSM Unigram] Similarity between SVN (entirely) and Summary - Summary as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmSvnSummarySummaryAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmSvnSummarySummaryAsQuery[\"vsm_svn_summary_summary_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Commit_natural_text, x.Summary, processedData_JIRASummaries_academyCountVectorizer, processedData_JIRASummaries_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmSvnSummarySummaryAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmSvnSummarySummaryAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [VSM Unigram] Similarity between SVN (entirely) and Description - SVN as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmSvnDescriptionSvnAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmSvnDescriptionSvnAsQuery[\"vsm_svn_description_svn_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Commit_natural_text, x.Description, processedData_SVN_academyCountVectorizer, processedData_SVN_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmSvnDescriptionSvnAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmSvnDescriptionSvnAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [VSM Unigram] Similarity between SVN (entirely) and Description - Description as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmSvnDescriptionDescriptionAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmSvnDescriptionDescriptionAsQuery[\"vsm_svn_description_description_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Commit_natural_text, x.Description, processedData_JIRADescriptions_academyCountVectorizer, processedData_JIRADescriptions_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmSvnDescriptionDescriptionAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmSvnDescriptionDescriptionAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-intersection",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [VSM Unigram] Similarity between SVN (entirely) and Comments - SVN as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [VSM Unigram] Similarity between SVN (entirely) and Comments - Comments as query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-absorption",
   "metadata": {},
   "source": [
    "#### 3.4.3 [VSM unigram - verb pruning] Similarity between JIRA issue and Unit Names and verb pruning - Unit Names As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery[\"vsm_verb_pruning_unit_names_log_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarityWithPOSPruning(x.Jira_natural_text, x.Unit_names, processedData_SVNUnitNames_academyCountVectorizer, processedData_SVNUnitNames_academyCountTF_IDF, x.verbs), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-freeze",
   "metadata": {},
   "source": [
    "#### 3.4.5 [VSM bigram] Similarity between JIRA issue and Commit Log - Jira As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmLogsJiraAsQuery_2gram = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmLogsJiraAsQuery_2gram[\"vsm_logs_jira_as_query_2gram\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Logs, processedData_JIRA_academyCountVectorizer_2gram, processedData_JIRA_academyCountTF_IDF_2gram), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmLogsJiraAsQuery_2gram.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmLogsJiraAsQuery_2gram.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-northeast",
   "metadata": {},
   "source": [
    "#### 3.4.6 [VSM bigram] Similarity between JIRA issue and Commit Log - Logs As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmLogsLogAsQuery_2gram = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmLogsLogAsQuery_2gram[\"vsm_logs_log_as_query_2gram\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Logs, processedData_SVNLogs_academyCountVectorizer_2gram, processedData_SVNLogs_academyCountTF_IDF_2gram), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmLogsLogAsQuery_2gram.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmLogsLogAsQuery_2gram.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-indie",
   "metadata": {},
   "source": [
    "#### 3.4.6 [VSM bigram] Similarity between JIRA issue and Unit Names - Jira As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmUnitNamesJiraAsQuery_2gram = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmUnitNamesJiraAsQuery_2gram[\"vsm_unit_names_jira_as_query_2gram\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Unit_names, processedData_JIRA_academyCountVectorizer_2gram, processedData_JIRA_academyCountTF_IDF_2gram), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmUnitNamesJiraAsQuery_2gram.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmUnitNamesJiraAsQuery_2gram.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-sixth",
   "metadata": {},
   "source": [
    "#### 3.4.6 [VSM bigram] Similarity between JIRA issue and Unit Names - UnitNames As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_2gram = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_2gram[\"vsm_unit_names_log_as_query_2gram\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Unit_names, processedData_SVNUnitNames_academyCountVectorizer_2gram, processedData_SVNUnitNames_academyCountTF_IDF_2gram), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_2gram.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_2gram.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-sector",
   "metadata": {},
   "source": [
    "#### [VSM bigram] Similarity between Logs and Description - Logs as Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmDescriptionLogsAsQuery_2gram = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmDescriptionLogsAsQuery_2gram[\"vsm_description_log_as_query_2gram\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Description, x.Unit_names, processedData_SVNUnitNames_academyCountVectorizer_2gram, processedData_SVNUnitNames_academyCountTF_IDF_2gram), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmDescriptionLogsAsQuery_2gram.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmDescriptionLogsAsQuery_2gram.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-prince",
   "metadata": {},
   "source": [
    "#### [VSM bigram] Similarity between Logs and Description - Description as Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmDescriptionDescriptionAsQuery_2gram = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmDescriptionDescriptionAsQuery_2gram[\"vsm_description_description_as_query_2gram\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Description, x.Logs, processedData_JIRADescriptions_academyCountVectorizer_2gram, processedData_JIRADescriptions_academyCountTF_IDF_2gram), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmDescriptionDescriptionAsQuery_2gram.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmDescriptionDescriptionAsQuery_2gram.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Bigrams' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-simon",
   "metadata": {},
   "source": [
    "#### [VSM bigram] Similarity between Logs and Summary - Logs as Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-throat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "continent-african",
   "metadata": {},
   "source": [
    "#### [VSM bigram] Similarity between Logs and Summary - Summary as Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmSummaryLogsSummaryAsQuery_2gram = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmSummaryLogsSummaryAsQuery_2gram[\"vsm_summary_logs_summary_as_query_2gram\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarityNGrams(x.Summary, x.Logs, processedData_JIRASummaries_academyCountVectorizer_2gram, processedData_JIRASummaries_academyCountTF_IDF_2gram), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmSummaryLogsSummaryAsQuery_2gram.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmSummaryLogsSummaryAsQuery_2gram.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-separation",
   "metadata": {},
   "source": [
    "## 3.6 Document Statistics\n",
    "\n",
    "### academy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-warren",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRA_academyFeaturesUniqueWordCount = pd.DataFrame() \n",
    "processedData_SVN_academyFeaturesUniqueWordCount = pd.DataFrame() \n",
    "processedData_JIRA_academyFeaturesTotalWordCount = pd.DataFrame() \n",
    "processedData_SVN_academyFeaturesTotalWordCount = pd.DataFrame()\n",
    "\n",
    "processedData_JIRA_academyFeaturesOverlapPercentage = pd.DataFrame()\n",
    "processedData_SVN_academyFeaturesOverlapPercentage = pd.DataFrame()\n",
    "processedData_UNION_academyFeaturesOverlapPercentage = pd.DataFrame()\n",
    "\n",
    "#Calculate unique terms JIRA for each trace\n",
    "processedData_JIRA_academyFeaturesUniqueWordCount[\"unique_term_count_jira\"] = processedData_academyCartesian.apply(lambda x: calculateUniqueWordCount(x.Jira_natural_text), \n",
    "                                                            axis=1)\n",
    "#Calculate unique terms JIRA for each trace\n",
    "processedData_SVN_academyFeaturesUniqueWordCount[\"unique_term_count_svn\"] = processedData_academyCartesian.apply(lambda x: calculateUniqueWordCount(x.Commit_natural_text), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Calculate total terms JIRA for each trace\n",
    "processedData_JIRA_academyFeaturesTotalWordCount[\"total_term_count_jira\"] = processedData_academyCartesian.apply(lambda x: calculateTotalWordCount(x.Jira_natural_text), \n",
    "                                                            axis=1)\n",
    "#Calculate total terms JIRA for each trace\n",
    "processedData_SVN_academyFeaturesTotalWordCount[\"total_term_count_svn\"] = processedData_academyCartesian.apply(lambda x: calculateTotalWordCount(x.Commit_natural_text), \n",
    "                                                            axis=1)\n",
    "\n",
    "processedData_JIRA_academyFeaturesOverlapPercentage[\"overlap_percentage_compared_to_jira\"] = processedData_academyCartesian.apply(lambda x: calculateOverlapBetweenDocuments(x.Jira_natural_text, x.Commit_natural_text, 'list1'),\n",
    "                                                            axis=1)\n",
    "processedData_SVN_academyFeaturesOverlapPercentage[\"overlap_percentage_compared_to_svn\"] = processedData_academyCartesian.apply(lambda x: calculateOverlapBetweenDocuments(x.Jira_natural_text, x.Commit_natural_text, 'list2'),\n",
    "                                                            axis=1)\n",
    "processedData_UNION_academyFeaturesOverlapPercentage[\"overlap_percentage_compared_to_union\"] = processedData_academyCartesian.apply(lambda x: calculateOverlapBetweenDocuments(x.Jira_natural_text, x.Commit_natural_text, 'union'),\n",
    "                                                            axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRA_academyFeaturesUniqueWordCount.to_pickle(path= \"../data/03_processed/processedData_JIRA_academyFeaturesUniqueWordCount.pkl\")\n",
    "processedData_SVN_academyFeaturesUniqueWordCount.to_pickle(path= \"../data/03_processed/processedData_SVN_academyFeaturesUniqueWordCount.pkl\")\n",
    "processedData_JIRA_academyFeaturesTotalWordCount.to_pickle(path= \"../data/03_processed/processedData_JIRA_academyFeaturesTotalWordCount.pkl\")\n",
    "processedData_SVN_academyFeaturesTotalWordCount.to_pickle(path= \"../data/03_processed/processedData_SVN_academyFeaturesTotalWordCount.pkl\")\n",
    "\n",
    "processedData_JIRA_academyFeaturesOverlapPercentage.to_pickle(path= \"../data/03_processed/processedData_JIRA_academyFeaturesOverlapPercentage.pkl\")\n",
    "processedData_SVN_academyFeaturesOverlapPercentage.to_pickle(path= \"../data/03_processed/processedData_SVN_academyFeaturesOverlapPercentage.pkl\")\n",
    "processedData_UNION_academyFeaturesOverlapPercentage.to_pickle(path= \"../data/03_processed/processedData_UNION_academyFeaturesOverlapPercentage.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating document statistics in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-pressing",
   "metadata": {},
   "source": [
    "## 3.7 Query Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the count vectorizer and tfidf for the corpus\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from statistics import mean, median, mode, stdev, variance\n",
    "from math import log, sqrt\n",
    "import itertools\n",
    "\n",
    "#Function calculating the IDFs of all query terms. Returns a list containing all IDFs\n",
    "def calcIDFList(document, cv, tfidf_transformer):\n",
    "    idfScoreList=[]\n",
    "    if isinstance(document, list):\n",
    "        termCount = len(document)\n",
    "        for term in document:\n",
    "            try:\n",
    "                indexOfWord = cv.get_feature_names().index(term)\n",
    "                idfScore = tfidf_transformer.idf_[indexOfWord]\n",
    "                idfScoreList.append(idfScore)\n",
    "            except:\n",
    "                idfScoreList.append(0)\n",
    "    else:\n",
    "        termCount = 0\n",
    "    return(idfScoreList)\n",
    "\n",
    "\n",
    "def calcAvgIDF(IDFList):\n",
    "    termCount = len(IDFList)\n",
    "    if(termCount != 0):\n",
    "        avgIdf = sum(IDFList) / termCount\n",
    "    else:\n",
    "        avgIdf = 0\n",
    "    return(avgIdf)\n",
    "\n",
    "def calcMaxIDF(IDFList): \n",
    "    termCount = len(IDFList)\n",
    "    if(termCount != 0):\n",
    "        maxIdf = np.amax(IDFList)\n",
    "    else: \n",
    "        maxIdf = 0\n",
    "    return(maxIdf)\n",
    "\n",
    "def calcDevIDF(IDFList):\n",
    "    termCount = len(IDFList)\n",
    "    if(termCount > 1):\n",
    "        stdevIdf = stdev(IDFList)\n",
    "    else: \n",
    "        stdevIdf = 0\n",
    "    return(stdevIdf)\n",
    "\n",
    "#Function calculating the ICTF of all query terms. Returns a list containing all IDFs\n",
    "def calcICTFList(document, cv, documentCount):\n",
    "    ICTFList = []\n",
    "        #For all terms in query, find how often they occur in the Corpus\n",
    "    if isinstance(document, list):\n",
    "        for term in document:\n",
    "            try:\n",
    "            #Find out how often the term occurs in the corpus\n",
    "                termFrequency = (cv.vocabulary_[term])\n",
    "                \n",
    "                #Compute the log\n",
    "                ictF = log(documentCount/termFrequency)\n",
    "            except:\n",
    "                ictF = 0\n",
    "            \n",
    "            ICTFList.append(ictF)\n",
    "    return(ICTFList)\n",
    "\n",
    "def calcAvgICTF(ICTFList, documentCount):\n",
    "    avgICTF = sum(ICTFList) / documentCount\n",
    "    return(avgICTF)\n",
    "\n",
    "\n",
    "def calcMaxICTF(ICTFList): \n",
    "    termCount = len(ICTFList)\n",
    "    if(termCount != 0):\n",
    "        maxICTF = np.amax(ICTFList)\n",
    "    else: \n",
    "        maxICTF = 0\n",
    "    return(maxICTF)\n",
    "\n",
    "def calcDevICTF(ICTFList):\n",
    "    termCount = len(ICTFList)\n",
    "    if(termCount > 1):\n",
    "        stdevICTF = stdev(ICTFList)\n",
    "    else: \n",
    "        stdevICTF = 0\n",
    "    return(stdevICTF)\n",
    "\n",
    "\n",
    "def calcEntropyList(query, cv, documentCount, docCollection):\n",
    "    #entropy(t) = ∑ (d∈Dt)  ( tf(t,d) / tf(t, D) ) * log |D|(tf(t,d) / tf(t, D) )\n",
    "        \n",
    "    entropyValueList = []\n",
    "    #for each term in the query, calculate the entropy of the query\n",
    "    if isinstance(query, list):\n",
    "        for queryTerm in query:\n",
    "            #For each d ∈ D\n",
    "            \n",
    "            partialEntropyList = []\n",
    "            \n",
    "            for d in docCollection:\n",
    "                #Check if queryTerm occurs in D (i.e/ d∈Dt)\n",
    "                if (isinstance(d, list)):\n",
    "                    if queryTerm in d:\n",
    "                        try:\n",
    "                            #Calculate the frequency of the term occurs in the document (i.e tf(t,d))\n",
    "                            queryTermFrequencyInDocument = d.count(queryTerm)\n",
    "                            \n",
    "                            #calculate the frequency the term occurs in the query corpus (i.e tf(t,D))\n",
    "                            queryTermFrequencyInCorpus = (cv.vocabulary_[queryTerm])\n",
    "                             \n",
    "                            # This part of the calculation tf(t,d) / tf(t, D)  * log |D|(tf(t,d) / tf(t, D))\n",
    "                            partialEntropy1stHalf = queryTermFrequencyInDocument / queryTermFrequencyInCorpus\n",
    "                            partialEntropy2ndHalf = log((queryTermFrequencyInDocument / queryTermFrequencyInCorpus), documentCount)\n",
    "                            partialEntropy = partialEntropy1stHalf\n",
    "                            partialEntropyList.append(partialEntropy)\n",
    "                        except:\n",
    "                            partialEntropyList.append(0) #If term not found entropy is 0\n",
    "            #this part of the calculation ∑ (d∈Dt)\n",
    "            entropyValueOfQueryTerm = sum(partialEntropyList)\n",
    "            entropyValueList.append(entropyValueOfQueryTerm)\n",
    "    \n",
    "    return(entropyValueList)\n",
    "\n",
    "\n",
    "def calcAvgEntropy(entropyValueList):\n",
    "    termCount = len(entropyValueList)\n",
    "    if(termCount != 0):\n",
    "        #Calculate the average of all the entropies\n",
    "        avgEntropy = sum(entropyValueList) / len(entropyValueList)\n",
    "    else:\n",
    "        avgEntropy = 0\n",
    "    return(avgEntropy)\n",
    "\n",
    "    \n",
    "def calcMedEntropy(entropyValueList):\n",
    "    termCount = len(entropyValueList)\n",
    "    if(termCount != 0):\n",
    "        #Calculate the average of all the entropies\n",
    "        medEntropy = median(entropyValueList)\n",
    "    else:\n",
    "        medEntropy = 0\n",
    "    return(medEntropy)\n",
    "    \n",
    "def calcMaxEntropy(entropyValueList):\n",
    "    termCount = len(entropyValueList)\n",
    "    if(termCount != 0):\n",
    "        maxEntropy = np.amax(entropyValueList)\n",
    "    else: \n",
    "        maxEntropy = 0\n",
    "    return(maxEntropy)\n",
    "    \n",
    "def calcDevEntropy(entropyValueList):\n",
    "    termCount = len(entropyValueList)\n",
    "    if(termCount > 1):\n",
    "        #Calculate the average of all the entropies\n",
    "        devEntropy = stdev(entropyValueList)\n",
    "    else:\n",
    "        devEntropy = 0\n",
    "    return(devEntropy)\n",
    "\n",
    "#The percentage of documents in the collection containing at least one of the query terms\n",
    "def calcQueryScope(query, docCollection): \n",
    "    counter = 0\n",
    "    if isinstance(query, list):\n",
    "        for document in docCollection:\n",
    "            #check if query occurs in term. \n",
    "            if(isinstance(document, list)):\n",
    "                for queryTerm in query:\n",
    "                    if queryTerm in document:\n",
    "                        counter = counter + 1\n",
    "                        break\n",
    "    queryScope = counter / len(docCollection)\n",
    "    return(queryScope)\n",
    "\n",
    "#The Kullback-Leiber divergence of the query language model from the collection language model\n",
    "def calcSCS(query, cv, docCount):\n",
    "    divergenceList = []\n",
    "    if isinstance(query, list):\n",
    "        for queryTerm in query:\n",
    "            try:\n",
    "                #frequency of term in query - tf(q, Q)/|Q|\n",
    "                pqQ = query.count(queryTerm) / len(query)\n",
    "                \n",
    "                #frequency of term in documentlist - tf(q, D)/|D|\n",
    "                pqD = cv.vocabulary_[queryTerm]\n",
    "                \n",
    "                divergence = pqQ * log(pqQ / pqD)\n",
    "                divergenceList.append(divergence)\n",
    "            except:\n",
    "                continue\n",
    "    SCS = sum(divergenceList)\n",
    "    return(SCS)\n",
    "\n",
    "#The average of the collection-query similarity (SCQ) over all query terms\n",
    "def calcSCQList(query, docCollection, cv, fittedTF_IDF, documentCount):\n",
    "    SCQList = []\n",
    "    if isinstance(query, list):\n",
    "        documentString = ' '.join(query)\n",
    "        \n",
    "        #Calculate the Term Frequency of the document\n",
    "        inputDocs = [documentString] \n",
    "        \n",
    "        # count matrix \n",
    "        count_vector = cv.transform(inputDocs) \n",
    " \n",
    "        #tf-idf scores \n",
    "        tf_idf_vector = fittedTF_IDF.transform(count_vector)\n",
    "        \n",
    "        feature_names = cv.get_feature_names() \n",
    "        # place tf-idf values in a pandas data frame \n",
    "        df = pd.DataFrame(tf_idf_vector.T.todense(), \n",
    "                          index=feature_names, columns=[\"tfidf\"])\n",
    "    \n",
    "        \n",
    "        #Find the tfidf of the term\n",
    "        for queryTerm in query:    \n",
    "            try:\n",
    "                tfidf = df[\"tfidf\"][queryTerm]\n",
    "                SCQ = (1 + log(tfidf))\n",
    "                SCQList.append(SCQ)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "    avgSCQ = sum(SCQList) / documentCount\n",
    "    return(SCQList)\n",
    "\n",
    "#The average of the collection-query similarity (SCQ) over all query terms\n",
    "def calcAvgSCQ(SCQList, documentCount):\n",
    "    avgSCQ = sum(SCQList) / documentCount\n",
    "    return(avgSCQ)\n",
    "    \n",
    "#The average of the collection-query similarity (SCQ) over all query terms\n",
    "def calcMaxSCQ(SCQList):\n",
    "    termCount = len(SCQList)\n",
    "    if(termCount != 0):\n",
    "        maxSCQ = np.amax(SCQList)\n",
    "    else:\n",
    "        maxSCQ = np.NaN\n",
    "    return(maxSCQ)\n",
    "\n",
    "#The average of the collection-query similarity (SCQ) over all query terms\n",
    "def calcSumSCQ(SCQList):\n",
    "    sumSCQ = sum(SCQList)\n",
    "    return(sumSCQ)\n",
    "\n",
    "def createTermPairs(cv):\n",
    "    terms = list(cv.vocabulary_.keys())\n",
    "    #Create all possible pair combinations from the terms in the query \n",
    "    pairCombinationList = list(itertools.combinations(terms, 2))\n",
    "    return(pairCombinationList)\n",
    "\n",
    "#Method to find out how often a term occurs in a document\n",
    "def findTermFrequencies(cv, docCollection):\n",
    "    terms = list(cv.vocabulary_.keys())\n",
    "    termFrequencies = {}\n",
    "    for term in terms:\n",
    "        termCounter = 0\n",
    "        for document in docCollection:\n",
    "            if isinstance(document, list):\n",
    "                if term in document: \n",
    "                    termCounter = termCounter + 1\n",
    "        termFrequencies[term] = termCounter\n",
    "    return(termFrequencies)\n",
    "\n",
    "#Method to find out how often both terms occur in a document. \n",
    "def findTermPairFrequencies(termPairs, docCollection):\n",
    "    termPairFrequencies = {}\n",
    "    for termPair in termPairs:\n",
    "        termPairCount = 0\n",
    "        for document in docCollection:\n",
    "            if (isinstance(document, list)):\n",
    "                if all(i in document for i in termPair):\n",
    "                    termPairCount = termPairCount + 1\n",
    "        termPairFrequencies[termPair] = termPairCount\n",
    "    return(termPairFrequencies)   \n",
    "\n",
    "def calcPMIList(query, termFrequencies, termPairFrequencies, docCollection):\n",
    "    if isinstance(query, list):\n",
    "    #Find the frequencies of the individual terms and the pairs\n",
    "        pairCombinationList = list(itertools.combinations(query, 2))\n",
    "        termOccurances = []\n",
    "        for pair in pairCombinationList:\n",
    "            try:\n",
    "                q1Freq = termFrequencies[pair[0]]\n",
    "            except:\n",
    "                q1Freq = 0\n",
    "            try:\n",
    "                q2Freq = termFrequencies[pair[1]]\n",
    "            except:\n",
    "                q2Freq = 0\n",
    "            try:\n",
    "                q1q2Freq = termPairFrequencies[pair]\n",
    "            except:\n",
    "                q1q2Freq = 0\n",
    "                    \n",
    "            termOccurances.append({'q1Freq': q1Freq, \n",
    "                                   'q2Freq': q2Freq, \n",
    "                                   'q1q2Freq': q1q2Freq})\n",
    "    \n",
    "        docCount = len(docCollection)\n",
    "        pmiList = []\n",
    "        for term in termOccurances:\n",
    "            pq1 = term['q1Freq'] / docCount\n",
    "            pq2 = term['q2Freq'] / docCount\n",
    "            pq1q2 = term['q1q2Freq'] / docCount\n",
    "\n",
    "            try:\n",
    "                pmi = log(pq1q2 /(pq1 * pq2))\n",
    "            except:\n",
    "                pmi = np.nan\n",
    "            pmiList.append(pmi)\n",
    "        return(pmiList)\n",
    "    else:\n",
    "        return(np.nan)\n",
    "\n",
    "def calcAvgPMI(pmiList):\n",
    "    if(isinstance(pmiList, list)):\n",
    "        pairCount = len(pmiList)\n",
    "        if(pairCount != 0):\n",
    "            #Calculate the average of all the entropies\n",
    "            avgPMI= np.nansum(pmiList) / pairCount\n",
    "        else:\n",
    "            avgPMI = 0\n",
    "        return(avgPMI)\n",
    "    return(np.nan)\n",
    "\n",
    "def calcMaxPMI(pmiList): \n",
    "    if(isinstance(pmiList, list)):\n",
    "        pairCount = len(pmiList)\n",
    "        if(pairCount != 0):\n",
    "            maxPMI = np.nanmax(pmiList)\n",
    "        else: \n",
    "            maxPMI = np.nan\n",
    "        return(maxPMI)\n",
    "    return(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-mexican",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read datasets from disk\n",
    "processedData_academyCartesian = pd.read_pickle(r\"../data/03_processed/processedData_academyCartesian.pkl\")\n",
    "\n",
    "#instantiate CountVectorizer() for SVN\n",
    "processedData_SVN_academyCountVectorizer = CountVectorizer()\n",
    "processedData_SVN_academyTF_IDF = createFittedTF_IDF(processedData_SVN_academyCountVectorizer, intermediateData_SVN_academyCorpusAll)\n",
    "\n",
    "#instantiate CountVectorizer() for JIRA\n",
    "processedData_JIRA_academyCountVectorizer = CountVectorizer()\n",
    "processedData_JIRA_academyTF_IDF = createFittedTF_IDF(processedData_JIRA_academyCountVectorizer, intermediateData_JIRA_academyCorpus)\n",
    "\n",
    "#Determine document counts\n",
    "intermediateData_JIRA_academy_documentCount = len(intermediateData_JIRA_academy.index)\n",
    "intermediateData_SVN_academy_documentCount = len(intermediateData_SVN_academy.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-stage",
   "metadata": {},
   "source": [
    "#### IDF Scores (SVN as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVN_academyFeaturesIDF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVN_academyFeaturesIDF[\"SvnAsQuery_IDF\"] = processedData_academyCartesian.apply(lambda x: calcIDFList(x.Commit_natural_text, \n",
    "                                                                                                                processedData_SVN_academyCountVectorizer, \n",
    "                                                                                                                processedData_SVN_academyTF_IDF),axis=1)\n",
    "\n",
    "processedData_SVN_academyFeaturesIDF[\"SvnAsQuery_avgIDF\"] = processedData_SVN_academyFeaturesIDF.apply(lambda x: calcAvgIDF(x.SvnAsQuery_IDF), axis=1)\n",
    "processedData_SVN_academyFeaturesIDF[\"SvnAsQuery_maxIDF\"] = processedData_SVN_academyFeaturesIDF.apply(lambda x: calcMaxIDF(x.SvnAsQuery_IDF), axis=1)\n",
    "processedData_SVN_academyFeaturesIDF[\"SvnAsQuery_devIDF\"] = processedData_SVN_academyFeaturesIDF.apply(lambda x: calcDevIDF(x.SvnAsQuery_IDF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVN_academyFeaturesIDF.to_pickle(path= \"../data/03_processed/processedData_SVN_academyFeaturesIDF.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-moment",
   "metadata": {},
   "source": [
    "#### IDF Scores (SVNLogs as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-warehouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNLogs_academyFeaturesIDF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNLogs_academyFeaturesIDF[\"SvnLogsAsQuery_IDF\"] = processedData_academyCartesian.apply(lambda x: calcIDFList(x.Logs, \n",
    "                                                                                                                processedData_SVNLogs_academyCountVectorizer, \n",
    "                                                                                                                processedData_SVNLogs_academyCountTF_IDF),axis=1)\n",
    "\n",
    "processedData_SVNLogs_academyFeaturesIDF[\"SvnLogsAsQuery_avgIDF\"] = processedData_SVNLogs_academyFeaturesIDF.apply(lambda x: calcAvgIDF(x.SvnLogsAsQuery_IDF), axis=1)\n",
    "processedData_SVNLogs_academyFeaturesIDF[\"SvnLogsAsQuery_maxIDF\"] = processedData_SVNLogs_academyFeaturesIDF.apply(lambda x: calcMaxIDF(x.SvnLogsAsQuery_IDF), axis=1)\n",
    "processedData_SVNLogs_academyFeaturesIDF[\"SvnLogsAsQuery_devIDF\"] = processedData_SVNLogs_academyFeaturesIDF.apply(lambda x: calcDevIDF(x.SvnLogsAsQuery_IDF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNLogs_academyFeaturesIDF.to_pickle(path= \"../data/03_processed/processedData_SVNLogs_academyFeaturesIDF.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-sampling",
   "metadata": {},
   "source": [
    "#### IDF Scores (SVNUnitNames as Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNUnitNames_academyFeaturesIDF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNUnitNames_academyFeaturesIDF[\"SvnUnitNamesAsQuery_IDF\"] = processedData_academyCartesian.apply(lambda x: calcIDFList(x.Logs, \n",
    "                                                                                                                processedData_SVNLogs_academyCountVectorizer, \n",
    "                                                                                                                processedData_SVNLogs_academyCountTF_IDF),axis=1)\n",
    "\n",
    "processedData_SVNUnitNames_academyFeaturesIDF[\"SvnUnitNamesAsQuery_avgIDF\"] = processedData_SVNUnitNames_academyFeaturesIDF.apply(lambda x: calcAvgIDF(x.SvnUnitNamesAsQuery_IDF), axis=1)\n",
    "processedData_SVNUnitNames_academyFeaturesIDF[\"SvnUnitNamesAsQuery_maxIDF\"] = processedData_SVNUnitNames_academyFeaturesIDF.apply(lambda x: calcMaxIDF(x.SvnUnitNamesAsQuery_IDF), axis=1)\n",
    "processedData_SVNUnitNames_academyFeaturesIDF[\"SvnUnitNamesAsQuery_devIDF\"] = processedData_SVNUnitNames_academyFeaturesIDF.apply(lambda x: calcDevIDF(x.SvnUnitNamesAsQuery_IDF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNUnitNames_academyFeaturesIDF.to_pickle(path= \"../data/03_processed/processedData_SVNUnitNames_academyFeaturesIDF.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-arena",
   "metadata": {},
   "source": [
    "##### IDF Scores (JIRA as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRA_academyFeaturesIDF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRA_academyFeaturesIDF[\"JiraAsQuery_IDF\"] = processedData_academyCartesian.apply(lambda x: calcIDFList(x.Jira_natural_text, \n",
    "                                                                                                                processedData_JIRA_academyCountVectorizer, \n",
    "                                                                                                                processedData_JIRA_academyTF_IDF),axis=1)\n",
    "\n",
    "processedData_JIRA_academyFeaturesIDF[\"JiraAsQuery_avgIDF\"] = processedData_JIRA_academyFeaturesIDF.apply(lambda x: calcAvgIDF(x.JiraAsQuery_IDF), axis=1)\n",
    "processedData_JIRA_academyFeaturesIDF[\"JiraAsQuery_maxIDF\"] = processedData_JIRA_academyFeaturesIDF.apply(lambda x: calcMaxIDF(x.JiraAsQuery_IDF), axis=1)\n",
    "processedData_JIRA_academyFeaturesIDF[\"JiraAsQuery_devIDF\"] = processedData_JIRA_academyFeaturesIDF.apply(lambda x: calcDevIDF(x.JiraAsQuery_IDF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRA_academyFeaturesIDF.to_pickle(path= \"../data/03_processed/processedData_JIRA_academyFeaturesIDF.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-gothic",
   "metadata": {},
   "source": [
    "##### IDF Scores (JIRA Summaries as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRASummaries_academyFeaturesIDF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRASummaries_academyFeaturesIDF[\"JiraSummariesAsQuery_IDF\"] = processedData_academyCartesian.apply(lambda x: calcIDFList(x.Summary, \n",
    "                                                                                                                processedData_JIRASummaries_academyCountVectorizer, \n",
    "                                                                                                                processedData_JIRASummaries_academyCountTF_IDF),axis=1)\n",
    "\n",
    "processedData_JIRASummaries_academyFeaturesIDF[\"JiraSummariesAsQuery_avgIDF\"] = processedData_JIRASummaries_academyFeaturesIDF.apply(lambda x: calcAvgIDF(x.JiraSummariesAsQuery_IDF), axis=1)\n",
    "processedData_JIRASummaries_academyFeaturesIDF[\"JiraSummariesAsQuery_maxIDF\"] = processedData_JIRASummaries_academyFeaturesIDF.apply(lambda x: calcMaxIDF(x.JiraSummariesAsQuery_IDF), axis=1)\n",
    "processedData_JIRASummaries_academyFeaturesIDF[\"JiraSummariesAsQuery_devIDF\"] = processedData_JIRASummaries_academyFeaturesIDF.apply(lambda x: calcDevIDF(x.JiraSummariesAsQuery_IDF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRASummaries_academyFeaturesIDF.to_pickle(path= \"../data/03_processed/processedData_JIRASummaries_academyFeaturesIDF.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-specialist",
   "metadata": {},
   "source": [
    "##### IDF Scores (JIRA Descriptions as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRADescriptions_academyFeaturesIDF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRADescriptions_academyFeaturesIDF[\"JiraDescriptionsAsQuery_IDF\"] = processedData_academyCartesian.apply(lambda x: calcIDFList(x.Description, \n",
    "                                                                                                                processedData_JIRADescriptions_academyCountVectorizer, \n",
    "                                                                                                                processedData_JIRADescriptions_academyCountTF_IDF),axis=1)\n",
    "\n",
    "processedData_JIRADescriptions_academyFeaturesIDF[\"JiraDescriptionsAsQuery_avgIDF\"] = processedData_JIRADescriptions_academyFeaturesIDF.apply(lambda x: calcAvgIDF(x.JiraDescriptionsAsQuery_IDF), axis=1)\n",
    "processedData_JIRADescriptions_academyFeaturesIDF[\"JiraDescriptionsAsQuery_maxIDF\"] = processedData_JIRADescriptions_academyFeaturesIDF.apply(lambda x: calcMaxIDF(x.JiraDescriptionsAsQuery_IDF), axis=1)\n",
    "processedData_JIRADescriptions_academyFeaturesIDF[\"JiraDescriptionsAsQuery_devIDF\"] = processedData_JIRADescriptions_academyFeaturesIDF.apply(lambda x: calcDevIDF(x.JiraDescriptionsAsQuery_IDF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRADescriptions_academyFeaturesIDF.to_pickle(path= \"../data/03_processed/processedData_JIRADescriptions_academyFeaturesIDF.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-chile",
   "metadata": {},
   "source": [
    "##### IDF Scores (JIRA Comments as Query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-ensemble",
   "metadata": {},
   "source": [
    "#### ICTF Scores (SVN as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVN_academyFeaturesICTF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVN_academyFeaturesICTF[\"SvnAsQuery_ICTF\"] = processedData_academyCartesian.apply(lambda x: calcIDFList(x.Commit_natural_text, \n",
    "                                                                                                                processedData_SVN_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_academy_documentCount),axis=1)\n",
    "\n",
    "processedData_SVN_academyFeaturesICTF[\"SvnAsQuery_avgICTF\"] = processedData_SVN_academyFeaturesICTF.apply(lambda x: calcAvgICTF(x.SvnAsQuery_ICTF, intermediateData_SVN_academy_documentCount), axis=1)\n",
    "processedData_SVN_academyFeaturesICTF[\"SvnAsQuery_maxICTF\"] = processedData_SVN_academyFeaturesICTF.apply(lambda x: calcMaxICTF(x.SvnAsQuery_ICTF), axis=1)\n",
    "processedData_SVN_academyFeaturesICTF[\"SvnAsQuery_devICTF\"] = processedData_SVN_academyFeaturesICTF.apply(lambda x: calcDevICTF(x.SvnAsQuery_ICTF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVN_academyFeaturesICTF.to_pickle(path= \"../data/03_processed/processedData_SVN_academyFeaturesICTF.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-anthropology",
   "metadata": {},
   "source": [
    "#### ICTF Scores (SVNLogs as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNLogs_academyFeaturesICTF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNLogs_academyFeaturesICTF[\"SvnLogsAsQuery_ICTF\"] = processedData_academyCartesian.apply(lambda x: calcICTFList(x.Logs, \n",
    "                                                                                                                processedData_SVNLogs_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_academy_documentCount),axis=1)\n",
    "##\n",
    "processedData_SVNLogs_academyFeaturesICTF[\"SvnLogsAsQuery_avgICTF\"] = processedData_SVNLogs_academyFeaturesICTF.apply(lambda x: calcAvgICTF(x.SvnLogsAsQuery_ICTF, intermediateData_SVN_academy_documentCount), axis=1)\n",
    "processedData_SVNLogs_academyFeaturesICTF[\"SvnLogsAsQuery_maxICTF\"] = processedData_SVNLogs_academyFeaturesICTF.apply(lambda x: calcMaxICTF(x.SvnLogsAsQuery_ICTF), axis=1)\n",
    "processedData_SVNLogs_academyFeaturesICTF[\"SvnLogsAsQuery_devICTF\"] = processedData_SVNLogs_academyFeaturesICTF.apply(lambda x: calcDevICTF(x.SvnLogsAsQuery_ICTF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNLogs_academyFeaturesICTF.to_pickle(path= \"../data/03_processed/processedData_SVNLogs_academyFeaturesICTF.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-bikini",
   "metadata": {},
   "source": [
    "#### ICTF Scores (SVNUnitNames as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-maryland",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNUnitNames_academyFeaturesICTF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNUnitNames_academyFeaturesICTF[\"SvnUnitNamesAsQuery_ICTF\"] = processedData_academyCartesian.apply(lambda x: calcICTFList(x.Unit_names, \n",
    "                                                                                                                processedData_SVNUnitNames_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_academy_documentCount),axis=1)\n",
    "##\n",
    "processedData_SVNUnitNames_academyFeaturesICTF[\"SvnUnitNamesAsQuery_avgICTF\"] = processedData_SVNUnitNames_academyFeaturesICTF.apply(lambda x: calcAvgICTF(x.SvnUnitNamesAsQuery_ICTF, intermediateData_SVN_academy_documentCount), axis=1)\n",
    "processedData_SVNUnitNames_academyFeaturesICTF[\"SvnUnitNamesAsQuery_maxICTF\"] = processedData_SVNUnitNames_academyFeaturesICTF.apply(lambda x: calcMaxICTF(x.SvnUnitNamesAsQuery_ICTF), axis=1)\n",
    "processedData_SVNUnitNames_academyFeaturesICTF[\"SvnUnitNamesAsQuery_devICTF\"] = processedData_SVNUnitNames_academyFeaturesICTF.apply(lambda x: calcDevICTF(x.SvnUnitNamesAsQuery_ICTF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNUnitNames_academyFeaturesICTF.to_pickle(path= \"../data/03_processed/processedData_SVNUnitNames_academyFeaturesICTF.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-japan",
   "metadata": {},
   "source": [
    "#### ICTF Scores (JIRA as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRA_academyFeaturesICTF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRA_academyFeaturesICTF[\"JiraAsQuery_ICTF\"] = processedData_academyCartesian.apply(lambda x: calcICTFList(x.Jira_natural_text, \n",
    "                                                                                                                processedData_JIRA_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_academy_documentCount),axis=1)\n",
    "##\n",
    "processedData_JIRA_academyFeaturesICTF[\"JiraAsQuery_avgICTF\"] = processedData_JIRA_academyFeaturesICTF.apply(lambda x: calcAvgICTF(x.JiraAsQuery_ICTF, intermediateData_JIRA_academy_documentCount), axis=1)\n",
    "processedData_JIRA_academyFeaturesICTF[\"JiraAsQuery_maxICTF\"] = processedData_JIRA_academyFeaturesICTF.apply(lambda x: calcMaxICTF(x.JiraAsQuery_ICTF), axis=1)\n",
    "processedData_JIRA_academyFeaturesICTF[\"JiraAsQuery_devICTF\"] = processedData_JIRA_academyFeaturesICTF.apply(lambda x: calcDevICTF(x.JiraAsQuery_ICTF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRA_academyFeaturesICTF.to_pickle(path= \"../data/03_processed/processedData_JIRA_academyFeaturesICTF.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-freeware",
   "metadata": {},
   "source": [
    "#### ICTF Scores (JIRA Summaries as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRASummaries_academyFeaturesICTF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRASummaries_academyFeaturesICTF[\"JiraSummariesAsQuery_ICTF\"] = processedData_academyCartesian.apply(lambda x: calcICTFList(x.Summary, \n",
    "                                                                                                                processedData_JIRASummaries_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_academy_documentCount),axis=1)\n",
    "##\n",
    "processedData_JIRASummaries_academyFeaturesICTF[\"JiraSummariesAsQuery_avgICTF\"] = processedData_JIRASummaries_academyFeaturesICTF.apply(lambda x: calcAvgICTF(x.JiraSummariesAsQuery_ICTF, intermediateData_JIRA_academy_documentCount), axis=1)\n",
    "processedData_JIRASummaries_academyFeaturesICTF[\"JiraSummariesAsQuery_maxICTF\"] = processedData_JIRASummaries_academyFeaturesICTF.apply(lambda x: calcMaxICTF(x.JiraSummariesAsQuery_ICTF), axis=1)\n",
    "processedData_JIRASummaries_academyFeaturesICTF[\"JiraSummariesAsQuery_devICTF\"] = processedData_JIRASummaries_academyFeaturesICTF.apply(lambda x: calcDevICTF(x.JiraSummariesAsQuery_ICTF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRASummaries_academyFeaturesICTF.to_pickle(path= \"../data/03_processed/processedData_JIRASummaries_academyFeaturesICTF.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-offset",
   "metadata": {},
   "source": [
    "#### ICTF Scores (JIRA Descriptions as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRADescriptions_academyFeaturesICTF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRADescriptions_academyFeaturesICTF[\"JiraDescriptionsAsQuery_ICTF\"] = processedData_academyCartesian.apply(lambda x: calcICTFList(x.Description, \n",
    "                                                                                                                processedData_JIRADescriptions_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_academy_documentCount),axis=1)\n",
    "##\n",
    "processedData_JIRADescriptions_academyFeaturesICTF[\"JiraDescriptionsAsQuery_avgICTF\"] = processedData_JIRADescriptions_academyFeaturesICTF.apply(lambda x: calcAvgICTF(x.JiraDescriptionsAsQuery_ICTF, intermediateData_JIRA_academy_documentCount), axis=1)\n",
    "processedData_JIRADescriptions_academyFeaturesICTF[\"JiraDescriptionsAsQuery_maxICTF\"] = processedData_JIRADescriptions_academyFeaturesICTF.apply(lambda x: calcMaxICTF(x.JiraDescriptionsAsQuery_ICTF), axis=1)\n",
    "processedData_JIRADescriptions_academyFeaturesICTF[\"JiraDescriptionsAsQuery_devICTF\"] = processedData_JIRADescriptions_academyFeaturesICTF.apply(lambda x: calcDevICTF(x.JiraDescriptionsAsQuery_ICTF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRADescriptions_academyFeaturesICTF.to_pickle(path= \"../data/03_processed/processedData_JIRADescriptions_academyFeaturesICTF.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-ontario",
   "metadata": {},
   "source": [
    "#### ICTF Scores (JIRA Comments as query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-sheffield",
   "metadata": {},
   "source": [
    "#### Entropy (SVN as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVN_academyFeaturesEntropy = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVN_academyFeaturesEntropy[\"SvnAsQuery_Entropy\"] = processedData_academyCartesian.apply(lambda x: calcEntropyList(x.Commit_natural_text, \n",
    "                                                                                                                processedData_SVN_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_academy_documentCount,\n",
    "                                                                                                                intermediateData_SVN_academy.Commit_natural_text),axis=1)\n",
    "\n",
    "processedData_SVN_academyFeaturesEntropy[\"SvnAsQuery_avgEntropy\"] = processedData_SVN_academyFeaturesEntropy.apply(lambda x: calcAvgEntropy(x.SvnAsQuery_Entropy), axis=1)\n",
    "processedData_SVN_academyFeaturesEntropy[\"SvnAsQuery_medEntropy\"] = processedData_SVN_academyFeaturesEntropy.apply(lambda x: calcMedEntropy(x.SvnAsQuery_Entropy), axis=1)\n",
    "processedData_SVN_academyFeaturesEntropy[\"SvnAsQuery_maxEntropy\"] = processedData_SVN_academyFeaturesEntropy.apply(lambda x: calcMaxEntropy(x.SvnAsQuery_Entropy), axis=1)\n",
    "processedData_SVN_academyFeaturesEntropy[\"SvnAsQuery_devEntropy\"] = processedData_SVN_academyFeaturesEntropy.apply(lambda x: calcDevEntropy(x.SvnAsQuery_Entropy), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVN_academyFeaturesEntropy.to_pickle(path= \"../data/03_processed/processedData_SVN_academyFeaturesEntropy.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-iraqi",
   "metadata": {},
   "source": [
    "#### Entropy (SVNLogs as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNLogs_academyFeaturesEntropy = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNLogs_academyFeaturesEntropy[\"SvnLogsAsQuery_Entropy\"] = processedData_academyCartesian.apply(lambda x: calcEntropyList(x.Logs, \n",
    "                                                                                                                processedData_SVNLogs_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_academy_documentCount,\n",
    "                                                                                                                intermediateData_SVN_academy.Logs),axis=1)\n",
    "##\n",
    "processedData_SVNLogs_academyFeaturesEntropy[\"SvnLogsAsQuery_avgEntropy\"] = processedData_SVNLogs_academyFeaturesEntropy.apply(lambda x: calcAvgEntropy(x.SvnLogsAsQuery_Entropy), axis=1)\n",
    "processedData_SVNLogs_academyFeaturesEntropy[\"SvnLogsAsQuery_medEntropy\"] = processedData_SVNLogs_academyFeaturesEntropy.apply(lambda x: calcMedEntropy(x.SvnLogsAsQuery_Entropy), axis=1)\n",
    "processedData_SVNLogs_academyFeaturesEntropy[\"SvnLogsAsQuery_maxEntropy\"] = processedData_SVNLogs_academyFeaturesEntropy.apply(lambda x: calcMaxEntropy(x.SvnLogsAsQuery_Entropy), axis=1)\n",
    "processedData_SVNLogs_academyFeaturesEntropy[\"SvnLogsAsQuery_devEntropy\"] = processedData_SVNLogs_academyFeaturesEntropy.apply(lambda x: calcDevEntropy(x.SvnLogsAsQuery_Entropy), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNLogs_academyFeaturesEntropy.to_pickle(path= \"../data/03_processed/processedData_SVNLogs_academyFeaturesEntropy.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-recorder",
   "metadata": {},
   "source": [
    "#### Entropy (SVNUnitNames as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-roberts",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNUnitNames_academyFeaturesEntropy = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNUnitNames_academyFeaturesEntropy[\"SvnUnitNamesAsQuery_Entropy\"] = processedData_academyCartesian.apply(lambda x: calcEntropyList(x.Unit_names, \n",
    "                                                                                                                processedData_SVNUnitNames_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_academy_documentCount,\n",
    "                                                                                                                intermediateData_SVN_academy.Unit_names),axis=1)\n",
    "##\n",
    "processedData_SVNUnitNames_academyFeaturesEntropy[\"SvnUnitNamesAsQuery_avgEntropy\"] = processedData_SVNUnitNames_academyFeaturesEntropy.apply(lambda x: calcAvgEntropy(x.SvnUnitNamesAsQuery_Entropy), axis=1)\n",
    "processedData_SVNUnitNames_academyFeaturesEntropy[\"SvnUnitNamesAsQuery_medEntropy\"] = processedData_SVNUnitNames_academyFeaturesEntropy.apply(lambda x: calcMedEntropy(x.SvnUnitNamesAsQuery_Entropy), axis=1)\n",
    "processedData_SVNUnitNames_academyFeaturesEntropy[\"SvnUnitNamesAsQuery_maxEntropy\"] = processedData_SVNUnitNames_academyFeaturesEntropy.apply(lambda x: calcMaxEntropy(x.SvnUnitNamesAsQuery_Entropy), axis=1)\n",
    "processedData_SVNUnitNames_academyFeaturesEntropy[\"SvnUnitNamesAsQuery_devEntropy\"] = processedData_SVNUnitNames_academyFeaturesEntropy.apply(lambda x: calcDevEntropy(x.SvnUnitNamesAsQuery_Entropy), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNUnitNames_academyFeaturesEntropy.to_pickle(path= \"../data/03_processed/processedData_SVNUnitNames_academyFeaturesEntropy.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-kingston",
   "metadata": {},
   "source": [
    "#### Entropy (JIRA as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRA_academyFeaturesEntropy = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRA_academyFeaturesEntropy[\"JiraAsQuery_Entropy\"] = processedData_academyCartesian.apply(lambda x: calcEntropyList(x.Jira_natural_text, \n",
    "                                                                                                                processedData_JIRA_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_academy_documentCount,\n",
    "                                                                                                                intermediateData_JIRA_academy.Jira_natural_text),axis=1)\n",
    "##\n",
    "processedData_JIRA_academyFeaturesEntropy[\"JiraAsQuery_avgEntropy\"] = processedData_JIRA_academyFeaturesEntropy.apply(lambda x: calcAvgEntropy(x.JiraAsQuery_Entropy), axis=1)\n",
    "processedData_JIRA_academyFeaturesEntropy[\"JiraAsQuery_medEntropy\"] = processedData_JIRA_academyFeaturesEntropy.apply(lambda x: calcMedEntropy(x.JiraAsQuery_Entropy), axis=1)\n",
    "processedData_JIRA_academyFeaturesEntropy[\"JiraAsQuery_maxEntropy\"] = processedData_JIRA_academyFeaturesEntropy.apply(lambda x: calcMaxEntropy(x.JiraAsQuery_Entropy), axis=1)\n",
    "processedData_JIRA_academyFeaturesEntropy[\"JiraAsQuery_devEntropy\"] = processedData_JIRA_academyFeaturesEntropy.apply(lambda x: calcDevEntropy(x.JiraAsQuery_Entropy), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRA_academyFeaturesEntropy.to_pickle(path= \"../data/03_processed/processedData_JIRA_academyFeaturesEntropy.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-technical",
   "metadata": {},
   "source": [
    "#### Entropy (JIRA Summaries as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-romania",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRASummaries_academyFeaturesEntropy = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRASummaries_academyFeaturesEntropy[\"JiraSummariesAsQuery_Entropy\"] = processedData_academyCartesian.apply(lambda x: calcEntropyList(x.Summary, \n",
    "                                                                                                                processedData_JIRASummaries_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_academy_documentCount,\n",
    "                                                                                                                intermediateData_JIRA_academy.Summary),axis=1)\n",
    "##\n",
    "processedData_JIRASummaries_academyFeaturesEntropy[\"JiraSummariesAsQuery_avgEntropy\"] = processedData_JIRASummaries_academyFeaturesEntropy.apply(lambda x: calcAvgEntropy(x.JiraSummariesAsQuery_Entropy), axis=1)\n",
    "processedData_JIRASummaries_academyFeaturesEntropy[\"JiraSummariesAsQuery_medEntropy\"] = processedData_JIRASummaries_academyFeaturesEntropy.apply(lambda x: calcMedEntropy(x.JiraSummariesAsQuery_Entropy), axis=1)\n",
    "processedData_JIRASummaries_academyFeaturesEntropy[\"JiraSummariesAsQuery_maxEntropy\"] = processedData_JIRASummaries_academyFeaturesEntropy.apply(lambda x: calcMaxEntropy(x.JiraSummariesAsQuery_Entropy), axis=1)\n",
    "processedData_JIRASummaries_academyFeaturesEntropy[\"JiraSummariesAsQuery_devEntropy\"] = processedData_JIRASummaries_academyFeaturesEntropy.apply(lambda x: calcDevEntropy(x.JiraSummariesAsQuery_Entropy), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRASummaries_academyFeaturesEntropy.to_pickle(path= \"../data/03_processed/processedData_JIRASummaries_academyFeaturesEntropy.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-wallace",
   "metadata": {},
   "source": [
    "#### Entropy (JIRA Descriptions as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRADescriptions_academyFeaturesEntropy = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRADescriptions_academyFeaturesEntropy[\"JiraDescriptionsAsQuery_Entropy\"] = processedData_academyCartesian.apply(lambda x: calcEntropyList(x.Description, \n",
    "                                                                                                                processedData_JIRADescriptions_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_academy_documentCount,\n",
    "                                                                                                                intermediateData_JIRA_academy.Description),axis=1)\n",
    "##\n",
    "processedData_JIRADescriptions_academyFeaturesEntropy[\"JiraDescriptionsAsQuery_avgEntropy\"] = processedData_JIRADescriptions_academyFeaturesEntropy.apply(lambda x: calcAvgEntropy(x.JiraDescriptionsAsQuery_Entropy), axis=1)\n",
    "processedData_JIRADescriptions_academyFeaturesEntropy[\"JiraDescriptionsAsQuery_medEntropy\"] = processedData_JIRADescriptions_academyFeaturesEntropy.apply(lambda x: calcMedEntropy(x.JiraDescriptionsAsQuery_Entropy), axis=1)\n",
    "processedData_JIRADescriptions_academyFeaturesEntropy[\"JiraDescriptionsAsQuery_maxEntropy\"] = processedData_JIRADescriptions_academyFeaturesEntropy.apply(lambda x: calcMaxEntropy(x.JiraDescriptionsAsQuery_Entropy), axis=1)\n",
    "processedData_JIRADescriptions_academyFeaturesEntropy[\"JiraDescriptionsAsQuery_devEntropy\"] = processedData_JIRADescriptions_academyFeaturesEntropy.apply(lambda x: calcDevEntropy(x.JiraDescriptionsAsQuery_Entropy), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRADescriptions_academyFeaturesEntropy.to_pickle(path= \"../data/03_processed/processedData_JIRADescriptions_academyFeaturesEntropy.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-affiliation",
   "metadata": {},
   "source": [
    "#### Entropy (JIRA Comments as query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-kazakhstan",
   "metadata": {},
   "source": [
    "##### Query Scope (SVN as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVN_academyFeaturesQueryScope = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVN_academyFeaturesQueryScope[\"SvnAsQuery_QueryScope\"] = processedData_academyCartesian.apply(lambda x: calcQueryScope(x.Commit_natural_text, \n",
    "                                                                                                                intermediateData_SVN_academy.Commit_natural_text),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVN_academyFeaturesQueryScope.to_pickle(path= \"../data/03_processed/processedData_SVN_academyFeaturesQueryScope.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-madrid",
   "metadata": {},
   "source": [
    "##### Query Scope (SVNLogs as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNLogs_academyFeaturesQueryScope = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNLogs_academyFeaturesQueryScope[\"SvnLogsAsQuery_QueryScope\"] = processedData_academyCartesian.apply(lambda x: calcQueryScope(x.Logs, \n",
    "                                                                                                                intermediateData_SVN_academy.Logs),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNLogs_academyFeaturesQueryScope.to_pickle(path= \"../data/03_processed/processedData_SVNLogs_academyFeaturesQueryScope.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-brooks",
   "metadata": {},
   "source": [
    "##### Query Scope (SVNUnitNames as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNUnitNames_academyFeaturesQueryScope = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNUnitNames_academyFeaturesQueryScope[\"SvnUnitNamesAsQuery_QueryScope\"] = processedData_academyCartesian.apply(lambda x: calcQueryScope(x.Unit_names, \n",
    "                                                                                                                intermediateData_SVN_academy.Unit_names),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNUnitNames_academyFeaturesQueryScope.to_pickle(path= \"../data/03_processed/processedData_SVNUnitNames_academyFeaturesQueryScope.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-cocktail",
   "metadata": {},
   "source": [
    "##### Query Scope (JIRA as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-keyboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRA_academyFeaturesQueryScope = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRA_academyFeaturesQueryScope[\"JiraAsQuery_QueryScope\"] = processedData_academyCartesian.apply(lambda x: calcQueryScope(x.Jira_natural_text, \n",
    "                                                                                                                intermediateData_JIRA_academy.Jira_natural_text),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRA_academyFeaturesQueryScope.to_pickle(path= \"../data/03_processed/processedData_JIRA_academyFeaturesQueryScope.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-mumbai",
   "metadata": {},
   "source": [
    "##### Query Scope (JIRA Summaries as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-paint",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRASummaries_academyFeaturesQueryScope = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRASummaries_academyFeaturesQueryScope[\"JiraSummariesAsQuery_QueryScope\"] = processedData_academyCartesian.apply(lambda x: calcQueryScope(x.Summary, \n",
    "                                                                                                                intermediateData_JIRA_academy.Summary),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRASummaries_academyFeaturesQueryScope.to_pickle(path= \"../data/03_processed/processedData_JIRASummaries_academyFeaturesQueryScope.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-hopkins",
   "metadata": {},
   "source": [
    "##### Query Scope (JIRA Descriptions as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRADescriptions_academyFeaturesQueryScope = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRADescriptions_academyFeaturesQueryScope[\"JiraDescriptionsAsQuery_QueryScope\"] = processedData_academyCartesian.apply(lambda x: calcQueryScope(x.Description, \n",
    "                                                                                                                intermediateData_JIRA_academy.Description),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRADescriptions_academyFeaturesQueryScope.to_pickle(path= \"../data/03_processed/processedData_JIRADescriptions_academyFeaturesQueryScope.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-israel",
   "metadata": {},
   "source": [
    "##### Query Scope (JIRA Comments as query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-yorkshire",
   "metadata": {},
   "source": [
    "#### Kullback-Leiber divergence (SVN as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-marks",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVN_academyFeaturesSCS = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVN_academyFeaturesSCS[\"SvnAsQuery_SCS\"] = processedData_academyCartesian.apply(lambda x: calcSCS(x.Commit_natural_text, \n",
    "                                                                                                                processedData_SVN_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_academy_documentCount),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVN_academyFeaturesSCS.to_pickle(path= \"../data/03_processed/processedData_SVN_academyFeaturesSCS.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-paint",
   "metadata": {},
   "source": [
    "#### Kullback-Leiber divergence (SVNLogs as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-helmet",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNLogs_academyFeaturesSCS = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNLogs_academyFeaturesSCS[\"SvnLogsAsQuery_SCS\"] = processedData_academyCartesian.apply(lambda x: calcSCS(x.Logs, \n",
    "                                                                                                                processedData_SVNLogs_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_academy_documentCount),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNLogs_academyFeaturesSCS.to_pickle(path= \"../data/03_processed/processedData_SVNLogs_academyFeaturesSCS.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-calendar",
   "metadata": {},
   "source": [
    "#### Kullback-Leiber divergence (SVNUnitNames as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNUnitNames_academyFeaturesSCS = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNUnitNames_academyFeaturesSCS[\"SvnUnitNamesAsQuery_SCS\"] = processedData_academyCartesian.apply(lambda x: calcSCS(x.Unit_names, \n",
    "                                                                                                                processedData_SVNUnitNames_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_academy_documentCount),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNUnitNames_academyFeaturesSCS.to_pickle(path= \"../data/03_processed/processedData_SVNUnitNames_academyFeaturesSCS.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-cargo",
   "metadata": {},
   "source": [
    "#### Kullback-Leiber divergence (JIRA as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRA_academyFeaturesSCS = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRA_academyFeaturesSCS[\"JiraAsQuery_SCS\"] = processedData_academyCartesian.apply(lambda x: calcSCS(x.Jira_natural_text, \n",
    "                                                                                                                processedData_JIRA_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_academy_documentCount),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRA_academyFeaturesSCS.to_pickle(path= \"../data/03_processed/processedData_JIRA_academyFeaturesSCS.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-keeping",
   "metadata": {},
   "source": [
    "#### Kullback-Leiber divergence (JIRA Summaries as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRASummaries_academyFeaturesSCS = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRASummaries_academyFeaturesSCS[\"JiraSummariesAsQuery_SCS\"] = processedData_academyCartesian.apply(lambda x: calcSCS(x.Summary, \n",
    "                                                                                                                processedData_JIRASummaries_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_academy_documentCount),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRASummaries_academyFeaturesSCS.to_pickle(path= \"../data/03_processed/processedData_JIRASummaries_academyFeaturesSCS.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Kullback-Leiber divergence (JIRA Description as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-adventure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRADescriptions_academyFeaturesSCS = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRADescriptions_academyFeaturesSCS[\"JiraDescriptionsAsQuery_SCS\"] = processedData_academyCartesian.apply(lambda x: calcSCS(x.Description, \n",
    "                                                                                                                processedData_JIRADescriptions_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_academy_documentCount),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRADescriptions_academyFeaturesSCS.to_pickle(path= \"../data/03_processed/processedData_JIRADescriptions_academyFeaturesSCS.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Kullback-Leiber divergence (JIRA Comments as query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-execution",
   "metadata": {},
   "source": [
    "#### SCQ (SVN as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVN_academyFeaturesSCQ = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVN_academyFeaturesSCQ[\"SvnAsQuery_SCQ\"] = processedData_academyCartesian.apply(lambda x: calcSCQList(x.Commit_natural_text, intermediateData_SVN_academy.Commit_natural_text,\n",
    "                                                                                                                                         processedData_SVN_academyCountVectorizer,\n",
    "                                                                                                                                         processedData_SVN_academyCountTF_IDF,\n",
    "                                                                                                                                         intermediateData_SVN_academy_documentCount),axis=1)\n",
    "\n",
    "processedData_SVN_academyFeaturesSCQ[\"SvnAsQuery_avgSCQ\"] = processedData_SVN_academyFeaturesSCQ.apply(lambda x: calcAvgSCQ(x.SvnAsQuery_SCQ, intermediateData_SVN_academy_documentCount), axis=1)\n",
    "processedData_SVN_academyFeaturesSCQ[\"SvnAsQuery_maxSCQ\"] = processedData_SVN_academyFeaturesSCQ.apply(lambda x: calcMaxSCQ(x.SvnAsQuery_SCQ), axis=1)\n",
    "processedData_SVN_academyFeaturesSCQ[\"SvnAsQuery_sumSCQ\"] = processedData_SVN_academyFeaturesSCQ.apply(lambda x: calcSumSCQ(x.SvnAsQuery_SCQ), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVN_academyFeaturesSCQ.to_pickle(path= \"../data/03_processed/processedData_SVN_academyFeaturesSCQ.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-technical",
   "metadata": {},
   "source": [
    "#### SCQ (SVNLogs as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-cattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNLogs_academyFeaturesSCQ = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNLogs_academyFeaturesSCQ[\"SvnLogsAsQuery_SCQ\"] = processedData_academyCartesian.apply(lambda x: calcSCQList(x.Logs, intermediateData_SVN_academy.Logs,\n",
    "                                                                                                                                         processedData_SVNLogs_academyCountVectorizer,\n",
    "                                                                                                                                         processedData_SVNLogs_academyCountTF_IDF,\n",
    "                                                                                                                                         intermediateData_SVN_academy_documentCount),axis=1)\n",
    "\n",
    "processedData_SVNLogs_academyFeaturesSCQ[\"SvnLogsAsQuery_avgSCQ\"] = processedData_SVNLogs_academyFeaturesSCQ.apply(lambda x: calcAvgSCQ(x.SvnLogsAsQuery_SCQ, intermediateData_SVN_academy_documentCount), axis=1)\n",
    "processedData_SVNLogs_academyFeaturesSCQ[\"SvnLogsAsQuery_maxSCQ\"] = processedData_SVNLogs_academyFeaturesSCQ.apply(lambda x: calcMaxSCQ(x.SvnLogsAsQuery_SCQ), axis=1)\n",
    "processedData_SVNLogs_academyFeaturesSCQ[\"SvnLogsAsQuery_sumSCQ\"] = processedData_SVNLogs_academyFeaturesSCQ.apply(lambda x: calcSumSCQ(x.SvnLogsAsQuery_SCQ), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNLogs_academyFeaturesSCQ.to_pickle(path= \"../data/03_processed/processedData_SVNLogs_academyFeaturesSCQ.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-guess",
   "metadata": {},
   "source": [
    "#### SCQ (SVNUnitNames as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNUnitNames_academyFeaturesSCQ = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNUnitNames_academyFeaturesSCQ[\"SvnUnitNamesAsQuery_SCQ\"] = processedData_academyCartesian.apply(lambda x: calcSCQList(x.Unit_names, intermediateData_SVN_academy.Unit_names,\n",
    "                                                                                                                                         processedData_SVNUnitNames_academyCountVectorizer,\n",
    "                                                                                                                                         processedData_SVNUnitNames_academyCountTF_IDF,\n",
    "                                                                                                                                         intermediateData_SVN_academy_documentCount),axis=1)\n",
    "\n",
    "processedData_SVNUnitNames_academyFeaturesSCQ[\"SvnUnitNamesAsQuery_avgSCQ\"] = processedData_SVNUnitNames_academyFeaturesSCQ.apply(lambda x: calcAvgSCQ(x.SvnUnitNamesAsQuery_SCQ, intermediateData_SVN_academy_documentCount), axis=1)\n",
    "processedData_SVNUnitNames_academyFeaturesSCQ[\"SvnUnitNamesAsQuery_maxSCQ\"] = processedData_SVNUnitNames_academyFeaturesSCQ.apply(lambda x: calcMaxSCQ(x.SvnUnitNamesAsQuery_SCQ), axis=1)\n",
    "processedData_SVNUnitNames_academyFeaturesSCQ[\"SvnUnitNamesAsQuery_sumSCQ\"] = processedData_SVNUnitNames_academyFeaturesSCQ.apply(lambda x: calcSumSCQ(x.SvnUnitNamesAsQuery_SCQ), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNUnitNames_academyFeaturesSCQ.to_pickle(path= \"../data/03_processed/processedData_SVNUnitNames_academyFeaturesSCQ.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-laundry",
   "metadata": {},
   "source": [
    "#### SCQ (JIRA as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-police",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRA_academyFeaturesSCQ = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRA_academyFeaturesSCQ[\"JiraAsQuery_SCQ\"] = processedData_academyCartesian.apply(lambda x: calcSCQList(x.Jira_natural_text, intermediateData_JIRA_academy.Jira_natural_text,\n",
    "                                                                                                                                         processedData_JIRA_academyCountVectorizer,\n",
    "                                                                                                                                         processedData_JIRA_academyTF_IDF,\n",
    "                                                                                                                                         intermediateData_JIRA_academy_documentCount),axis=1)\n",
    "\n",
    "processedData_JIRA_academyFeaturesSCQ[\"JiraAsQuery_avgSCQ\"] = processedData_JIRA_academyFeaturesSCQ.apply(lambda x: calcAvgSCQ(x.JiraAsQuery_SCQ, intermediateData_JIRA_academy_documentCount), axis=1)\n",
    "processedData_JIRA_academyFeaturesSCQ[\"JiraAsQuery_maxSCQ\"] = processedData_JIRA_academyFeaturesSCQ.apply(lambda x: calcMaxSCQ(x.JiraAsQuery_SCQ), axis=1)\n",
    "processedData_JIRA_academyFeaturesSCQ[\"JiraAsQuery_sumSCQ\"] = processedData_JIRA_academyFeaturesSCQ.apply(lambda x: calcSumSCQ(x.JiraAsQuery_SCQ), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRA_academyFeaturesSCQ.to_pickle(path= \"../data/03_processed/processedData_JIRA_academyFeaturesSCQ.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-updating",
   "metadata": {},
   "source": [
    "#### SCQ (JIRA Summaries as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRASummaries_academyFeaturesSCQ = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRASummaries_academyFeaturesSCQ[\"JiraSummariesAsQuery_SCQ\"] = processedData_academyCartesian.apply(lambda x: calcSCQList(x.Summary, intermediateData_JIRA_academy.Summary,\n",
    "                                                                                                                                         processedData_JIRASummaries_academyCountVectorizer,\n",
    "                                                                                                                                         processedData_JIRASummaries_academyCountTF_IDF,\n",
    "                                                                                                                                         intermediateData_JIRA_academy_documentCount),axis=1)\n",
    "\n",
    "processedData_JIRASummaries_academyFeaturesSCQ[\"JiraSummariesAsQuery_avgSCQ\"] = processedData_JIRASummaries_academyFeaturesSCQ.apply(lambda x: calcAvgSCQ(x.JiraSummariesAsQuery_SCQ, intermediateData_JIRA_academy_documentCount), axis=1)\n",
    "processedData_JIRASummaries_academyFeaturesSCQ[\"JiraSummariesAsQuery_maxSCQ\"] = processedData_JIRASummaries_academyFeaturesSCQ.apply(lambda x: calcMaxSCQ(x.JiraSummariesAsQuery_SCQ), axis=1)\n",
    "processedData_JIRASummaries_academyFeaturesSCQ[\"JiraSummariesAsQuery_sumSCQ\"] = processedData_JIRASummaries_academyFeaturesSCQ.apply(lambda x: calcSumSCQ(x.JiraSummariesAsQuery_SCQ), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRASummaries_academyFeaturesSCQ.to_pickle(path= \"../data/03_processed/processedData_JIRASummaries_academyFeaturesSCQ.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-spirit",
   "metadata": {},
   "source": [
    "#### SCQ (JIRA Descriptions as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRADescriptions_academyFeaturesSCQ = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRADescriptions_academyFeaturesSCQ[\"JiraDescriptionsAsQuery_SCQ\"] = processedData_academyCartesian.apply(lambda x: calcSCQList(x.Description, intermediateData_JIRA_academy.Description,\n",
    "                                                                                                                                         processedData_JIRADescriptions_academyCountVectorizer,\n",
    "                                                                                                                                         processedData_JIRADescriptions_academyCountTF_IDF,\n",
    "                                                                                                                                         intermediateData_JIRA_academy_documentCount),axis=1)\n",
    "\n",
    "processedData_JIRADescriptions_academyFeaturesSCQ[\"JiraDescriptionsAsQuery_avgSCQ\"] = processedData_JIRADescriptions_academyFeaturesSCQ.apply(lambda x: calcAvgSCQ(x.JiraDescriptionsAsQuery_SCQ, intermediateData_JIRA_academy_documentCount), axis=1)\n",
    "processedData_JIRADescriptions_academyFeaturesSCQ[\"JiraDescriptionsAsQuery_maxSCQ\"] = processedData_JIRADescriptions_academyFeaturesSCQ.apply(lambda x: calcMaxSCQ(x.JiraDescriptionsAsQuery_SCQ), axis=1)\n",
    "processedData_JIRADescriptions_academyFeaturesSCQ[\"JiraDescriptionsAsQuery_sumSCQ\"] = processedData_JIRADescriptions_academyFeaturesSCQ.apply(lambda x: calcSumSCQ(x.JiraDescriptionsAsQuery_SCQ), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRADescriptions_academyFeaturesSCQ.to_pickle(path= \"../data/03_processed/processedData_JIRADescriptions_academyFeaturesSCQ.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-walker",
   "metadata": {},
   "source": [
    "#### SCQ (JIRA Comments as Query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-owner",
   "metadata": {},
   "source": [
    "#### PMI (SVN as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create pairs and find frequencies\n",
    "termPairs = createTermPairs(processedData_SVN_academyCountVectorizer)\n",
    "termFrequencies = findTermFrequencies(processedData_SVN_academyCountVectorizer, intermediateData_SVN_academy.Commit_natural_text)\n",
    "termPairFrequencies = findTermPairFrequencies(termPairs, intermediateData_SVN_academy.Commit_natural_text)\n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVN_academyFeaturesPMI = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVN_academyFeaturesPMI[\"SvnAsQuery_PMI\"] = processedData_academyCartesian.apply(lambda x: calcPMIList(x.Commit_natural_text, \n",
    "                                                                                                                                  termFrequencies, \n",
    "                                                                                                                                  termPairFrequencies, \n",
    "                                                                                                                                  intermediateData_SVN_academy.Commit_natural_text),axis=1)\n",
    "\n",
    "processedData_SVN_academyFeaturesPMI[\"SvnAsQuery_avgPMI\"] = processedData_SVN_academyFeaturesPMI.apply(lambda x: calcAvgPMI(x.SvnAsQuery_PMI), axis=1)\n",
    "processedData_SVN_academyFeaturesPMI[\"SvnAsQuery_maxPMI\"] = processedData_SVN_academyFeaturesPMI.apply(lambda x: calcMaxPMI(x.SvnAsQuery_PMI), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "processedData_SVN_academyFeaturesPMI.drop('SvnAsQuery_PMI', axis = 1, inplace=True)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVN_academyFeaturesPMI.to_pickle(path= \"../data/03_processed/processedData_SVN_academyFeaturesPMI.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-hotel",
   "metadata": {},
   "source": [
    "#### PMI (SVNLogs as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create pairs and find frequencies\n",
    "termPairs = createTermPairs(processedData_SVNLogs_academyCountVectorizer)\n",
    "termFrequencies = findTermFrequencies(processedData_SVNLogs_academyCountVectorizer, intermediateData_SVN_academy.Logs)\n",
    "termPairFrequencies = findTermPairFrequencies(termPairs, intermediateData_SVN_academy.Logs)\n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNLogs_academyFeaturesPMI = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNLogs_academyFeaturesPMI[\"SvnLogsAsQuery_PMI\"] = processedData_academyCartesian.apply(lambda x: calcPMIList(x.Logs, \n",
    "                                                                                                                                  termFrequencies, \n",
    "                                                                                                                                  termPairFrequencies, \n",
    "                                                                                                                                  intermediateData_SVN_academy.Logs),axis=1)\n",
    "\n",
    "processedData_SVNLogs_academyFeaturesPMI[\"SvnLogsAsQuery_avgPMI\"] = processedData_SVNLogs_academyFeaturesPMI.apply(lambda x: calcAvgPMI(x.SvnLogsAsQuery_PMI), axis=1)\n",
    "processedData_SVNLogs_academyFeaturesPMI[\"SvnLogsAsQuery_maxPMI\"] = processedData_SVNLogs_academyFeaturesPMI.apply(lambda x: calcMaxPMI(x.SvnLogsAsQuery_PMI), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "processedData_SVNLogs_academyFeaturesPMI.drop('SvnLogsAsQuery_PMI', axis = 1, inplace=True)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNLogs_academyFeaturesPMI.to_pickle(path= \"../data/03_processed/processedData_SVNLogs_academyFeaturesPMI.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-efficiency",
   "metadata": {},
   "source": [
    "#### PMI (SVNUnitNames as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-feeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create pairs and find frequencies\n",
    "termPairs = createTermPairs(processedData_SVNUnitNames_academyCountVectorizer)\n",
    "termFrequencies = findTermFrequencies(processedData_SVNUnitNames_academyCountVectorizer, intermediateData_SVN_academy.Unit_names)\n",
    "termPairFrequencies = findTermPairFrequencies(termPairs, intermediateData_SVN_academy.Unit_names)\n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNUnitNames_academyFeaturesPMI = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNUnitNames_academyFeaturesPMI[\"SvnUnitNamesAsQuery_PMI\"] = processedData_academyCartesian.apply(lambda x: calcPMIList(x.Unit_names, \n",
    "                                                                                                                                  termFrequencies, \n",
    "                                                                                                                                  termPairFrequencies, \n",
    "                                                                                                                                  intermediateData_SVN_academy.Unit_names),axis=1)\n",
    "\n",
    "processedData_SVNUnitNames_academyFeaturesPMI[\"SvnUnitNamesAsQuery_avgPMI\"] = processedData_SVNUnitNames_academyFeaturesPMI.apply(lambda x: calcAvgPMI(x.SvnUnitNamesAsQuery_PMI), axis=1)\n",
    "processedData_SVNUnitNames_academyFeaturesPMI[\"SvnUnitNamesAsQuery_maxPMI\"] = processedData_SVNUnitNames_academyFeaturesPMI.apply(lambda x: calcMaxPMI(x.SvnUnitNamesAsQuery_PMI), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "processedData_SVNUnitNames_academyFeaturesPMI.drop('SvnUnitNamesAsQuery_PMI', axis = 1, inplace=True)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNUnitNames_academyFeaturesPMI.to_pickle(path= \"../data/03_processed/processedData_SVNUnitNames_academyFeaturesPMI.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-stomach",
   "metadata": {},
   "source": [
    "#### PMI (JIRA as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create pairs and find frequencies\n",
    "termPairs = createTermPairs(processedData_JIRA_academyCountVectorizer)\n",
    "termFrequencies = findTermFrequencies(processedData_JIRA_academyCountVectorizer, intermediateData_JIRA_academy.Jira_natural_text)\n",
    "termPairFrequencies = findTermPairFrequencies(termPairs, intermediateData_JIRA_academy.Jira_natural_text)\n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRA_academyFeaturesPMI = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRA_academyFeaturesPMI[\"JiraAsQuery_PMI\"] = processedData_academyCartesian.apply(lambda x: calcPMIList(x.Jira_natural_text, \n",
    "                                                                                                                                  termFrequencies, \n",
    "                                                                                                                                  termPairFrequencies, \n",
    "                                                                                                                                  intermediateData_JIRA_academy.Jira_natural_text),axis=1)\n",
    "\n",
    "processedData_JIRA_academyFeaturesPMI[\"JiraAsQuery_avgPMI\"] = processedData_JIRA_academyFeaturesPMI.apply(lambda x: calcAvgPMI(x.JiraAsQuery_PMI), axis=1)\n",
    "processedData_JIRA_academyFeaturesPMI[\"JiraAsQuery_maxPMI\"] = processedData_JIRA_academyFeaturesPMI.apply(lambda x: calcMaxPMI(x.JiraAsQuery_PMI), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "processedData_JIRA_academyFeaturesPMI.drop('JiraAsQuery_PMI', axis = 1, inplace=True)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRA_academyFeaturesPMI.to_pickle(path= \"../data/03_processed/processedData_JIRA_academyFeaturesPMI.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-youth",
   "metadata": {},
   "source": [
    "#### PMI (JIRA Summaries as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create pairs and find frequencies\n",
    "termPairs = createTermPairs(processedData_JIRASummaries_academyCountVectorizer)\n",
    "termFrequencies = findTermFrequencies(processedData_JIRASummaries_academyCountVectorizer, intermediateData_JIRA_academy.Summary)\n",
    "termPairFrequencies = findTermPairFrequencies(termPairs, intermediateData_JIRA_academy.Summary)\n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRASummaries_academyFeaturesPMI = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRASummaries_academyFeaturesPMI[\"JiraSummariesAsQuery_PMI\"] = processedData_academyCartesian.apply(lambda x: calcPMIList(x.Summary, \n",
    "                                                                                                                                  termFrequencies, \n",
    "                                                                                                                                  termPairFrequencies, \n",
    "                                                                                                                                  intermediateData_JIRA_academy.Summary),axis=1)\n",
    "\n",
    "processedData_JIRASummaries_academyFeaturesPMI[\"JiraSummariesAsQuery_avgPMI\"] = processedData_JIRASummaries_academyFeaturesPMI.apply(lambda x: calcAvgPMI(x.JiraSummariesAsQuery_PMI), axis=1)\n",
    "processedData_JIRASummaries_academyFeaturesPMI[\"JiraSummariesAsQuery_maxPMI\"] = processedData_JIRASummaries_academyFeaturesPMI.apply(lambda x: calcMaxPMI(x.JiraSummariesAsQuery_PMI), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "processedData_JIRASummaries_academyFeaturesPMI.drop('JiraSummariesAsQuery_PMI', axis = 1, inplace=True)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRASummaries_academyFeaturesPMI.to_pickle(path= \"../data/03_processed/processedData_JIRASummaries_academyFeaturesPMI.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-award",
   "metadata": {},
   "source": [
    "#### PMI (JIRA Descriptions as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create pairs and find frequencies\n",
    "termPairs = createTermPairs(processedData_JIRADescriptions_academyCountVectorizer)\n",
    "termFrequencies = findTermFrequencies(processedData_JIRADescriptions_academyCountVectorizer, intermediateData_JIRA_academy.Description)\n",
    "termPairFrequencies = findTermPairFrequencies(termPairs, intermediateData_JIRA_academy.Description)\n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRADescriptions_academyFeaturesPMI = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRADescriptions_academyFeaturesPMI[\"JiraDescriptionsAsQuery_PMI\"] = processedData_academyCartesian.apply(lambda x: calcPMIList(x.Description, \n",
    "                                                                                                                                  termFrequencies, \n",
    "                                                                                                                                  termPairFrequencies, \n",
    "                                                                                                                                  intermediateData_JIRA_academy.Description),axis=1)\n",
    "\n",
    "processedData_JIRADescriptions_academyFeaturesPMI[\"JiraDescriptionsAsQuery_avgPMI\"] = processedData_JIRADescriptions_academyFeaturesPMI.apply(lambda x: calcAvgPMI(x.JiraDescriptionsAsQuery_PMI), axis=1)\n",
    "processedData_JIRADescriptions_academyFeaturesPMI[\"JiraDescriptionsAsQuery_maxPMI\"] = processedData_JIRADescriptions_academyFeaturesPMI.apply(lambda x: calcMaxPMI(x.JiraDescriptionsAsQuery_PMI), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "processedData_JIRADescriptions_academyFeaturesPMI.drop('JiraDescriptionsAsQuery_PMI', axis = 1, inplace=True)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRADescriptions_academyFeaturesPMI.to_pickle(path= \"../data/03_processed/processedData_JIRADescriptions_academyFeaturesPMI.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-convert",
   "metadata": {},
   "source": [
    "#### PMI (JIRA Comments as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-blocking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def normalizeData(dataFrame):\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    names = dataFrame.columns\n",
    "    d = scaler.fit_transform(dataFrame)\n",
    "    scaledDataFrame = pd.DataFrame(d, columns=names)\n",
    "    return(scaledDataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-fifteen",
   "metadata": {},
   "source": [
    "# Normalize all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-dominican",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "################################## Loading #################################\n",
    "#Load Process-Related Features\n",
    "processedData_academyFeaturesTime = pd.read_pickle(r'../data/03_processed/processedData_academyFeaturesTime.pkl')\n",
    "processedData_academyFeaturesStakeholder = pd.read_pickle(r'../data/03_processed/processedData_academyFeaturesStakeholder.pkl')\n",
    "\n",
    "#Load IR-Related Features - unigram\n",
    "processedData_academy_features_VsmLogsJiraAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmLogsJiraAsQuery.pkl')\n",
    "processedData_academy_features_VsmLogsLogAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmLogsLogAsQuery.pkl')\n",
    "processedData_academy_features_VsmUnitNamesJiraAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmUnitNamesJiraAsQuery.pkl')\n",
    "processedData_academy_features_VsmUnitNamesUnitNamesAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmUnitNamesUnitNamesAsQuery.pkl')\n",
    "\n",
    "#processedData_academy_features_VsmUnitNamesCommentsCommentsAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmUnitNamesCommentsCommentsAsQuery.pkl')\n",
    "#processedData_academy_features_VsmUnitNamesCommentsUnitNamesAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmUnitNamesCommentsUnitNamesAsQuery.pkl')\n",
    "processedData_academy_features_VsmUnitNamesDescriptionDescriptionAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmUnitNamesDescriptionDescriptionAsQuery.pkl')\n",
    "processedData_academy_features_VsmUnitNamesDescriptionUnitNamesAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmUnitNamesDescriptionUnitNamesAsQuery.pkl')\n",
    "\n",
    "#processedData_academy_features_VsmVerbPruningUnitNamesJiraAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmVerbPruningUnitNamesJiraAsQuery.pkl')\n",
    "#processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery.pkl')\n",
    "processedData_academy_features_VsmSummaryLogsSummaryAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSummaryLogsSummaryAsQuery.pkl')\n",
    "processedData_academy_features_VsmSummaryLogsLogsAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSummaryLogsLogsAsQuery.pkl')\n",
    "processedData_academy_features_VsmSummaryUnitNamesSummaryAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSummaryUnitNamesSummaryAsQuery.pkl')\n",
    "processedData_academy_features_VsmSummaryUnitNamesUnitNamesAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSummaryUnitNamesUnitNamesAsQuery.pkl')\n",
    "processedData_academy_features_VsmDescriptionDescriptionAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmDescriptionDescriptionAsQuery.pkl')\n",
    "processedData_academy_features_VsmDescriptionLogsAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmDescriptionLogsAsQuery.pkl')\n",
    "#processedData_academy_features_VsmCommentsCommentsAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmCommentsCommentsAsQuery.pkl')\n",
    "#processedData_academy_features_VsmCommentsLogsAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmCommentsLogsAsQuery.pkl')\n",
    "\n",
    "processedData_academy_features_VsmSvnJiraJiraAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSvnJiraJiraAsQuery.pkl')\n",
    "processedData_academy_features_VsmSvnJiraSvnAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSvnJiraSvnAsQuery.pkl')\n",
    "processedData_academy_features_VsmSvnSummarySvnAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSvnSummarySvnAsQuery.pkl')\n",
    "processedData_academy_features_VsmSvnSummarySummaryAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSvnSummarySummaryAsQuery.pkl')\n",
    "processedData_academy_features_VsmSvnDescriptionSvnAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSvnDescriptionSvnAsQuery.pkl')\n",
    "processedData_academy_features_VsmSvnDescriptionDescriptionAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSvnDescriptionDescriptionAsQuery.pkl')\n",
    "#processedData_academy_features_VsmSvnCommentsSvnAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSvnCommentsSvnAsQuery.pkl')\n",
    "#processedData_academy_features_VsmSvnCommentsCommentsAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSvnCommentsCommentsAsQuery.pkl')\n",
    "\n",
    "\n",
    "#Load IR-Related Features - bigram\n",
    "#processedData_academy_features_VsmLogsJiraAsQuery_2gram = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmLogsJiraAsQuery_2gram.pkl')\n",
    "#processedData_academy_features_VsmLogsLogAsQuery_2gram = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmLogsLogAsQuery_2gram.pkl')\n",
    "#processedData_academy_features_VsmUnitNamesJiraAsQuery_2gram = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmUnitNamesJiraAsQuery_2gram.pkl')\n",
    "#processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_2gram = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_2gram.pkl')\n",
    "#processedData_academy_features_VsmCommentsLogsAsQuery_2gram = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmCommentsLogsAsQuery_2gram.pkl')\n",
    "#processedData_academy_features_VsmCommentsCommentsAsQuery_2gram = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmCommentsCommentsAsQuery_2gram.pkl')\n",
    "\n",
    "\n",
    "#Load Document Statistics Features\n",
    "processedData_JIRA_academyFeaturesUniqueWordCount = pd.read_pickle(r\"../data/03_processed/processedData_JIRA_academyFeaturesUniqueWordCount.pkl\")\n",
    "processedData_SVN_academyFeaturesUniqueWordCount = pd.read_pickle(r\"../data/03_processed/processedData_SVN_academyFeaturesUniqueWordCount.pkl\")\n",
    "processedData_JIRA_academyFeaturesTotalWordCount = pd.read_pickle(r\"../data/03_processed/processedData_JIRA_academyFeaturesTotalWordCount.pkl\")\n",
    "processedData_SVN_academyFeaturesTotalWordCount = pd.read_pickle(r\"../data/03_processed/processedData_SVN_academyFeaturesTotalWordCount.pkl\")\n",
    "processedData_JIRA_academyFeaturesOverlapPercentage = pd.read_pickle(r\"../data/03_processed/processedData_JIRA_academyFeaturesOverlapPercentage.pkl\")\n",
    "processedData_SVN_academyFeaturesOverlapPercentage = pd.read_pickle(r\"../data/03_processed/processedData_SVN_academyFeaturesOverlapPercentage.pkl\")\n",
    "processedData_UNION_academyFeaturesOverlapPercentage = pd.read_pickle(r\"../data/03_processed/processedData_UNION_academyFeaturesOverlapPercentage.pkl\")\n",
    "\n",
    "#Load Query Quality Features\n",
    "#processedData_academyFeaturesQueryQuality = pd.read_pickle(r'../data/03_processed/processedData_academyFeaturesQueryQuality.pkl')\n",
    "processedData_SVN_academyFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_SVN_academyFeaturesIDF.pkl')\n",
    "processedData_SVNLogs_academyFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_academyFeaturesIDF.pkl')\n",
    "processedData_SVNUnitNames_academyFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_academyFeaturesIDF.pkl')\n",
    "processedData_JIRA_academyFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_JIRA_academyFeaturesIDF.pkl')\n",
    "processedData_JIRASummaries_academyFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_academyFeaturesIDF.pkl')\n",
    "processedData_JIRADescriptions_academyFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_academyFeaturesIDF.pkl')\n",
    "#processedData_JIRAComments_academyFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_academyFeaturesIDF.pkl')\n",
    "\n",
    "\n",
    "processedData_SVN_academyFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_SVN_academyFeaturesICTF.pkl')\n",
    "processedData_SVNLogs_academyFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_academyFeaturesICTF.pkl')\n",
    "processedData_SVNUnitNames_academyFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_academyFeaturesICTF.pkl')\n",
    "processedData_JIRA_academyFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_JIRA_academyFeaturesICTF.pkl')\n",
    "processedData_JIRASummaries_academyFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_academyFeaturesICTF.pkl')\n",
    "processedData_JIRADescriptions_academyFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_academyFeaturesICTF.pkl')\n",
    "#processedData_JIRAComments_academyFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_academyFeaturesICTF.pkl')\n",
    "\n",
    "\n",
    "processedData_SVN_academyFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_SVN_academyFeaturesEntropy.pkl')\n",
    "processedData_SVNLogs_academyFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_academyFeaturesEntropy.pkl')\n",
    "processedData_SVNUnitNames_academyFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_academyFeaturesEntropy.pkl')\n",
    "processedData_JIRA_academyFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_JIRA_academyFeaturesEntropy.pkl')\n",
    "processedData_JIRASummaries_academyFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_academyFeaturesEntropy.pkl')\n",
    "processedData_JIRADescriptions_academyFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_academyFeaturesEntropy.pkl')\n",
    "#processedData_JIRAComments_academyFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_academyFeaturesEntropy.pkl')\n",
    "\n",
    "\n",
    "processedData_SVN_academyFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_SVN_academyFeaturesQueryScope.pkl')\n",
    "processedData_SVNLogs_academyFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_academyFeaturesQueryScope.pkl')\n",
    "processedData_SVNUnitNames_academyFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_academyFeaturesQueryScope.pkl')\n",
    "processedData_JIRA_academyFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_JIRA_academyFeaturesQueryScope.pkl')\n",
    "processedData_JIRASummaries_academyFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_academyFeaturesQueryScope.pkl')\n",
    "processedData_JIRADescriptions_academyFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_academyFeaturesQueryScope.pkl')\n",
    "#processedData_JIRAComments_academyFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_academyFeaturesQueryScope.pkl')\n",
    "\n",
    "\n",
    "processedData_SVN_academyFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_SVN_academyFeaturesSCS.pkl')\n",
    "processedData_SVNLogs_academyFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_academyFeaturesSCS.pkl')\n",
    "processedData_SVNUnitNames_academyFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_academyFeaturesSCS.pkl')\n",
    "processedData_JIRA_academyFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_JIRA_academyFeaturesSCS.pkl')\n",
    "processedData_JIRASummaries_academyFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_academyFeaturesSCS.pkl')\n",
    "processedData_JIRADescriptions_academyFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_academyFeaturesSCS.pkl')\n",
    "#processedData_JIRAComments_academyFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_academyFeaturesSCS.pkl')\n",
    "\n",
    "\n",
    "processedData_SVN_academyFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_SVN_academyFeaturesSCQ.pkl')\n",
    "processedData_SVNLogs_academyFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_academyFeaturesSCQ.pkl')\n",
    "processedData_SVNUnitNames_academyFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_academyFeaturesSCQ.pkl')\n",
    "processedData_JIRA_academyFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_JIRA_academyFeaturesSCQ.pkl')\n",
    "processedData_JIRASummaries_academyFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_academyFeaturesSCQ.pkl')\n",
    "processedData_JIRADescriptions_academyFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_academyFeaturesSCQ.pkl')\n",
    "#processedData_JIRAComments_academyFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_academyFeaturesSCQ.pkl')\n",
    "\n",
    "\n",
    "#processedData_SVN_academyFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_SVN_academyFeaturesPMI.pkl')\n",
    "processedData_SVNLogs_academyFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_academyFeaturesPMI.pkl')\n",
    "#processedData_SVNUnitNames_academyFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_academyFeaturesPMI.pkl')\n",
    "#processedData_JIRA_academyFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_JIRA_academyFeaturesPMI.pkl')\n",
    "processedData_JIRASummaries_academyFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_academyFeaturesPMI.pkl')\n",
    "#processedData_JIRADescriptions_academyFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_academyFeaturesPMI.pkl')\n",
    "#processedData_JIRAComments_academyFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_academyFeaturesPMI.pkl')\n",
    "\n",
    "\n",
    "################################## Drop query array for normalization ###############################################\n",
    "\n",
    "\n",
    "processedData_SVN_academyFeaturesIDF.drop('SvnAsQuery_IDF', axis = 1, inplace=True)\n",
    "processedData_SVNLogs_academyFeaturesIDF.drop('SvnLogsAsQuery_IDF', axis = 1, inplace=True)\n",
    "processedData_SVNUnitNames_academyFeaturesIDF.drop('SvnUnitNamesAsQuery_IDF', axis = 1, inplace=True)\n",
    "processedData_JIRA_academyFeaturesIDF.drop('JiraAsQuery_IDF', axis = 1, inplace=True)\n",
    "processedData_JIRASummaries_academyFeaturesIDF.drop('JiraSummariesAsQuery_IDF', axis = 1, inplace=True)\n",
    "processedData_JIRADescriptions_academyFeaturesIDF.drop('JiraDescriptionsAsQuery_IDF', axis = 1, inplace=True)\n",
    "#processedData_JIRAComments_academyFeaturesIDF.drop('JiraCommentsAsQuery_IDF', axis = 1, inplace=True)\n",
    "\n",
    "processedData_SVN_academyFeaturesICTF.drop('SvnAsQuery_ICTF', axis = 1, inplace=True)\n",
    "processedData_SVNLogs_academyFeaturesICTF.drop('SvnLogsAsQuery_ICTF', axis = 1, inplace=True)\n",
    "processedData_SVNUnitNames_academyFeaturesICTF.drop('SvnUnitNamesAsQuery_ICTF', axis = 1, inplace=True)\n",
    "processedData_JIRA_academyFeaturesICTF.drop('JiraAsQuery_ICTF', axis = 1, inplace=True)\n",
    "processedData_JIRASummaries_academyFeaturesICTF.drop('JiraSummariesAsQuery_ICTF', axis = 1, inplace=True)\n",
    "processedData_JIRADescriptions_academyFeaturesICTF.drop('JiraDescriptionsAsQuery_ICTF', axis = 1, inplace=True)\n",
    "#processedData_JIRAComments_academyFeaturesICTF.drop('JiraCommentsAsQuery_ICTF', axis = 1, inplace=True)\n",
    "\n",
    "processedData_SVN_academyFeaturesEntropy.drop('SvnAsQuery_Entropy', axis = 1, inplace=True)\n",
    "processedData_SVNLogs_academyFeaturesEntropy.drop('SvnLogsAsQuery_Entropy', axis = 1, inplace=True)\n",
    "processedData_SVNUnitNames_academyFeaturesEntropy.drop('SvnUnitNamesAsQuery_Entropy', axis = 1, inplace=True)\n",
    "processedData_JIRA_academyFeaturesEntropy.drop('JiraAsQuery_Entropy', axis = 1, inplace=True)\n",
    "processedData_JIRASummaries_academyFeaturesEntropy.drop('JiraSummariesAsQuery_Entropy', axis = 1, inplace=True)\n",
    "processedData_JIRADescriptions_academyFeaturesEntropy.drop('JiraDescriptionsAsQuery_Entropy', axis = 1, inplace=True)\n",
    "#processedData_JIRAComments_academyFeaturesEntropy.drop('JiraCommentsAsQuery_Entropy', axis = 1, inplace=True)\n",
    "\n",
    "processedData_SVN_academyFeaturesSCQ.drop('SvnAsQuery_SCQ', axis = 1, inplace=True)\n",
    "processedData_SVNLogs_academyFeaturesSCQ.drop('SvnLogsAsQuery_SCQ', axis = 1, inplace=True)\n",
    "processedData_SVNUnitNames_academyFeaturesSCQ.drop('SvnUnitNamesAsQuery_SCQ', axis = 1, inplace=True)\n",
    "processedData_JIRA_academyFeaturesSCQ.drop('JiraAsQuery_SCQ', axis = 1, inplace=True)\n",
    "processedData_JIRASummaries_academyFeaturesSCQ.drop('JiraSummariesAsQuery_SCQ', axis = 1, inplace=True)\n",
    "processedData_JIRADescriptions_academyFeaturesSCQ.drop('JiraDescriptionsAsQuery_SCQ', axis = 1, inplace=True)\n",
    "#processedData_JIRAComments_academyFeaturesSCQ.drop('JiraCommentsAsQuery_SCQ', axis = 1, inplace=True)\n",
    "\n",
    "################################## Normalizing ################################################\n",
    "\n",
    "processedData_academyFeaturesTime_normalized = normalizeData(processedData_academyFeaturesTime)\n",
    "processedData_academyFeaturesStakeholder_normalized = normalizeData(processedData_academyFeaturesStakeholder)\n",
    "\n",
    "#Load IR-Related Features - unigram\n",
    "processedData_academy_features_VsmLogsJiraAsQuery_normalized = normalizeData(processedData_academy_features_VsmLogsJiraAsQuery)\n",
    "processedData_academy_features_VsmLogsLogAsQuery_normalized = normalizeData(processedData_academy_features_VsmLogsLogAsQuery)\n",
    "processedData_academy_features_VsmUnitNamesJiraAsQuery_normalized = normalizeData(processedData_academy_features_VsmUnitNamesJiraAsQuery)\n",
    "processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_normalized = normalizeData(processedData_academy_features_VsmUnitNamesUnitNamesAsQuery)\n",
    "#processedData_academy_features_VsmUnitNamesCommentsCommentsAsQuery_normalized = normalizeData(processedData_academy_features_VsmUnitNamesCommentsCommentsAsQuery)\n",
    "#processedData_academy_features_VsmUnitNamesCommentsUnitNamesAsQuery_normalized = normalizeData(processedData_academy_features_VsmUnitNamesCommentsUnitNamesAsQuery)\n",
    "processedData_academy_features_VsmUnitNamesDescriptionDescriptionAsQuery_normalized = normalizeData(processedData_academy_features_VsmUnitNamesDescriptionDescriptionAsQuery)\n",
    "processedData_academy_features_VsmUnitNamesDescriptionUnitNamesAsQuery_normalized = normalizeData(processedData_academy_features_VsmUnitNamesDescriptionUnitNamesAsQuery)\n",
    "\n",
    "#processedData_academy_features_VsmVerbPruningUnitNamesJiraAsQuery_normalized = normalizeData(processedData_academy_features_VsmVerbPruningUnitNamesJiraAsQuery)\n",
    "#processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery_normalized = normalizeData(processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery)\n",
    "processedData_academy_features_VsmSummaryLogsSummaryAsQuery_normalized = normalizeData(processedData_academy_features_VsmSummaryLogsSummaryAsQuery)\n",
    "processedData_academy_features_VsmSummaryLogsLogsAsQuery_normalized = normalizeData(processedData_academy_features_VsmSummaryLogsLogsAsQuery)\n",
    "processedData_academy_features_VsmSummaryUnitNamesSummaryAsQuery_normalized = normalizeData(processedData_academy_features_VsmSummaryUnitNamesSummaryAsQuery)\n",
    "processedData_academy_features_VsmSummaryUnitNamesUnitNamesAsQuery_normalized = normalizeData(processedData_academy_features_VsmSummaryUnitNamesUnitNamesAsQuery)\n",
    "processedData_academy_features_VsmDescriptionDescriptionAsQuery_normalized = normalizeData(processedData_academy_features_VsmDescriptionDescriptionAsQuery)\n",
    "processedData_academy_features_VsmDescriptionLogsAsQuery_normalized = normalizeData(processedData_academy_features_VsmDescriptionLogsAsQuery)\n",
    "#processedData_academy_features_VsmCommentsCommentsAsQuery_normalized = normalizeData(processedData_academy_features_VsmCommentsCommentsAsQuery)\n",
    "#processedData_academy_features_VsmCommentsLogsAsQuery_normalized = normalizeData(processedData_academy_features_VsmCommentsLogsAsQuery)\n",
    "\n",
    "processedData_academy_features_VsmSvnJiraJiraAsQuery_normalized = normalizeData(processedData_academy_features_VsmSvnJiraJiraAsQuery)\n",
    "processedData_academy_features_VsmSvnJiraSvnAsQuery_normalized = normalizeData(processedData_academy_features_VsmSvnJiraSvnAsQuery)\n",
    "processedData_academy_features_VsmSvnSummarySvnAsQuery_normalized = normalizeData(processedData_academy_features_VsmSvnSummarySvnAsQuery)\n",
    "processedData_academy_features_VsmSvnSummarySummaryAsQuery_normalized = normalizeData(processedData_academy_features_VsmSvnSummarySummaryAsQuery)\n",
    "processedData_academy_features_VsmSvnDescriptionSvnAsQuery_normalized = normalizeData(processedData_academy_features_VsmSvnDescriptionSvnAsQuery)\n",
    "processedData_academy_features_VsmSvnDescriptionDescriptionAsQuery_normalized = normalizeData(processedData_academy_features_VsmSvnDescriptionDescriptionAsQuery)\n",
    "#processedData_academy_features_VsmSvnCommentsSvnAsQuery_normalized = normalizeData(processedData_academy_features_VsmSvnCommentsSvnAsQuery)\n",
    "#processedData_academy_features_VsmSvnCommentsCommentsAsQuery_normalized = normalizeData(processedData_academy_features_VsmSvnCommentsCommentsAsQuery)\n",
    "\n",
    "\n",
    "\n",
    "#Load IR-Related Features - bigram\n",
    "#processedData_academy_features_VsmLogsJiraAsQuery_2gram_normalized = normalizeData(processedData_academy_features_VsmLogsJiraAsQuery_2gram)\n",
    "#processedData_academy_features_VsmLogsLogAsQuery_2gram_normalized = normalizeData(processedData_academy_features_VsmLogsLogAsQuery_2gram)\n",
    "#processedData_academy_features_VsmUnitNamesJiraAsQuery_2gram_normalized = normalizeData(processedData_academy_features_VsmUnitNamesJiraAsQuery_2gram)\n",
    "#processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_2gram_normalized = normalizeData(processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_2gram)\n",
    "#processedData_academy_features_VsmCommentsLogsAsQuery_2gram_normalized = normalizeData(processedData_academy_features_VsmCommentsLogsAsQuery_2gram)\n",
    "#processedData_academy_features_VsmCommentsCommentsAsQuery_2gram_normalized = normalizeData(processedData_academy_features_VsmCommentsCommentsAsQuery_2gram)\n",
    "\n",
    "\n",
    "#Load Document Statistics Features\n",
    "processedData_JIRA_academyFeaturesUniqueWordCount_normalized = normalizeData(processedData_JIRA_academyFeaturesUniqueWordCount)\n",
    "processedData_SVN_academyFeaturesUniqueWordCount_normalized = normalizeData(processedData_SVN_academyFeaturesUniqueWordCount)\n",
    "processedData_JIRA_academyFeaturesTotalWordCount_normalized = normalizeData(processedData_JIRA_academyFeaturesTotalWordCount)\n",
    "processedData_SVN_academyFeaturesTotalWordCount_normalized = normalizeData(processedData_SVN_academyFeaturesTotalWordCount)\n",
    "processedData_JIRA_academyFeaturesOverlapPercentage_normalized = normalizeData(processedData_JIRA_academyFeaturesOverlapPercentage)\n",
    "processedData_SVN_academyFeaturesOverlapPercentage_normalized = normalizeData(processedData_SVN_academyFeaturesOverlapPercentage)\n",
    "processedData_UNION_academyFeaturesOverlapPercentage_normalized = normalizeData(processedData_UNION_academyFeaturesOverlapPercentage)\n",
    "\n",
    "#Load Query Quality Features\n",
    "processedData_SVN_academyFeaturesIDF_normalized = normalizeData(processedData_SVN_academyFeaturesIDF)\n",
    "processedData_SVNLogs_academyFeaturesIDF_normalized = normalizeData(processedData_SVNLogs_academyFeaturesIDF)\n",
    "processedData_SVNUnitNames_academyFeaturesIDF_normalized = normalizeData(processedData_SVNUnitNames_academyFeaturesIDF)\n",
    "processedData_JIRA_academyFeaturesIDF_normalized = normalizeData(processedData_JIRA_academyFeaturesIDF)\n",
    "processedData_JIRASummaries_academyFeaturesIDF_normalized = normalizeData(processedData_JIRASummaries_academyFeaturesIDF)\n",
    "processedData_JIRADescriptions_academyFeaturesIDF_normalized = normalizeData(processedData_JIRADescriptions_academyFeaturesIDF)\n",
    "#processedData_JIRAComments_academyFeaturesIDF_normalized = normalizeData(processedData_JIRAComments_academyFeaturesIDF)\n",
    "\n",
    "processedData_SVN_academyFeaturesICTF_normalized = normalizeData(processedData_SVN_academyFeaturesICTF)\n",
    "processedData_SVNLogs_academyFeaturesICTF_normalized = normalizeData(processedData_SVNLogs_academyFeaturesICTF)\n",
    "processedData_SVNUnitNames_academyFeaturesICTF_normalized = normalizeData(processedData_SVNUnitNames_academyFeaturesICTF)\n",
    "processedData_JIRA_academyFeaturesICTF_normalized = normalizeData(processedData_JIRA_academyFeaturesICTF)\n",
    "processedData_JIRASummaries_academyFeaturesICTF_normalized = normalizeData(processedData_JIRASummaries_academyFeaturesICTF)\n",
    "processedData_JIRADescriptions_academyFeaturesICTF_normalized = normalizeData(processedData_JIRADescriptions_academyFeaturesICTF)\n",
    "#processedData_JIRAComments_academyFeaturesICTF_normalized = normalizeData(processedData_JIRAComments_academyFeaturesICTF)\n",
    "\n",
    "processedData_SVN_academyFeaturesEntropy_normalized = normalizeData(processedData_SVN_academyFeaturesEntropy)\n",
    "processedData_SVNLogs_academyFeaturesEntropy_normalized = normalizeData(processedData_SVNLogs_academyFeaturesEntropy)\n",
    "processedData_SVNUnitNames_academyFeaturesEntropy_normalized = normalizeData(processedData_SVNUnitNames_academyFeaturesEntropy)\n",
    "processedData_JIRA_academyFeaturesEntropy_normalized = normalizeData(processedData_JIRA_academyFeaturesEntropy)\n",
    "processedData_JIRASummaries_academyFeaturesEntropy_normalized = normalizeData(processedData_JIRASummaries_academyFeaturesEntropy)\n",
    "processedData_JIRADescriptions_academyFeaturesEntropy_normalized = normalizeData(processedData_JIRADescriptions_academyFeaturesEntropy)\n",
    "#processedData_JIRAComments_academyFeaturesEntropy_normalized = normalizeData(processedData_JIRAComments_academyFeaturesEntropy)\n",
    "\n",
    "processedData_SVN_academyFeaturesQueryScope_normalized = normalizeData(processedData_SVN_academyFeaturesQueryScope)\n",
    "processedData_SVNLogs_academyFeaturesQueryScope_normalized = normalizeData(processedData_SVNLogs_academyFeaturesQueryScope)\n",
    "processedData_SVNUnitNames_academyFeaturesQueryScope_normalized = normalizeData(processedData_SVNUnitNames_academyFeaturesQueryScope)\n",
    "processedData_JIRA_academyFeaturesQueryScope_normalized = normalizeData(processedData_JIRA_academyFeaturesQueryScope)\n",
    "processedData_JIRASummaries_academyFeaturesQueryScope_normalized = normalizeData(processedData_JIRASummaries_academyFeaturesQueryScope)\n",
    "processedData_JIRADescriptions_academyFeaturesQueryScope_normalized = normalizeData(processedData_JIRADescriptions_academyFeaturesQueryScope)\n",
    "#processedData_JIRAComments_academyFeaturesQueryScope_normalized = normalizeData(processedData_JIRAComments_academyFeaturesQueryScope)\n",
    "\n",
    "processedData_SVN_academyFeaturesSCS_normalized = normalizeData(processedData_SVN_academyFeaturesSCS)\n",
    "processedData_SVNLogs_academyFeaturesSCS_normalized = normalizeData(processedData_SVNLogs_academyFeaturesSCS)\n",
    "processedData_SVNUnitNames_academyFeaturesSCS_normalized = normalizeData(processedData_SVNUnitNames_academyFeaturesSCS)\n",
    "processedData_JIRA_academyFeaturesSCS_normalized = normalizeData(processedData_JIRA_academyFeaturesSCS)\n",
    "processedData_JIRASummaries_academyFeaturesSCS_normalized = normalizeData(processedData_JIRASummaries_academyFeaturesSCS)\n",
    "processedData_JIRADescriptions_academyFeaturesSCS_normalized = normalizeData(processedData_JIRADescriptions_academyFeaturesSCS)\n",
    "#processedData_JIRAComments_academyFeaturesSCS_normalized = normalizeData(processedData_JIRAComments_academyFeaturesSCS)\n",
    "\n",
    "processedData_SVN_academyFeaturesSCQ_normalized = normalizeData(processedData_SVN_academyFeaturesSCQ)\n",
    "processedData_SVNLogs_academyFeaturesSCQ_normalized = normalizeData(processedData_SVNLogs_academyFeaturesSCQ)\n",
    "processedData_SVNUnitNames_academyFeaturesSCQ_normalized = normalizeData(processedData_SVNUnitNames_academyFeaturesSCQ)\n",
    "processedData_JIRA_academyFeaturesSCQ_normalized = normalizeData(processedData_JIRA_academyFeaturesSCQ)\n",
    "processedData_JIRASummaries_academyFeaturesSCQ_normalized = normalizeData(processedData_JIRASummaries_academyFeaturesSCQ)\n",
    "processedData_JIRADescriptions_academyFeaturesSCQ_normalized = normalizeData(processedData_JIRADescriptions_academyFeaturesSCQ)\n",
    "#processedData_JIRAComments_academyFeaturesSCQ_normalized = normalizeData(processedData_JIRAComments_academyFeaturesSCQ)\n",
    "\n",
    "#processedData_SVN_academyFeaturesPMI_normalized = normalizeData(processedData_SVN_academyFeaturesPMI)\n",
    "processedData_SVNLogs_academyFeaturesPMI_normalized = normalizeData(processedData_SVNLogs_academyFeaturesPMI)\n",
    "#processedData_SVNUnitNames_academyFeaturesPMI_normalized = normalizeData(processedData_SVNUnitNames_academyFeaturesPMI)\n",
    "#processedData_JIRA_academyFeaturesPMI_normalized = normalizeData(processedData_JIRA_academyFeaturesPMI)\n",
    "processedData_JIRASummaries_academyFeaturesPMI_normalized = normalizeData(processedData_JIRASummaries_academyFeaturesPMI)\n",
    "#processedData_JIRADescriptions_academyFeaturesPMI_normalized = normalizeData(processedData_JIRADescriptions_academyFeaturesPMI)\n",
    "#processedData_JIRAComments_academyFeaturesPMI_normalized = normalizeData(processedData_JIRAComments_academyFeaturesPMI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-material",
   "metadata": {},
   "source": [
    "## 3.8 Preprocess Data - Load and transform feature families needed for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Merge features into 1 dataframe\n",
    "processedData_academyFeatures_normalized = pd.concat([processedData_academyFeaturesTime_normalized,\n",
    "                                                  processedData_academyFeaturesStakeholder_normalized,\n",
    "                                                  #IR-based\n",
    "                                                  processedData_academy_features_VsmLogsJiraAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmLogsLogAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmUnitNamesJiraAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_normalized,\n",
    "                                                #  processedData_academy_features_VsmUnitNamesCommentsCommentsAsQuery_normalized,\n",
    "                                                #  processedData_academy_features_VsmUnitNamesCommentsUnitNamesAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmUnitNamesDescriptionDescriptionAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmUnitNamesDescriptionUnitNamesAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmSummaryLogsSummaryAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmSummaryLogsLogsAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmSummaryUnitNamesSummaryAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmSummaryUnitNamesUnitNamesAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmDescriptionDescriptionAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmDescriptionLogsAsQuery_normalized,\n",
    "                                                 # processedData_academy_features_VsmCommentsCommentsAsQuery_normalized,\n",
    "                                                #  processedData_academy_features_VsmCommentsLogsAsQuery_normalized,\n",
    "                                                 # processedData_academy_features_VsmLogsJiraAsQuery_2gram_normalized,\n",
    "                                                 # processedData_academy_features_VsmLogsLogAsQuery_2gram_normalized,\n",
    "                                                 # processedData_academy_features_VsmUnitNamesJiraAsQuery_2gram_normalized,\n",
    "                                                 # processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_2gram_normalized,\n",
    "                                                  #processedData_academy_features_VsmVerbPruningUnitNamesJiraAsQuery_normalized,\n",
    "                                                 # processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmSvnJiraJiraAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmSvnJiraSvnAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmSvnSummarySvnAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmSvnSummarySummaryAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmSvnDescriptionSvnAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmSvnDescriptionDescriptionAsQuery_normalized,\n",
    "                                                #  processedData_academy_features_VsmSvnCommentsSvnAsQuery_normalized,\n",
    "                                                #  processedData_academy_features_VsmSvnCommentsCommentsAsQuery_normalized,\n",
    "\n",
    "                                                  \n",
    "                                                  #Document Statistics\n",
    "                                                  processedData_JIRA_academyFeaturesUniqueWordCount_normalized,\n",
    "                                                  processedData_SVN_academyFeaturesUniqueWordCount_normalized,\n",
    "                                                  processedData_JIRA_academyFeaturesTotalWordCount_normalized,\n",
    "                                                  processedData_SVN_academyFeaturesTotalWordCount_normalized,\n",
    "                                                  processedData_JIRA_academyFeaturesOverlapPercentage_normalized,\n",
    "                                                  processedData_SVN_academyFeaturesOverlapPercentage_normalized,\n",
    "                                                  processedData_UNION_academyFeaturesOverlapPercentage_normalized,\n",
    "                                                 #Query Quality\n",
    "                                                  processedData_SVN_academyFeaturesIDF_normalized['SvnAsQuery_avgIDF'],\n",
    "                                                  processedData_SVN_academyFeaturesIDF_normalized['SvnAsQuery_maxIDF'],\n",
    "                                                  processedData_SVN_academyFeaturesIDF_normalized['SvnAsQuery_devIDF'],\n",
    "                                                  processedData_SVNLogs_academyFeaturesIDF_normalized['SvnLogsAsQuery_avgIDF'],\n",
    "                                                  processedData_SVNLogs_academyFeaturesIDF_normalized['SvnLogsAsQuery_maxIDF'],\n",
    "                                                  processedData_SVNLogs_academyFeaturesIDF_normalized['SvnLogsAsQuery_devIDF'],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesIDF_normalized['SvnUnitNamesAsQuery_avgIDF'],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesIDF_normalized['SvnUnitNamesAsQuery_maxIDF'],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesIDF_normalized['SvnUnitNamesAsQuery_devIDF'],\n",
    "                                                  processedData_JIRA_academyFeaturesIDF_normalized['JiraAsQuery_avgIDF'],\n",
    "                                                  processedData_JIRA_academyFeaturesIDF_normalized['JiraAsQuery_maxIDF'],\n",
    "                                                  processedData_JIRA_academyFeaturesIDF_normalized['JiraAsQuery_devIDF'],  \n",
    "                                                  processedData_JIRASummaries_academyFeaturesIDF_normalized['JiraSummariesAsQuery_avgIDF'],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesIDF_normalized['JiraSummariesAsQuery_maxIDF'],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesIDF_normalized['JiraSummariesAsQuery_devIDF'],  \n",
    "                                                  processedData_JIRADescriptions_academyFeaturesIDF_normalized['JiraDescriptionsAsQuery_avgIDF'],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesIDF_normalized['JiraDescriptionsAsQuery_maxIDF'],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesIDF_normalized['JiraDescriptionsAsQuery_devIDF'],  \n",
    "                                                #  processedData_JIRAComments_academyFeaturesIDF_normalized['JiraCommentsAsQuery_avgIDF'],\n",
    "                                                #  processedData_JIRAComments_academyFeaturesIDF_normalized['JiraCommentsAsQuery_maxIDF'],\n",
    "                                                #  processedData_JIRAComments_academyFeaturesIDF_normalized['JiraCommentsAsQuery_devIDF'],  \n",
    "                                                  \n",
    "                                                  processedData_SVN_academyFeaturesICTF_normalized[\"SvnAsQuery_avgICTF\"],\n",
    "                                                  processedData_SVN_academyFeaturesICTF_normalized[\"SvnAsQuery_maxICTF\"],\n",
    "                                                  processedData_SVN_academyFeaturesICTF_normalized[\"SvnAsQuery_devICTF\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesICTF_normalized[\"SvnLogsAsQuery_avgICTF\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesICTF_normalized[\"SvnLogsAsQuery_maxICTF\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesICTF_normalized[\"SvnLogsAsQuery_devICTF\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesICTF_normalized[\"SvnUnitNamesAsQuery_avgICTF\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesICTF_normalized[\"SvnUnitNamesAsQuery_maxICTF\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesICTF_normalized[\"SvnUnitNamesAsQuery_devICTF\"],\n",
    "                                                  processedData_JIRA_academyFeaturesICTF_normalized[\"JiraAsQuery_avgICTF\"],\n",
    "                                                  processedData_JIRA_academyFeaturesICTF_normalized[\"JiraAsQuery_maxICTF\"],\n",
    "                                                  processedData_JIRA_academyFeaturesICTF_normalized[\"JiraAsQuery_devICTF\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesICTF_normalized[\"JiraSummariesAsQuery_avgICTF\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesICTF_normalized[\"JiraSummariesAsQuery_maxICTF\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesICTF_normalized[\"JiraSummariesAsQuery_devICTF\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesICTF_normalized[\"JiraDescriptionsAsQuery_avgICTF\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesICTF_normalized[\"JiraDescriptionsAsQuery_maxICTF\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesICTF_normalized[\"JiraDescriptionsAsQuery_devICTF\"],\n",
    "                                              #    processedData_JIRAComments_academyFeaturesICTF_normalized[\"JiraCommentsAsQuery_avgICTF\"],\n",
    "                                              #    processedData_JIRAComments_academyFeaturesICTF_normalized[\"JiraCommentsAsQuery_maxICTF\"],\n",
    "                                              #    processedData_JIRAComments_academyFeaturesICTF_normalized[\"JiraCommentsAsQuery_devICTF\"],\n",
    "                                                  \n",
    "                                                  processedData_SVN_academyFeaturesEntropy_normalized[\"SvnAsQuery_avgEntropy\"],\n",
    "                                                  processedData_SVN_academyFeaturesEntropy_normalized[\"SvnAsQuery_medEntropy\"],\n",
    "                                                  processedData_SVN_academyFeaturesEntropy_normalized[\"SvnAsQuery_maxEntropy\"],\n",
    "                                                  processedData_SVN_academyFeaturesEntropy_normalized[\"SvnAsQuery_devEntropy\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesEntropy_normalized[\"SvnLogsAsQuery_avgEntropy\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesEntropy_normalized[\"SvnLogsAsQuery_medEntropy\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesEntropy_normalized[\"SvnLogsAsQuery_maxEntropy\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesEntropy_normalized[\"SvnLogsAsQuery_devEntropy\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesEntropy_normalized[\"SvnUnitNamesAsQuery_avgEntropy\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesEntropy_normalized[\"SvnUnitNamesAsQuery_medEntropy\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesEntropy_normalized[\"SvnUnitNamesAsQuery_maxEntropy\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesEntropy_normalized[\"SvnUnitNamesAsQuery_devEntropy\"],\n",
    "                                                  processedData_JIRA_academyFeaturesEntropy_normalized[\"JiraAsQuery_avgEntropy\"],\n",
    "                                                  processedData_JIRA_academyFeaturesEntropy_normalized[\"JiraAsQuery_medEntropy\"],\n",
    "                                                  processedData_JIRA_academyFeaturesEntropy_normalized[\"JiraAsQuery_maxEntropy\"],\n",
    "                                                  processedData_JIRA_academyFeaturesEntropy_normalized[\"JiraAsQuery_devEntropy\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesEntropy_normalized[\"JiraSummariesAsQuery_avgEntropy\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesEntropy_normalized[\"JiraSummariesAsQuery_medEntropy\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesEntropy_normalized[\"JiraSummariesAsQuery_maxEntropy\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesEntropy_normalized[\"JiraSummariesAsQuery_devEntropy\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesEntropy_normalized[\"JiraDescriptionsAsQuery_avgEntropy\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesEntropy_normalized[\"JiraDescriptionsAsQuery_medEntropy\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesEntropy_normalized[\"JiraDescriptionsAsQuery_maxEntropy\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesEntropy_normalized[\"JiraDescriptionsAsQuery_devEntropy\"],\n",
    "                                               #   processedData_JIRAComments_academyFeaturesEntropy_normalized[\"JiraCommentsAsQuery_avgEntropy\"],\n",
    "                                               #   processedData_JIRAComments_academyFeaturesEntropy_normalized[\"JiraCommentsAsQuery_medEntropy\"],\n",
    "                                               #   processedData_JIRAComments_academyFeaturesEntropy_normalized[\"JiraCommentsAsQuery_maxEntropy\"],\n",
    "                                               #   processedData_JIRAComments_academyFeaturesEntropy_normalized[\"JiraCommentsAsQuery_devEntropy\"],\n",
    "                                                  \n",
    "                                                  processedData_SVN_academyFeaturesQueryScope_normalized,\n",
    "                                                  processedData_SVNLogs_academyFeaturesQueryScope_normalized,\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesQueryScope_normalized,\n",
    "                                                  processedData_JIRA_academyFeaturesQueryScope_normalized,\n",
    "                                                  processedData_JIRASummaries_academyFeaturesQueryScope_normalized,\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesQueryScope_normalized,\n",
    "                                                #  processedData_JIRAComments_academyFeaturesQueryScope_normalized,\n",
    "                                                  \n",
    "                                                  processedData_SVN_academyFeaturesSCS_normalized,\n",
    "                                                  processedData_SVNLogs_academyFeaturesSCS_normalized,\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesSCS_normalized,\n",
    "                                                  processedData_JIRA_academyFeaturesSCS_normalized,\n",
    "                                                  processedData_JIRASummaries_academyFeaturesSCS_normalized,\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesSCS_normalized,\n",
    "                                                #  processedData_JIRAComments_academyFeaturesSCS_normalized,\n",
    "                                                  \n",
    "                                                  processedData_SVN_academyFeaturesSCQ_normalized[\"SvnAsQuery_avgSCQ\"],\n",
    "                                                  processedData_SVN_academyFeaturesSCQ_normalized[\"SvnAsQuery_maxSCQ\"],\n",
    "                                                  processedData_SVN_academyFeaturesSCQ_normalized[\"SvnAsQuery_sumSCQ\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesSCQ_normalized[\"SvnLogsAsQuery_avgSCQ\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesSCQ_normalized[\"SvnLogsAsQuery_maxSCQ\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesSCQ_normalized[\"SvnLogsAsQuery_sumSCQ\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesSCQ_normalized[\"SvnUnitNamesAsQuery_avgSCQ\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesSCQ_normalized[\"SvnUnitNamesAsQuery_maxSCQ\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesSCQ_normalized[\"SvnUnitNamesAsQuery_sumSCQ\"],\n",
    "                                                  processedData_JIRA_academyFeaturesSCQ_normalized[\"JiraAsQuery_avgSCQ\"],\n",
    "                                                  processedData_JIRA_academyFeaturesSCQ_normalized[\"JiraAsQuery_maxSCQ\"],\n",
    "                                                  processedData_JIRA_academyFeaturesSCQ_normalized[\"JiraAsQuery_sumSCQ\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesSCQ_normalized[\"JiraSummariesAsQuery_avgSCQ\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesSCQ_normalized[\"JiraSummariesAsQuery_maxSCQ\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesSCQ_normalized[\"JiraSummariesAsQuery_sumSCQ\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesSCQ_normalized[\"JiraDescriptionsAsQuery_avgSCQ\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesSCQ_normalized[\"JiraDescriptionsAsQuery_maxSCQ\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesSCQ_normalized[\"JiraDescriptionsAsQuery_sumSCQ\"],\n",
    "                                                 # processedData_JIRAComments_academyFeaturesSCQ_normalized[\"JiraCommentsAsQuery_avgSCQ\"],\n",
    "                                                #  processedData_JIRAComments_academyFeaturesSCQ_normalized[\"JiraCommentsAsQuery_maxSCQ\"],\n",
    "                                                #  processedData_JIRAComments_academyFeaturesSCQ_normalized[\"JiraCommentsAsQuery_sumSCQ\"],\n",
    "                                                  \n",
    "                                                 # processedData_SVN_academyFeaturesPMI_normalized[\"SvnAsQuery_avgPMI\"],\n",
    "                                                 # processedData_SVN_academyFeaturesPMI_normalized[\"SvnAsQuery_maxPMI\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesPMI_normalized[\"SvnLogsAsQuery_avgPMI\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesPMI_normalized[\"SvnLogsAsQuery_maxPMI\"],\n",
    "                                                 # processedData_SVNUnitNames_academyFeaturesPMI_normalized[\"SvnUnitNamesAsQuery_avgPMI\"],\n",
    "                                                 # processedData_SVNUnitNames_academyFeaturesPMI_normalized[\"SvnUnitNamesAsQuery_maxPMI\"],\n",
    "                                                 # processedData_JIRA_academyFeaturesPMI_normalized[\"JiraAsQuery_avgPMI\"],\n",
    "                                                 # processedData_JIRA_academyFeaturesPMI_normalized[\"JiraAsQuery_maxPMI\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesPMI_normalized[\"JiraSummariesAsQuery_avgPMI\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesPMI_normalized[\"JiraSummariesAsQuery_maxPMI\"],\n",
    "                                                 # processedData_JIRADescriptions_academyFeaturesPMI_normalized[\"JiraDescriptionsAsQuery_avgPMI\"],\n",
    "                                                 # processedData_JIRADescriptions_academyFeaturesPMI_normalized[\"JiraDescriptionsAsQuery_maxPMI\"],\n",
    "                                                #  processedData_JIRAComments_academyFeaturesPMI_normalized[\"JiraCommentsAsQuery_avgPMI\"],\n",
    "                                               #   processedData_JIRAComments_academyFeaturesPMI_normalized[\"JiraCommentssAsQuery_maxPMI\"],                                                  \n",
    "                                                 ], axis=1)\n",
    "#Set the NaN to 0\n",
    "processedData_academyFeatures_normalized = processedData_academyFeatures_normalized.fillna(0)\n",
    "\n",
    "#Saving feature names for later use\n",
    "processedData_academyFeatureNames_normalized = list(processedData_academyFeatures_normalized.columns)\n",
    "\n",
    "#Transform pandas data frame into numpy arrays\n",
    "processedData_academyFeatures_normalized = np.array(processedData_academyFeatures_normalized)\n",
    "\n",
    "#Load labels\n",
    "processedData_academyLabels_normalized = pd.read_pickle(r'../data/03_processed/processedData_academyLabels.pkl')\n",
    "processedData_academyLabels_normalized = np.array(processedData_academyLabels_normalized[\"is_valid\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-devon",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Merge features into 1 dataframe\n",
    "processedData_academyFeatures = pd.concat([processedData_academyFeaturesTime,\n",
    "                                                  processedData_academyFeaturesStakeholder,\n",
    "                                                  #IR-based\n",
    "                                                  processedData_academy_features_VsmLogsJiraAsQuery,\n",
    "                                                  processedData_academy_features_VsmLogsLogAsQuery,\n",
    "                                                  processedData_academy_features_VsmUnitNamesJiraAsQuery,\n",
    "                                                  processedData_academy_features_VsmUnitNamesUnitNamesAsQuery,\n",
    "                                                 # processedData_academy_features_VsmUnitNamesCommentsCommentsAsQuery,\n",
    "                                                 # processedData_academy_features_VsmUnitNamesCommentsUnitNamesAsQuery,\n",
    "                                                  processedData_academy_features_VsmUnitNamesDescriptionDescriptionAsQuery,\n",
    "                                                  processedData_academy_features_VsmUnitNamesDescriptionUnitNamesAsQuery,\n",
    "                                                  processedData_academy_features_VsmSummaryLogsSummaryAsQuery,\n",
    "                                                  processedData_academy_features_VsmSummaryLogsLogsAsQuery,\n",
    "                                                  processedData_academy_features_VsmSummaryUnitNamesSummaryAsQuery,\n",
    "                                                  processedData_academy_features_VsmSummaryUnitNamesUnitNamesAsQuery,\n",
    "                                                  processedData_academy_features_VsmDescriptionDescriptionAsQuery,\n",
    "                                                  processedData_academy_features_VsmDescriptionLogsAsQuery,\n",
    "                                                 # processedData_academy_features_VsmLogsJiraAsQuery_2gram,\n",
    "                                                 # processedData_academy_features_VsmLogsLogAsQuery_2gram,\n",
    "                                                 # processedData_academy_features_VsmUnitNamesJiraAsQuery_2gram,\n",
    "                                                 # processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_2gram,\n",
    "                                                 # processedData_academy_features_VsmVerbPruningUnitNamesJiraAsQuery,\n",
    "                                                 # processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery,\n",
    "                                                  processedData_academy_features_VsmSvnJiraJiraAsQuery,\n",
    "                                                  processedData_academy_features_VsmSvnJiraSvnAsQuery,\n",
    "                                                  processedData_academy_features_VsmSvnSummarySvnAsQuery,\n",
    "                                                  processedData_academy_features_VsmSvnSummarySummaryAsQuery,\n",
    "                                                  processedData_academy_features_VsmSvnDescriptionSvnAsQuery,\n",
    "                                                  processedData_academy_features_VsmSvnDescriptionDescriptionAsQuery,\n",
    "                                                #  processedData_academy_features_VsmSvnCommentsSvnAsQuery,\n",
    "                                                #  processedData_academy_features_VsmSvnCommentsCommentsAsQuery,\n",
    "\n",
    "                                                  \n",
    "                                                  #Document Statistics\n",
    "                                                  processedData_JIRA_academyFeaturesUniqueWordCount,\n",
    "                                                  processedData_SVN_academyFeaturesUniqueWordCount,\n",
    "                                                  processedData_JIRA_academyFeaturesTotalWordCount,\n",
    "                                                  processedData_SVN_academyFeaturesTotalWordCount,\n",
    "                                                  processedData_JIRA_academyFeaturesOverlapPercentage,\n",
    "                                                  processedData_SVN_academyFeaturesOverlapPercentage,\n",
    "                                                  processedData_UNION_academyFeaturesOverlapPercentage,\n",
    "                                                 #Query Quality\n",
    "                                                  processedData_SVN_academyFeaturesIDF['SvnAsQuery_avgIDF'],\n",
    "                                                  processedData_SVN_academyFeaturesIDF['SvnAsQuery_maxIDF'],\n",
    "                                                  processedData_SVN_academyFeaturesIDF['SvnAsQuery_devIDF'],\n",
    "                                                  processedData_SVNLogs_academyFeaturesIDF['SvnLogsAsQuery_avgIDF'],\n",
    "                                                  processedData_SVNLogs_academyFeaturesIDF['SvnLogsAsQuery_maxIDF'],\n",
    "                                                  processedData_SVNLogs_academyFeaturesIDF['SvnLogsAsQuery_devIDF'],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesIDF['SvnUnitNamesAsQuery_avgIDF'],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesIDF['SvnUnitNamesAsQuery_maxIDF'],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesIDF['SvnUnitNamesAsQuery_devIDF'],\n",
    "                                                  processedData_JIRA_academyFeaturesIDF['JiraAsQuery_avgIDF'],\n",
    "                                                  processedData_JIRA_academyFeaturesIDF['JiraAsQuery_maxIDF'],\n",
    "                                                  processedData_JIRA_academyFeaturesIDF['JiraAsQuery_devIDF'], \n",
    "                                                  processedData_JIRASummaries_academyFeaturesIDF['JiraSummariesAsQuery_avgIDF'],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesIDF['JiraSummariesAsQuery_maxIDF'],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesIDF['JiraSummariesAsQuery_devIDF'], \n",
    "                                                  processedData_JIRADescriptions_academyFeaturesIDF['JiraDescriptionsAsQuery_avgIDF'],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesIDF['JiraDescriptionsAsQuery_maxIDF'],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesIDF['JiraDescriptionsAsQuery_devIDF'], \n",
    "                                                #  processedData_JIRAComments_academyFeaturesIDF['JiraCommentsAsQuery_avgIDF'],\n",
    "                                               #   processedData_JIRAComments_academyFeaturesIDF['JiraCommentsAsQuery_maxIDF'],\n",
    "                                               #   processedData_JIRAComments_academyFeaturesIDF['JiraCommentsAsQuery_devIDF'], \n",
    "                                                  \n",
    "                                                  processedData_SVN_academyFeaturesICTF[\"SvnAsQuery_avgICTF\"],\n",
    "                                                  processedData_SVN_academyFeaturesICTF[\"SvnAsQuery_maxICTF\"],\n",
    "                                                  processedData_SVN_academyFeaturesICTF[\"SvnAsQuery_devICTF\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesICTF[\"SvnLogsAsQuery_avgICTF\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesICTF[\"SvnLogsAsQuery_maxICTF\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesICTF[\"SvnLogsAsQuery_devICTF\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesICTF[\"SvnUnitNamesAsQuery_avgICTF\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesICTF[\"SvnUnitNamesAsQuery_maxICTF\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesICTF[\"SvnUnitNamesAsQuery_devICTF\"],\n",
    "                                                  processedData_JIRA_academyFeaturesICTF[\"JiraAsQuery_avgICTF\"],\n",
    "                                                  processedData_JIRA_academyFeaturesICTF[\"JiraAsQuery_maxICTF\"],\n",
    "                                                  processedData_JIRA_academyFeaturesICTF[\"JiraAsQuery_devICTF\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesICTF[\"JiraSummariesAsQuery_avgICTF\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesICTF[\"JiraSummariesAsQuery_maxICTF\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesICTF[\"JiraSummariesAsQuery_devICTF\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesICTF[\"JiraDescriptionsAsQuery_avgICTF\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesICTF[\"JiraDescriptionsAsQuery_maxICTF\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesICTF[\"JiraDescriptionsAsQuery_devICTF\"],\n",
    "                                                 # processedData_JIRAComments_academyFeaturesICTF[\"JiraCommentsAsQuery_avgICTF\"],\n",
    "                                                #  processedData_JIRAComments_academyFeaturesICTF[\"JiraCommentsAsQuery_maxICTF\"],\n",
    "                                               #   processedData_JIRAComments_academyFeaturesICTF[\"JiraCommentsAsQuery_devICTF\"],\n",
    "                                                  \n",
    "                                                  processedData_SVN_academyFeaturesEntropy[\"SvnAsQuery_avgEntropy\"],\n",
    "                                                  processedData_SVN_academyFeaturesEntropy[\"SvnAsQuery_medEntropy\"],\n",
    "                                                  processedData_SVN_academyFeaturesEntropy[\"SvnAsQuery_maxEntropy\"],\n",
    "                                                  processedData_SVN_academyFeaturesEntropy[\"SvnAsQuery_devEntropy\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesEntropy[\"SvnLogsAsQuery_avgEntropy\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesEntropy[\"SvnLogsAsQuery_medEntropy\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesEntropy[\"SvnLogsAsQuery_maxEntropy\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesEntropy[\"SvnLogsAsQuery_devEntropy\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesEntropy[\"SvnUnitNamesAsQuery_avgEntropy\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesEntropy[\"SvnUnitNamesAsQuery_medEntropy\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesEntropy[\"SvnUnitNamesAsQuery_maxEntropy\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesEntropy[\"SvnUnitNamesAsQuery_devEntropy\"],\n",
    "                                                  processedData_JIRA_academyFeaturesEntropy[\"JiraAsQuery_avgEntropy\"],\n",
    "                                                  processedData_JIRA_academyFeaturesEntropy[\"JiraAsQuery_medEntropy\"],\n",
    "                                                  processedData_JIRA_academyFeaturesEntropy[\"JiraAsQuery_maxEntropy\"],\n",
    "                                                  processedData_JIRA_academyFeaturesEntropy[\"JiraAsQuery_devEntropy\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesEntropy[\"JiraSummariesAsQuery_avgEntropy\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesEntropy[\"JiraSummariesAsQuery_medEntropy\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesEntropy[\"JiraSummariesAsQuery_maxEntropy\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesEntropy[\"JiraSummariesAsQuery_devEntropy\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesEntropy[\"JiraDescriptionsAsQuery_avgEntropy\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesEntropy[\"JiraDescriptionsAsQuery_medEntropy\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesEntropy[\"JiraDescriptionsAsQuery_maxEntropy\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesEntropy[\"JiraDescriptionsAsQuery_devEntropy\"],\n",
    "                                                #  processedData_JIRAComments_academyFeaturesEntropy[\"JiraCommentsAsQuery_avgEntropy\"],\n",
    "                                                 # processedData_JIRAComments_academyFeaturesEntropy[\"JiraCommentsAsQuery_medEntropy\"],\n",
    "                                                 # processedData_JIRAComments_academyFeaturesEntropy[\"JiraCommentsAsQuery_maxEntropy\"],\n",
    "                                                 # processedData_JIRAComments_academyFeaturesEntropy[\"JiraCommentsAsQuery_devEntropy\"],\n",
    "                                                  \n",
    "                                                  processedData_SVN_academyFeaturesQueryScope,\n",
    "                                                  processedData_SVNLogs_academyFeaturesQueryScope,\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesQueryScope,\n",
    "                                                  processedData_JIRA_academyFeaturesQueryScope,\n",
    "                                                  processedData_JIRASummaries_academyFeaturesQueryScope,\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesQueryScope,\n",
    "                                                #  processedData_JIRAComments_academyFeaturesQueryScope,\n",
    "                                                  \n",
    "                                                  processedData_SVN_academyFeaturesSCS,\n",
    "                                                  processedData_SVNLogs_academyFeaturesSCS,\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesSCS,\n",
    "                                                  processedData_JIRA_academyFeaturesSCS,\n",
    "                                                  processedData_JIRASummaries_academyFeaturesSCS,\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesSCS,\n",
    "                                                 # processedData_JIRAComments_academyFeaturesSCS,\n",
    "                                                  \n",
    "                                                  processedData_SVN_academyFeaturesSCQ[\"SvnAsQuery_avgSCQ\"],\n",
    "                                                  processedData_SVN_academyFeaturesSCQ[\"SvnAsQuery_maxSCQ\"],\n",
    "                                                  processedData_SVN_academyFeaturesSCQ[\"SvnAsQuery_sumSCQ\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesSCQ[\"SvnLogsAsQuery_avgSCQ\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesSCQ[\"SvnLogsAsQuery_maxSCQ\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesSCQ[\"SvnLogsAsQuery_sumSCQ\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesSCQ[\"SvnUnitNamesAsQuery_avgSCQ\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesSCQ[\"SvnUnitNamesAsQuery_maxSCQ\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesSCQ[\"SvnUnitNamesAsQuery_sumSCQ\"],\n",
    "                                                  processedData_JIRA_academyFeaturesSCQ[\"JiraAsQuery_avgSCQ\"],\n",
    "                                                  processedData_JIRA_academyFeaturesSCQ[\"JiraAsQuery_maxSCQ\"],\n",
    "                                                  processedData_JIRA_academyFeaturesSCQ[\"JiraAsQuery_sumSCQ\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesSCQ[\"JiraSummariesAsQuery_avgSCQ\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesSCQ[\"JiraSummariesAsQuery_maxSCQ\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesSCQ[\"JiraSummariesAsQuery_sumSCQ\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesSCQ[\"JiraDescriptionsAsQuery_avgSCQ\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesSCQ[\"JiraDescriptionsAsQuery_maxSCQ\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesSCQ[\"JiraDescriptionsAsQuery_sumSCQ\"],\n",
    "                                                 # processedData_JIRAComments_academyFeaturesSCQ[\"JiraCommentsAsQuery_avgSCQ\"],\n",
    "                                                 # processedData_JIRAComments_academyFeaturesSCQ[\"JiraCommentsAsQuery_maxSCQ\"],\n",
    "                                                 # processedData_JIRAComments_academyFeaturesSCQ[\"JiraCommentsAsQuery_sumSCQ\"],\n",
    "                                                  \n",
    "                                                  #processedData_SVN_academyFeaturesPMI[\"SvnAsQuery_avgPMI\"],\n",
    "                                                  #processedData_SVN_academyFeaturesPMI[\"SvnAsQuery_maxPMI\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesPMI[\"SvnLogsAsQuery_avgPMI\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesPMI[\"SvnLogsAsQuery_maxPMI\"],\n",
    "                                                 # processedData_SVNUnitNames_academyFeaturesPMI[\"SvnUnitNamesAsQuery_avgPMI\"],\n",
    "                                                 # processedData_SVNUnitNames_academyFeaturesPMI[\"SvnUnitNamesAsQuery_maxPMI\"],\n",
    "                                                 # processedData_JIRA_academyFeaturesPMI[\"JiraAsQuery_avgPMI\"],\n",
    "                                                 # processedData_JIRA_academyFeaturesPMI[\"JiraAsQuery_maxPMI\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesPMI[\"JiraSummariesAsQuery_avgPMI\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesPMI[\"JiraSummariesAsQuery_maxPMI\"],\n",
    "                                                #  processedData_JIRADescriptions_academyFeaturesPMI[\"JiraDescriptionsAsQuery_avgPMI\"],\n",
    "                                                #  processedData_JIRADescriptions_academyFeaturesPMI[\"JiraDescriptionsAsQuery_maxPMI\"],\n",
    "                                                  #processedData_JIRAComments_academyFeaturesPMI[\"JiraCommentsAsQuery_avgPMI\"],\n",
    "                                                  #processedData_JIRAComments_academyFeaturesPMI[\"JiraCommentssAsQuery_maxPMI\"],\n",
    "                                                 ], axis=1)\n",
    "#Set the NaN to 0\n",
    "processedData_academyFeatures = processedData_academyFeatures.fillna(0)\n",
    "\n",
    "#Saving feature names for later use\n",
    "processedData_academyFeatureNames = list(processedData_academyFeatures.columns)\n",
    "\n",
    "#Transform pandas data frame into numpy arrays\n",
    "processedData_academyFeatures = np.array(processedData_academyFeatures)\n",
    "\n",
    "#Load labels\n",
    "processedData_academyLabels = pd.read_pickle(r'../data/03_processed/processedData_academyLabels.pkl')\n",
    "processedData_academyLabels = np.array(processedData_academyLabels[\"is_valid\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-location",
   "metadata": {},
   "source": [
    "# 4. Modeling - Normalization\n",
    "First select which data set to train:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "\n",
    "\n",
    "def showModelPerformance(trainedModel, testFeatures, testLabels):\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictionLabels = trainedModel.predict(testFeatures)\n",
    "    \n",
    "    accuracyValue = accuracy_score(testLabels.astype(bool), predictionLabels)\n",
    "    precisionValue = precision_score(testLabels.astype(bool), predictionLabels, average='binary')\n",
    "    f1Value = f1_score(testLabels.astype(bool), predictionLabels)\n",
    "    f2Value = fbeta_score(testLabels.astype(bool), predictionLabels, beta=2.0)\n",
    "    f05Value = fbeta_score(testLabels.astype(bool), predictionLabels, beta=0.5)\n",
    "    recallValue = recall_score(testLabels.astype(bool), predictionLabels)\n",
    "    averagePrecisionValue = average_precision_score(testLabels.astype(bool), predictionLabels)\n",
    "          \n",
    "    performanceData = {'Accuracy':  [accuracyValue],\n",
    "                       'Precision': [precisionValue],\n",
    "                       'Recall': [recallValue],\n",
    "                       'F1': [f1Value],\n",
    "                       'F2': [f2Value],\n",
    "                       'F0.5': [f05Value],\n",
    "                       'Average Precision': [averagePrecisionValue]\n",
    "                      }\n",
    "    performanceDf = pd.DataFrame(performanceData)\n",
    "    return(performanceDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_normalized = processedData_academyFeatures_normalized\n",
    "labels_normalized = processedData_academyLabels_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-recruitment",
   "metadata": {},
   "source": [
    "## 4.1 Rebalancing Strategy - None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-belize",
   "metadata": {},
   "source": [
    "### 4.1.1 Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "none_randomforest_normalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized,\n",
    "                                                    labels_normalized,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels_normalized)\n",
    "\n",
    "\n",
    "    pipeline = Pipeline(steps = [#['smote', SMOTE(sampling_strategy = 0.5, n_jobs=2)],\n",
    "                              #['under', RandomUnderSampler()],\n",
    "                                ['classifier', RandomForestClassifier(n_jobs=-1)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    spaceEmpty = dict() \n",
    "\n",
    "    search = RandomizedSearchCV(estimator = pipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring='f1', \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedRFModel = search.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    #print(f\"Elapsed time to compute best fit: \"\n",
    "      #f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedRFModel.best_score_\n",
    "    test_score = optimizedRFModel.score(X_test, y_test)\n",
    "    #print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    #print('Best Hyperparameters: %s' % optimizedRFModel.best_params_)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedRFModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    \n",
    "    none_randomforest_normalized_performance_df = pd.concat([none_randomforest_normalized_performance_df, new_performance_df])\n",
    "    \n",
    "none_randomforest_normalized_performance_df.to_csv(\"../data/05_model_output/none_randomforest_normalized_performance_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-flesh",
   "metadata": {},
   "source": [
    "### 4.1.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "fhalf_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "\n",
    "none_xgboost_normalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized,\n",
    "                                                    labels_normalized,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels_normalized)\n",
    "\n",
    "\n",
    "    GXBoostPipeline = Pipeline(steps = [#['smote', SMOTE()],\n",
    "                                    #['under', RandomUnderSampler()],\n",
    "                                ['classifier', xgb.XGBClassifier(n_jobs=2)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    space['classifier__learning_rate'] = [0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60]\n",
    "    space['classifier__max_depth'] = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "    space['classifier__min_child_weight'] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    space['classifier__gamma'] = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    space['classifier__colsample_bytree'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    spaceEmpty = dict()\n",
    "\n",
    "    GXBoostSearch = RandomizedSearchCV(estimator = GXBoostPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring=fhalf_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedGXBoostModel = GXBoostSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    \n",
    "    cv_score = optimizedGXBoostModel.best_score_\n",
    "    test_score = optimizedGXBoostModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedGXBoostModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedGXBoostModel.best_estimator_._final_estimator.feature_importances_\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedGXBoostModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    print(new_performance_df)\n",
    "    none_xgboost_normalized_performance_df = pd.concat([none_xgboost_normalized_performance_df, new_performance_df])\n",
    "    \n",
    "\n",
    "none_xgboost_normalized_performance_df.to_csv(\"../data/05_model_output/none_xgboost_normalized_performance_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-quebec",
   "metadata": {},
   "source": [
    "### 4.1.3 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-genre",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "\n",
    "#Import feature selection stuff\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "\n",
    "# Import the model we are using\n",
    "import lightgbm as lgb\n",
    "\n",
    "none_lightgbm_performance_normalized_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "\n",
    "    ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized,\n",
    "                                                    labels_normalized,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels_normalized)\n",
    "\n",
    "\n",
    "    LightGBMPipeline = Pipeline(steps = [#['smote', SMOTE(sampling_strategy = 0.5, n_jobs=2)],\n",
    "                                    #['under', RandomUnderSampler()],\n",
    "                                ['classifier', lgb.LGBMClassifier(n_jobs=-1, importance_type='gain')]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "# define search space\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    spaceEmpty = dict()\n",
    "    space['classifier__num_leaves'] = [11, 16, 21, 26, 31, 36, 41, 46, 51, 56]\n",
    "    space['classifier__min_data_in_leaf'] =  [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__max_depth'] = [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__learning_rate'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9, 1.0]\n",
    "    space['classifier__max_bin'] = [50, 100, 150, 200, 255, 300, 350, 400, 450, 500]\n",
    "\n",
    "    LightGBMSearch = RandomizedSearchCV(estimator = LightGBMPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring= ftwo_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedLightGBMModel = LightGBMSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedLightGBMModel.best_score_\n",
    "    test_score = optimizedLightGBMModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedLightGBMModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedLightGBMModel.best_estimator_._final_estimator.booster_.feature_importance(importance_type='gain')\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedLightGBMModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    none_lightgbm_performance_normalized_df = pd.concat([none_lightgbm_performance_normalized_df, new_performance_df])\n",
    "    \n",
    "\n",
    "none_lightgbm_performance_normalized_df.to_csv(\"../data/05_model_output/none_lightgbm_performance_normalized_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-addition",
   "metadata": {},
   "source": [
    "## 4.2 Rebalancing Strategy - SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-nashville",
   "metadata": {},
   "source": [
    "### 4.2.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "smote_randomforest_normalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized,\n",
    "                                                    labels_normalized,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels_normalized)\n",
    "\n",
    "\n",
    "    pipeline = Pipeline(steps = [['smote', SMOTE()],\n",
    "                              #['under', RandomUnderSampler()],\n",
    "                                ['classifier', RandomForestClassifier(n_jobs=-1)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    spaceEmpty = dict() \n",
    "\n",
    "    search = RandomizedSearchCV(estimator = pipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring='f1', \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedRFModel = search.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    #print(f\"Elapsed time to compute best fit: \"\n",
    "      #f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedRFModel.best_score_\n",
    "    test_score = optimizedRFModel.score(X_test, y_test)\n",
    "    #print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    #print('Best Hyperparameters: %s' % optimizedRFModel.best_params_)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedRFModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    \n",
    "    smote_randomforest_normalized_performance_df = pd.concat([smote_randomforest_normalized_performance_df, new_performance_df])\n",
    "    \n",
    "smote_randomforest_normalized_performance_df.to_csv(\"../data/05_model_output/smote_randomforest_normalized_performance_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-accessory",
   "metadata": {},
   "source": [
    "### 4.2.3 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "fhalf_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "\n",
    "smote_xgboost_normalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized,\n",
    "                                                    labels_normalized,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels_normalized)\n",
    "\n",
    "\n",
    "    GXBoostPipeline = Pipeline(steps = [['smote', SMOTE()],\n",
    "                                    #['under', RandomUnderSampler()],\n",
    "                                ['classifier', xgb.XGBClassifier(n_jobs=2)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    space['classifier__learning_rate'] = [0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60]\n",
    "    space['classifier__max_depth'] = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "    space['classifier__min_child_weight'] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    space['classifier__gamma'] = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    space['classifier__colsample_bytree'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    spaceEmpty = dict()\n",
    "\n",
    "    GXBoostSearch = RandomizedSearchCV(estimator = GXBoostPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring=fhalf_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedGXBoostModel = GXBoostSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    \n",
    "    cv_score = optimizedGXBoostModel.best_score_\n",
    "    test_score = optimizedGXBoostModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedGXBoostModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedGXBoostModel.best_estimator_._final_estimator.feature_importances_\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedGXBoostModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    print(new_performance_df)\n",
    "    smote_xgboost_normalized_performance_df = pd.concat([smote_xgboost_normalized_performance_df, new_performance_df])\n",
    "    \n",
    "\n",
    "smote_xgboost_normalized_performance_df.to_csv(\"../data/05_model_output/smote_xgboost_normalized_performance_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-solution",
   "metadata": {},
   "source": [
    "### 4.2.4 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-cheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "\n",
    "#Import feature selection stuff\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "\n",
    "# Import the model we are using\n",
    "import lightgbm as lgb\n",
    "\n",
    "smote_lightgbm_performance_normalized_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "\n",
    "    ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized,\n",
    "                                                    labels_normalized,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels_normalized)\n",
    "\n",
    "\n",
    "    LightGBMPipeline = Pipeline(steps = [['smote', SMOTE()],\n",
    "                                    #['under', RandomUnderSampler()],\n",
    "                                ['classifier', lgb.LGBMClassifier(n_jobs=-1, importance_type='gain')]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "# define search space\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    spaceEmpty = dict()\n",
    "    space['classifier__num_leaves'] = [11, 16, 21, 26, 31, 36, 41, 46, 51, 56]\n",
    "    space['classifier__min_data_in_leaf'] =  [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__max_depth'] = [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__learning_rate'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9, 1.0]\n",
    "    space['classifier__max_bin'] = [50, 100, 150, 200, 255, 300, 350, 400, 450, 500]\n",
    "\n",
    "    LightGBMSearch = RandomizedSearchCV(estimator = LightGBMPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring= ftwo_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedLightGBMModel = LightGBMSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedLightGBMModel.best_score_\n",
    "    test_score = optimizedLightGBMModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedLightGBMModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedLightGBMModel.best_estimator_._final_estimator.booster_.feature_importance(importance_type='gain')\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedLightGBMModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    smote_lightgbm_performance_normalized_df = pd.concat([smote_lightgbm_performance_normalized_df, new_performance_df])\n",
    "    \n",
    "\n",
    "smote_lightgbm_performance_normalized_df.to_csv(\"../data/05_model_output/smote_lightgbm_performance_normalized_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-impression",
   "metadata": {},
   "source": [
    "## 4.3 Rebalancing Strategy - UNDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-class",
   "metadata": {},
   "source": [
    "### 4.3.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-venue",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "under_randomforest_normalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized,\n",
    "                                                    labels_normalized,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels_normalized)\n",
    "\n",
    "\n",
    "    pipeline = Pipeline(steps = [#['smote', SMOTE(sampling_strategy = 0.5, n_jobs=2)],\n",
    "                              ['under', RandomUnderSampler()],\n",
    "                                ['classifier', RandomForestClassifier(n_jobs=-1)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    spaceEmpty = dict() \n",
    "\n",
    "    search = RandomizedSearchCV(estimator = pipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring='f1', \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedRFModel = search.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    #print(f\"Elapsed time to compute best fit: \"\n",
    "      #f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedRFModel.best_score_\n",
    "    test_score = optimizedRFModel.score(X_test, y_test)\n",
    "    #print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    #print('Best Hyperparameters: %s' % optimizedRFModel.best_params_)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedRFModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    \n",
    "    under_randomforest_normalized_performance_df = pd.concat([under_randomforest_normalized_performance_df, new_performance_df])\n",
    "    \n",
    "under_randomforest_normalized_performance_df.to_csv(\"../data/05_model_output/under_randomforest_normalized_performance_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-housing",
   "metadata": {},
   "source": [
    "### 4.3.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "fhalf_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "\n",
    "under_xgboost_normalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized,\n",
    "                                                    labels_normalized,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels_normalized)\n",
    "\n",
    "\n",
    "    GXBoostPipeline = Pipeline(steps = [#['smote', SMOTE()],\n",
    "                                    ['under', RandomUnderSampler()],\n",
    "                                ['classifier', xgb.XGBClassifier(n_jobs=2)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    space['classifier__learning_rate'] = [0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60]\n",
    "    space['classifier__max_depth'] = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "    space['classifier__min_child_weight'] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    space['classifier__gamma'] = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    space['classifier__colsample_bytree'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    spaceEmpty = dict()\n",
    "\n",
    "    GXBoostSearch = RandomizedSearchCV(estimator = GXBoostPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring=fhalf_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedGXBoostModel = GXBoostSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    \n",
    "    cv_score = optimizedGXBoostModel.best_score_\n",
    "    test_score = optimizedGXBoostModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedGXBoostModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedGXBoostModel.best_estimator_._final_estimator.feature_importances_\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedGXBoostModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    print(new_performance_df)\n",
    "    under_xgboost_normalized_performance_df = pd.concat([under_xgboost_normalized_performance_df, new_performance_df])\n",
    "    \n",
    "\n",
    "under_xgboost_normalized_performance_df.to_csv(\"../data/05_model_output/under_xgboost_normalized_performance_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-beads",
   "metadata": {},
   "source": [
    "### 4.2.3 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-relay",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "\n",
    "#Import feature selection stuff\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "\n",
    "# Import the model we are using\n",
    "import lightgbm as lgb\n",
    "\n",
    "under_lightgbm_performance_normalized_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "\n",
    "    ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized,\n",
    "                                                    labels_normalized,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels_normalized)\n",
    "\n",
    "\n",
    "    LightGBMPipeline = Pipeline(steps = [#['smote', SMOTE()],\n",
    "                                    ['under', RandomUnderSampler()],\n",
    "                                ['classifier', lgb.LGBMClassifier(n_jobs=-1, importance_type='gain')]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "# define search space\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    spaceEmpty = dict()\n",
    "    space['classifier__num_leaves'] = [11, 16, 21, 26, 31, 36, 41, 46, 51, 56]\n",
    "    space['classifier__min_data_in_leaf'] =  [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__max_depth'] = [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__learning_rate'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9, 1.0]\n",
    "    space['classifier__max_bin'] = [50, 100, 150, 200, 255, 300, 350, 400, 450, 500]\n",
    "\n",
    "    LightGBMSearch = RandomizedSearchCV(estimator = LightGBMPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring= ftwo_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedLightGBMModel = LightGBMSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedLightGBMModel.best_score_\n",
    "    test_score = optimizedLightGBMModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedLightGBMModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedLightGBMModel.best_estimator_._final_estimator.booster_.feature_importance(importance_type='gain')\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedLightGBMModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    under_lightgbm_performance_normalized_df = pd.concat([under_lightgbm_performance_normalized_df, new_performance_df])\n",
    "    \n",
    "\n",
    "under_lightgbm_performance_normalized_df.to_csv(\"../data/05_model_output/under_lightgbm_performance_normalized_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-evanescence",
   "metadata": {},
   "source": [
    "## 4.4 Rebalancing Strategy - 5050"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-punch",
   "metadata": {},
   "source": [
    "### 4.4.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-gateway",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "fiftyfifty_randomforest_normalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized,\n",
    "                                                    labels_normalized,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels_normalized)\n",
    "\n",
    "\n",
    "    pipeline = Pipeline(steps = [['smote', SMOTE(sampling_strategy = 0.5)],\n",
    "                              ['under', RandomUnderSampler()],\n",
    "                                ['classifier', RandomForestClassifier(n_jobs=-1)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    spaceEmpty = dict() \n",
    "\n",
    "    search = RandomizedSearchCV(estimator = pipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring='f1', \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedRFModel = search.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    #print(f\"Elapsed time to compute best fit: \"\n",
    "      #f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedRFModel.best_score_\n",
    "    test_score = optimizedRFModel.score(X_test, y_test)\n",
    "    #print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    #print('Best Hyperparameters: %s' % optimizedRFModel.best_params_)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedRFModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    \n",
    "    fiftyfifty_randomforest_normalized_performance_df = pd.concat([fiftyfifty_randomforest_normalized_performance_df, new_performance_df])\n",
    "    \n",
    "fiftyfifty_randomforest_normalized_performance_df.to_csv(\"../data/05_model_output/fiftyfifty_randomforest_normalized_performance_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-jacket",
   "metadata": {},
   "source": [
    "### 4.4.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "fhalf_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "\n",
    "fiftyfifty_xgboost_normalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized,\n",
    "                                                    labels_normalized,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels_normalized)\n",
    "\n",
    "\n",
    "    GXBoostPipeline = Pipeline(steps = [['smote', SMOTE(sampling_strategy = 0.5)],\n",
    "                                    ['under', RandomUnderSampler()],\n",
    "                                ['classifier', xgb.XGBClassifier(n_jobs=2)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    space['classifier__learning_rate'] = [0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60]\n",
    "    space['classifier__max_depth'] = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "    space['classifier__min_child_weight'] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    space['classifier__gamma'] = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    space['classifier__colsample_bytree'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    spaceEmpty = dict()\n",
    "\n",
    "    GXBoostSearch = RandomizedSearchCV(estimator = GXBoostPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring=fhalf_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedGXBoostModel = GXBoostSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    \n",
    "    cv_score = optimizedGXBoostModel.best_score_\n",
    "    test_score = optimizedGXBoostModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedGXBoostModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedGXBoostModel.best_estimator_._final_estimator.feature_importances_\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedGXBoostModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    print(new_performance_df)\n",
    "    fiftyfifty_xgboost_normalized_performance_df = pd.concat([fiftyfifty_xgboost_normalized_performance_df, new_performance_df])\n",
    "    \n",
    "\n",
    "fiftyfifty_xgboost_normalized_performance_df.to_csv(\"../data/05_model_output/fiftyfifty_xgboost_normalized_performance_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-bibliography",
   "metadata": {},
   "source": [
    "### 4.4.3 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-salem",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "\n",
    "#Import feature selection stuff\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "\n",
    "# Import the model we are using\n",
    "import lightgbm as lgb\n",
    "\n",
    "fiftyfifty_lightgbm_performance_normalized_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "\n",
    "    ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized,\n",
    "                                                    labels_normalized,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels_normalized)\n",
    "\n",
    "\n",
    "    LightGBMPipeline = Pipeline(steps = [['smote', SMOTE(sampling_strategy = 0.5)],\n",
    "                                    ['under', RandomUnderSampler()],\n",
    "                                ['classifier', lgb.LGBMClassifier(n_jobs=-1, importance_type='gain')]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "# define search space\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    spaceEmpty = dict()\n",
    "    space['classifier__num_leaves'] = [11, 16, 21, 26, 31, 36, 41, 46, 51, 56]\n",
    "    space['classifier__min_data_in_leaf'] =  [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__max_depth'] = [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__learning_rate'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9, 1.0]\n",
    "    space['classifier__max_bin'] = [50, 100, 150, 200, 255, 300, 350, 400, 450, 500]\n",
    "\n",
    "    LightGBMSearch = RandomizedSearchCV(estimator = LightGBMPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring= ftwo_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedLightGBMModel = LightGBMSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedLightGBMModel.best_score_\n",
    "    test_score = optimizedLightGBMModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedLightGBMModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedLightGBMModel.best_estimator_._final_estimator.booster_.feature_importance(importance_type='gain')\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedLightGBMModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    fiftyfifty_lightgbm_performance_normalized_df = pd.concat([fiftyfifty_lightgbm_performance_normalized_df, new_performance_df])\n",
    "    \n",
    "\n",
    "fiftyfifty_lightgbm_performance_normalized_df.to_csv(\"../data/05_model_output/fiftyfifty_lightgbm_performance_normalized_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-republican",
   "metadata": {},
   "source": [
    "# 5. Modeling - Non-Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = processedData_academyFeatures\n",
    "labels = processedData_academyLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-bunch",
   "metadata": {},
   "source": [
    "## 5.1 Rebalancing Strategy - None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-century",
   "metadata": {},
   "source": [
    "### 5.1.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "none_randomforest_nonnormalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "    pipeline = Pipeline(steps = [#['smote', SMOTE(sampling_strategy = 0.5, n_jobs=2)],\n",
    "                              #['under', RandomUnderSampler()],\n",
    "                                ['classifier', RandomForestClassifier(n_jobs=-1)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    spaceEmpty = dict() \n",
    "\n",
    "    search = RandomizedSearchCV(estimator = pipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring='f1', \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedRFModel = search.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    #print(f\"Elapsed time to compute best fit: \"\n",
    "      #f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedRFModel.best_score_\n",
    "    test_score = optimizedRFModel.score(X_test, y_test)\n",
    "    #print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    #print('Best Hyperparameters: %s' % optimizedRFModel.best_params_)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedRFModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    \n",
    "    none_randomforest_nonnormalized_performance_df = pd.concat([none_randomforest_nonnormalized_performance_df, new_performance_df])\n",
    "    \n",
    "none_randomforest_nonnormalized_performance_df.to_csv(\"../data/05_model_output/none_randomforest_nonnormalized_performance_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-street",
   "metadata": {},
   "source": [
    "### 5.1.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "fhalf_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "\n",
    "none_xgboost_nonnormalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "    GXBoostPipeline = Pipeline(steps = [#['smote', SMOTE()],\n",
    "                                    #['under', RandomUnderSampler()],\n",
    "                                ['classifier', xgb.XGBClassifier(n_jobs=2)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    space['classifier__learning_rate'] = [0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60]\n",
    "    space['classifier__max_depth'] = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "    space['classifier__min_child_weight'] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    space['classifier__gamma'] = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    space['classifier__colsample_bytree'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    spaceEmpty = dict()\n",
    "\n",
    "    GXBoostSearch = RandomizedSearchCV(estimator = GXBoostPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring=fhalf_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedGXBoostModel = GXBoostSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    \n",
    "    cv_score = optimizedGXBoostModel.best_score_\n",
    "    test_score = optimizedGXBoostModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedGXBoostModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedGXBoostModel.best_estimator_._final_estimator.feature_importances_\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedGXBoostModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    print(new_performance_df)\n",
    "    none_xgboost_nonnormalized_performance_df = pd.concat([none_xgboost_nonnormalized_performance_df, new_performance_df])\n",
    "    \n",
    "\n",
    "none_xgboost_nonnormalized_performance_df.to_csv(\"../data/05_model_output/none_xgboost_nonnormalized_performance_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-kitty",
   "metadata": {},
   "source": [
    "### 5.1.3 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-isolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "\n",
    "#Import feature selection stuff\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "\n",
    "# Import the model we are using\n",
    "import lightgbm as lgb\n",
    "\n",
    "none_lightgbm_performance_nonnormalized_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "\n",
    "    ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "    LightGBMPipeline = Pipeline(steps = [#['smote', SMOTE()],\n",
    "                                    #['under', RandomUnderSampler()],\n",
    "                                ['classifier', lgb.LGBMClassifier(n_jobs=-1, importance_type='gain')]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "# define search space\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    spaceEmpty = dict()\n",
    "    space['classifier__num_leaves'] = [11, 16, 21, 26, 31, 36, 41, 46, 51, 56]\n",
    "    space['classifier__min_data_in_leaf'] =  [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__max_depth'] = [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__learning_rate'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9, 1.0]\n",
    "    space['classifier__max_bin'] = [50, 100, 150, 200, 255, 300, 350, 400, 450, 500]\n",
    "\n",
    "    LightGBMSearch = RandomizedSearchCV(estimator = LightGBMPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring= ftwo_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedLightGBMModel = LightGBMSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedLightGBMModel.best_score_\n",
    "    test_score = optimizedLightGBMModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedLightGBMModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedLightGBMModel.best_estimator_._final_estimator.booster_.feature_importance(importance_type='gain')\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedLightGBMModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    none_lightgbm_performance_nonnormalized_df = pd.concat([none_lightgbm_performance_nonnormalized_df, new_performance_df])\n",
    "    \n",
    "\n",
    "none_lightgbm_performance_nonnormalized_df.to_csv(\"../data/05_model_output/none_lightgbm_performance_nonnormalized_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-short",
   "metadata": {},
   "source": [
    "## 5.2 Rebalancing Strategy - SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-madison",
   "metadata": {},
   "source": [
    "### 5.2.1 Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-advocate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "smote_randomforest_nonnormalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "    pipeline = Pipeline(steps = [['smote', SMOTE()],\n",
    "                              #['under', RandomUnderSampler()],\n",
    "                                ['classifier', RandomForestClassifier(n_jobs=-1)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    spaceEmpty = dict() \n",
    "\n",
    "    search = RandomizedSearchCV(estimator = pipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring='f1', \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedRFModel = search.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    #print(f\"Elapsed time to compute best fit: \"\n",
    "      #f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedRFModel.best_score_\n",
    "    test_score = optimizedRFModel.score(X_test, y_test)\n",
    "    #print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    #print('Best Hyperparameters: %s' % optimizedRFModel.best_params_)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedRFModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    \n",
    "    smote_randomforest_nonnormalized_performance_df = pd.concat([smote_randomforest_nonnormalized_performance_df, new_performance_df])\n",
    "    \n",
    "smote_randomforest_nonnormalized_performance_df.to_csv(\"../data/05_model_output/smote_randomforest_nonnormalized_performance_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-custody",
   "metadata": {},
   "source": [
    "### 5.2.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "fhalf_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "\n",
    "smote_xgboost_nonnormalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "    GXBoostPipeline = Pipeline(steps = [['smote', SMOTE()],\n",
    "                                    #['under', RandomUnderSampler()],\n",
    "                                ['classifier', xgb.XGBClassifier(n_jobs=2)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    space['classifier__learning_rate'] = [0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60]\n",
    "    space['classifier__max_depth'] = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "    space['classifier__min_child_weight'] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    space['classifier__gamma'] = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    space['classifier__colsample_bytree'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    spaceEmpty = dict()\n",
    "\n",
    "    GXBoostSearch = RandomizedSearchCV(estimator = GXBoostPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring=fhalf_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedGXBoostModel = GXBoostSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    \n",
    "    cv_score = optimizedGXBoostModel.best_score_\n",
    "    test_score = optimizedGXBoostModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedGXBoostModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedGXBoostModel.best_estimator_._final_estimator.feature_importances_\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedGXBoostModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    print(new_performance_df)\n",
    "    smote_xgboost_nonnormalized_performance_df = pd.concat([smote_xgboost_nonnormalized_performance_df, new_performance_df])\n",
    "    \n",
    "\n",
    "smote_xgboost_nonnormalized_performance_df.to_csv(\"../data/05_model_output/smote_xgboost_nonnormalized_performance_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-request",
   "metadata": {},
   "source": [
    "### 5.2.3 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "\n",
    "#Import feature selection stuff\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "\n",
    "# Import the model we are using\n",
    "import lightgbm as lgb\n",
    "\n",
    "smote_lightgbm_performance_nonnormalized_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "\n",
    "    ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "    LightGBMPipeline = Pipeline(steps = [['smote', SMOTE()],\n",
    "                                    #['under', RandomUnderSampler()],\n",
    "                                ['classifier', lgb.LGBMClassifier(n_jobs=-1, importance_type='gain')]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "# define search space\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    spaceEmpty = dict()\n",
    "    space['classifier__num_leaves'] = [11, 16, 21, 26, 31, 36, 41, 46, 51, 56]\n",
    "    space['classifier__min_data_in_leaf'] =  [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__max_depth'] = [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__learning_rate'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9, 1.0]\n",
    "    space['classifier__max_bin'] = [50, 100, 150, 200, 255, 300, 350, 400, 450, 500]\n",
    "\n",
    "    LightGBMSearch = RandomizedSearchCV(estimator = LightGBMPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring= ftwo_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedLightGBMModel = LightGBMSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedLightGBMModel.best_score_\n",
    "    test_score = optimizedLightGBMModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedLightGBMModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedLightGBMModel.best_estimator_._final_estimator.booster_.feature_importance(importance_type='gain')\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedLightGBMModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    smote_lightgbm_performance_nonnormalized_df = pd.concat([smote_lightgbm_performance_nonnormalized_df, new_performance_df])\n",
    "    \n",
    "\n",
    "smote_lightgbm_performance_nonnormalized_df.to_csv(\"../data/05_model_output/smote_lightgbm_performance_nonnormalized_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-short",
   "metadata": {},
   "source": [
    "## 5.3 Rebalancing Strategy - UNDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-allocation",
   "metadata": {},
   "source": [
    "### 5.3.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "under_randomforest_nonnormalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "    pipeline = Pipeline(steps = [#['smote', SMOTE()],\n",
    "                              ['under', RandomUnderSampler()],\n",
    "                                ['classifier', RandomForestClassifier(n_jobs=-1)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    spaceEmpty = dict() \n",
    "\n",
    "    search = RandomizedSearchCV(estimator = pipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring='f1', \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedRFModel = search.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    #print(f\"Elapsed time to compute best fit: \"\n",
    "      #f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedRFModel.best_score_\n",
    "    test_score = optimizedRFModel.score(X_test, y_test)\n",
    "    #print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    #print('Best Hyperparameters: %s' % optimizedRFModel.best_params_)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedRFModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    \n",
    "    under_randomforest_nonnormalized_performance_df = pd.concat([under_randomforest_nonnormalized_performance_df, new_performance_df])\n",
    "    \n",
    "under_randomforest_nonnormalized_performance_df.to_csv(\"../data/05_model_output/under_randomforest_nonnormalized_performance_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-alias",
   "metadata": {},
   "source": [
    "### 5.3.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "fhalf_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "\n",
    "under_xgboost_nonnormalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "    GXBoostPipeline = Pipeline(steps = [#['smote', SMOTE()],\n",
    "                                    ['under', RandomUnderSampler()],\n",
    "                                ['classifier', xgb.XGBClassifier(n_jobs=2)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    space['classifier__learning_rate'] = [0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60]\n",
    "    space['classifier__max_depth'] = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "    space['classifier__min_child_weight'] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    space['classifier__gamma'] = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    space['classifier__colsample_bytree'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    spaceEmpty = dict()\n",
    "\n",
    "    GXBoostSearch = RandomizedSearchCV(estimator = GXBoostPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring=fhalf_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedGXBoostModel = GXBoostSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    \n",
    "    cv_score = optimizedGXBoostModel.best_score_\n",
    "    test_score = optimizedGXBoostModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedGXBoostModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedGXBoostModel.best_estimator_._final_estimator.feature_importances_\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedGXBoostModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    print(new_performance_df)\n",
    "    under_xgboost_nonnormalized_performance_df = pd.concat([under_xgboost_nonnormalized_performance_df, new_performance_df])\n",
    "    \n",
    "\n",
    "under_xgboost_nonnormalized_performance_df.to_csv(\"../data/05_model_output/under_xgboost_nonnormalized_performance_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-vinyl",
   "metadata": {},
   "source": [
    "### 5.3.3 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "\n",
    "#Import feature selection stuff\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "\n",
    "# Import the model we are using\n",
    "import lightgbm as lgb\n",
    "\n",
    "under_lightgbm_performance_nonnormalized_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "\n",
    "    ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "    LightGBMPipeline = Pipeline(steps = [#['smote', SMOTE()],\n",
    "                                    ['under', RandomUnderSampler()],\n",
    "                                ['classifier', lgb.LGBMClassifier(n_jobs=-1, importance_type='gain')]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "# define search space\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    spaceEmpty = dict()\n",
    "    space['classifier__num_leaves'] = [11, 16, 21, 26, 31, 36, 41, 46, 51, 56]\n",
    "    space['classifier__min_data_in_leaf'] =  [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__max_depth'] = [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__learning_rate'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9, 1.0]\n",
    "    space['classifier__max_bin'] = [50, 100, 150, 200, 255, 300, 350, 400, 450, 500]\n",
    "\n",
    "    LightGBMSearch = RandomizedSearchCV(estimator = LightGBMPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring= ftwo_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedLightGBMModel = LightGBMSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedLightGBMModel.best_score_\n",
    "    test_score = optimizedLightGBMModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedLightGBMModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedLightGBMModel.best_estimator_._final_estimator.booster_.feature_importance(importance_type='gain')\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedLightGBMModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    under_lightgbm_performance_nonnormalized_df = pd.concat([under_lightgbm_performance_nonnormalized_df, new_performance_df])\n",
    "    \n",
    "\n",
    "under_lightgbm_performance_nonnormalized_df.to_csv(\"../data/05_model_output/under_lightgbm_performance_nonnormalized_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-spider",
   "metadata": {},
   "source": [
    "## 5.1 Rebalancing Strategy - 5050"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-clerk",
   "metadata": {},
   "source": [
    "### 5.4.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "fiftyfifty_randomforest_nonnormalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "    pipeline = Pipeline(steps = [['smote', SMOTE(sampling_strategy = 0.5)],\n",
    "                              ['under', RandomUnderSampler()],\n",
    "                                ['classifier', RandomForestClassifier(n_jobs=-1)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    spaceEmpty = dict() \n",
    "\n",
    "    search = RandomizedSearchCV(estimator = pipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring='f1', \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedRFModel = search.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    #print(f\"Elapsed time to compute best fit: \"\n",
    "      #f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedRFModel.best_score_\n",
    "    test_score = optimizedRFModel.score(X_test, y_test)\n",
    "    #print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    #print('Best Hyperparameters: %s' % optimizedRFModel.best_params_)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedRFModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    \n",
    "    fiftyfifty_randomforest_nonnormalized_performance_df = pd.concat([fiftyfifty_randomforest_nonnormalized_performance_df, new_performance_df])\n",
    "    \n",
    "fiftyfifty_randomforest_nonnormalized_performance_df.to_csv(\"../data/05_model_output/fiftyfifty_randomforest_nonnormalized_performance_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-feedback",
   "metadata": {},
   "source": [
    "### 5.4.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-revision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "fhalf_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "\n",
    "fiftyfifty_xgboost_nonnormalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "    GXBoostPipeline = Pipeline(steps = [['smote', SMOTE(sampling_strategy = 0.5)],\n",
    "                                    ['under', RandomUnderSampler()],\n",
    "                                ['classifier', xgb.XGBClassifier(n_jobs=2)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    space['classifier__learning_rate'] = [0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60]\n",
    "    space['classifier__max_depth'] = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "    space['classifier__min_child_weight'] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    space['classifier__gamma'] = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    space['classifier__colsample_bytree'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    spaceEmpty = dict()\n",
    "\n",
    "    GXBoostSearch = RandomizedSearchCV(estimator = GXBoostPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring=fhalf_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedGXBoostModel = GXBoostSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    \n",
    "    cv_score = optimizedGXBoostModel.best_score_\n",
    "    test_score = optimizedGXBoostModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedGXBoostModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedGXBoostModel.best_estimator_._final_estimator.feature_importances_\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedGXBoostModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    print(new_performance_df)\n",
    "    fiftyfifty_xgboost_nonnormalized_performance_df = pd.concat([fiftyfifty_xgboost_nonnormalized_performance_df, new_performance_df])\n",
    "    \n",
    "\n",
    "fiftyfifty_xgboost_nonnormalized_performance_df.to_csv(\"../data/05_model_output/fiftyfifty_xgboost_nonnormalized_performance_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-drain",
   "metadata": {},
   "source": [
    "### 5.4.3 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-wheel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "\n",
    "#Import feature selection stuff\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "\n",
    "# Import the model we are using\n",
    "import lightgbm as lgb\n",
    "\n",
    "fiftyfifty_lightgbm_performance_nonnormalized_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "\n",
    "    ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "    LightGBMPipeline = Pipeline(steps = [['smote', SMOTE(sampling_strategy = 0.5)],\n",
    "                                    ['under', RandomUnderSampler()],\n",
    "                                ['classifier', lgb.LGBMClassifier(n_jobs=-1, importance_type='gain')]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "# define search space\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    spaceEmpty = dict()\n",
    "    space['classifier__num_leaves'] = [11, 16, 21, 26, 31, 36, 41, 46, 51, 56]\n",
    "    space['classifier__min_data_in_leaf'] =  [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__max_depth'] = [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__learning_rate'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9, 1.0]\n",
    "    space['classifier__max_bin'] = [50, 100, 150, 200, 255, 300, 350, 400, 450, 500]\n",
    "\n",
    "    LightGBMSearch = RandomizedSearchCV(estimator = LightGBMPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring= ftwo_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedLightGBMModel = LightGBMSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedLightGBMModel.best_score_\n",
    "    test_score = optimizedLightGBMModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedLightGBMModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedLightGBMModel.best_estimator_._final_estimator.booster_.feature_importance(importance_type='gain')\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedLightGBMModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    fiftyfifty_lightgbm_performance_nonnormalized_df = pd.concat([fiftyfifty_lightgbm_performance_nonnormalized_df, new_performance_df])\n",
    "    \n",
    "\n",
    "fiftyfifty_lightgbm_performance_nonnormalized_df.to_csv(\"../data/05_model_output/fiftyfifty_lightgbm_performance_nonnormalized_df.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-might",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-sharp",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-strategy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-chambers",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-death",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-balance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
