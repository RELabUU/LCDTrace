{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "handled-prediction",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rande\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rande\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "#Import Python Libraries\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "#Import Self-written Functions\n",
    "import os\n",
    "import sys\n",
    "src_dir = os.path.join(os.getcwd(), '..', 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from d00_utils.calculateTimeDifference import calculateTimeDifference #Function to calc time difference\n",
    "from d01_data.loadCommits import loadCommits #Function to load SVN data\n",
    "from d02_intermediate.cleanCommitData import cleanCommitData #Function to clean commit data\n",
    "from d02_intermediate.cleanJiraData import cleanJiraData #Function to clean JIRA data\n",
    "\n",
    "from d03_processing.createFittedTF_IDF import createFittedTF_IDF #Function to see if a trace is valid\n",
    "from d03_processing.createCorpusFromDocumentList import createCorpusFromDocumentList #Function to create a corpus\n",
    "from d03_processing.checkValidityTrace import checkValidityTrace #Function to see if a trace is valid\n",
    "from d03_processing.calculateTimeDif import calculateTimeDif #Calculate the time difference between 2 dates in seconds\n",
    "from d03_processing.checkFullnameEqualsEmail import checkFullnameEqualsEmail #Check if fullName is equal to the email\n",
    "from d03_processing.calculateCosineSimilarity import calculateCosineSimilarity #Calculate the cos similarity\n",
    "from d03_processing.calculateDocumentStatistics import calculateUniqueWordCount\n",
    "from d03_processing.calculateDocumentStatistics import calculateTotalWordCount\n",
    "from d03_processing.calculateDocumentStatistics import calculateOverlapBetweenDocuments\n",
    "\n",
    "from d04_modelling.summariseClassDistribution import summariseClassDistribution #Visualize the class distribution\n",
    "from d04_modelling.showModelPerformance import showModelPerformance # Show several performance measures\n",
    "\n",
    "#Display full value of a column\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "#Display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-sellers",
   "metadata": {},
   "source": [
    "# 1. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "amended-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set dataset\n",
    "\n",
    "datasetDirectory = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "played-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import raw JIRA dataset\n",
    "rawData_JIRA_mxShop = pd.read_excel('../data/01_raw/JIRA Mendix Engagement export_22_06_2021.xlsx')\n",
    "\n",
    "#import\n",
    "rawData_SVN_mxShop = loadCommits('../data/01_raw/MxShop-dump.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-utility",
   "metadata": {},
   "source": [
    "# 2. Clean Raw Data\n",
    "## 2.1 Clean Raw Data - SVN Data\n",
    "Clean the raw data of the SVN files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "institutional-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "#nltk for NLP \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.util import ngrams\n",
    "\n",
    "#Function to transform natural text into unigram tokens\n",
    "def preprocessNaturalLanguage(text, porterStemmer, cachedStopWords):\n",
    "    string_text = str(text)\n",
    "    #lowercase the string\n",
    "    lower_case_string = string_text.lower()\n",
    "    \n",
    "    #Remove interpunction\n",
    "    no_interpunction = lower_case_string.translate(str.maketrans('','',string.punctuation))\n",
    "    \n",
    "    #Remove numbers\n",
    "    no_numbers = ''.join([i for i in no_interpunction if not i.isdigit()])\n",
    "    \n",
    "    #tokenize string\n",
    "    tokens = word_tokenize(no_interpunction)\n",
    "    \n",
    "    #remove stopwords\n",
    "    tokens_without_sw = [word for word in tokens if not word in cachedStopWords]\n",
    "    \n",
    "    #Stem the tokens\n",
    "    stemmedToken = list(map(porterStemmer.stem, tokens_without_sw))\n",
    "\n",
    "    return(stemmedToken)\n",
    "\n",
    "#Function to transform natural text into n-gram tokens\n",
    "def preprocessNGrams(text, porterStemmer, cachedStopWords, nGramSize):\n",
    "    string_text = str(text)\n",
    "    \n",
    "    #lowercase the string\n",
    "    lower_case_string = string_text.lower()\n",
    "    \n",
    "    #Remove interpunction\n",
    "    no_interpunction = lower_case_string.translate(str.maketrans('','',string.punctuation))\n",
    "    \n",
    "    #Remove numbers\n",
    "    no_numbers = ''.join([i for i in no_interpunction if not i.isdigit()])\n",
    "    \n",
    "    #tokenize string\n",
    "    tokens = word_tokenize(no_interpunction)\n",
    "    \n",
    "    #Create the ngrams\n",
    "    ngrams = list(nltk.ngrams(tokens, nGramSize))\n",
    "    \n",
    "    #remove all the n-grams containing a stopword\n",
    "    cleanNGrams = [ngram for ngram in ngrams if not any(stop in ngram for stop in cachedStopWords)]\n",
    "    \n",
    "    #Stem the tokens\n",
    "    stemmedNGrams = []\n",
    "    for ngram in cleanNGrams:\n",
    "        stemmed = list(map(porterStemmer.stem, ngram))\n",
    "        stemmedNGrams.append(stemmed)\n",
    "    return(stemmedNGrams)\n",
    "\n",
    "#Function to transform date into a date object\n",
    "def preprocessCommitDate(date_string):\n",
    "    date_time_obj = datetime.strptime(date_string, '%Y-%m-%dT%H:%M:%S.%fZ')  \n",
    "    return(date_time_obj)\n",
    "    \n",
    "#Remove the found Issue key from the log\n",
    "def removeIssueKey(log_message):\n",
    "    issue_keys = re.findall(r\"LRN+.[0-9]+|AFM+.[0-9]+|MA+.[0-9]+|AFI+.[0-9]+|EM+.[0-9]+|OE+.[0-9]+|EM+.[0-9]+\", log_message)\n",
    "    log_message_without_key = log_message\n",
    "    for issue_key in issue_keys:\n",
    "        log_message_without_key = log_message_without_key.replace(issue_key, \"\")\n",
    "    return(log_message_without_key)\n",
    "\n",
    "def unitNamesLambdaFunc(unitName, stemmer):\n",
    "    #Lower case\n",
    "    unitNameLowered = unitName.lower()\n",
    "    \n",
    "    #Remove interpunction\n",
    "    noInterpunction = unitNameLowered.translate(str.maketrans('','',string.punctuation))\n",
    "    \n",
    "    #Remove numbers\n",
    "    noNumbers = ''.join([i for i in noInterpunction if not i.isdigit()])\n",
    "    \n",
    "    stemmendUnitName = stemmer.stem(noInterpunction)\n",
    "    \n",
    "    \n",
    "    return(stemmendUnitName)\n",
    "    \n",
    "\n",
    "def preprocessUnitNames(unitName, porterStemmer, cachedStopWords):\n",
    "    if (isinstance(unitName, str)):\n",
    "        #Split camelCasing\n",
    "        unitNameSplitList = re.sub('([A-Z][a-z]+)', r' \\1', re.sub('([A-Z]+)', r' \\1', unitName)).split()\n",
    "        \n",
    "        porterStemmer = PorterStemmer() #create an object of class PorterStemmer\n",
    "        \n",
    "        #Preprocess each split found.\n",
    "        unitNameLowered = list(map(lambda unitName: unitNamesLambdaFunc(unitName, porterStemmer), \n",
    "                                   unitNameSplitList))\n",
    "        \n",
    "        #Check for stopwords\n",
    "        tokensWithoutSW = [word for word in unitNameLowered if not word in cachedStopWords]\n",
    "\n",
    "        return(tokensWithoutSW)\n",
    "\n",
    "def preprocessNGramsUnitNames(unitName, porterStemmer, cachedStopWords, nGramSize):\n",
    "    if (isinstance(unitName, str)):\n",
    "        #Split camelCasing\n",
    "        unitNameSplitList = re.sub('([A-Z][a-z]+)', r' \\1', re.sub('([A-Z]+)', r' \\1', unitName)).split()\n",
    "        \n",
    "        cleanedUnitNames = []\n",
    "        for unitNameSplit in unitNameSplitList:\n",
    "            #Lower case unit names\n",
    "            lowerCased = unitNameSplit.lower()\n",
    "\n",
    "            #Remove interpunction\n",
    "            removedInterpunction = lowerCased.translate(str.maketrans('','',string.punctuation))\n",
    "            cleanedUnitNames.append(removedInterpunction)\n",
    "            \n",
    "        #Transform to string (needed for tokenizer\n",
    "        unitNameString = ' '.join(cleanedUnitNames)\n",
    "\n",
    "        #Tokenzize words\n",
    "        tokenized = word_tokenize(unitNameString)\n",
    "        \n",
    "        #Create the ngrams\n",
    "        ngrams = list(nltk.ngrams(tokenized, nGramSize))\n",
    "        \n",
    "        porterStemmer = PorterStemmer() #create an object of class PorterStemmer\n",
    "        \n",
    "        #remove all the n-grams containing a stopword\n",
    "        cleanNGrams = [ngram for ngram in ngrams if not any(stop in ngram for stop in cachedStopWords)]\n",
    "    \n",
    "        #Stem the tokens\n",
    "        stemmedNGrams = []\n",
    "        for ngram in cleanNGrams:\n",
    "            stemmed = list(map(porterStemmer.stem, ngram))\n",
    "            stemmedNGrams.append(stemmed)\n",
    "            \n",
    "        return(stemmedNGrams)\n",
    "\n",
    "#Method to clean all columns of the provided data\n",
    "def cleanCommitData(rawCommitData): \n",
    "    #create an object of class PorterStemmer\n",
    "    porterStemmer = PorterStemmer()\n",
    "    \n",
    "    #Find all stopwords\n",
    "    cachedStopWords = stopwords.words(\"english\")\n",
    "    \n",
    "    #Remove all revisions without an issue key in the log message\n",
    "    commit_df = rawCommitData[rawCommitData[\"related_issue_key\"].notna()]\n",
    "\n",
    "    #Execute cleaning methods on dataset\n",
    "    cleaned_commit_logs = commit_df['log'].apply(lambda x: removeIssueKey(x))\n",
    "    processed_commit_logs = cleaned_commit_logs.apply(lambda x: preprocessNaturalLanguage(x, porterStemmer, cachedStopWords))\n",
    "    processed_commit_logs_2grams = cleaned_commit_logs.apply(lambda x: preprocessNGrams(x, porterStemmer, cachedStopWords, 2))\n",
    "    processed_commit_logs_3grams = cleaned_commit_logs.apply(lambda x: preprocessNGrams(x, porterStemmer, cachedStopWords, 3))\n",
    "    processed_date_times = commit_df['date'].apply(lambda x: preprocessCommitDate(x))\n",
    "    processed_unit_names = commit_df['impacted_unit_names'].apply(lambda x: preprocessUnitNames(x, porterStemmer, cachedStopWords))\n",
    "    processed_unit_names_2grams = commit_df['impacted_unit_names'].apply(lambda x: preprocessNGramsUnitNames(x, porterStemmer, cachedStopWords, 2))\n",
    "    processed_unit_names_3grams = commit_df['impacted_unit_names'].apply(lambda x: preprocessNGramsUnitNames(x, porterStemmer, cachedStopWords, 3))\n",
    "    \n",
    "\n",
    "    #Put all data together into a new dataframe\n",
    "    commit_data = {'Revision': commit_df[\"revision\"],\n",
    "               'Email' : commit_df[\"email\"],\n",
    "               'Commit_date': processed_date_times,\n",
    "               \"Issue_key_commit\": commit_df[\"related_issue_key\"],\n",
    "               'Logs': processed_commit_logs, \n",
    "               'Logs_2grams': processed_commit_logs_2grams, \n",
    "               'Logs_3grams': processed_commit_logs_3grams, \n",
    "               'Unit_names': processed_unit_names,\n",
    "               'Unit_names_2grams': processed_unit_names_2grams,\n",
    "               'Unit_names_3grams': processed_unit_names_3grams,\n",
    "               'Commit_natural_text': processed_commit_logs + processed_unit_names,\n",
    "               'Commit_natural_text_2grams': processed_commit_logs_2grams + processed_unit_names_2grams,\n",
    "               'Commit_natural_text_3grams': processed_commit_logs_3grams + processed_unit_names_3grams\n",
    "               }\n",
    "               \n",
    "    commit_processed_df = pd.DataFrame(data=commit_data)\n",
    "\n",
    "    return(commit_processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "continent-knowing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished cleaning after 0 minutes and 1.5980095863342285 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "intermediateData_SVN_mxShop = cleanCommitData(rawData_SVN_mxShop)\n",
    "\n",
    "#Create a temp XLSX file for all intermediate datasets\n",
    "intermediateData_SVN_mxShop.to_excel(excel_writer = \"../data/02_intermediate/intermediateData_SVN_mxShop.xlsx\", index = False)\n",
    "\n",
    "#Create a pickle file for all intermediate datasets\n",
    "intermediateData_SVN_mxShop.to_pickle(path= \"../data/02_intermediate/intermediateData_SVN_mxShop.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished cleaning after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "specialized-shame",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\rande\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import string\n",
    "#nltk for NLP \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag  import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "#Function to clean the comments\n",
    "def clean_comments(comment):\n",
    "    try:\n",
    "        commentDates = re.findall(r\"[0-9]{2} [A-Z][a-z]{2} [0-9]{4} [0-9]{2}:[0-9]{2};[a-zA-Z0-9_]{24};\", comment)\n",
    "        accountIds = re.findall(r\"\\[~accountid:[a-zA-Z0-9]{24}\\]\", comment)\n",
    "               \n",
    "        \n",
    "        cleanedComment = comment.replace(\"nan\",'')\n",
    "        for commentDate in commentDates:\n",
    "            cleanedComment = cleanedComment.replace(commentDate,'')\n",
    "        \n",
    "        for accountId in accountIds: \n",
    "            cleanedComment = cleanedComment.replace(accountId,'')\n",
    "        \n",
    "        return(cleanedComment)\n",
    "    except:\n",
    "        return(\"\")\n",
    "\n",
    "def preprocess(text, porterStemmer, cachedStopwords):\n",
    "    string_text = str(text)\n",
    "    #lowercase the string\n",
    "    lower_case_string = string_text.lower()\n",
    "    \n",
    "    #Remove interpunction\n",
    "    no_interpunction = lower_case_string.translate(str.maketrans('','',string.punctuation))\n",
    "    \n",
    "    #Remove numbers\n",
    "    no_numbers = ''.join([i for i in no_interpunction if not i.isdigit()])\n",
    "    \n",
    "    #tokenize string\n",
    "    tokens = word_tokenize(no_numbers)\n",
    "    \n",
    "    #remove stopwords\n",
    "    tokens_without_sw = [word for word in tokens if not word in cachedStopwords]\n",
    "    \n",
    "    #Stem the tokens\n",
    "    stemmedToken = list(map(porterStemmer.stem, tokens_without_sw))\n",
    "\n",
    "    return(stemmedToken)\n",
    "\n",
    "def preprocessNGrams(text, porterStemmer, cachedStopWords, nGramSize):\n",
    "    string_text = str(text)\n",
    "    \n",
    "    #lowercase the string\n",
    "    lower_case_string = string_text.lower()\n",
    "    \n",
    "    #Remove interpunction\n",
    "    no_interpunction = lower_case_string.translate(str.maketrans('','',string.punctuation))\n",
    "    \n",
    "    #Remove numbers\n",
    "    no_numbers = ''.join([i for i in no_interpunction if not i.isdigit()])\n",
    "    \n",
    "    #tokenize string\n",
    "    tokens = word_tokenize(no_numbers)\n",
    "    \n",
    "    #Create the ngrams\n",
    "    ngrams = list(nltk.ngrams(tokens, nGramSize))\n",
    "    \n",
    "    #remove all the n-grams containing a stopword\n",
    "    cleanNGrams = [ngram for ngram in ngrams if not any(stop in ngram for stop in cachedStopWords)]\n",
    "    \n",
    "    #Stem the tokens\n",
    "    stemmedNGrams = []\n",
    "    for ngram in cleanNGrams:\n",
    "        stemmed = list(map(porterStemmer.stem, ngram))\n",
    "        stemmedNGrams.append(stemmed)\n",
    "    return(stemmedNGrams)\n",
    "\n",
    "#Function to transform date into a date object\n",
    "def preprocess_jira_date(date_string):\n",
    "    if(isinstance(date_string, str)):\n",
    "        try:\n",
    "            date_time_obj = datetime.strptime(date_string, '%d %b %Y %H:%M')\n",
    "        except:\n",
    "            date_time_obj = datetime.strptime(date_string, '%Y-%m-%d %H:%M:%S:%f')\n",
    "        return(date_time_obj)\n",
    "    elif(isinstance(date_string, datetime)): \n",
    "        return(date_string)\n",
    "    else:\n",
    "        return(np.nan)\n",
    "    \n",
    "    \n",
    "def findVerbs(tokenList):\n",
    "    posTags = pos_tag(tokenList)\n",
    "    verbAbrList = ['VBP', 'VBG', 'VBN', 'VBP', 'VBZ', 'RB', 'RBR', 'RBS']\n",
    "    verbList = []\n",
    "    for posTag in posTags:\n",
    "        if posTag[1] in verbAbrList:\n",
    "            verbList.append(posTag[0])\n",
    "    return(verbList)\n",
    "\n",
    "#Preprocess all the features and transform to the format needed for further processing.\n",
    "def preprocessJiraData(cleanDataFrame, preprocessComments, porterStemmer, cachedStopWords, startTime):\n",
    "    if (preprocessComments == True):\n",
    "        nOfSteps = '4'\n",
    "    else:\n",
    "        nOfSteps = '3'\n",
    "\n",
    "    #preprocess Summaries\n",
    "    jira_summaries = cleanDataFrame['Summary'].apply(lambda x: preprocess(x, porterStemmer, cachedStopWords))\n",
    "    jira_summaries_2grams = cleanDataFrame['Summary'].apply(lambda x: preprocessNGrams(x, porterStemmer, cachedStopWords, 2))\n",
    "    jira_summaries_3grams = cleanDataFrame['Summary'].apply(lambda x: preprocessNGrams(x, porterStemmer, cachedStopWords, 3))\n",
    "    \n",
    "    endTimeCleaningSummaries = time.time() - startTime\n",
    "    print(\"1/\" + nOfSteps + \") Finished Cleaning Summaries after \" + str(endTimeCleaningSummaries) + \" sec\")\n",
    "\n",
    "    #preprocess Descriptions\n",
    "    jira_descriptions = cleanDataFrame['Description'].apply(lambda x: preprocess(x, porterStemmer, cachedStopWords))\n",
    "    jira_descriptions_2grams = cleanDataFrame['Description'].apply(lambda x: preprocessNGrams(x, porterStemmer, cachedStopWords, 2))\n",
    "    jira_descriptions_3grams = cleanDataFrame['Description'].apply(lambda x: preprocessNGrams(x, porterStemmer, cachedStopWords, 2))\n",
    "    \n",
    "    endTimeCleaningDescriptions = time.time() - startTime\n",
    "    print(\"2/\" + nOfSteps + \") Finished Cleaning Description after \" + str(endTimeCleaningDescriptions) + \" sec\")\n",
    "\n",
    "    #preprocess Dates\n",
    "    jira_creation = cleanDataFrame['Created'].apply(lambda x: preprocess_jira_date(x))\n",
    "    jira_updated = cleanDataFrame['Updated'].apply(lambda x: preprocess_jira_date(x))\n",
    "    jira_resolved = cleanDataFrame['Resolved'].apply(lambda x: preprocess_jira_date(x))\n",
    "    endTimeCleaningDates = time.time() - startTime\n",
    "    print(\"3/\" + nOfSteps + \") Finished Cleaning Dates after \" + str(endTimeCleaningDates) + \" sec\")\n",
    "\n",
    "    #Comments take too long for a test run.\n",
    "    if (preprocessComments == True):\n",
    "        jira_comments = cleanDataFrame['Comments'].apply(lambda x: preprocess(x, porterStemmer, cachedStopWords))\n",
    "        jira_comments_2grams = cleanDataFrame['Comments'].apply(lambda x: preprocessNGrams(x, porterStemmer, cachedStopWords, 2))\n",
    "        jira_comments_3grams = cleanDataFrame['Comments'].apply(lambda x: preprocessNGrams(x, porterStemmer, cachedStopWords, 2))\n",
    "        endTimeCleaningComments = time.time() - startTime\n",
    "        print(\"4/\" + nOfSteps + \") Finished Cleaning Comments after \" + str(endTimeCleaningComments) + \" sec\")\n",
    "\n",
    "         #create JIRA corpus by merging Summary and Description\n",
    "        jira_data = {'Issue_key_jira': cleanDataFrame['Issue key'], \n",
    "             'Assignee': cleanDataFrame['Assignee'],\n",
    "             'Jira_created_date': jira_creation, \n",
    "             'Jira_updated_date': jira_updated, \n",
    "             'Jira_resolved_date': jira_resolved, \n",
    "             'Summary': jira_summaries, \n",
    "             'Summary_2grams': jira_summaries_2grams,\n",
    "             'Summary_3grams': jira_summaries_3grams, \n",
    "             'Description': jira_descriptions,\n",
    "             'Description_2grams': jira_descriptions_2grams,\n",
    "             'Description_3grams': jira_descriptions_3grams,\n",
    "             'Comments': jira_comments,\n",
    "             'Comments_2grams': jira_comments_2grams,\n",
    "             'Comments_3grams': jira_comments_3grams,\n",
    "             'Jira_natural_text': jira_summaries +  jira_descriptions + jira_comments,\n",
    "             'Jira_natural_text_2grams': jira_summaries_2grams +  jira_descriptions_2grams + jira_comments_2grams,\n",
    "             'Jira_natural_text_3grams': jira_summaries_3grams +  jira_descriptions_3grams + jira_comments_3grams}\n",
    "    else:\n",
    "         #create JIRA corpus by merging Summary and Description\n",
    "        jira_data = {'Issue_key_jira': cleanDataFrame['Issue key'], \n",
    "             'Assignee': cleanDataFrame['Assignee'],\n",
    "             'Jira_created_date': jira_creation, \n",
    "             'Jira_updated_date': jira_updated, \n",
    "             'Jira_resolved_date': jira_resolved, \n",
    "             'Summary': jira_summaries,\n",
    "             'Summary_2grams': jira_summaries_2grams,\n",
    "             'Summary_3grams': jira_summaries_3grams,\n",
    "             'Description': jira_descriptions,\n",
    "             'Description_2grams': jira_descriptions_2grams,\n",
    "             'Description_3grams': jira_descriptions_3grams,\n",
    "             'Jira_natural_text': jira_summaries +  jira_descriptions,\n",
    "             'Jira_natural_text_2grams': jira_summaries_2grams +  jira_descriptions_2grams,\n",
    "             'Jira_natural_text_3grams': jira_summaries_3grams +  jira_descriptions_3grams}\n",
    "\n",
    "    jira_processed_df = pd.DataFrame(data=jira_data)\n",
    "    \n",
    "    #Find verbs\n",
    "    jira_processed_df['verbs'] = jira_processed_df['Jira_natural_text'].apply(lambda x: findVerbs(x))\n",
    "    \n",
    "    return(jira_processed_df)\n",
    "\n",
    "#Input dataframe and num of_comments, and bool to determine if comments need to be cleaned\n",
    "def cleanJiraData(dataFrame, cleanComments, commentAmount):\n",
    "    startTime = time.time()\n",
    "\n",
    "    #create an object of class PorterStemmer\n",
    "    porterStemmer = PorterStemmer()\n",
    "    \n",
    "    #Find all stopwords\n",
    "    cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "    if (cleanComments == True):\n",
    "        #Subset only all comments \n",
    "        loc_first_comment = dataFrame.columns.get_loc('Comment') # Variable storing the col location of the 1st comment\n",
    "    \n",
    "        dataFrame[\"Comments\"] = dataFrame.iloc[:,loc_first_comment:loc_first_comment+commentAmount].apply(\n",
    "            lambda x: \" \".join(x.astype(str)), axis=1)\n",
    "    \n",
    "        #First remove the date and comment string from the comments\n",
    "        dataFrame[\"Comments\"] = dataFrame[\"Comments\"].apply(lambda x: clean_comments(x))\n",
    "\n",
    "        #Subset JIRA ID, Summary, Description, comments\n",
    "        jira_issues_subset = dataFrame[[\"Issue key\", \"Assignee\", \"Summary\", \"Description\", \"Comments\", \"Created\", \"Resolved\", \"Updated\"]]\n",
    "        cleanedAndProcessedJiraData = preprocessJiraData(jira_issues_subset, preprocessComments = True, porterStemmer = porterStemmer, cachedStopWords = cachedStopWords, startTime = startTime)\n",
    "        return(cleanedAndProcessedJiraData)\n",
    "    else: \n",
    "        jira_issues_subset = dataFrame[[\"Issue key\", \"Assignee\", \"Summary\", \"Description\", \"Created\", \"Resolved\", \"Updated\"]]\n",
    "        cleanedAndProcessedJiraData = preprocessJiraData(jira_issues_subset, preprocessComments = False, porterStemmer = porterStemmer, cachedStopWords = cachedStopWords, startTime = startTime)\n",
    "        return(cleanedAndProcessedJiraData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "loaded-zambia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3) Finished Cleaning Summaries after 0.39092397689819336 sec\n",
      "2/3) Finished Cleaning Description after 3.141378164291382 sec\n",
      "3/3) Finished Cleaning Dates after 3.146327495574951 sec\n"
     ]
    }
   ],
   "source": [
    "#Rename key to Issue key\n",
    "rawData_JIRA_mxShop = rawData_JIRA_mxShop.rename({'Key': 'Issue key'}, axis=1)\n",
    "\n",
    "#Clean Data sets\n",
    "intermediateData_JIRA_mxShop = cleanJiraData(dataFrame = rawData_JIRA_mxShop, cleanComments = False, commentAmount = 39)\n",
    "\n",
    "#Create a temp XLSX file for all intermediate datasets\n",
    "intermediateData_JIRA_mxShop.to_excel(excel_writer = \"../data/02_intermediate/intermediateData_JIRA_mxShop.xlsx\", index = False)\n",
    "\n",
    "#Create a pickle file for all intermediate datasets\n",
    "intermediateData_JIRA_mxShop.to_pickle(path= \"../data/02_intermediate/intermediateData_JIRA_mxShop.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-bankruptcy",
   "metadata": {},
   "source": [
    "## 2.4 Clean Raw Data - Create JIRA Corpora\n",
    "Create the corpora for JIRA UNIGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "provincial-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCorpusFromDocumentList(token_column):\n",
    "    token_list = token_column.tolist()\n",
    "    corpus_list = []\n",
    "    \n",
    "    for document in token_list:\n",
    "        #Only join to the string when a list. When it is not a list, then it is np.NaN, thus no changes\n",
    "        if(isinstance(document, list)):\n",
    "            #Transform list to a string for SKLEARN to accept the input.\n",
    "            token_string = ' '.join(document)\n",
    "        \n",
    "            #Add string to the corpus list\n",
    "            corpus_list.append(token_string)\n",
    "    return(corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "confused-corrections",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create JIRA corpus for mxShop dataset\n",
    "intermediateData_JIRA_mxShopCorpusSummary = createCorpusFromDocumentList(intermediateData_JIRA_mxShop.Summary)\n",
    "intermediateData_JIRA_mxShopCorpusDescription = createCorpusFromDocumentList(intermediateData_JIRA_mxShop.Description)\n",
    "\n",
    "#Merge all JIRA Corpora into 1 corpus\n",
    "intermediateData_JIRA_mxShopCorpus = [i+\" \"+j for i,j in zip(intermediateData_JIRA_mxShopCorpusSummary,\n",
    "                                                                             intermediateData_JIRA_mxShopCorpusDescription\n",
    "                                                                            )]\n",
    "\n",
    "#Save intermediate pickles\n",
    "with open('../data/02_intermediate/intermediateData_JIRA_mxShopCorpus.pkl', 'wb') as f:\n",
    "    pickle.dump(intermediateData_JIRA_mxShopCorpus, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-tanzania",
   "metadata": {},
   "source": [
    "Bigram corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fifth-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCorpusNGrams(tokenColumn):\n",
    "    tokenList = tokenColumn.tolist()\n",
    "    corpusList = []\n",
    "    \n",
    "    #Transform to strings\n",
    "    for document in tokenList:\n",
    "        if(isinstance(document, list)):\n",
    "            for ngram in document:\n",
    "                ngramString = ' '.join(ngram)\n",
    "                corpusList.append(ngramString)         \n",
    "    return(corpusList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "internal-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create JIRA corpus for mxShop dataset\n",
    "intermediateData_JIRA_mxShopCorpusSummary_2grams = createCorpusNGrams(intermediateData_JIRA_mxShop.Summary_2grams)\n",
    "intermediateData_JIRA_mxShopCorpusDescription_2grams = createCorpusNGrams(intermediateData_JIRA_mxShop.Description_2grams)\n",
    "\n",
    "#Merge all JIRA Corpora into 1 corpus\n",
    "intermediateData_JIRA_mxShopCorpus_2gram = [i+\" \"+j for i,j in zip(intermediateData_JIRA_mxShopCorpusSummary_2grams,\n",
    "                                                                             intermediateData_JIRA_mxShopCorpusDescription_2grams\n",
    "                                                                             )]\n",
    "\n",
    "\n",
    "#Save intermediate pickles\n",
    "with open('../data/02_intermediate/intermediateData_JIRA_mxShopCorpus_2gram.pkl', 'wb') as f:\n",
    "    pickle.dump(intermediateData_JIRA_mxShopCorpus_2gram, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-syntax",
   "metadata": {},
   "source": [
    "## 2.4 Clean Raw Data - Create SVN Corpora\n",
    "Create the corpora for SVN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "tropical-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediateData_SVN_mxShop = pd.read_pickle(\"../data/02_intermediate/intermediateData_SVN_mxShop.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "modern-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create corpus for log messages\n",
    "intermediateData_SVNLogs_mxShopCorpus = createCorpusFromDocumentList(intermediateData_SVN_mxShop.Logs)\n",
    "\n",
    "#Create corpus for unit names\n",
    "intermediateData_SVNUnitNames_mxShopCorpus = createCorpusFromDocumentList(intermediateData_SVN_mxShop.Unit_names)\n",
    "\n",
    "#Create corpus for entire commit (log message + model)\n",
    "intermediateData_SVN_mxShopCorpus = createCorpusFromDocumentList(intermediateData_SVN_mxShop.Logs + intermediateData_SVN_mxShop.Unit_names)\n",
    "intermediateData_SVN_mxShopCorpusAll = createCorpusFromDocumentList(intermediateData_SVN_mxShop.Logs + intermediateData_SVN_mxShop.Unit_names)\n",
    "#Save intermediate pickles\n",
    "with open('../data/02_intermediate/intermediateData_SVNLogs_mxShopCorpus.pkl', 'wb') as f:\n",
    "    pickle.dump(intermediateData_SVNLogs_mxShopCorpus, f)\n",
    "\n",
    "with open('../data/02_intermediate/intermediateData_SVNUnitNames_mxShopCorpus.pkl', 'wb') as f:\n",
    "    pickle.dump(intermediateData_SVNUnitNames_mxShopCorpus, f)\n",
    "\n",
    "with open('../data/02_intermediate/intermediateData_SVN_mxShopCorpus.pkl', 'wb') as f:\n",
    "    pickle.dump(intermediateData_SVN_mxShopCorpus, f)\n",
    "    \n",
    "with open('../data/02_intermediate/intermediateData_SVN_mxShopCorpusAll.pkl', 'wb') as f:\n",
    "    pickle.dump(intermediateData_SVN_mxShopCorpusAll, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-tactics",
   "metadata": {},
   "source": [
    "bigram corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "found-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediateData_SVNLogs_mxShopCorpus_2gram = createCorpusNGrams(intermediateData_SVN_mxShop.Logs_2grams)\n",
    "intermediateData_SVNUnitNames_mxShopCorpus_2gram = createCorpusNGrams(intermediateData_SVN_mxShop.Unit_names_2grams)\n",
    "with open('../data/02_intermediate/intermediateData_SVNLogs_mxShopCorpus_2gram.pkl', 'wb') as f:\n",
    "    pickle.dump(intermediateData_SVNLogs_mxShopCorpus_2gram, f)\n",
    "    \n",
    "    \n",
    "with open('../data/02_intermediate/intermediateData_SVNUnitNames_mxShopCorpus_2gram.pkl', 'wb') as f:\n",
    "    pickle.dump(intermediateData_SVNUnitNames_mxShopCorpus_2gram, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-collaboration",
   "metadata": {},
   "source": [
    "# 3. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "raising-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this code block when you've restarted the kernel, and want to use previously gained results.\n",
    "intermediateData_JIRA_mxShop = pd.read_pickle(\"../data/02_intermediate/intermediateData_JIRA_mxShop.pkl\")\n",
    "\n",
    "intermediateData_SVN_mxShop = pd.read_pickle(\"../data/02_intermediate/intermediateData_SVN_mxShop.pkl\")\n",
    "\n",
    "intermediateData_JIRA_mxShopCorpus = pd.read_pickle(r'../data/02_intermediate/intermediateData_JIRA_mxShopCorpus.pkl')\n",
    "intermediateData_JIRA_mxShopCorpus = pd.read_pickle(r'../data/02_intermediate/intermediateData_JIRA_mxShopCorpus.pkl')\n",
    "#intermediateData_SVN_mxShopCorpusAll = pd.read_pickle(r'../data/02_intermediate/intermediateData_SVN_mxShopCorpusAll.pkl')\n",
    "#intermediateData_SVN_mxShopCorpusModel = pd.read_pickle(r'../data/02_intermediate/intermediateData_SVN_mxShopCorpusModel.pkl')\n",
    "intermediateData_SVN_mxShopCorpus = pd.read_pickle(r'../data/02_intermediate/intermediateData_SVN_mxShopCorpus.pkl')\n",
    "\n",
    "############# Bigrams\n",
    "\n",
    "\n",
    "############# Trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-mouse",
   "metadata": {},
   "source": [
    "## 3.0 Preprocess Data - Create cartesian product JIRA x Commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "marked-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create cartesian products JIRA x Commits\n",
    "processedData_mxShopCartesian = intermediateData_JIRA_mxShop.merge(intermediateData_SVN_mxShop, how='cross')\n",
    "\n",
    "processedData_mxShopCartesian = processedData_mxShopCartesian.drop(processedData_mxShopCartesian[processedData_mxShopCartesian.Jira_created_date > processedData_mxShopCartesian.Commit_date].index)\n",
    "\n",
    "#Create a pickle file for all intermediate datasets\n",
    "processedData_mxShopCartesian.to_pickle(path= \"../data/03_processed/processedData_mxShopCartesian.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-texas",
   "metadata": {},
   "source": [
    "## 3.1 Preprocess Data - Create Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "romance-dubai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating labels for mxShop\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 33627 entries, 1432 to 129969\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   is_valid  33627 non-null  bool \n",
      "dtypes: bool(1)\n",
      "memory usage: 295.5 KB\n"
     ]
    }
   ],
   "source": [
    "#Create new dataFrames for the time features\n",
    "processedData_mxShopLabels = pd.DataFrame() \n",
    "\n",
    "\n",
    "#Create a column, which indicates which traces are valid.\n",
    "processedData_mxShopLabels[\"is_valid\"] = processedData_mxShopCartesian.apply(lambda x: checkValidityTrace(x.Issue_key_jira, x.Issue_key_commit), axis=1)\n",
    "print(\"Finished creating labels for mxShop\")\n",
    "\n",
    "#Save intermediate results\n",
    "processedData_mxShopLabels.to_pickle(path= \"../data/03_processed/processedData_mxShopLabels.pkl\")\n",
    "\n",
    "processedData_mxShopLabels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "special-november",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_valid    86\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#processedData_mxShopLabels[processedData_mxShopLabels.is_valid == True].count()\n",
    "processedData_mxShopLabels[processedData_mxShopLabels.is_valid == True].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-helicopter",
   "metadata": {},
   "source": [
    "## 3.2 Preprocess Data - Create Time-Related Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "emerging-driving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished data Processing\n"
     ]
    }
   ],
   "source": [
    "#Create new dataFrames for the time features\n",
    "processedData_mxShopFeaturesTime = pd.DataFrame() \n",
    "\n",
    "\n",
    "#Calculate the time features for data Processing Dataset\n",
    "processedData_mxShopFeaturesTime['Creation_commit_date_dif'] = processedData_mxShopCartesian.apply(lambda x: calculateTimeDif(x.Jira_created_date, x.Commit_date), axis=1)\n",
    "processedData_mxShopFeaturesTime['Updated_commit_date_dif'] = processedData_mxShopCartesian.apply(lambda x: calculateTimeDif(x.Jira_updated_date, x.Commit_date), axis=1)\n",
    "processedData_mxShopFeaturesTime['Resolved_commit_date_dif'] = processedData_mxShopCartesian.apply(lambda x: calculateTimeDif(x.Jira_resolved_date, x.Commit_date), axis=1)\n",
    "print(\"Finished data Processing\")\n",
    "\n",
    "#Create a pickle file for all intermediate datasets\n",
    "processedData_mxShopFeaturesTime.to_pickle(path= \"../data/03_processed/processedData_mxShopFeaturesTime.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-exchange",
   "metadata": {},
   "source": [
    "## 3.3 Preprocess Data - Create Stakeholder-Related Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "thousand-logistics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished mxShop\n"
     ]
    }
   ],
   "source": [
    "#Create new dataFrames for the Stakeholder features\n",
    "processedData_mxShopFeaturesStakeholder = pd.DataFrame() \n",
    "\n",
    "processedData_mxShopFeaturesStakeholder['Assignee_is_commiter'] = processedData_mxShopCartesian.apply(lambda x: checkFullnameEqualsEmail(x.Assignee, x.Email), axis=1)\n",
    "print(\"Finished mxShop\")\n",
    "\n",
    "#Create a pickle file for all intermediate datasets\n",
    "processedData_mxShopFeaturesStakeholder.to_pickle(path= \"../data/03_processed/processedData_mxShopFeaturesStakeholder.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-marijuana",
   "metadata": {},
   "source": [
    "## 3.4 Preprocess Data - Create Cosine Similarity Features\n",
    "### 3.4.1 mxShop - Cosine Similarity UniGrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "infectious-imagination",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "import pandas as pd\n",
    "\n",
    "def calc_vector_representation(document, cv, fittedTF_IDF):        \n",
    "    #Transform document type to a string\n",
    "    documentString = document\n",
    "    \n",
    "    #Calculate the Term Frequency of the document\n",
    "    inputDocs = [documentString] \n",
    "\n",
    "    # count matrix \n",
    "    count_vector = cv.transform(inputDocs) \n",
    " \n",
    "    #tf-idf scores \n",
    "    tf_idf_vector = fittedTF_IDF.transform(count_vector)\n",
    "\n",
    "    feature_names = cv.get_feature_names() \n",
    " \n",
    "    #get tfidf vector for first document \n",
    "    document_vector=tf_idf_vector[0] \n",
    " \n",
    "    #print the scores \n",
    "    \n",
    "    # place tf-idf values in a pandas data frame \n",
    "    df = pd.DataFrame(document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"]) \n",
    "    df.sort_values(by=[\"tfidf\"],ascending=False)\n",
    "\n",
    "    return(document_vector.T.todense())\n",
    "\n",
    "def calculateCosineSimilarity(document1, document2, cv, fittedTF_IDF):\n",
    "\n",
    "    #If both doc1 and doc2 are lists\n",
    "    if (isinstance(document1, list) & isinstance(document2, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ' '.join(document1)\n",
    "        document2String = ' '.join(document2)\n",
    "\n",
    "    #Only document1 is a list\n",
    "    elif(isinstance(document1, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ' '.join(document1)\n",
    "        document2String = ''\n",
    "\n",
    "    #Only document2 is a list\n",
    "    elif(isinstance(document2, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ''\n",
    "        document2String = ' '.join(document2)\n",
    "        \n",
    "    else:\n",
    "        document1String = ''\n",
    "        document2String = ''\n",
    "\n",
    "    vector1 = calc_vector_representation(document1String, cv, fittedTF_IDF)\n",
    "    vector2 = calc_vector_representation(document2String, cv, fittedTF_IDF)\n",
    "    \n",
    "    #The cosine similarity. Produces NaN if no terms are found in the corpus.\n",
    "    result = 1 - spatial.distance.cosine(vector1, vector2)\n",
    "    \n",
    "    return(result)\n",
    "\n",
    "def calculateCosineSimilarityNGrams(document1, document2, cv, fittedTF_IDF):\n",
    "\n",
    "    #If both doc1 and doc2 are lists\n",
    "    if (isinstance(document1, list) & isinstance(document2, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ' '.join(document1)\n",
    "        document2String = ' '.join(document2)\n",
    "\n",
    "    #Only document1 is a list\n",
    "    elif(isinstance(document1, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ' '.join(document1)\n",
    "        document2String = ''\n",
    "\n",
    "    #Only document2 is a list\n",
    "    elif(isinstance(document2, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ''\n",
    "        document2String = ' '.join(document2)\n",
    "        \n",
    "    else:\n",
    "        document1String = ''\n",
    "        document2String = ''\n",
    "\n",
    "    vector1 = calc_vector_representation(document1String, cv, fittedTF_IDF)\n",
    "    vector2 = calc_vector_representation(document2String, cv, fittedTF_IDF)\n",
    "    \n",
    "    #The cosine similarity. Produces NaN if no terms are found in the corpus.\n",
    "    result = 1 - spatial.distance.cosine(vector1, vector2)\n",
    "    \n",
    "    return(result)\n",
    "\n",
    "\n",
    "def calculateCosineSimilarityWithPOSPruning(document1, document2, cv, fittedTF_IDF, verbList):\n",
    "\n",
    "    #If both doc1 and doc2 are lists\n",
    "    if (isinstance(document1, list) & isinstance(document2, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ' '.join(document1)\n",
    "        document2String = ' '.join(document2)\n",
    "\n",
    "    #Only document1 is a list\n",
    "    elif(isinstance(document1, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ' '.join(document1)\n",
    "        document2String = ''\n",
    "\n",
    "    #Only document2 is a list\n",
    "    elif(isinstance(document2, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ''\n",
    "        document2String = ' '.join(document2)\n",
    "        \n",
    "    else:\n",
    "        document1String = ''\n",
    "        document2String = ''\n",
    "\n",
    "    vector1 = calc_vector_representation(document1String, cv, fittedTF_IDF)\n",
    "    vector2 = calc_vector_representation(document2String, cv, fittedTF_IDF)\n",
    "    \n",
    "    #The cosine similarity. Produces NaN if no terms are found in the corpus.\n",
    "    result = 1 - spatial.distance.cosine(vector1, vector2)\n",
    "    \n",
    "    verbCounter = 0\n",
    "    if(isinstance(document2, list)):\n",
    "        for token in document2:\n",
    "            if token in verbList:\n",
    "                verbCounter = verbCounter + 1\n",
    "    \n",
    "    if verbCounter > 0:\n",
    "        result = result * (1 + (0.1 * verbCounter))\n",
    "    else:\n",
    "        result = 0\n",
    "    \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "incorporate-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the count vectorizer and tfidf for the corpus\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "######################################################\n",
    "#                       mxShop              #\n",
    "######################################################\n",
    "\n",
    "################# Unigrams ###############\n",
    "#instantiate CountVectorizer() for SVN\n",
    "processedData_SVN_mxShopCountVectorizer = CountVectorizer()\n",
    "processedData_SVN_mxShopCountTF_IDF = createFittedTF_IDF(processedData_SVN_mxShopCountVectorizer, intermediateData_SVN_mxShopCorpus)\n",
    "\n",
    "processedData_SVNLogs_mxShopCountVectorizer = CountVectorizer()\n",
    "processedData_SVNLogs_mxShopCountTF_IDF = createFittedTF_IDF(processedData_SVNLogs_mxShopCountVectorizer, intermediateData_SVNLogs_mxShopCorpus)\n",
    "\n",
    "processedData_SVNUnitNames_mxShopCountVectorizer = CountVectorizer()\n",
    "processedData_SVNUnitNames_mxShopCountTF_IDF = createFittedTF_IDF(processedData_SVNUnitNames_mxShopCountVectorizer, intermediateData_SVNUnitNames_mxShopCorpus)\n",
    "\n",
    "#instantiate CountVectorizer() for JIRA - unigram\n",
    "processedData_JIRA_mxShopCountVectorizer = CountVectorizer()\n",
    "processedData_JIRA_mxShopCountTF_IDF = createFittedTF_IDF(processedData_JIRA_mxShopCountVectorizer, intermediateData_JIRA_mxShopCorpus)\n",
    "\n",
    "processedData_JIRASummaries_mxShopCountVectorizer = CountVectorizer()\n",
    "processedData_JIRASummaries_mxShopCountTF_IDF = createFittedTF_IDF(processedData_JIRASummaries_mxShopCountVectorizer, intermediateData_JIRA_mxShopCorpusSummary)\n",
    "\n",
    "processedData_JIRADescriptions_mxShopCountVectorizer = CountVectorizer()\n",
    "processedData_JIRADescriptions_mxShopCountTF_IDF = createFittedTF_IDF(processedData_JIRADescriptions_mxShopCountVectorizer, intermediateData_JIRA_mxShopCorpusDescription)\n",
    "\n",
    "#processedData_JIRAComments_mxShopCountVectorizer = CountVectorizer()\n",
    "#processedData_JIRAComments_mxShopCountTF_IDF = createFittedTF_IDF(processedData_JIRAComments_mxShopCountVectorizer, intermediateData_JIRA_mxShopCorpusComments)\n",
    "\n",
    "\n",
    "################# Bigrams ###############\n",
    "#instantiate CountVectorizer() for SVN - bigrams\n",
    "processedData_SVNLogs_mxShopCountVectorizer_2gram = CountVectorizer(ngram_range=(2, 2))\n",
    "processedData_SVNLogs_mxShopCountTF_IDF_2gram = createFittedTF_IDF(processedData_SVNLogs_mxShopCountVectorizer_2gram, intermediateData_SVNLogs_mxShopCorpus_2gram)\n",
    "\n",
    "processedData_SVNUnitNames_mxShopCountVectorizer_2gram = CountVectorizer()\n",
    "processedData_SVNUnitNames_mxShopCountTF_IDF_2gram = createFittedTF_IDF(processedData_SVNUnitNames_mxShopCountVectorizer_2gram, intermediateData_SVNUnitNames_mxShopCorpus_2gram)\n",
    "\n",
    "\n",
    "#instantiate CountVectorizer() for JIRA - biigram\n",
    "processedData_JIRA_mxShopCountVectorizer_2gram = CountVectorizer(ngram_range=(2, 2))\n",
    "processedData_JIRA_mxShopCountTF_IDF_2gram = createFittedTF_IDF(processedData_JIRA_mxShopCountVectorizer_2gram, intermediateData_JIRA_mxShopCorpus_2gram)\n",
    "\n",
    "processedData_JIRASummaries_mxShopCountVectorizer_2gram = CountVectorizer(ngram_range=(2, 2))\n",
    "processedData_JIRASummaries_mxShopCountTF_IDF_2gram = createFittedTF_IDF(processedData_JIRASummaries_mxShopCountVectorizer_2gram, intermediateData_JIRA_mxShopCorpusSummary_2grams)\n",
    "\n",
    "processedData_JIRADescriptions_mxShopCountVectorizer_2gram = CountVectorizer(ngram_range=(2, 2))\n",
    "processedData_JIRADescriptions_mxShopCountTF_IDF_2gram = createFittedTF_IDF(processedData_JIRADescriptions_mxShopCountVectorizer_2gram, intermediateData_JIRA_mxShopCorpusDescription_2grams)\n",
    "\n",
    "#processedData_JIRAComments_mxShopCountVectorizer_2gram = CountVectorizer(ngram_range=(2, 2))\n",
    "#processedData_JIRAComments_mxShopCountTF_IDF_2gram = createFittedTF_IDF(processedData_JIRAComments_mxShopCountVectorizer_2gram, intermediateData_JIRA_mxShopCorpusComments_2grams)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-audience",
   "metadata": {},
   "source": [
    "#### 3.4.1 [VSM unigram] Similarity between JIRA issue and Commit Log - Jira As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "governmental-replication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM Logs Jira as query' after 3 minutes and 40.32604956626892 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmLogsJiraAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmLogsJiraAsQuery[\"vsm_logs_jira_as_query\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Logs, processedData_JIRA_mxShopCountVectorizer, processedData_JIRA_mxShopCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmLogsJiraAsQuery.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmLogsJiraAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-september",
   "metadata": {},
   "source": [
    "#### 3.4.2 [VSM unigram] Similarity between JIRA issue and Commit Log - Log As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "suspected-stretch",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\scipy\\spatial\\distance.py:728: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM Logs Jira as query' after 1 minutes and 27.145812034606934 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmLogsLogAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmLogsLogAsQuery[\"vsm_logs_log_as_query\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Logs, processedData_SVNLogs_mxShopCountVectorizer, processedData_SVNLogs_mxShopCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmLogsLogAsQuery.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmLogsLogAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-basic",
   "metadata": {},
   "source": [
    "#### 3.4.3 [VSM unigram] Similarity between JIRA issue and Unit Names - JIRA As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "broadband-commodity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM Logs Jira as query' after 3 minutes and 43.94310140609741 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmUnitNamesJiraAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmUnitNamesJiraAsQuery[\"vsm_unit_names_jira_as_query\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Unit_names, processedData_JIRA_mxShopCountVectorizer, processedData_JIRA_mxShopCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmUnitNamesJiraAsQuery.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmUnitNamesJiraAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-drink",
   "metadata": {},
   "source": [
    "#### 3.4.1 [VSM unigram] Similarity between JIRA Summary and Commit Log - Jira As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "limiting-classics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM Logs Jira as query' after 2 minutes and 37.656718492507935 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmSummaryLogsSummaryAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmSummaryLogsSummaryAsQuery[\"vsm_summary_logs_summary_as_query\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarity(x.Summary, x.Logs, processedData_JIRASummaries_mxShopCountVectorizer, processedData_JIRASummaries_mxShopCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmSummaryLogsSummaryAsQuery.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmSummaryLogsSummaryAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-victor",
   "metadata": {},
   "source": [
    "#### 3.4.1 [VSM unigram] Similarity between JIRA Summary and Commit Log - Log As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "polar-lying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM Logs Jira as query' after 1 minutes and 25.61216139793396 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmSummaryLogsLogsAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmSummaryLogsLogsAsQuery[\"vsm_summary_logs_logs_as_query\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarity(x.Summary, x.Logs, processedData_SVNLogs_mxShopCountVectorizer, processedData_SVNLogs_mxShopCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmSummaryLogsLogsAsQuery.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmSummaryLogsLogsAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-receiver",
   "metadata": {},
   "source": [
    "#### 3.4.1 [VSM unigram] Similarity between JIRA Summary and UnitNames - Summary As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "small-request",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM Logs Jira as query' after 2 minutes and 55.66054844856262 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmSummaryUnitNamesSummaryAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmSummaryUnitNamesSummaryAsQuery[\"vsm_summary_unitNames_summary_as_query\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarity(x.Summary, x.Unit_names, processedData_JIRASummaries_mxShopCountVectorizer, processedData_JIRASummaries_mxShopCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmSummaryUnitNamesSummaryAsQuery.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmSummaryUnitNamesSummaryAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-guinea",
   "metadata": {},
   "source": [
    "#### 3.4.1 [VSM unigram] Similarity between JIRA Summary and UnitNames - UnitNames As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "convinced-terminology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM Logs Jira as query' after 2 minutes and 32.42275404930115 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmSummaryUnitNamesUnitNamesAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmSummaryUnitNamesUnitNamesAsQuery[\"vsm_summary_unitNames_unitNames_as_query\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarity(x.Summary, x.Unit_names, processedData_SVNUnitNames_mxShopCountVectorizer, processedData_SVNUnitNames_mxShopCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmSummaryUnitNamesSummaryAsQuery.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmSummaryUnitNamesUnitNamesAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-greek",
   "metadata": {},
   "source": [
    "#### 3.4.3 [VSM unigram - verb pruning] Similarity between JIRA issue and Unit Names - JIRA As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "rural-cholesterol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM Logs Jira as query and verb pruning' after 3 minutes and 42.609020471572876 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmVerbPruningUnitNamesJiraAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmVerbPruningUnitNamesJiraAsQuery[\"vsm_verb_pruning_unit_names_jira_as_query\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarityWithPOSPruning(x.Jira_natural_text, x.Unit_names, processedData_JIRA_mxShopCountVectorizer, processedData_JIRA_mxShopCountTF_IDF, x.verbs), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmVerbPruningUnitNamesJiraAsQuery.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmVerbPruningUnitNamesJiraAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query and verb pruning' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-jungle",
   "metadata": {},
   "source": [
    "#### 3.4.4 [VSM unigram] Similarity between JIRA issue and Unit Names  - Unit Names As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "plastic-northern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 2 minutes and 30.3442542552948 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmUnitNamesUnitNamesAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmUnitNamesUnitNamesAsQuery[\"vsm_unit_names_log_as_query\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Unit_names, processedData_SVNUnitNames_mxShopCountVectorizer, processedData_SVNUnitNames_mxShopCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmUnitNamesUnitNamesAsQuery.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmUnitNamesUnitNamesAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-hearts",
   "metadata": {},
   "source": [
    "#### 3.4.5 [VSM unigram] Similarity between JIRA description and commit log - Description as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "durable-afghanistan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 3 minutes and 38.9091432094574 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmDescriptionDescriptionAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmDescriptionDescriptionAsQuery[\"vsm_description_description_as_query\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarity(x.Description, x.Logs, processedData_JIRADescriptions_mxShopCountVectorizer, processedData_JIRADescriptions_mxShopCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmDescriptionDescriptionAsQuery.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmDescriptionDescriptionAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-trash",
   "metadata": {},
   "source": [
    "#### 3.4.5 [VSM unigram Silarity between JIRA description and commit log - Log as descrintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "exciting-colony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 2 minutes and 31.22728157043457 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmDescriptionLogsAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmDescriptionLogsAsQuery[\"vsm_description_log_as_query\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarity(x.Description, x.Unit_names, processedData_SVNUnitNames_mxShopCountVectorizer, processedData_SVNUnitNames_mxShopCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmDescriptionLogsAsQuery.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmDescriptionLogsAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-landing",
   "metadata": {},
   "source": [
    "#### 3.4.5 [VSM unigram Silarity between JIRA Comment and unitnames - Comment as query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-beginning",
   "metadata": {},
   "source": [
    "#### 3.4.5 [VSM unigram Silarity between JIRA Comment and unitnames - Comment as query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-accused",
   "metadata": {},
   "source": [
    "#### 3.4.5 [VSM unigram Silarity between JIRA Comment and commit log - Comment as description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-medicaid",
   "metadata": {},
   "source": [
    "#### 3.4.5 [VSM unigram Silarity between JIRA description and commit log - Log as description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-romantic",
   "metadata": {},
   "source": [
    "#### [VSM bigram] Similarity between JIRA comments and Commit Logs - Logs as query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-festival",
   "metadata": {},
   "source": [
    "#### 3.4.5 [VSM bigram] Silarity between JIRA Comment and commit log - Comment as query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-fairy",
   "metadata": {},
   "source": [
    "#### [VSM Unigram] Similarity between Unit Names and Description - Unit Names as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "violent-pound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 2 minutes and 32.14757180213928 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmUnitNamesDescriptionUnitNamesAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmUnitNamesDescriptionUnitNamesAsQuery[\"vsm_unitnames_description_unitnames_as_query\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarity(x.Description, x.Unit_names, processedData_SVNUnitNames_mxShopCountVectorizer, processedData_SVNUnitNames_mxShopCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmUnitNamesDescriptionUnitNamesAsQuery.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmUnitNamesDescriptionUnitNamesAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-patio",
   "metadata": {},
   "source": [
    "#### [VSM Unigram] Similarity between Unit Names and Description - Description as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "psychological-ghost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 3 minutes and 39.299832344055176 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmUnitNamesDescriptionDescriptionAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmUnitNamesDescriptionDescriptionAsQuery[\"vsm_unitnames_description_description_as_query\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarity(x.Description, x.Unit_names, processedData_JIRADescriptions_mxShopCountVectorizer, processedData_JIRADescriptions_mxShopCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmUnitNamesDescriptionDescriptionAsQuery.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmUnitNamesDescriptionDescriptionAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-schedule",
   "metadata": {},
   "source": [
    "#### [VSM Unigram] Similarity between Unit Names and Comments - Unit Names as query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-council",
   "metadata": {},
   "source": [
    "#### [VSM Unigram] Similarity between Unit Names and Comments - Comments as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ideal-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [VSM Unigram] Similarity between SVN (entirely) and JIRA (entirely)- JIRA as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "happy-charger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 3 minutes and 42.32733869552612 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmSvnJiraJiraAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmSvnJiraJiraAsQuery[\"vsm_svn_jira_jira_as_query\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Commit_natural_text, processedData_JIRA_mxShopCountVectorizer, processedData_JIRA_mxShopCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmSvnJiraJiraAsQuery.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmSvnJiraJiraAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "listed-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [VSM Unigram] Similarity between SVN (entirely) and JIRA (entirely) - SVN as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "deluxe-allergy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 2 minutes and 37.55129528045654 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmSvnJiraSvnAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmSvnJiraSvnAsQuery[\"vsm_svn_jira_svn_as_query\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Commit_natural_text, processedData_SVN_mxShopCountVectorizer, processedData_SVN_mxShopCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmSvnJiraSvnAsQuery.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmSvnJiraSvnAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "hindu-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [VSM Unigram] Similarity between SVN (entirely) and Summary - SVN as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "documentary-amazon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 2 minutes and 33.45942139625549 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmSvnSummarySvnAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmSvnSummarySvnAsQuery[\"vsm_svn_summary_svn_as_query\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarity(x.Commit_natural_text, x.Summary, processedData_SVN_mxShopCountVectorizer, processedData_SVN_mxShopCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmSvnSummarySvnAsQuery.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmSvnSummarySvnAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "incorporated-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [VSM Unigram] Similarity between SVN (entirely) and Summary - Summary as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "religious-fruit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 2 minutes and 38.702887296676636 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmSvnSummarySummaryAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmSvnSummarySummaryAsQuery[\"vsm_svn_summary_summary_as_query\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarity(x.Commit_natural_text, x.Summary, processedData_JIRASummaries_mxShopCountVectorizer, processedData_JIRASummaries_mxShopCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmSvnSummarySummaryAsQuery.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmSvnSummarySummaryAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "disabled-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [VSM Unigram] Similarity between SVN (entirely) and Description - SVN as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "located-blond",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 2 minutes and 37.61386013031006 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmSvnDescriptionSvnAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmSvnDescriptionSvnAsQuery[\"vsm_svn_description_svn_as_query\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarity(x.Commit_natural_text, x.Description, processedData_SVN_mxShopCountVectorizer, processedData_SVN_mxShopCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmSvnDescriptionSvnAsQuery.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmSvnDescriptionSvnAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "floppy-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [VSM Unigram] Similarity between SVN (entirely) and Description - Description as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "departmental-prediction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 3 minutes and 38.98972415924072 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmSvnDescriptionDescriptionAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmSvnDescriptionDescriptionAsQuery[\"vsm_svn_description_description_as_query\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarity(x.Commit_natural_text, x.Description, processedData_JIRADescriptions_mxShopCountVectorizer, processedData_JIRADescriptions_mxShopCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmSvnDescriptionDescriptionAsQuery.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmSvnDescriptionDescriptionAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "valuable-intersection",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [VSM Unigram] Similarity between SVN (entirely) and Comments - SVN as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cubic-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [VSM Unigram] Similarity between SVN (entirely) and Comments - Comments as query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-absorption",
   "metadata": {},
   "source": [
    "#### 3.4.3 [VSM unigram - verb pruning] Similarity between JIRA issue and Unit Names and verb pruning - Unit Names As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ruled-norman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 2 minutes and 33.43541121482849 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmVerbPruningUnitNamesUnitNamesAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmVerbPruningUnitNamesUnitNamesAsQuery[\"vsm_verb_pruning_unit_names_log_as_query\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarityWithPOSPruning(x.Jira_natural_text, x.Unit_names, processedData_SVNUnitNames_mxShopCountVectorizer, processedData_SVNUnitNames_mxShopCountTF_IDF, x.verbs), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmVerbPruningUnitNamesUnitNamesAsQuery.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmVerbPruningUnitNamesUnitNamesAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-freeze",
   "metadata": {},
   "source": [
    "#### 3.4.5 [VSM bigram] Similarity between JIRA issue and Commit Log - Jira As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "rolled-deficit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM Logs Jira as query' after 3 minutes and 57.775928020477295 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmLogsJiraAsQuery_2gram = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmLogsJiraAsQuery_2gram[\"vsm_logs_jira_as_query_2gram\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Logs, processedData_JIRA_mxShopCountVectorizer_2gram, processedData_JIRA_mxShopCountTF_IDF_2gram), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmLogsJiraAsQuery_2gram.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmLogsJiraAsQuery_2gram.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-northeast",
   "metadata": {},
   "source": [
    "#### 3.4.6 [VSM bigram] Similarity between JIRA issue and Commit Log - Logs As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "certain-editor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM Logs Jira as query' after 1 minutes and 28.329726219177246 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmLogsLogAsQuery_2gram = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmLogsLogAsQuery_2gram[\"vsm_logs_log_as_query_2gram\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Logs, processedData_SVNLogs_mxShopCountVectorizer_2gram, processedData_SVNLogs_mxShopCountTF_IDF_2gram), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmLogsLogAsQuery_2gram.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmLogsLogAsQuery_2gram.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-indie",
   "metadata": {},
   "source": [
    "#### 3.4.6 [VSM bigram] Similarity between JIRA issue and Unit Names - Jira As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "organic-button",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM Logs Jira as query' after 3 minutes and 6.739144325256348 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmUnitNamesJiraAsQuery_2gram = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmUnitNamesJiraAsQuery_2gram[\"vsm_unit_names_jira_as_query_2gram\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Unit_names, processedData_JIRA_mxShopCountVectorizer_2gram, processedData_JIRA_mxShopCountTF_IDF_2gram), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmUnitNamesJiraAsQuery_2gram.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmUnitNamesJiraAsQuery_2gram.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-sixth",
   "metadata": {},
   "source": [
    "#### 3.4.6 [VSM bigram] Similarity between JIRA issue and Unit Names - UnitNames As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "driven-contributor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 2 minutes and 33.26380109786987 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmUnitNamesUnitNamesAsQuery_2gram = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmUnitNamesUnitNamesAsQuery_2gram[\"vsm_unit_names_log_as_query_2gram\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Unit_names, processedData_SVNUnitNames_mxShopCountVectorizer_2gram, processedData_SVNUnitNames_mxShopCountTF_IDF_2gram), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmUnitNamesUnitNamesAsQuery_2gram.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmUnitNamesUnitNamesAsQuery_2gram.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-sector",
   "metadata": {},
   "source": [
    "#### [VSM bigram] Similarity between Logs and Description - Logs as Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "tropical-comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 1 minutes and 29.75190806388855 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmDescriptionLogsAsQuery_2gram = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmDescriptionLogsAsQuery_2gram[\"vsm_description_log_as_query_2gram\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarity(x.Description, x.Unit_names, processedData_SVNUnitNames_mxShopCountVectorizer_2gram, processedData_SVNUnitNames_mxShopCountTF_IDF_2gram), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmDescriptionLogsAsQuery_2gram.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmDescriptionLogsAsQuery_2gram.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-prince",
   "metadata": {},
   "source": [
    "#### [VSM bigram] Similarity between Logs and Description - Description as Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bacterial-scenario",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM Bigrams' after 5 minutes and 32.54574370384216 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmDescriptionDescriptionAsQuery_2gram = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmDescriptionDescriptionAsQuery_2gram[\"vsm_description_description_as_query_2gram\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarity(x.Description, x.Logs, processedData_JIRADescriptions_mxShopCountVectorizer_2gram, processedData_JIRADescriptions_mxShopCountTF_IDF_2gram), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmDescriptionDescriptionAsQuery_2gram.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmDescriptionDescriptionAsQuery_2gram.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Bigrams' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-simon",
   "metadata": {},
   "source": [
    "#### [VSM bigram] Similarity between Logs and Summary - Logs as Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-throat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "continent-african",
   "metadata": {},
   "source": [
    "#### [VSM bigram] Similarity between Logs and Summary - Summary as Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "legendary-significance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM Logs Jira as query' after 2 minutes and 45.65132427215576 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_mxShop_features_VsmSummaryLogsSummaryAsQuery_2gram = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_mxShop_features_VsmSummaryLogsSummaryAsQuery_2gram[\"vsm_summary_logs_summary_as_query_2gram\"] = processedData_mxShopCartesian.apply(lambda x: calculateCosineSimilarityNGrams(x.Summary, x.Logs, processedData_JIRASummaries_mxShopCountVectorizer_2gram, processedData_JIRASummaries_mxShopCountTF_IDF_2gram), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_mxShop_features_VsmSummaryLogsSummaryAsQuery_2gram.to_pickle(path= \"../data/03_processed/processedData_mxShop_features_VsmSummaryLogsSummaryAsQuery_2gram.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-separation",
   "metadata": {},
   "source": [
    "## 3.6 Document Statistics\n",
    "\n",
    "### mxShop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "armed-warren",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating document statistics in 0 minutes and 6.26347541809082 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRA_mxShopFeaturesUniqueWordCount = pd.DataFrame() \n",
    "processedData_SVN_mxShopFeaturesUniqueWordCount = pd.DataFrame() \n",
    "processedData_JIRA_mxShopFeaturesTotalWordCount = pd.DataFrame() \n",
    "processedData_SVN_mxShopFeaturesTotalWordCount = pd.DataFrame()\n",
    "\n",
    "processedData_JIRA_mxShopFeaturesOverlapPercentage = pd.DataFrame()\n",
    "processedData_SVN_mxShopFeaturesOverlapPercentage = pd.DataFrame()\n",
    "processedData_UNION_mxShopFeaturesOverlapPercentage = pd.DataFrame()\n",
    "\n",
    "#Calculate unique terms JIRA for each trace\n",
    "processedData_JIRA_mxShopFeaturesUniqueWordCount[\"unique_term_count_jira\"] = processedData_mxShopCartesian.apply(lambda x: calculateUniqueWordCount(x.Jira_natural_text), \n",
    "                                                            axis=1)\n",
    "#Calculate unique terms JIRA for each trace\n",
    "processedData_SVN_mxShopFeaturesUniqueWordCount[\"unique_term_count_svn\"] = processedData_mxShopCartesian.apply(lambda x: calculateUniqueWordCount(x.Commit_natural_text), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Calculate total terms JIRA for each trace\n",
    "processedData_JIRA_mxShopFeaturesTotalWordCount[\"total_term_count_jira\"] = processedData_mxShopCartesian.apply(lambda x: calculateTotalWordCount(x.Jira_natural_text), \n",
    "                                                            axis=1)\n",
    "#Calculate total terms JIRA for each trace\n",
    "processedData_SVN_mxShopFeaturesTotalWordCount[\"total_term_count_svn\"] = processedData_mxShopCartesian.apply(lambda x: calculateTotalWordCount(x.Commit_natural_text), \n",
    "                                                            axis=1)\n",
    "\n",
    "processedData_JIRA_mxShopFeaturesOverlapPercentage[\"overlap_percentage_compared_to_jira\"] = processedData_mxShopCartesian.apply(lambda x: calculateOverlapBetweenDocuments(x.Jira_natural_text, x.Commit_natural_text, 'list1'),\n",
    "                                                            axis=1)\n",
    "processedData_SVN_mxShopFeaturesOverlapPercentage[\"overlap_percentage_compared_to_svn\"] = processedData_mxShopCartesian.apply(lambda x: calculateOverlapBetweenDocuments(x.Jira_natural_text, x.Commit_natural_text, 'list2'),\n",
    "                                                            axis=1)\n",
    "processedData_UNION_mxShopFeaturesOverlapPercentage[\"overlap_percentage_compared_to_union\"] = processedData_mxShopCartesian.apply(lambda x: calculateOverlapBetweenDocuments(x.Jira_natural_text, x.Commit_natural_text, 'union'),\n",
    "                                                            axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRA_mxShopFeaturesUniqueWordCount.to_pickle(path= \"../data/03_processed/processedData_JIRA_mxShopFeaturesUniqueWordCount.pkl\")\n",
    "processedData_SVN_mxShopFeaturesUniqueWordCount.to_pickle(path= \"../data/03_processed/processedData_SVN_mxShopFeaturesUniqueWordCount.pkl\")\n",
    "processedData_JIRA_mxShopFeaturesTotalWordCount.to_pickle(path= \"../data/03_processed/processedData_JIRA_mxShopFeaturesTotalWordCount.pkl\")\n",
    "processedData_SVN_mxShopFeaturesTotalWordCount.to_pickle(path= \"../data/03_processed/processedData_SVN_mxShopFeaturesTotalWordCount.pkl\")\n",
    "\n",
    "processedData_JIRA_mxShopFeaturesOverlapPercentage.to_pickle(path= \"../data/03_processed/processedData_JIRA_mxShopFeaturesOverlapPercentage.pkl\")\n",
    "processedData_SVN_mxShopFeaturesOverlapPercentage.to_pickle(path= \"../data/03_processed/processedData_SVN_mxShopFeaturesOverlapPercentage.pkl\")\n",
    "processedData_UNION_mxShopFeaturesOverlapPercentage.to_pickle(path= \"../data/03_processed/processedData_UNION_mxShopFeaturesOverlapPercentage.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating document statistics in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-pressing",
   "metadata": {},
   "source": [
    "## 3.7 Query Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dirty-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the count vectorizer and tfidf for the corpus\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from statistics import mean, median, mode, stdev, variance\n",
    "from math import log, sqrt\n",
    "import itertools\n",
    "\n",
    "#Function calculating the IDFs of all query terms. Returns a list containing all IDFs\n",
    "def calcIDFList(document, cv, tfidf_transformer):\n",
    "    idfScoreList=[]\n",
    "    if isinstance(document, list):\n",
    "        termCount = len(document)\n",
    "        for term in document:\n",
    "            try:\n",
    "                indexOfWord = cv.get_feature_names().index(term)\n",
    "                idfScore = tfidf_transformer.idf_[indexOfWord]\n",
    "                idfScoreList.append(idfScore)\n",
    "            except:\n",
    "                idfScoreList.append(0)\n",
    "    else:\n",
    "        termCount = 0\n",
    "    return(idfScoreList)\n",
    "\n",
    "\n",
    "def calcAvgIDF(IDFList):\n",
    "    termCount = len(IDFList)\n",
    "    if(termCount != 0):\n",
    "        avgIdf = sum(IDFList) / termCount\n",
    "    else:\n",
    "        avgIdf = 0\n",
    "    return(avgIdf)\n",
    "\n",
    "def calcMaxIDF(IDFList): \n",
    "    termCount = len(IDFList)\n",
    "    if(termCount != 0):\n",
    "        maxIdf = np.amax(IDFList)\n",
    "    else: \n",
    "        maxIdf = 0\n",
    "    return(maxIdf)\n",
    "\n",
    "def calcDevIDF(IDFList):\n",
    "    termCount = len(IDFList)\n",
    "    if(termCount > 1):\n",
    "        stdevIdf = stdev(IDFList)\n",
    "    else: \n",
    "        stdevIdf = 0\n",
    "    return(stdevIdf)\n",
    "\n",
    "#Function calculating the ICTF of all query terms. Returns a list containing all IDFs\n",
    "def calcICTFList(document, cv, documentCount):\n",
    "    ICTFList = []\n",
    "        #For all terms in query, find how often they occur in the Corpus\n",
    "    if isinstance(document, list):\n",
    "        for term in document:\n",
    "            try:\n",
    "            #Find out how often the term occurs in the corpus\n",
    "                termFrequency = (cv.vocabulary_[term])\n",
    "                \n",
    "                #Compute the log\n",
    "                ictF = log(documentCount/termFrequency)\n",
    "            except:\n",
    "                ictF = 0\n",
    "            \n",
    "            ICTFList.append(ictF)\n",
    "    return(ICTFList)\n",
    "\n",
    "def calcAvgICTF(ICTFList, documentCount):\n",
    "    avgICTF = sum(ICTFList) / documentCount\n",
    "    return(avgICTF)\n",
    "\n",
    "\n",
    "def calcMaxICTF(ICTFList): \n",
    "    termCount = len(ICTFList)\n",
    "    if(termCount != 0):\n",
    "        maxICTF = np.amax(ICTFList)\n",
    "    else: \n",
    "        maxICTF = 0\n",
    "    return(maxICTF)\n",
    "\n",
    "def calcDevICTF(ICTFList):\n",
    "    termCount = len(ICTFList)\n",
    "    if(termCount > 1):\n",
    "        stdevICTF = stdev(ICTFList)\n",
    "    else: \n",
    "        stdevICTF = 0\n",
    "    return(stdevICTF)\n",
    "\n",
    "\n",
    "def calcEntropyList(query, cv, documentCount, docCollection):\n",
    "    #entropy(t) = ∑ (d∈Dt)  ( tf(t,d) / tf(t, D) ) * log |D|(tf(t,d) / tf(t, D) )\n",
    "        \n",
    "    entropyValueList = []\n",
    "    #for each term in the query, calculate the entropy of the query\n",
    "    if isinstance(query, list):\n",
    "        for queryTerm in query:\n",
    "            #For each d ∈ D\n",
    "            \n",
    "            partialEntropyList = []\n",
    "            \n",
    "            for d in docCollection:\n",
    "                #Check if queryTerm occurs in D (i.e/ d∈Dt)\n",
    "                if (isinstance(d, list)):\n",
    "                    if queryTerm in d:\n",
    "                        try:\n",
    "                            #Calculate the frequency of the term occurs in the document (i.e tf(t,d))\n",
    "                            queryTermFrequencyInDocument = d.count(queryTerm)\n",
    "                            \n",
    "                            #calculate the frequency the term occurs in the query corpus (i.e tf(t,D))\n",
    "                            queryTermFrequencyInCorpus = (cv.vocabulary_[queryTerm])\n",
    "                             \n",
    "                            # This part of the calculation tf(t,d) / tf(t, D)  * log |D|(tf(t,d) / tf(t, D))\n",
    "                            partialEntropy1stHalf = queryTermFrequencyInDocument / queryTermFrequencyInCorpus\n",
    "                            partialEntropy2ndHalf = log((queryTermFrequencyInDocument / queryTermFrequencyInCorpus), documentCount)\n",
    "                            partialEntropy = partialEntropy1stHalf\n",
    "                            partialEntropyList.append(partialEntropy)\n",
    "                        except:\n",
    "                            partialEntropyList.append(0) #If term not found entropy is 0\n",
    "            #this part of the calculation ∑ (d∈Dt)\n",
    "            entropyValueOfQueryTerm = sum(partialEntropyList)\n",
    "            entropyValueList.append(entropyValueOfQueryTerm)\n",
    "    \n",
    "    return(entropyValueList)\n",
    "\n",
    "\n",
    "def calcAvgEntropy(entropyValueList):\n",
    "    termCount = len(entropyValueList)\n",
    "    if(termCount != 0):\n",
    "        #Calculate the average of all the entropies\n",
    "        avgEntropy = sum(entropyValueList) / len(entropyValueList)\n",
    "    else:\n",
    "        avgEntropy = 0\n",
    "    return(avgEntropy)\n",
    "\n",
    "    \n",
    "def calcMedEntropy(entropyValueList):\n",
    "    termCount = len(entropyValueList)\n",
    "    if(termCount != 0):\n",
    "        #Calculate the average of all the entropies\n",
    "        medEntropy = median(entropyValueList)\n",
    "    else:\n",
    "        medEntropy = 0\n",
    "    return(medEntropy)\n",
    "    \n",
    "def calcMaxEntropy(entropyValueList):\n",
    "    termCount = len(entropyValueList)\n",
    "    if(termCount != 0):\n",
    "        maxEntropy = np.amax(entropyValueList)\n",
    "    else: \n",
    "        maxEntropy = 0\n",
    "    return(maxEntropy)\n",
    "    \n",
    "def calcDevEntropy(entropyValueList):\n",
    "    termCount = len(entropyValueList)\n",
    "    if(termCount > 1):\n",
    "        #Calculate the average of all the entropies\n",
    "        devEntropy = stdev(entropyValueList)\n",
    "    else:\n",
    "        devEntropy = 0\n",
    "    return(devEntropy)\n",
    "\n",
    "#The percentage of documents in the collection containing at least one of the query terms\n",
    "def calcQueryScope(query, docCollection): \n",
    "    counter = 0\n",
    "    if isinstance(query, list):\n",
    "        for document in docCollection:\n",
    "            #check if query occurs in term. \n",
    "            if(isinstance(document, list)):\n",
    "                for queryTerm in query:\n",
    "                    if queryTerm in document:\n",
    "                        counter = counter + 1\n",
    "                        break\n",
    "    queryScope = counter / len(docCollection)\n",
    "    return(queryScope)\n",
    "\n",
    "#The Kullback-Leiber divergence of the query language model from the collection language model\n",
    "def calcSCS(query, cv, docCount):\n",
    "    divergenceList = []\n",
    "    if isinstance(query, list):\n",
    "        for queryTerm in query:\n",
    "            try:\n",
    "                #frequency of term in query - tf(q, Q)/|Q|\n",
    "                pqQ = query.count(queryTerm) / len(query)\n",
    "                \n",
    "                #frequency of term in documentlist - tf(q, D)/|D|\n",
    "                pqD = cv.vocabulary_[queryTerm]\n",
    "                \n",
    "                divergence = pqQ * log(pqQ / pqD)\n",
    "                divergenceList.append(divergence)\n",
    "            except:\n",
    "                continue\n",
    "    SCS = sum(divergenceList)\n",
    "    return(SCS)\n",
    "\n",
    "#The average of the collection-query similarity (SCQ) over all query terms\n",
    "def calcSCQList(query, docCollection, cv, fittedTF_IDF, documentCount):\n",
    "    SCQList = []\n",
    "    if isinstance(query, list):\n",
    "        documentString = ' '.join(query)\n",
    "        \n",
    "        #Calculate the Term Frequency of the document\n",
    "        inputDocs = [documentString] \n",
    "        \n",
    "        # count matrix \n",
    "        count_vector = cv.transform(inputDocs) \n",
    " \n",
    "        #tf-idf scores \n",
    "        tf_idf_vector = fittedTF_IDF.transform(count_vector)\n",
    "        \n",
    "        feature_names = cv.get_feature_names() \n",
    "        # place tf-idf values in a pandas data frame \n",
    "        df = pd.DataFrame(tf_idf_vector.T.todense(), \n",
    "                          index=feature_names, columns=[\"tfidf\"])\n",
    "    \n",
    "        \n",
    "        #Find the tfidf of the term\n",
    "        for queryTerm in query:    \n",
    "            try:\n",
    "                tfidf = df[\"tfidf\"][queryTerm]\n",
    "                SCQ = (1 + log(tfidf))\n",
    "                SCQList.append(SCQ)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "    avgSCQ = sum(SCQList) / documentCount\n",
    "    return(SCQList)\n",
    "\n",
    "#The average of the collection-query similarity (SCQ) over all query terms\n",
    "def calcAvgSCQ(SCQList, documentCount):\n",
    "    avgSCQ = sum(SCQList) / documentCount\n",
    "    return(avgSCQ)\n",
    "    \n",
    "#The average of the collection-query similarity (SCQ) over all query terms\n",
    "def calcMaxSCQ(SCQList):\n",
    "    termCount = len(SCQList)\n",
    "    if(termCount != 0):\n",
    "        maxSCQ = np.amax(SCQList)\n",
    "    else:\n",
    "        maxSCQ = np.NaN\n",
    "    return(maxSCQ)\n",
    "\n",
    "#The average of the collection-query similarity (SCQ) over all query terms\n",
    "def calcSumSCQ(SCQList):\n",
    "    sumSCQ = sum(SCQList)\n",
    "    return(sumSCQ)\n",
    "\n",
    "def createTermPairs(cv):\n",
    "    terms = list(cv.vocabulary_.keys())\n",
    "    #Create all possible pair combinations from the terms in the query \n",
    "    pairCombinationList = list(itertools.combinations(terms, 2))\n",
    "    return(pairCombinationList)\n",
    "\n",
    "#Method to find out how often a term occurs in a document\n",
    "def findTermFrequencies(cv, docCollection):\n",
    "    terms = list(cv.vocabulary_.keys())\n",
    "    termFrequencies = {}\n",
    "    for term in terms:\n",
    "        termCounter = 0\n",
    "        for document in docCollection:\n",
    "            if isinstance(document, list):\n",
    "                if term in document: \n",
    "                    termCounter = termCounter + 1\n",
    "        termFrequencies[term] = termCounter\n",
    "    return(termFrequencies)\n",
    "\n",
    "#Method to find out how often both terms occur in a document. \n",
    "def findTermPairFrequencies(termPairs, docCollection):\n",
    "    termPairFrequencies = {}\n",
    "    for termPair in termPairs:\n",
    "        termPairCount = 0\n",
    "        for document in docCollection:\n",
    "            if (isinstance(document, list)):\n",
    "                if all(i in document for i in termPair):\n",
    "                    termPairCount = termPairCount + 1\n",
    "        termPairFrequencies[termPair] = termPairCount\n",
    "    return(termPairFrequencies)   \n",
    "\n",
    "def calcPMIList(query, termFrequencies, termPairFrequencies, docCollection):\n",
    "    if isinstance(query, list):\n",
    "    #Find the frequencies of the individual terms and the pairs\n",
    "        pairCombinationList = list(itertools.combinations(query, 2))\n",
    "        termOccurances = []\n",
    "        for pair in pairCombinationList:\n",
    "            try:\n",
    "                q1Freq = termFrequencies[pair[0]]\n",
    "            except:\n",
    "                q1Freq = 0\n",
    "            try:\n",
    "                q2Freq = termFrequencies[pair[1]]\n",
    "            except:\n",
    "                q2Freq = 0\n",
    "            try:\n",
    "                q1q2Freq = termPairFrequencies[pair]\n",
    "            except:\n",
    "                q1q2Freq = 0\n",
    "                    \n",
    "            termOccurances.append({'q1Freq': q1Freq, \n",
    "                                   'q2Freq': q2Freq, \n",
    "                                   'q1q2Freq': q1q2Freq})\n",
    "    \n",
    "        docCount = len(docCollection)\n",
    "        pmiList = []\n",
    "        for term in termOccurances:\n",
    "            pq1 = term['q1Freq'] / docCount\n",
    "            pq2 = term['q2Freq'] / docCount\n",
    "            pq1q2 = term['q1q2Freq'] / docCount\n",
    "\n",
    "            try:\n",
    "                pmi = log(pq1q2 /(pq1 * pq2))\n",
    "            except:\n",
    "                pmi = np.nan\n",
    "            pmiList.append(pmi)\n",
    "        return(pmiList)\n",
    "    else:\n",
    "        return(np.nan)\n",
    "\n",
    "def calcAvgPMI(pmiList):\n",
    "    if(isinstance(pmiList, list)):\n",
    "        pairCount = len(pmiList)\n",
    "        if(pairCount != 0):\n",
    "            #Calculate the average of all the entropies\n",
    "            avgPMI= np.nansum(pmiList) / pairCount\n",
    "        else:\n",
    "            avgPMI = 0\n",
    "        return(avgPMI)\n",
    "    return(np.nan)\n",
    "\n",
    "def calcMaxPMI(pmiList): \n",
    "    if(isinstance(pmiList, list)):\n",
    "        pairCount = len(pmiList)\n",
    "        if(pairCount != 0):\n",
    "            maxPMI = np.nanmax(pmiList)\n",
    "        else: \n",
    "            maxPMI = np.nan\n",
    "        return(maxPMI)\n",
    "    return(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "pharmaceutical-mexican",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read datasets from disk\n",
    "processedData_mxShopCartesian = pd.read_pickle(r\"../data/03_processed/processedData_mxShopCartesian.pkl\")\n",
    "\n",
    "#instantiate CountVectorizer() for SVN\n",
    "processedData_SVN_mxShopCountVectorizer = CountVectorizer()\n",
    "processedData_SVN_mxShopTF_IDF = createFittedTF_IDF(processedData_SVN_mxShopCountVectorizer, intermediateData_SVN_mxShopCorpusAll)\n",
    "\n",
    "#instantiate CountVectorizer() for JIRA\n",
    "processedData_JIRA_mxShopCountVectorizer = CountVectorizer()\n",
    "processedData_JIRA_mxShopTF_IDF = createFittedTF_IDF(processedData_JIRA_mxShopCountVectorizer, intermediateData_JIRA_mxShopCorpus)\n",
    "\n",
    "#Determine document counts\n",
    "intermediateData_JIRA_mxShop_documentCount = len(intermediateData_JIRA_mxShop.index)\n",
    "intermediateData_SVN_mxShop_documentCount = len(intermediateData_SVN_mxShop.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-stage",
   "metadata": {},
   "source": [
    "#### IDF Scores (SVN as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "opened-identity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 11 minutes and 33.5739266872406 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVN_mxShopFeaturesIDF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVN_mxShopFeaturesIDF[\"SvnAsQuery_IDF\"] = processedData_mxShopCartesian.apply(lambda x: calcIDFList(x.Commit_natural_text, \n",
    "                                                                                                                processedData_SVN_mxShopCountVectorizer, \n",
    "                                                                                                                processedData_SVN_mxShopTF_IDF),axis=1)\n",
    "\n",
    "processedData_SVN_mxShopFeaturesIDF[\"SvnAsQuery_avgIDF\"] = processedData_SVN_mxShopFeaturesIDF.apply(lambda x: calcAvgIDF(x.SvnAsQuery_IDF), axis=1)\n",
    "processedData_SVN_mxShopFeaturesIDF[\"SvnAsQuery_maxIDF\"] = processedData_SVN_mxShopFeaturesIDF.apply(lambda x: calcMaxIDF(x.SvnAsQuery_IDF), axis=1)\n",
    "processedData_SVN_mxShopFeaturesIDF[\"SvnAsQuery_devIDF\"] = processedData_SVN_mxShopFeaturesIDF.apply(lambda x: calcDevIDF(x.SvnAsQuery_IDF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVN_mxShopFeaturesIDF.to_pickle(path= \"../data/03_processed/processedData_SVN_mxShopFeaturesIDF.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-moment",
   "metadata": {},
   "source": [
    "#### IDF Scores (SVNLogs as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "statistical-warehouse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 1 minutes and 34.83880829811096 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNLogs_mxShopFeaturesIDF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNLogs_mxShopFeaturesIDF[\"SvnLogsAsQuery_IDF\"] = processedData_mxShopCartesian.apply(lambda x: calcIDFList(x.Logs, \n",
    "                                                                                                                processedData_SVNLogs_mxShopCountVectorizer, \n",
    "                                                                                                                processedData_SVNLogs_mxShopCountTF_IDF),axis=1)\n",
    "\n",
    "processedData_SVNLogs_mxShopFeaturesIDF[\"SvnLogsAsQuery_avgIDF\"] = processedData_SVNLogs_mxShopFeaturesIDF.apply(lambda x: calcAvgIDF(x.SvnLogsAsQuery_IDF), axis=1)\n",
    "processedData_SVNLogs_mxShopFeaturesIDF[\"SvnLogsAsQuery_maxIDF\"] = processedData_SVNLogs_mxShopFeaturesIDF.apply(lambda x: calcMaxIDF(x.SvnLogsAsQuery_IDF), axis=1)\n",
    "processedData_SVNLogs_mxShopFeaturesIDF[\"SvnLogsAsQuery_devIDF\"] = processedData_SVNLogs_mxShopFeaturesIDF.apply(lambda x: calcDevIDF(x.SvnLogsAsQuery_IDF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNLogs_mxShopFeaturesIDF.to_pickle(path= \"../data/03_processed/processedData_SVNLogs_mxShopFeaturesIDF.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-sampling",
   "metadata": {},
   "source": [
    "#### IDF Scores (SVNUnitNames as Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "polish-peeing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 1 minutes and 34.84552049636841 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNUnitNames_mxShopFeaturesIDF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNUnitNames_mxShopFeaturesIDF[\"SvnUnitNamesAsQuery_IDF\"] = processedData_mxShopCartesian.apply(lambda x: calcIDFList(x.Logs, \n",
    "                                                                                                                processedData_SVNLogs_mxShopCountVectorizer, \n",
    "                                                                                                                processedData_SVNLogs_mxShopCountTF_IDF),axis=1)\n",
    "\n",
    "processedData_SVNUnitNames_mxShopFeaturesIDF[\"SvnUnitNamesAsQuery_avgIDF\"] = processedData_SVNUnitNames_mxShopFeaturesIDF.apply(lambda x: calcAvgIDF(x.SvnUnitNamesAsQuery_IDF), axis=1)\n",
    "processedData_SVNUnitNames_mxShopFeaturesIDF[\"SvnUnitNamesAsQuery_maxIDF\"] = processedData_SVNUnitNames_mxShopFeaturesIDF.apply(lambda x: calcMaxIDF(x.SvnUnitNamesAsQuery_IDF), axis=1)\n",
    "processedData_SVNUnitNames_mxShopFeaturesIDF[\"SvnUnitNamesAsQuery_devIDF\"] = processedData_SVNUnitNames_mxShopFeaturesIDF.apply(lambda x: calcDevIDF(x.SvnUnitNamesAsQuery_IDF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNUnitNames_mxShopFeaturesIDF.to_pickle(path= \"../data/03_processed/processedData_SVNUnitNames_mxShopFeaturesIDF.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-arena",
   "metadata": {},
   "source": [
    "##### IDF Scores (JIRA as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "explicit-egypt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 22 minutes and 23.688847303390503 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRA_mxShopFeaturesIDF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRA_mxShopFeaturesIDF[\"JiraAsQuery_IDF\"] = processedData_mxShopCartesian.apply(lambda x: calcIDFList(x.Jira_natural_text, \n",
    "                                                                                                                processedData_JIRA_mxShopCountVectorizer, \n",
    "                                                                                                                processedData_JIRA_mxShopTF_IDF),axis=1)\n",
    "\n",
    "processedData_JIRA_mxShopFeaturesIDF[\"JiraAsQuery_avgIDF\"] = processedData_JIRA_mxShopFeaturesIDF.apply(lambda x: calcAvgIDF(x.JiraAsQuery_IDF), axis=1)\n",
    "processedData_JIRA_mxShopFeaturesIDF[\"JiraAsQuery_maxIDF\"] = processedData_JIRA_mxShopFeaturesIDF.apply(lambda x: calcMaxIDF(x.JiraAsQuery_IDF), axis=1)\n",
    "processedData_JIRA_mxShopFeaturesIDF[\"JiraAsQuery_devIDF\"] = processedData_JIRA_mxShopFeaturesIDF.apply(lambda x: calcDevIDF(x.JiraAsQuery_IDF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRA_mxShopFeaturesIDF.to_pickle(path= \"../data/03_processed/processedData_JIRA_mxShopFeaturesIDF.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-gothic",
   "metadata": {},
   "source": [
    "##### IDF Scores (JIRA Summaries as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "underlying-cleaner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 1 minutes and 52.58431792259216 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRASummaries_mxShopFeaturesIDF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRASummaries_mxShopFeaturesIDF[\"JiraSummariesAsQuery_IDF\"] = processedData_mxShopCartesian.apply(lambda x: calcIDFList(x.Summary, \n",
    "                                                                                                                processedData_JIRASummaries_mxShopCountVectorizer, \n",
    "                                                                                                                processedData_JIRASummaries_mxShopCountTF_IDF),axis=1)\n",
    "\n",
    "processedData_JIRASummaries_mxShopFeaturesIDF[\"JiraSummariesAsQuery_avgIDF\"] = processedData_JIRASummaries_mxShopFeaturesIDF.apply(lambda x: calcAvgIDF(x.JiraSummariesAsQuery_IDF), axis=1)\n",
    "processedData_JIRASummaries_mxShopFeaturesIDF[\"JiraSummariesAsQuery_maxIDF\"] = processedData_JIRASummaries_mxShopFeaturesIDF.apply(lambda x: calcMaxIDF(x.JiraSummariesAsQuery_IDF), axis=1)\n",
    "processedData_JIRASummaries_mxShopFeaturesIDF[\"JiraSummariesAsQuery_devIDF\"] = processedData_JIRASummaries_mxShopFeaturesIDF.apply(lambda x: calcDevIDF(x.JiraSummariesAsQuery_IDF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRASummaries_mxShopFeaturesIDF.to_pickle(path= \"../data/03_processed/processedData_JIRASummaries_mxShopFeaturesIDF.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-specialist",
   "metadata": {},
   "source": [
    "##### IDF Scores (JIRA Descriptions as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "seeing-worker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 19 minutes and 49.29271125793457 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRADescriptions_mxShopFeaturesIDF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRADescriptions_mxShopFeaturesIDF[\"JiraDescriptionsAsQuery_IDF\"] = processedData_mxShopCartesian.apply(lambda x: calcIDFList(x.Description, \n",
    "                                                                                                                processedData_JIRADescriptions_mxShopCountVectorizer, \n",
    "                                                                                                                processedData_JIRADescriptions_mxShopCountTF_IDF),axis=1)\n",
    "\n",
    "processedData_JIRADescriptions_mxShopFeaturesIDF[\"JiraDescriptionsAsQuery_avgIDF\"] = processedData_JIRADescriptions_mxShopFeaturesIDF.apply(lambda x: calcAvgIDF(x.JiraDescriptionsAsQuery_IDF), axis=1)\n",
    "processedData_JIRADescriptions_mxShopFeaturesIDF[\"JiraDescriptionsAsQuery_maxIDF\"] = processedData_JIRADescriptions_mxShopFeaturesIDF.apply(lambda x: calcMaxIDF(x.JiraDescriptionsAsQuery_IDF), axis=1)\n",
    "processedData_JIRADescriptions_mxShopFeaturesIDF[\"JiraDescriptionsAsQuery_devIDF\"] = processedData_JIRADescriptions_mxShopFeaturesIDF.apply(lambda x: calcDevIDF(x.JiraDescriptionsAsQuery_IDF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRADescriptions_mxShopFeaturesIDF.to_pickle(path= \"../data/03_processed/processedData_JIRADescriptions_mxShopFeaturesIDF.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-chile",
   "metadata": {},
   "source": [
    "##### IDF Scores (JIRA Comments as Query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-ensemble",
   "metadata": {},
   "source": [
    "#### ICTF Scores (SVN as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "homeless-trash",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 5 minutes and 29.143274068832397 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVN_mxShopFeaturesICTF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVN_mxShopFeaturesICTF[\"SvnAsQuery_ICTF\"] = processedData_mxShopCartesian.apply(lambda x: calcIDFList(x.Commit_natural_text, \n",
    "                                                                                                                processedData_SVN_mxShopCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_mxShop_documentCount),axis=1)\n",
    "\n",
    "processedData_SVN_mxShopFeaturesICTF[\"SvnAsQuery_avgICTF\"] = processedData_SVN_mxShopFeaturesICTF.apply(lambda x: calcAvgICTF(x.SvnAsQuery_ICTF, intermediateData_SVN_mxShop_documentCount), axis=1)\n",
    "processedData_SVN_mxShopFeaturesICTF[\"SvnAsQuery_maxICTF\"] = processedData_SVN_mxShopFeaturesICTF.apply(lambda x: calcMaxICTF(x.SvnAsQuery_ICTF), axis=1)\n",
    "processedData_SVN_mxShopFeaturesICTF[\"SvnAsQuery_devICTF\"] = processedData_SVN_mxShopFeaturesICTF.apply(lambda x: calcDevICTF(x.SvnAsQuery_ICTF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVN_mxShopFeaturesICTF.to_pickle(path= \"../data/03_processed/processedData_SVN_mxShopFeaturesICTF.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-anthropology",
   "metadata": {},
   "source": [
    "#### ICTF Scores (SVNLogs as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "sought-arena",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 0 minutes and 5.362651348114014 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNLogs_mxShopFeaturesICTF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNLogs_mxShopFeaturesICTF[\"SvnLogsAsQuery_ICTF\"] = processedData_mxShopCartesian.apply(lambda x: calcICTFList(x.Logs, \n",
    "                                                                                                                processedData_SVNLogs_mxShopCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_mxShop_documentCount),axis=1)\n",
    "##\n",
    "processedData_SVNLogs_mxShopFeaturesICTF[\"SvnLogsAsQuery_avgICTF\"] = processedData_SVNLogs_mxShopFeaturesICTF.apply(lambda x: calcAvgICTF(x.SvnLogsAsQuery_ICTF, intermediateData_SVN_mxShop_documentCount), axis=1)\n",
    "processedData_SVNLogs_mxShopFeaturesICTF[\"SvnLogsAsQuery_maxICTF\"] = processedData_SVNLogs_mxShopFeaturesICTF.apply(lambda x: calcMaxICTF(x.SvnLogsAsQuery_ICTF), axis=1)\n",
    "processedData_SVNLogs_mxShopFeaturesICTF[\"SvnLogsAsQuery_devICTF\"] = processedData_SVNLogs_mxShopFeaturesICTF.apply(lambda x: calcDevICTF(x.SvnLogsAsQuery_ICTF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNLogs_mxShopFeaturesICTF.to_pickle(path= \"../data/03_processed/processedData_SVNLogs_mxShopFeaturesICTF.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-bikini",
   "metadata": {},
   "source": [
    "#### ICTF Scores (SVNUnitNames as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "drawn-maryland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 0 minutes and 10.362074613571167 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNUnitNames_mxShopFeaturesICTF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNUnitNames_mxShopFeaturesICTF[\"SvnUnitNamesAsQuery_ICTF\"] = processedData_mxShopCartesian.apply(lambda x: calcICTFList(x.Unit_names, \n",
    "                                                                                                                processedData_SVNUnitNames_mxShopCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_mxShop_documentCount),axis=1)\n",
    "##\n",
    "processedData_SVNUnitNames_mxShopFeaturesICTF[\"SvnUnitNamesAsQuery_avgICTF\"] = processedData_SVNUnitNames_mxShopFeaturesICTF.apply(lambda x: calcAvgICTF(x.SvnUnitNamesAsQuery_ICTF, intermediateData_SVN_mxShop_documentCount), axis=1)\n",
    "processedData_SVNUnitNames_mxShopFeaturesICTF[\"SvnUnitNamesAsQuery_maxICTF\"] = processedData_SVNUnitNames_mxShopFeaturesICTF.apply(lambda x: calcMaxICTF(x.SvnUnitNamesAsQuery_ICTF), axis=1)\n",
    "processedData_SVNUnitNames_mxShopFeaturesICTF[\"SvnUnitNamesAsQuery_devICTF\"] = processedData_SVNUnitNames_mxShopFeaturesICTF.apply(lambda x: calcDevICTF(x.SvnUnitNamesAsQuery_ICTF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNUnitNames_mxShopFeaturesICTF.to_pickle(path= \"../data/03_processed/processedData_SVNUnitNames_mxShopFeaturesICTF.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-japan",
   "metadata": {},
   "source": [
    "#### ICTF Scores (JIRA as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "separate-morris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 0 minutes and 10.448076725006104 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRA_mxShopFeaturesICTF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRA_mxShopFeaturesICTF[\"JiraAsQuery_ICTF\"] = processedData_mxShopCartesian.apply(lambda x: calcICTFList(x.Jira_natural_text, \n",
    "                                                                                                                processedData_JIRA_mxShopCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_mxShop_documentCount),axis=1)\n",
    "##\n",
    "processedData_JIRA_mxShopFeaturesICTF[\"JiraAsQuery_avgICTF\"] = processedData_JIRA_mxShopFeaturesICTF.apply(lambda x: calcAvgICTF(x.JiraAsQuery_ICTF, intermediateData_JIRA_mxShop_documentCount), axis=1)\n",
    "processedData_JIRA_mxShopFeaturesICTF[\"JiraAsQuery_maxICTF\"] = processedData_JIRA_mxShopFeaturesICTF.apply(lambda x: calcMaxICTF(x.JiraAsQuery_ICTF), axis=1)\n",
    "processedData_JIRA_mxShopFeaturesICTF[\"JiraAsQuery_devICTF\"] = processedData_JIRA_mxShopFeaturesICTF.apply(lambda x: calcDevICTF(x.JiraAsQuery_ICTF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRA_mxShopFeaturesICTF.to_pickle(path= \"../data/03_processed/processedData_JIRA_mxShopFeaturesICTF.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-freeware",
   "metadata": {},
   "source": [
    "#### ICTF Scores (JIRA Summaries as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "chemical-spank",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 0 minutes and 6.820654630661011 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRASummaries_mxShopFeaturesICTF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRASummaries_mxShopFeaturesICTF[\"JiraSummariesAsQuery_ICTF\"] = processedData_mxShopCartesian.apply(lambda x: calcICTFList(x.Summary, \n",
    "                                                                                                                processedData_JIRASummaries_mxShopCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_mxShop_documentCount),axis=1)\n",
    "##\n",
    "processedData_JIRASummaries_mxShopFeaturesICTF[\"JiraSummariesAsQuery_avgICTF\"] = processedData_JIRASummaries_mxShopFeaturesICTF.apply(lambda x: calcAvgICTF(x.JiraSummariesAsQuery_ICTF, intermediateData_JIRA_mxShop_documentCount), axis=1)\n",
    "processedData_JIRASummaries_mxShopFeaturesICTF[\"JiraSummariesAsQuery_maxICTF\"] = processedData_JIRASummaries_mxShopFeaturesICTF.apply(lambda x: calcMaxICTF(x.JiraSummariesAsQuery_ICTF), axis=1)\n",
    "processedData_JIRASummaries_mxShopFeaturesICTF[\"JiraSummariesAsQuery_devICTF\"] = processedData_JIRASummaries_mxShopFeaturesICTF.apply(lambda x: calcDevICTF(x.JiraSummariesAsQuery_ICTF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRASummaries_mxShopFeaturesICTF.to_pickle(path= \"../data/03_processed/processedData_JIRASummaries_mxShopFeaturesICTF.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-offset",
   "metadata": {},
   "source": [
    "#### ICTF Scores (JIRA Descriptions as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "contained-infrastructure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 0 minutes and 10.199738025665283 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRADescriptions_mxShopFeaturesICTF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRADescriptions_mxShopFeaturesICTF[\"JiraDescriptionsAsQuery_ICTF\"] = processedData_mxShopCartesian.apply(lambda x: calcICTFList(x.Description, \n",
    "                                                                                                                processedData_JIRADescriptions_mxShopCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_mxShop_documentCount),axis=1)\n",
    "##\n",
    "processedData_JIRADescriptions_mxShopFeaturesICTF[\"JiraDescriptionsAsQuery_avgICTF\"] = processedData_JIRADescriptions_mxShopFeaturesICTF.apply(lambda x: calcAvgICTF(x.JiraDescriptionsAsQuery_ICTF, intermediateData_JIRA_mxShop_documentCount), axis=1)\n",
    "processedData_JIRADescriptions_mxShopFeaturesICTF[\"JiraDescriptionsAsQuery_maxICTF\"] = processedData_JIRADescriptions_mxShopFeaturesICTF.apply(lambda x: calcMaxICTF(x.JiraDescriptionsAsQuery_ICTF), axis=1)\n",
    "processedData_JIRADescriptions_mxShopFeaturesICTF[\"JiraDescriptionsAsQuery_devICTF\"] = processedData_JIRADescriptions_mxShopFeaturesICTF.apply(lambda x: calcDevICTF(x.JiraDescriptionsAsQuery_ICTF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRADescriptions_mxShopFeaturesICTF.to_pickle(path= \"../data/03_processed/processedData_JIRADescriptions_mxShopFeaturesICTF.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-ontario",
   "metadata": {},
   "source": [
    "#### ICTF Scores (JIRA Comments as query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-sheffield",
   "metadata": {},
   "source": [
    "#### Entropy (SVN as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "threaded-wonder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 9 minutes and 27.337192058563232 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVN_mxShopFeaturesEntropy = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVN_mxShopFeaturesEntropy[\"SvnAsQuery_Entropy\"] = processedData_mxShopCartesian.apply(lambda x: calcEntropyList(x.Commit_natural_text, \n",
    "                                                                                                                processedData_SVN_mxShopCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_mxShop_documentCount,\n",
    "                                                                                                                intermediateData_SVN_mxShop.Commit_natural_text),axis=1)\n",
    "\n",
    "processedData_SVN_mxShopFeaturesEntropy[\"SvnAsQuery_avgEntropy\"] = processedData_SVN_mxShopFeaturesEntropy.apply(lambda x: calcAvgEntropy(x.SvnAsQuery_Entropy), axis=1)\n",
    "processedData_SVN_mxShopFeaturesEntropy[\"SvnAsQuery_medEntropy\"] = processedData_SVN_mxShopFeaturesEntropy.apply(lambda x: calcMedEntropy(x.SvnAsQuery_Entropy), axis=1)\n",
    "processedData_SVN_mxShopFeaturesEntropy[\"SvnAsQuery_maxEntropy\"] = processedData_SVN_mxShopFeaturesEntropy.apply(lambda x: calcMaxEntropy(x.SvnAsQuery_Entropy), axis=1)\n",
    "processedData_SVN_mxShopFeaturesEntropy[\"SvnAsQuery_devEntropy\"] = processedData_SVN_mxShopFeaturesEntropy.apply(lambda x: calcDevEntropy(x.SvnAsQuery_Entropy), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVN_mxShopFeaturesEntropy.to_pickle(path= \"../data/03_processed/processedData_SVN_mxShopFeaturesEntropy.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-iraqi",
   "metadata": {},
   "source": [
    "#### Entropy (SVNLogs as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "tight-engineer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 0 minutes and 14.758890867233276 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNLogs_mxShopFeaturesEntropy = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNLogs_mxShopFeaturesEntropy[\"SvnLogsAsQuery_Entropy\"] = processedData_mxShopCartesian.apply(lambda x: calcEntropyList(x.Logs, \n",
    "                                                                                                                processedData_SVNLogs_mxShopCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_mxShop_documentCount,\n",
    "                                                                                                                intermediateData_SVN_mxShop.Logs),axis=1)\n",
    "##\n",
    "processedData_SVNLogs_mxShopFeaturesEntropy[\"SvnLogsAsQuery_avgEntropy\"] = processedData_SVNLogs_mxShopFeaturesEntropy.apply(lambda x: calcAvgEntropy(x.SvnLogsAsQuery_Entropy), axis=1)\n",
    "processedData_SVNLogs_mxShopFeaturesEntropy[\"SvnLogsAsQuery_medEntropy\"] = processedData_SVNLogs_mxShopFeaturesEntropy.apply(lambda x: calcMedEntropy(x.SvnLogsAsQuery_Entropy), axis=1)\n",
    "processedData_SVNLogs_mxShopFeaturesEntropy[\"SvnLogsAsQuery_maxEntropy\"] = processedData_SVNLogs_mxShopFeaturesEntropy.apply(lambda x: calcMaxEntropy(x.SvnLogsAsQuery_Entropy), axis=1)\n",
    "processedData_SVNLogs_mxShopFeaturesEntropy[\"SvnLogsAsQuery_devEntropy\"] = processedData_SVNLogs_mxShopFeaturesEntropy.apply(lambda x: calcDevEntropy(x.SvnLogsAsQuery_Entropy), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNLogs_mxShopFeaturesEntropy.to_pickle(path= \"../data/03_processed/processedData_SVNLogs_mxShopFeaturesEntropy.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-recorder",
   "metadata": {},
   "source": [
    "#### Entropy (SVNUnitNames as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dirty-roberts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 8 minutes and 25.446935653686523 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNUnitNames_mxShopFeaturesEntropy = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNUnitNames_mxShopFeaturesEntropy[\"SvnUnitNamesAsQuery_Entropy\"] = processedData_mxShopCartesian.apply(lambda x: calcEntropyList(x.Unit_names, \n",
    "                                                                                                                processedData_SVNUnitNames_mxShopCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_mxShop_documentCount,\n",
    "                                                                                                                intermediateData_SVN_mxShop.Unit_names),axis=1)\n",
    "##\n",
    "processedData_SVNUnitNames_mxShopFeaturesEntropy[\"SvnUnitNamesAsQuery_avgEntropy\"] = processedData_SVNUnitNames_mxShopFeaturesEntropy.apply(lambda x: calcAvgEntropy(x.SvnUnitNamesAsQuery_Entropy), axis=1)\n",
    "processedData_SVNUnitNames_mxShopFeaturesEntropy[\"SvnUnitNamesAsQuery_medEntropy\"] = processedData_SVNUnitNames_mxShopFeaturesEntropy.apply(lambda x: calcMedEntropy(x.SvnUnitNamesAsQuery_Entropy), axis=1)\n",
    "processedData_SVNUnitNames_mxShopFeaturesEntropy[\"SvnUnitNamesAsQuery_maxEntropy\"] = processedData_SVNUnitNames_mxShopFeaturesEntropy.apply(lambda x: calcMaxEntropy(x.SvnUnitNamesAsQuery_Entropy), axis=1)\n",
    "processedData_SVNUnitNames_mxShopFeaturesEntropy[\"SvnUnitNamesAsQuery_devEntropy\"] = processedData_SVNUnitNames_mxShopFeaturesEntropy.apply(lambda x: calcDevEntropy(x.SvnUnitNamesAsQuery_Entropy), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNUnitNames_mxShopFeaturesEntropy.to_pickle(path= \"../data/03_processed/processedData_SVNUnitNames_mxShopFeaturesEntropy.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-kingston",
   "metadata": {},
   "source": [
    "#### Entropy (JIRA as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "featured-belle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 13 minutes and 37.50166034698486 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRA_mxShopFeaturesEntropy = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRA_mxShopFeaturesEntropy[\"JiraAsQuery_Entropy\"] = processedData_mxShopCartesian.apply(lambda x: calcEntropyList(x.Jira_natural_text, \n",
    "                                                                                                                processedData_JIRA_mxShopCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_mxShop_documentCount,\n",
    "                                                                                                                intermediateData_JIRA_mxShop.Jira_natural_text),axis=1)\n",
    "##\n",
    "processedData_JIRA_mxShopFeaturesEntropy[\"JiraAsQuery_avgEntropy\"] = processedData_JIRA_mxShopFeaturesEntropy.apply(lambda x: calcAvgEntropy(x.JiraAsQuery_Entropy), axis=1)\n",
    "processedData_JIRA_mxShopFeaturesEntropy[\"JiraAsQuery_medEntropy\"] = processedData_JIRA_mxShopFeaturesEntropy.apply(lambda x: calcMedEntropy(x.JiraAsQuery_Entropy), axis=1)\n",
    "processedData_JIRA_mxShopFeaturesEntropy[\"JiraAsQuery_maxEntropy\"] = processedData_JIRA_mxShopFeaturesEntropy.apply(lambda x: calcMaxEntropy(x.JiraAsQuery_Entropy), axis=1)\n",
    "processedData_JIRA_mxShopFeaturesEntropy[\"JiraAsQuery_devEntropy\"] = processedData_JIRA_mxShopFeaturesEntropy.apply(lambda x: calcDevEntropy(x.JiraAsQuery_Entropy), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRA_mxShopFeaturesEntropy.to_pickle(path= \"../data/03_processed/processedData_JIRA_mxShopFeaturesEntropy.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-technical",
   "metadata": {},
   "source": [
    "#### Entropy (JIRA Summaries as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "apart-romania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 0 minutes and 28.030139207839966 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRASummaries_mxShopFeaturesEntropy = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRASummaries_mxShopFeaturesEntropy[\"JiraSummariesAsQuery_Entropy\"] = processedData_mxShopCartesian.apply(lambda x: calcEntropyList(x.Summary, \n",
    "                                                                                                                processedData_JIRASummaries_mxShopCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_mxShop_documentCount,\n",
    "                                                                                                                intermediateData_JIRA_mxShop.Summary),axis=1)\n",
    "##\n",
    "processedData_JIRASummaries_mxShopFeaturesEntropy[\"JiraSummariesAsQuery_avgEntropy\"] = processedData_JIRASummaries_mxShopFeaturesEntropy.apply(lambda x: calcAvgEntropy(x.JiraSummariesAsQuery_Entropy), axis=1)\n",
    "processedData_JIRASummaries_mxShopFeaturesEntropy[\"JiraSummariesAsQuery_medEntropy\"] = processedData_JIRASummaries_mxShopFeaturesEntropy.apply(lambda x: calcMedEntropy(x.JiraSummariesAsQuery_Entropy), axis=1)\n",
    "processedData_JIRASummaries_mxShopFeaturesEntropy[\"JiraSummariesAsQuery_maxEntropy\"] = processedData_JIRASummaries_mxShopFeaturesEntropy.apply(lambda x: calcMaxEntropy(x.JiraSummariesAsQuery_Entropy), axis=1)\n",
    "processedData_JIRASummaries_mxShopFeaturesEntropy[\"JiraSummariesAsQuery_devEntropy\"] = processedData_JIRASummaries_mxShopFeaturesEntropy.apply(lambda x: calcDevEntropy(x.JiraSummariesAsQuery_Entropy), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRASummaries_mxShopFeaturesEntropy.to_pickle(path= \"../data/03_processed/processedData_JIRASummaries_mxShopFeaturesEntropy.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-wallace",
   "metadata": {},
   "source": [
    "#### Entropy (JIRA Descriptions as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "continuing-loading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 10 minutes and 53.47031378746033 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRADescriptions_mxShopFeaturesEntropy = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRADescriptions_mxShopFeaturesEntropy[\"JiraDescriptionsAsQuery_Entropy\"] = processedData_mxShopCartesian.apply(lambda x: calcEntropyList(x.Description, \n",
    "                                                                                                                processedData_JIRADescriptions_mxShopCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_mxShop_documentCount,\n",
    "                                                                                                                intermediateData_JIRA_mxShop.Description),axis=1)\n",
    "##\n",
    "processedData_JIRADescriptions_mxShopFeaturesEntropy[\"JiraDescriptionsAsQuery_avgEntropy\"] = processedData_JIRADescriptions_mxShopFeaturesEntropy.apply(lambda x: calcAvgEntropy(x.JiraDescriptionsAsQuery_Entropy), axis=1)\n",
    "processedData_JIRADescriptions_mxShopFeaturesEntropy[\"JiraDescriptionsAsQuery_medEntropy\"] = processedData_JIRADescriptions_mxShopFeaturesEntropy.apply(lambda x: calcMedEntropy(x.JiraDescriptionsAsQuery_Entropy), axis=1)\n",
    "processedData_JIRADescriptions_mxShopFeaturesEntropy[\"JiraDescriptionsAsQuery_maxEntropy\"] = processedData_JIRADescriptions_mxShopFeaturesEntropy.apply(lambda x: calcMaxEntropy(x.JiraDescriptionsAsQuery_Entropy), axis=1)\n",
    "processedData_JIRADescriptions_mxShopFeaturesEntropy[\"JiraDescriptionsAsQuery_devEntropy\"] = processedData_JIRADescriptions_mxShopFeaturesEntropy.apply(lambda x: calcDevEntropy(x.JiraDescriptionsAsQuery_Entropy), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRADescriptions_mxShopFeaturesEntropy.to_pickle(path= \"../data/03_processed/processedData_JIRADescriptions_mxShopFeaturesEntropy.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-affiliation",
   "metadata": {},
   "source": [
    "#### Entropy (JIRA Comments as query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-kazakhstan",
   "metadata": {},
   "source": [
    "##### Query Scope (SVN as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "integrated-parallel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 0 minutes and 17.28474998474121 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVN_mxShopFeaturesQueryScope = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVN_mxShopFeaturesQueryScope[\"SvnAsQuery_QueryScope\"] = processedData_mxShopCartesian.apply(lambda x: calcQueryScope(x.Commit_natural_text, \n",
    "                                                                                                                intermediateData_SVN_mxShop.Commit_natural_text),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVN_mxShopFeaturesQueryScope.to_pickle(path= \"../data/03_processed/processedData_SVN_mxShopFeaturesQueryScope.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-madrid",
   "metadata": {},
   "source": [
    "##### Query Scope (SVNLogs as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "macro-geology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 0 minutes and 4.86288595199585 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNLogs_mxShopFeaturesQueryScope = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNLogs_mxShopFeaturesQueryScope[\"SvnLogsAsQuery_QueryScope\"] = processedData_mxShopCartesian.apply(lambda x: calcQueryScope(x.Logs, \n",
    "                                                                                                                intermediateData_SVN_mxShop.Logs),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNLogs_mxShopFeaturesQueryScope.to_pickle(path= \"../data/03_processed/processedData_SVNLogs_mxShopFeaturesQueryScope.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-brooks",
   "metadata": {},
   "source": [
    "##### Query Scope (SVNUnitNames as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "turned-invasion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 0 minutes and 10.458050012588501 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNUnitNames_mxShopFeaturesQueryScope = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNUnitNames_mxShopFeaturesQueryScope[\"SvnUnitNamesAsQuery_QueryScope\"] = processedData_mxShopCartesian.apply(lambda x: calcQueryScope(x.Unit_names, \n",
    "                                                                                                                intermediateData_SVN_mxShop.Unit_names),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNUnitNames_mxShopFeaturesQueryScope.to_pickle(path= \"../data/03_processed/processedData_SVNUnitNames_mxShopFeaturesQueryScope.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-cocktail",
   "metadata": {},
   "source": [
    "##### Query Scope (JIRA as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "soviet-keyboard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 3 minutes and 40.0184326171875 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRA_mxShopFeaturesQueryScope = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRA_mxShopFeaturesQueryScope[\"JiraAsQuery_QueryScope\"] = processedData_mxShopCartesian.apply(lambda x: calcQueryScope(x.Jira_natural_text, \n",
    "                                                                                                                intermediateData_JIRA_mxShop.Jira_natural_text),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRA_mxShopFeaturesQueryScope.to_pickle(path= \"../data/03_processed/processedData_JIRA_mxShopFeaturesQueryScope.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-mumbai",
   "metadata": {},
   "source": [
    "##### Query Scope (JIRA Summaries as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "coordinated-paint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 0 minutes and 13.364269018173218 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRASummaries_mxShopFeaturesQueryScope = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRASummaries_mxShopFeaturesQueryScope[\"JiraSummariesAsQuery_QueryScope\"] = processedData_mxShopCartesian.apply(lambda x: calcQueryScope(x.Summary, \n",
    "                                                                                                                intermediateData_JIRA_mxShop.Summary),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRASummaries_mxShopFeaturesQueryScope.to_pickle(path= \"../data/03_processed/processedData_JIRASummaries_mxShopFeaturesQueryScope.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-hopkins",
   "metadata": {},
   "source": [
    "##### Query Scope (JIRA Descriptions as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "awful-trunk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 2 minutes and 3.145510673522949 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRADescriptions_mxShopFeaturesQueryScope = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRADescriptions_mxShopFeaturesQueryScope[\"JiraDescriptionsAsQuery_QueryScope\"] = processedData_mxShopCartesian.apply(lambda x: calcQueryScope(x.Description, \n",
    "                                                                                                                intermediateData_JIRA_mxShop.Description),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRADescriptions_mxShopFeaturesQueryScope.to_pickle(path= \"../data/03_processed/processedData_JIRADescriptions_mxShopFeaturesQueryScope.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-israel",
   "metadata": {},
   "source": [
    "##### Query Scope (JIRA Comments as query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-yorkshire",
   "metadata": {},
   "source": [
    "#### Kullback-Leiber divergence (SVN as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "saving-marks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 0 minutes and 26.224824905395508 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVN_mxShopFeaturesSCS = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVN_mxShopFeaturesSCS[\"SvnAsQuery_SCS\"] = processedData_mxShopCartesian.apply(lambda x: calcSCS(x.Commit_natural_text, \n",
    "                                                                                                                processedData_SVN_mxShopCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_mxShop_documentCount),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVN_mxShopFeaturesSCS.to_pickle(path= \"../data/03_processed/processedData_SVN_mxShopFeaturesSCS.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-paint",
   "metadata": {},
   "source": [
    "#### Kullback-Leiber divergence (SVNLogs as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "substantial-helmet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 0 minutes and 1.0075480937957764 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNLogs_mxShopFeaturesSCS = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNLogs_mxShopFeaturesSCS[\"SvnLogsAsQuery_SCS\"] = processedData_mxShopCartesian.apply(lambda x: calcSCS(x.Logs, \n",
    "                                                                                                                processedData_SVNLogs_mxShopCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_mxShop_documentCount),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNLogs_mxShopFeaturesSCS.to_pickle(path= \"../data/03_processed/processedData_SVNLogs_mxShopFeaturesSCS.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-calendar",
   "metadata": {},
   "source": [
    "#### Kullback-Leiber divergence (SVNUnitNames as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "breathing-collective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 0 minutes and 26.23382830619812 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNUnitNames_mxShopFeaturesSCS = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNUnitNames_mxShopFeaturesSCS[\"SvnUnitNamesAsQuery_SCS\"] = processedData_mxShopCartesian.apply(lambda x: calcSCS(x.Unit_names, \n",
    "                                                                                                                processedData_SVNUnitNames_mxShopCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_mxShop_documentCount),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNUnitNames_mxShopFeaturesSCS.to_pickle(path= \"../data/03_processed/processedData_SVNUnitNames_mxShopFeaturesSCS.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-cargo",
   "metadata": {},
   "source": [
    "#### Kullback-Leiber divergence (JIRA as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "pursuant-reduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 0 minutes and 2.8304619789123535 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRA_mxShopFeaturesSCS = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRA_mxShopFeaturesSCS[\"JiraAsQuery_SCS\"] = processedData_mxShopCartesian.apply(lambda x: calcSCS(x.Jira_natural_text, \n",
    "                                                                                                                processedData_JIRA_mxShopCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_mxShop_documentCount),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRA_mxShopFeaturesSCS.to_pickle(path= \"../data/03_processed/processedData_JIRA_mxShopFeaturesSCS.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-keeping",
   "metadata": {},
   "source": [
    "#### Kullback-Leiber divergence (JIRA Summaries as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "beginning-miniature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 0 minutes and 0.7719323635101318 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRASummaries_mxShopFeaturesSCS = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRASummaries_mxShopFeaturesSCS[\"JiraSummariesAsQuery_SCS\"] = processedData_mxShopCartesian.apply(lambda x: calcSCS(x.Summary, \n",
    "                                                                                                                processedData_JIRASummaries_mxShopCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_mxShop_documentCount),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRASummaries_mxShopFeaturesSCS.to_pickle(path= \"../data/03_processed/processedData_JIRASummaries_mxShopFeaturesSCS.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "quarterly-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Kullback-Leiber divergence (JIRA Description as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "waiting-adventure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 0 minutes and 2.652320623397827 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRADescriptions_mxShopFeaturesSCS = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRADescriptions_mxShopFeaturesSCS[\"JiraDescriptionsAsQuery_SCS\"] = processedData_mxShopCartesian.apply(lambda x: calcSCS(x.Description, \n",
    "                                                                                                                processedData_JIRADescriptions_mxShopCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_mxShop_documentCount),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRADescriptions_mxShopFeaturesSCS.to_pickle(path= \"../data/03_processed/processedData_JIRADescriptions_mxShopFeaturesSCS.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dated-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Kullback-Leiber divergence (JIRA Comments as query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-execution",
   "metadata": {},
   "source": [
    "#### SCQ (SVN as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "latin-toilet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 1 minutes and 39.3187518119812 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVN_mxShopFeaturesSCQ = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVN_mxShopFeaturesSCQ[\"SvnAsQuery_SCQ\"] = processedData_mxShopCartesian.apply(lambda x: calcSCQList(x.Commit_natural_text, intermediateData_SVN_mxShop.Commit_natural_text,\n",
    "                                                                                                                                         processedData_SVN_mxShopCountVectorizer,\n",
    "                                                                                                                                         processedData_SVN_mxShopCountTF_IDF,\n",
    "                                                                                                                                         intermediateData_SVN_mxShop_documentCount),axis=1)\n",
    "\n",
    "processedData_SVN_mxShopFeaturesSCQ[\"SvnAsQuery_avgSCQ\"] = processedData_SVN_mxShopFeaturesSCQ.apply(lambda x: calcAvgSCQ(x.SvnAsQuery_SCQ, intermediateData_SVN_mxShop_documentCount), axis=1)\n",
    "processedData_SVN_mxShopFeaturesSCQ[\"SvnAsQuery_maxSCQ\"] = processedData_SVN_mxShopFeaturesSCQ.apply(lambda x: calcMaxSCQ(x.SvnAsQuery_SCQ), axis=1)\n",
    "processedData_SVN_mxShopFeaturesSCQ[\"SvnAsQuery_sumSCQ\"] = processedData_SVN_mxShopFeaturesSCQ.apply(lambda x: calcSumSCQ(x.SvnAsQuery_SCQ), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVN_mxShopFeaturesSCQ.to_pickle(path= \"../data/03_processed/processedData_SVN_mxShopFeaturesSCQ.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-technical",
   "metadata": {},
   "source": [
    "#### SCQ (SVNLogs as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "together-cattle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 1 minutes and 35.09811496734619 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNLogs_mxShopFeaturesSCQ = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNLogs_mxShopFeaturesSCQ[\"SvnLogsAsQuery_SCQ\"] = processedData_mxShopCartesian.apply(lambda x: calcSCQList(x.Logs, intermediateData_SVN_mxShop.Logs,\n",
    "                                                                                                                                         processedData_SVNLogs_mxShopCountVectorizer,\n",
    "                                                                                                                                         processedData_SVNLogs_mxShopCountTF_IDF,\n",
    "                                                                                                                                         intermediateData_SVN_mxShop_documentCount),axis=1)\n",
    "\n",
    "processedData_SVNLogs_mxShopFeaturesSCQ[\"SvnLogsAsQuery_avgSCQ\"] = processedData_SVNLogs_mxShopFeaturesSCQ.apply(lambda x: calcAvgSCQ(x.SvnLogsAsQuery_SCQ, intermediateData_SVN_mxShop_documentCount), axis=1)\n",
    "processedData_SVNLogs_mxShopFeaturesSCQ[\"SvnLogsAsQuery_maxSCQ\"] = processedData_SVNLogs_mxShopFeaturesSCQ.apply(lambda x: calcMaxSCQ(x.SvnLogsAsQuery_SCQ), axis=1)\n",
    "processedData_SVNLogs_mxShopFeaturesSCQ[\"SvnLogsAsQuery_sumSCQ\"] = processedData_SVNLogs_mxShopFeaturesSCQ.apply(lambda x: calcSumSCQ(x.SvnLogsAsQuery_SCQ), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNLogs_mxShopFeaturesSCQ.to_pickle(path= \"../data/03_processed/processedData_SVNLogs_mxShopFeaturesSCQ.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-guess",
   "metadata": {},
   "source": [
    "#### SCQ (SVNUnitNames as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "celtic-better",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 1 minutes and 33.80674600601196 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNUnitNames_mxShopFeaturesSCQ = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNUnitNames_mxShopFeaturesSCQ[\"SvnUnitNamesAsQuery_SCQ\"] = processedData_mxShopCartesian.apply(lambda x: calcSCQList(x.Unit_names, intermediateData_SVN_mxShop.Unit_names,\n",
    "                                                                                                                                         processedData_SVNUnitNames_mxShopCountVectorizer,\n",
    "                                                                                                                                         processedData_SVNUnitNames_mxShopCountTF_IDF,\n",
    "                                                                                                                                         intermediateData_SVN_mxShop_documentCount),axis=1)\n",
    "\n",
    "processedData_SVNUnitNames_mxShopFeaturesSCQ[\"SvnUnitNamesAsQuery_avgSCQ\"] = processedData_SVNUnitNames_mxShopFeaturesSCQ.apply(lambda x: calcAvgSCQ(x.SvnUnitNamesAsQuery_SCQ, intermediateData_SVN_mxShop_documentCount), axis=1)\n",
    "processedData_SVNUnitNames_mxShopFeaturesSCQ[\"SvnUnitNamesAsQuery_maxSCQ\"] = processedData_SVNUnitNames_mxShopFeaturesSCQ.apply(lambda x: calcMaxSCQ(x.SvnUnitNamesAsQuery_SCQ), axis=1)\n",
    "processedData_SVNUnitNames_mxShopFeaturesSCQ[\"SvnUnitNamesAsQuery_sumSCQ\"] = processedData_SVNUnitNames_mxShopFeaturesSCQ.apply(lambda x: calcSumSCQ(x.SvnUnitNamesAsQuery_SCQ), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNUnitNames_mxShopFeaturesSCQ.to_pickle(path= \"../data/03_processed/processedData_SVNUnitNames_mxShopFeaturesSCQ.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-laundry",
   "metadata": {},
   "source": [
    "#### SCQ (JIRA as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "partial-police",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 1 minutes and 21.878973484039307 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRA_mxShopFeaturesSCQ = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRA_mxShopFeaturesSCQ[\"JiraAsQuery_SCQ\"] = processedData_mxShopCartesian.apply(lambda x: calcSCQList(x.Jira_natural_text, intermediateData_JIRA_mxShop.Jira_natural_text,\n",
    "                                                                                                                                         processedData_JIRA_mxShopCountVectorizer,\n",
    "                                                                                                                                         processedData_JIRA_mxShopTF_IDF,\n",
    "                                                                                                                                         intermediateData_JIRA_mxShop_documentCount),axis=1)\n",
    "\n",
    "processedData_JIRA_mxShopFeaturesSCQ[\"JiraAsQuery_avgSCQ\"] = processedData_JIRA_mxShopFeaturesSCQ.apply(lambda x: calcAvgSCQ(x.JiraAsQuery_SCQ, intermediateData_JIRA_mxShop_documentCount), axis=1)\n",
    "processedData_JIRA_mxShopFeaturesSCQ[\"JiraAsQuery_maxSCQ\"] = processedData_JIRA_mxShopFeaturesSCQ.apply(lambda x: calcMaxSCQ(x.JiraAsQuery_SCQ), axis=1)\n",
    "processedData_JIRA_mxShopFeaturesSCQ[\"JiraAsQuery_sumSCQ\"] = processedData_JIRA_mxShopFeaturesSCQ.apply(lambda x: calcSumSCQ(x.JiraAsQuery_SCQ), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRA_mxShopFeaturesSCQ.to_pickle(path= \"../data/03_processed/processedData_JIRA_mxShopFeaturesSCQ.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-updating",
   "metadata": {},
   "source": [
    "#### SCQ (JIRA Summaries as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "norwegian-alfred",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 1 minutes and 41.34452772140503 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRASummaries_mxShopFeaturesSCQ = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRASummaries_mxShopFeaturesSCQ[\"JiraSummariesAsQuery_SCQ\"] = processedData_mxShopCartesian.apply(lambda x: calcSCQList(x.Summary, intermediateData_JIRA_mxShop.Summary,\n",
    "                                                                                                                                         processedData_JIRASummaries_mxShopCountVectorizer,\n",
    "                                                                                                                                         processedData_JIRASummaries_mxShopCountTF_IDF,\n",
    "                                                                                                                                         intermediateData_JIRA_mxShop_documentCount),axis=1)\n",
    "\n",
    "processedData_JIRASummaries_mxShopFeaturesSCQ[\"JiraSummariesAsQuery_avgSCQ\"] = processedData_JIRASummaries_mxShopFeaturesSCQ.apply(lambda x: calcAvgSCQ(x.JiraSummariesAsQuery_SCQ, intermediateData_JIRA_mxShop_documentCount), axis=1)\n",
    "processedData_JIRASummaries_mxShopFeaturesSCQ[\"JiraSummariesAsQuery_maxSCQ\"] = processedData_JIRASummaries_mxShopFeaturesSCQ.apply(lambda x: calcMaxSCQ(x.JiraSummariesAsQuery_SCQ), axis=1)\n",
    "processedData_JIRASummaries_mxShopFeaturesSCQ[\"JiraSummariesAsQuery_sumSCQ\"] = processedData_JIRASummaries_mxShopFeaturesSCQ.apply(lambda x: calcSumSCQ(x.JiraSummariesAsQuery_SCQ), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRASummaries_mxShopFeaturesSCQ.to_pickle(path= \"../data/03_processed/processedData_JIRASummaries_mxShopFeaturesSCQ.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-spirit",
   "metadata": {},
   "source": [
    "#### SCQ (JIRA Descriptions as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "affected-thanks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 1 minutes and 17.451756477355957 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRADescriptions_mxShopFeaturesSCQ = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRADescriptions_mxShopFeaturesSCQ[\"JiraDescriptionsAsQuery_SCQ\"] = processedData_mxShopCartesian.apply(lambda x: calcSCQList(x.Description, intermediateData_JIRA_mxShop.Description,\n",
    "                                                                                                                                         processedData_JIRADescriptions_mxShopCountVectorizer,\n",
    "                                                                                                                                         processedData_JIRADescriptions_mxShopCountTF_IDF,\n",
    "                                                                                                                                         intermediateData_JIRA_mxShop_documentCount),axis=1)\n",
    "\n",
    "processedData_JIRADescriptions_mxShopFeaturesSCQ[\"JiraDescriptionsAsQuery_avgSCQ\"] = processedData_JIRADescriptions_mxShopFeaturesSCQ.apply(lambda x: calcAvgSCQ(x.JiraDescriptionsAsQuery_SCQ, intermediateData_JIRA_mxShop_documentCount), axis=1)\n",
    "processedData_JIRADescriptions_mxShopFeaturesSCQ[\"JiraDescriptionsAsQuery_maxSCQ\"] = processedData_JIRADescriptions_mxShopFeaturesSCQ.apply(lambda x: calcMaxSCQ(x.JiraDescriptionsAsQuery_SCQ), axis=1)\n",
    "processedData_JIRADescriptions_mxShopFeaturesSCQ[\"JiraDescriptionsAsQuery_sumSCQ\"] = processedData_JIRADescriptions_mxShopFeaturesSCQ.apply(lambda x: calcSumSCQ(x.JiraDescriptionsAsQuery_SCQ), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRADescriptions_mxShopFeaturesSCQ.to_pickle(path= \"../data/03_processed/processedData_JIRADescriptions_mxShopFeaturesSCQ.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-walker",
   "metadata": {},
   "source": [
    "#### SCQ (JIRA Comments as Query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-owner",
   "metadata": {},
   "source": [
    "#### PMI (SVN as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "stunning-legislation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 25 minutes and 56.55142426490784 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create pairs and find frequencies\n",
    "termPairs = createTermPairs(processedData_SVN_mxShopCountVectorizer)\n",
    "termFrequencies = findTermFrequencies(processedData_SVN_mxShopCountVectorizer, intermediateData_SVN_mxShop.Commit_natural_text)\n",
    "termPairFrequencies = findTermPairFrequencies(termPairs, intermediateData_SVN_mxShop.Commit_natural_text)\n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVN_mxShopFeaturesPMI = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVN_mxShopFeaturesPMI[\"SvnAsQuery_PMI\"] = processedData_mxShopCartesian.apply(lambda x: calcPMIList(x.Commit_natural_text, \n",
    "                                                                                                                                  termFrequencies, \n",
    "                                                                                                                                  termPairFrequencies, \n",
    "                                                                                                                                  intermediateData_SVN_mxShop.Commit_natural_text),axis=1)\n",
    "\n",
    "processedData_SVN_mxShopFeaturesPMI[\"SvnAsQuery_avgPMI\"] = processedData_SVN_mxShopFeaturesPMI.apply(lambda x: calcAvgPMI(x.SvnAsQuery_PMI), axis=1)\n",
    "processedData_SVN_mxShopFeaturesPMI[\"SvnAsQuery_maxPMI\"] = processedData_SVN_mxShopFeaturesPMI.apply(lambda x: calcMaxPMI(x.SvnAsQuery_PMI), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "processedData_SVN_mxShopFeaturesPMI.drop('SvnAsQuery_PMI', axis = 1, inplace=True)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVN_mxShopFeaturesPMI.to_pickle(path= \"../data/03_processed/processedData_SVN_mxShopFeaturesPMI.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-hotel",
   "metadata": {},
   "source": [
    "#### PMI (SVNLogs as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "verified-analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-59-48edd07688a2>:332: RuntimeWarning: All-NaN axis encountered\n",
      "  maxPMI = np.nanmax(pmiList)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 0 minutes and 17.834798574447632 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create pairs and find frequencies\n",
    "termPairs = createTermPairs(processedData_SVNLogs_mxShopCountVectorizer)\n",
    "termFrequencies = findTermFrequencies(processedData_SVNLogs_mxShopCountVectorizer, intermediateData_SVN_mxShop.Logs)\n",
    "termPairFrequencies = findTermPairFrequencies(termPairs, intermediateData_SVN_mxShop.Logs)\n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNLogs_mxShopFeaturesPMI = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNLogs_mxShopFeaturesPMI[\"SvnLogsAsQuery_PMI\"] = processedData_mxShopCartesian.apply(lambda x: calcPMIList(x.Logs, \n",
    "                                                                                                                                  termFrequencies, \n",
    "                                                                                                                                  termPairFrequencies, \n",
    "                                                                                                                                  intermediateData_SVN_mxShop.Logs),axis=1)\n",
    "\n",
    "processedData_SVNLogs_mxShopFeaturesPMI[\"SvnLogsAsQuery_avgPMI\"] = processedData_SVNLogs_mxShopFeaturesPMI.apply(lambda x: calcAvgPMI(x.SvnLogsAsQuery_PMI), axis=1)\n",
    "processedData_SVNLogs_mxShopFeaturesPMI[\"SvnLogsAsQuery_maxPMI\"] = processedData_SVNLogs_mxShopFeaturesPMI.apply(lambda x: calcMaxPMI(x.SvnLogsAsQuery_PMI), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "processedData_SVNLogs_mxShopFeaturesPMI.drop('SvnLogsAsQuery_PMI', axis = 1, inplace=True)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNLogs_mxShopFeaturesPMI.to_pickle(path= \"../data/03_processed/processedData_SVNLogs_mxShopFeaturesPMI.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-efficiency",
   "metadata": {},
   "source": [
    "#### PMI (SVNUnitNames as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "conscious-feeling",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-59-48edd07688a2>:332: RuntimeWarning: All-NaN axis encountered\n",
      "  maxPMI = np.nanmax(pmiList)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 24 minutes and 43.04617142677307 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create pairs and find frequencies\n",
    "termPairs = createTermPairs(processedData_SVNUnitNames_mxShopCountVectorizer)\n",
    "termFrequencies = findTermFrequencies(processedData_SVNUnitNames_mxShopCountVectorizer, intermediateData_SVN_mxShop.Unit_names)\n",
    "termPairFrequencies = findTermPairFrequencies(termPairs, intermediateData_SVN_mxShop.Unit_names)\n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNUnitNames_mxShopFeaturesPMI = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNUnitNames_mxShopFeaturesPMI[\"SvnUnitNamesAsQuery_PMI\"] = processedData_mxShopCartesian.apply(lambda x: calcPMIList(x.Unit_names, \n",
    "                                                                                                                                  termFrequencies, \n",
    "                                                                                                                                  termPairFrequencies, \n",
    "                                                                                                                                  intermediateData_SVN_mxShop.Unit_names),axis=1)\n",
    "\n",
    "processedData_SVNUnitNames_mxShopFeaturesPMI[\"SvnUnitNamesAsQuery_avgPMI\"] = processedData_SVNUnitNames_mxShopFeaturesPMI.apply(lambda x: calcAvgPMI(x.SvnUnitNamesAsQuery_PMI), axis=1)\n",
    "processedData_SVNUnitNames_mxShopFeaturesPMI[\"SvnUnitNamesAsQuery_maxPMI\"] = processedData_SVNUnitNames_mxShopFeaturesPMI.apply(lambda x: calcMaxPMI(x.SvnUnitNamesAsQuery_PMI), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "processedData_SVNUnitNames_mxShopFeaturesPMI.drop('SvnUnitNamesAsQuery_PMI', axis = 1, inplace=True)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNUnitNames_mxShopFeaturesPMI.to_pickle(path= \"../data/03_processed/processedData_SVNUnitNames_mxShopFeaturesPMI.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-stomach",
   "metadata": {},
   "source": [
    "#### PMI (JIRA as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "durable-murder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 61 minutes and 47.90031933784485 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create pairs and find frequencies\n",
    "termPairs = createTermPairs(processedData_JIRA_mxShopCountVectorizer)\n",
    "termFrequencies = findTermFrequencies(processedData_JIRA_mxShopCountVectorizer, intermediateData_JIRA_mxShop.Jira_natural_text)\n",
    "termPairFrequencies = findTermPairFrequencies(termPairs, intermediateData_JIRA_mxShop.Jira_natural_text)\n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRA_mxShopFeaturesPMI = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRA_mxShopFeaturesPMI[\"JiraAsQuery_PMI\"] = processedData_mxShopCartesian.apply(lambda x: calcPMIList(x.Jira_natural_text, \n",
    "                                                                                                                                  termFrequencies, \n",
    "                                                                                                                                  termPairFrequencies, \n",
    "                                                                                                                                  intermediateData_JIRA_mxShop.Jira_natural_text),axis=1)\n",
    "\n",
    "processedData_JIRA_mxShopFeaturesPMI[\"JiraAsQuery_avgPMI\"] = processedData_JIRA_mxShopFeaturesPMI.apply(lambda x: calcAvgPMI(x.JiraAsQuery_PMI), axis=1)\n",
    "processedData_JIRA_mxShopFeaturesPMI[\"JiraAsQuery_maxPMI\"] = processedData_JIRA_mxShopFeaturesPMI.apply(lambda x: calcMaxPMI(x.JiraAsQuery_PMI), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "processedData_JIRA_mxShopFeaturesPMI.drop('JiraAsQuery_PMI', axis = 1, inplace=True)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRA_mxShopFeaturesPMI.to_pickle(path= \"../data/03_processed/processedData_JIRA_mxShopFeaturesPMI.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-youth",
   "metadata": {},
   "source": [
    "#### PMI (JIRA Summaries as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "prerequisite-burke",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-59-48edd07688a2>:332: RuntimeWarning: All-NaN axis encountered\n",
      "  maxPMI = np.nanmax(pmiList)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 2 minutes and 12.151050567626953 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create pairs and find frequencies\n",
    "termPairs = createTermPairs(processedData_JIRASummaries_mxShopCountVectorizer)\n",
    "termFrequencies = findTermFrequencies(processedData_JIRASummaries_mxShopCountVectorizer, intermediateData_JIRA_mxShop.Summary)\n",
    "termPairFrequencies = findTermPairFrequencies(termPairs, intermediateData_JIRA_mxShop.Summary)\n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRASummaries_mxShopFeaturesPMI = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRASummaries_mxShopFeaturesPMI[\"JiraSummariesAsQuery_PMI\"] = processedData_mxShopCartesian.apply(lambda x: calcPMIList(x.Summary, \n",
    "                                                                                                                                  termFrequencies, \n",
    "                                                                                                                                  termPairFrequencies, \n",
    "                                                                                                                                  intermediateData_JIRA_mxShop.Summary),axis=1)\n",
    "\n",
    "processedData_JIRASummaries_mxShopFeaturesPMI[\"JiraSummariesAsQuery_avgPMI\"] = processedData_JIRASummaries_mxShopFeaturesPMI.apply(lambda x: calcAvgPMI(x.JiraSummariesAsQuery_PMI), axis=1)\n",
    "processedData_JIRASummaries_mxShopFeaturesPMI[\"JiraSummariesAsQuery_maxPMI\"] = processedData_JIRASummaries_mxShopFeaturesPMI.apply(lambda x: calcMaxPMI(x.JiraSummariesAsQuery_PMI), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "processedData_JIRASummaries_mxShopFeaturesPMI.drop('JiraSummariesAsQuery_PMI', axis = 1, inplace=True)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRASummaries_mxShopFeaturesPMI.to_pickle(path= \"../data/03_processed/processedData_JIRASummaries_mxShopFeaturesPMI.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-award",
   "metadata": {},
   "source": [
    "#### PMI (JIRA Descriptions as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "stable-mattress",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-59-48edd07688a2>:332: RuntimeWarning: All-NaN axis encountered\n",
      "  maxPMI = np.nanmax(pmiList)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 52 minutes and 42.46821045875549 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create pairs and find frequencies\n",
    "termPairs = createTermPairs(processedData_JIRADescriptions_mxShopCountVectorizer)\n",
    "termFrequencies = findTermFrequencies(processedData_JIRADescriptions_mxShopCountVectorizer, intermediateData_JIRA_mxShop.Description)\n",
    "termPairFrequencies = findTermPairFrequencies(termPairs, intermediateData_JIRA_mxShop.Description)\n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRADescriptions_mxShopFeaturesPMI = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRADescriptions_mxShopFeaturesPMI[\"JiraDescriptionsAsQuery_PMI\"] = processedData_mxShopCartesian.apply(lambda x: calcPMIList(x.Description, \n",
    "                                                                                                                                  termFrequencies, \n",
    "                                                                                                                                  termPairFrequencies, \n",
    "                                                                                                                                  intermediateData_JIRA_mxShop.Description),axis=1)\n",
    "\n",
    "processedData_JIRADescriptions_mxShopFeaturesPMI[\"JiraDescriptionsAsQuery_avgPMI\"] = processedData_JIRADescriptions_mxShopFeaturesPMI.apply(lambda x: calcAvgPMI(x.JiraDescriptionsAsQuery_PMI), axis=1)\n",
    "processedData_JIRADescriptions_mxShopFeaturesPMI[\"JiraDescriptionsAsQuery_maxPMI\"] = processedData_JIRADescriptions_mxShopFeaturesPMI.apply(lambda x: calcMaxPMI(x.JiraDescriptionsAsQuery_PMI), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "processedData_JIRADescriptions_mxShopFeaturesPMI.drop('JiraDescriptionsAsQuery_PMI', axis = 1, inplace=True)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRADescriptions_mxShopFeaturesPMI.to_pickle(path= \"../data/03_processed/processedData_JIRADescriptions_mxShopFeaturesPMI.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-convert",
   "metadata": {},
   "source": [
    "#### PMI (JIRA Comments as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "convenient-blocking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def normalizeData(dataFrame):\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    names = dataFrame.columns\n",
    "    d = scaler.fit_transform(dataFrame)\n",
    "    scaledDataFrame = pd.DataFrame(d, columns=names)\n",
    "    return(scaledDataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-fifteen",
   "metadata": {},
   "source": [
    "# Normalize all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "transsexual-dominican",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "################################## Loading #################################\n",
    "#Load Process-Related Features\n",
    "processedData_mxShopFeaturesTime = pd.read_pickle(r'../data/03_processed/processedData_mxShopFeaturesTime.pkl')\n",
    "processedData_mxShopFeaturesStakeholder = pd.read_pickle(r'../data/03_processed/processedData_mxShopFeaturesStakeholder.pkl')\n",
    "\n",
    "#Load IR-Related Features - unigram\n",
    "processedData_mxShop_features_VsmLogsJiraAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmLogsJiraAsQuery.pkl')\n",
    "processedData_mxShop_features_VsmLogsLogAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmLogsLogAsQuery.pkl')\n",
    "processedData_mxShop_features_VsmUnitNamesJiraAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmUnitNamesJiraAsQuery.pkl')\n",
    "processedData_mxShop_features_VsmUnitNamesUnitNamesAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmUnitNamesUnitNamesAsQuery.pkl')\n",
    "\n",
    "#processedData_mxShop_features_VsmUnitNamesCommentsCommentsAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmUnitNamesCommentsCommentsAsQuery.pkl')\n",
    "#processedData_mxShop_features_VsmUnitNamesCommentsUnitNamesAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmUnitNamesCommentsUnitNamesAsQuery.pkl')\n",
    "processedData_mxShop_features_VsmUnitNamesDescriptionDescriptionAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmUnitNamesDescriptionDescriptionAsQuery.pkl')\n",
    "processedData_mxShop_features_VsmUnitNamesDescriptionUnitNamesAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmUnitNamesDescriptionUnitNamesAsQuery.pkl')\n",
    "\n",
    "#processedData_mxShop_features_VsmVerbPruningUnitNamesJiraAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmVerbPruningUnitNamesJiraAsQuery.pkl')\n",
    "#processedData_mxShop_features_VsmVerbPruningUnitNamesUnitNamesAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmVerbPruningUnitNamesUnitNamesAsQuery.pkl')\n",
    "processedData_mxShop_features_VsmSummaryLogsSummaryAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmSummaryLogsSummaryAsQuery.pkl')\n",
    "processedData_mxShop_features_VsmSummaryLogsLogsAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmSummaryLogsLogsAsQuery.pkl')\n",
    "processedData_mxShop_features_VsmSummaryUnitNamesSummaryAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmSummaryUnitNamesSummaryAsQuery.pkl')\n",
    "processedData_mxShop_features_VsmSummaryUnitNamesUnitNamesAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmSummaryUnitNamesUnitNamesAsQuery.pkl')\n",
    "processedData_mxShop_features_VsmDescriptionDescriptionAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmDescriptionDescriptionAsQuery.pkl')\n",
    "processedData_mxShop_features_VsmDescriptionLogsAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmDescriptionLogsAsQuery.pkl')\n",
    "#processedData_mxShop_features_VsmCommentsCommentsAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmCommentsCommentsAsQuery.pkl')\n",
    "#processedData_mxShop_features_VsmCommentsLogsAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmCommentsLogsAsQuery.pkl')\n",
    "\n",
    "processedData_mxShop_features_VsmSvnJiraJiraAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmSvnJiraJiraAsQuery.pkl')\n",
    "processedData_mxShop_features_VsmSvnJiraSvnAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmSvnJiraSvnAsQuery.pkl')\n",
    "processedData_mxShop_features_VsmSvnSummarySvnAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmSvnSummarySvnAsQuery.pkl')\n",
    "processedData_mxShop_features_VsmSvnSummarySummaryAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmSvnSummarySummaryAsQuery.pkl')\n",
    "processedData_mxShop_features_VsmSvnDescriptionSvnAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmSvnDescriptionSvnAsQuery.pkl')\n",
    "processedData_mxShop_features_VsmSvnDescriptionDescriptionAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmSvnDescriptionDescriptionAsQuery.pkl')\n",
    "#processedData_mxShop_features_VsmSvnCommentsSvnAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmSvnCommentsSvnAsQuery.pkl')\n",
    "#processedData_mxShop_features_VsmSvnCommentsCommentsAsQuery = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmSvnCommentsCommentsAsQuery.pkl')\n",
    "\n",
    "\n",
    "#Load IR-Related Features - bigram\n",
    "#processedData_mxShop_features_VsmLogsJiraAsQuery_2gram = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmLogsJiraAsQuery_2gram.pkl')\n",
    "#processedData_mxShop_features_VsmLogsLogAsQuery_2gram = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmLogsLogAsQuery_2gram.pkl')\n",
    "#processedData_mxShop_features_VsmUnitNamesJiraAsQuery_2gram = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmUnitNamesJiraAsQuery_2gram.pkl')\n",
    "#processedData_mxShop_features_VsmUnitNamesUnitNamesAsQuery_2gram = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmUnitNamesUnitNamesAsQuery_2gram.pkl')\n",
    "#processedData_mxShop_features_VsmCommentsLogsAsQuery_2gram = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmCommentsLogsAsQuery_2gram.pkl')\n",
    "#processedData_mxShop_features_VsmCommentsCommentsAsQuery_2gram = pd.read_pickle(r'../data/03_processed/processedData_mxShop_features_VsmCommentsCommentsAsQuery_2gram.pkl')\n",
    "\n",
    "\n",
    "#Load Document Statistics Features\n",
    "processedData_JIRA_mxShopFeaturesUniqueWordCount = pd.read_pickle(r\"../data/03_processed/processedData_JIRA_mxShopFeaturesUniqueWordCount.pkl\")\n",
    "processedData_SVN_mxShopFeaturesUniqueWordCount = pd.read_pickle(r\"../data/03_processed/processedData_SVN_mxShopFeaturesUniqueWordCount.pkl\")\n",
    "processedData_JIRA_mxShopFeaturesTotalWordCount = pd.read_pickle(r\"../data/03_processed/processedData_JIRA_mxShopFeaturesTotalWordCount.pkl\")\n",
    "processedData_SVN_mxShopFeaturesTotalWordCount = pd.read_pickle(r\"../data/03_processed/processedData_SVN_mxShopFeaturesTotalWordCount.pkl\")\n",
    "processedData_JIRA_mxShopFeaturesOverlapPercentage = pd.read_pickle(r\"../data/03_processed/processedData_JIRA_mxShopFeaturesOverlapPercentage.pkl\")\n",
    "processedData_SVN_mxShopFeaturesOverlapPercentage = pd.read_pickle(r\"../data/03_processed/processedData_SVN_mxShopFeaturesOverlapPercentage.pkl\")\n",
    "processedData_UNION_mxShopFeaturesOverlapPercentage = pd.read_pickle(r\"../data/03_processed/processedData_UNION_mxShopFeaturesOverlapPercentage.pkl\")\n",
    "\n",
    "#Load Query Quality Features\n",
    "#processedData_mxShopFeaturesQueryQuality = pd.read_pickle(r'../data/03_processed/processedData_mxShopFeaturesQueryQuality.pkl')\n",
    "processedData_SVN_mxShopFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_SVN_mxShopFeaturesIDF.pkl')\n",
    "processedData_SVNLogs_mxShopFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_mxShopFeaturesIDF.pkl')\n",
    "processedData_SVNUnitNames_mxShopFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_mxShopFeaturesIDF.pkl')\n",
    "processedData_JIRA_mxShopFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_JIRA_mxShopFeaturesIDF.pkl')\n",
    "processedData_JIRASummaries_mxShopFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_mxShopFeaturesIDF.pkl')\n",
    "processedData_JIRADescriptions_mxShopFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_mxShopFeaturesIDF.pkl')\n",
    "#processedData_JIRAComments_mxShopFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_mxShopFeaturesIDF.pkl')\n",
    "\n",
    "\n",
    "processedData_SVN_mxShopFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_SVN_mxShopFeaturesICTF.pkl')\n",
    "processedData_SVNLogs_mxShopFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_mxShopFeaturesICTF.pkl')\n",
    "processedData_SVNUnitNames_mxShopFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_mxShopFeaturesICTF.pkl')\n",
    "processedData_JIRA_mxShopFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_JIRA_mxShopFeaturesICTF.pkl')\n",
    "processedData_JIRASummaries_mxShopFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_mxShopFeaturesICTF.pkl')\n",
    "processedData_JIRADescriptions_mxShopFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_mxShopFeaturesICTF.pkl')\n",
    "#processedData_JIRAComments_mxShopFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_mxShopFeaturesICTF.pkl')\n",
    "\n",
    "\n",
    "processedData_SVN_mxShopFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_SVN_mxShopFeaturesEntropy.pkl')\n",
    "processedData_SVNLogs_mxShopFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_mxShopFeaturesEntropy.pkl')\n",
    "processedData_SVNUnitNames_mxShopFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_mxShopFeaturesEntropy.pkl')\n",
    "processedData_JIRA_mxShopFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_JIRA_mxShopFeaturesEntropy.pkl')\n",
    "processedData_JIRASummaries_mxShopFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_mxShopFeaturesEntropy.pkl')\n",
    "processedData_JIRADescriptions_mxShopFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_mxShopFeaturesEntropy.pkl')\n",
    "#processedData_JIRAComments_mxShopFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_mxShopFeaturesEntropy.pkl')\n",
    "\n",
    "\n",
    "processedData_SVN_mxShopFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_SVN_mxShopFeaturesQueryScope.pkl')\n",
    "processedData_SVNLogs_mxShopFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_mxShopFeaturesQueryScope.pkl')\n",
    "processedData_SVNUnitNames_mxShopFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_mxShopFeaturesQueryScope.pkl')\n",
    "processedData_JIRA_mxShopFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_JIRA_mxShopFeaturesQueryScope.pkl')\n",
    "processedData_JIRASummaries_mxShopFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_mxShopFeaturesQueryScope.pkl')\n",
    "processedData_JIRADescriptions_mxShopFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_mxShopFeaturesQueryScope.pkl')\n",
    "#processedData_JIRAComments_mxShopFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_mxShopFeaturesQueryScope.pkl')\n",
    "\n",
    "\n",
    "processedData_SVN_mxShopFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_SVN_mxShopFeaturesSCS.pkl')\n",
    "processedData_SVNLogs_mxShopFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_mxShopFeaturesSCS.pkl')\n",
    "processedData_SVNUnitNames_mxShopFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_mxShopFeaturesSCS.pkl')\n",
    "processedData_JIRA_mxShopFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_JIRA_mxShopFeaturesSCS.pkl')\n",
    "processedData_JIRASummaries_mxShopFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_mxShopFeaturesSCS.pkl')\n",
    "processedData_JIRADescriptions_mxShopFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_mxShopFeaturesSCS.pkl')\n",
    "#processedData_JIRAComments_mxShopFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_mxShopFeaturesSCS.pkl')\n",
    "\n",
    "\n",
    "processedData_SVN_mxShopFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_SVN_mxShopFeaturesSCQ.pkl')\n",
    "processedData_SVNLogs_mxShopFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_mxShopFeaturesSCQ.pkl')\n",
    "processedData_SVNUnitNames_mxShopFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_mxShopFeaturesSCQ.pkl')\n",
    "processedData_JIRA_mxShopFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_JIRA_mxShopFeaturesSCQ.pkl')\n",
    "processedData_JIRASummaries_mxShopFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_mxShopFeaturesSCQ.pkl')\n",
    "processedData_JIRADescriptions_mxShopFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_mxShopFeaturesSCQ.pkl')\n",
    "#processedData_JIRAComments_mxShopFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_mxShopFeaturesSCQ.pkl')\n",
    "\n",
    "\n",
    "#processedData_SVN_mxShopFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_SVN_mxShopFeaturesPMI.pkl')\n",
    "processedData_SVNLogs_mxShopFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_mxShopFeaturesPMI.pkl')\n",
    "#processedData_SVNUnitNames_mxShopFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_mxShopFeaturesPMI.pkl')\n",
    "#processedData_JIRA_mxShopFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_JIRA_mxShopFeaturesPMI.pkl')\n",
    "processedData_JIRASummaries_mxShopFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_mxShopFeaturesPMI.pkl')\n",
    "#processedData_JIRADescriptions_mxShopFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_mxShopFeaturesPMI.pkl')\n",
    "#processedData_JIRAComments_mxShopFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_mxShopFeaturesPMI.pkl')\n",
    "\n",
    "\n",
    "################################## Drop query array for normalization ###############################################\n",
    "\n",
    "\n",
    "processedData_SVN_mxShopFeaturesIDF.drop('SvnAsQuery_IDF', axis = 1, inplace=True)\n",
    "processedData_SVNLogs_mxShopFeaturesIDF.drop('SvnLogsAsQuery_IDF', axis = 1, inplace=True)\n",
    "processedData_SVNUnitNames_mxShopFeaturesIDF.drop('SvnUnitNamesAsQuery_IDF', axis = 1, inplace=True)\n",
    "processedData_JIRA_mxShopFeaturesIDF.drop('JiraAsQuery_IDF', axis = 1, inplace=True)\n",
    "processedData_JIRASummaries_mxShopFeaturesIDF.drop('JiraSummariesAsQuery_IDF', axis = 1, inplace=True)\n",
    "processedData_JIRADescriptions_mxShopFeaturesIDF.drop('JiraDescriptionsAsQuery_IDF', axis = 1, inplace=True)\n",
    "#processedData_JIRAComments_mxShopFeaturesIDF.drop('JiraCommentsAsQuery_IDF', axis = 1, inplace=True)\n",
    "\n",
    "processedData_SVN_mxShopFeaturesICTF.drop('SvnAsQuery_ICTF', axis = 1, inplace=True)\n",
    "processedData_SVNLogs_mxShopFeaturesICTF.drop('SvnLogsAsQuery_ICTF', axis = 1, inplace=True)\n",
    "processedData_SVNUnitNames_mxShopFeaturesICTF.drop('SvnUnitNamesAsQuery_ICTF', axis = 1, inplace=True)\n",
    "processedData_JIRA_mxShopFeaturesICTF.drop('JiraAsQuery_ICTF', axis = 1, inplace=True)\n",
    "processedData_JIRASummaries_mxShopFeaturesICTF.drop('JiraSummariesAsQuery_ICTF', axis = 1, inplace=True)\n",
    "processedData_JIRADescriptions_mxShopFeaturesICTF.drop('JiraDescriptionsAsQuery_ICTF', axis = 1, inplace=True)\n",
    "#processedData_JIRAComments_mxShopFeaturesICTF.drop('JiraCommentsAsQuery_ICTF', axis = 1, inplace=True)\n",
    "\n",
    "processedData_SVN_mxShopFeaturesEntropy.drop('SvnAsQuery_Entropy', axis = 1, inplace=True)\n",
    "processedData_SVNLogs_mxShopFeaturesEntropy.drop('SvnLogsAsQuery_Entropy', axis = 1, inplace=True)\n",
    "processedData_SVNUnitNames_mxShopFeaturesEntropy.drop('SvnUnitNamesAsQuery_Entropy', axis = 1, inplace=True)\n",
    "processedData_JIRA_mxShopFeaturesEntropy.drop('JiraAsQuery_Entropy', axis = 1, inplace=True)\n",
    "processedData_JIRASummaries_mxShopFeaturesEntropy.drop('JiraSummariesAsQuery_Entropy', axis = 1, inplace=True)\n",
    "processedData_JIRADescriptions_mxShopFeaturesEntropy.drop('JiraDescriptionsAsQuery_Entropy', axis = 1, inplace=True)\n",
    "#processedData_JIRAComments_mxShopFeaturesEntropy.drop('JiraCommentsAsQuery_Entropy', axis = 1, inplace=True)\n",
    "\n",
    "processedData_SVN_mxShopFeaturesSCQ.drop('SvnAsQuery_SCQ', axis = 1, inplace=True)\n",
    "processedData_SVNLogs_mxShopFeaturesSCQ.drop('SvnLogsAsQuery_SCQ', axis = 1, inplace=True)\n",
    "processedData_SVNUnitNames_mxShopFeaturesSCQ.drop('SvnUnitNamesAsQuery_SCQ', axis = 1, inplace=True)\n",
    "processedData_JIRA_mxShopFeaturesSCQ.drop('JiraAsQuery_SCQ', axis = 1, inplace=True)\n",
    "processedData_JIRASummaries_mxShopFeaturesSCQ.drop('JiraSummariesAsQuery_SCQ', axis = 1, inplace=True)\n",
    "processedData_JIRADescriptions_mxShopFeaturesSCQ.drop('JiraDescriptionsAsQuery_SCQ', axis = 1, inplace=True)\n",
    "#processedData_JIRAComments_mxShopFeaturesSCQ.drop('JiraCommentsAsQuery_SCQ', axis = 1, inplace=True)\n",
    "\n",
    "################################## Normalizing ################################################\n",
    "\n",
    "processedData_mxShopFeaturesTime_normalized = normalizeData(processedData_mxShopFeaturesTime)\n",
    "processedData_mxShopFeaturesStakeholder_normalized = normalizeData(processedData_mxShopFeaturesStakeholder)\n",
    "\n",
    "#Load IR-Related Features - unigram\n",
    "processedData_mxShop_features_VsmLogsJiraAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmLogsJiraAsQuery)\n",
    "processedData_mxShop_features_VsmLogsLogAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmLogsLogAsQuery)\n",
    "processedData_mxShop_features_VsmUnitNamesJiraAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmUnitNamesJiraAsQuery)\n",
    "processedData_mxShop_features_VsmUnitNamesUnitNamesAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmUnitNamesUnitNamesAsQuery)\n",
    "#processedData_mxShop_features_VsmUnitNamesCommentsCommentsAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmUnitNamesCommentsCommentsAsQuery)\n",
    "#processedData_mxShop_features_VsmUnitNamesCommentsUnitNamesAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmUnitNamesCommentsUnitNamesAsQuery)\n",
    "processedData_mxShop_features_VsmUnitNamesDescriptionDescriptionAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmUnitNamesDescriptionDescriptionAsQuery)\n",
    "processedData_mxShop_features_VsmUnitNamesDescriptionUnitNamesAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmUnitNamesDescriptionUnitNamesAsQuery)\n",
    "\n",
    "#processedData_mxShop_features_VsmVerbPruningUnitNamesJiraAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmVerbPruningUnitNamesJiraAsQuery)\n",
    "#processedData_mxShop_features_VsmVerbPruningUnitNamesUnitNamesAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmVerbPruningUnitNamesUnitNamesAsQuery)\n",
    "processedData_mxShop_features_VsmSummaryLogsSummaryAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmSummaryLogsSummaryAsQuery)\n",
    "processedData_mxShop_features_VsmSummaryLogsLogsAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmSummaryLogsLogsAsQuery)\n",
    "processedData_mxShop_features_VsmSummaryUnitNamesSummaryAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmSummaryUnitNamesSummaryAsQuery)\n",
    "processedData_mxShop_features_VsmSummaryUnitNamesUnitNamesAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmSummaryUnitNamesUnitNamesAsQuery)\n",
    "processedData_mxShop_features_VsmDescriptionDescriptionAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmDescriptionDescriptionAsQuery)\n",
    "processedData_mxShop_features_VsmDescriptionLogsAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmDescriptionLogsAsQuery)\n",
    "#processedData_mxShop_features_VsmCommentsCommentsAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmCommentsCommentsAsQuery)\n",
    "#processedData_mxShop_features_VsmCommentsLogsAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmCommentsLogsAsQuery)\n",
    "\n",
    "processedData_mxShop_features_VsmSvnJiraJiraAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmSvnJiraJiraAsQuery)\n",
    "processedData_mxShop_features_VsmSvnJiraSvnAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmSvnJiraSvnAsQuery)\n",
    "processedData_mxShop_features_VsmSvnSummarySvnAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmSvnSummarySvnAsQuery)\n",
    "processedData_mxShop_features_VsmSvnSummarySummaryAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmSvnSummarySummaryAsQuery)\n",
    "processedData_mxShop_features_VsmSvnDescriptionSvnAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmSvnDescriptionSvnAsQuery)\n",
    "processedData_mxShop_features_VsmSvnDescriptionDescriptionAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmSvnDescriptionDescriptionAsQuery)\n",
    "#processedData_mxShop_features_VsmSvnCommentsSvnAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmSvnCommentsSvnAsQuery)\n",
    "#processedData_mxShop_features_VsmSvnCommentsCommentsAsQuery_normalized = normalizeData(processedData_mxShop_features_VsmSvnCommentsCommentsAsQuery)\n",
    "\n",
    "\n",
    "\n",
    "#Load IR-Related Features - bigram\n",
    "#processedData_mxShop_features_VsmLogsJiraAsQuery_2gram_normalized = normalizeData(processedData_mxShop_features_VsmLogsJiraAsQuery_2gram)\n",
    "#processedData_mxShop_features_VsmLogsLogAsQuery_2gram_normalized = normalizeData(processedData_mxShop_features_VsmLogsLogAsQuery_2gram)\n",
    "#processedData_mxShop_features_VsmUnitNamesJiraAsQuery_2gram_normalized = normalizeData(processedData_mxShop_features_VsmUnitNamesJiraAsQuery_2gram)\n",
    "#processedData_mxShop_features_VsmUnitNamesUnitNamesAsQuery_2gram_normalized = normalizeData(processedData_mxShop_features_VsmUnitNamesUnitNamesAsQuery_2gram)\n",
    "#processedData_mxShop_features_VsmCommentsLogsAsQuery_2gram_normalized = normalizeData(processedData_mxShop_features_VsmCommentsLogsAsQuery_2gram)\n",
    "#processedData_mxShop_features_VsmCommentsCommentsAsQuery_2gram_normalized = normalizeData(processedData_mxShop_features_VsmCommentsCommentsAsQuery_2gram)\n",
    "\n",
    "\n",
    "#Load Document Statistics Features\n",
    "processedData_JIRA_mxShopFeaturesUniqueWordCount_normalized = normalizeData(processedData_JIRA_mxShopFeaturesUniqueWordCount)\n",
    "processedData_SVN_mxShopFeaturesUniqueWordCount_normalized = normalizeData(processedData_SVN_mxShopFeaturesUniqueWordCount)\n",
    "processedData_JIRA_mxShopFeaturesTotalWordCount_normalized = normalizeData(processedData_JIRA_mxShopFeaturesTotalWordCount)\n",
    "processedData_SVN_mxShopFeaturesTotalWordCount_normalized = normalizeData(processedData_SVN_mxShopFeaturesTotalWordCount)\n",
    "processedData_JIRA_mxShopFeaturesOverlapPercentage_normalized = normalizeData(processedData_JIRA_mxShopFeaturesOverlapPercentage)\n",
    "processedData_SVN_mxShopFeaturesOverlapPercentage_normalized = normalizeData(processedData_SVN_mxShopFeaturesOverlapPercentage)\n",
    "processedData_UNION_mxShopFeaturesOverlapPercentage_normalized = normalizeData(processedData_UNION_mxShopFeaturesOverlapPercentage)\n",
    "\n",
    "#Load Query Quality Features\n",
    "processedData_SVN_mxShopFeaturesIDF_normalized = normalizeData(processedData_SVN_mxShopFeaturesIDF)\n",
    "processedData_SVNLogs_mxShopFeaturesIDF_normalized = normalizeData(processedData_SVNLogs_mxShopFeaturesIDF)\n",
    "processedData_SVNUnitNames_mxShopFeaturesIDF_normalized = normalizeData(processedData_SVNUnitNames_mxShopFeaturesIDF)\n",
    "processedData_JIRA_mxShopFeaturesIDF_normalized = normalizeData(processedData_JIRA_mxShopFeaturesIDF)\n",
    "processedData_JIRASummaries_mxShopFeaturesIDF_normalized = normalizeData(processedData_JIRASummaries_mxShopFeaturesIDF)\n",
    "processedData_JIRADescriptions_mxShopFeaturesIDF_normalized = normalizeData(processedData_JIRADescriptions_mxShopFeaturesIDF)\n",
    "#processedData_JIRAComments_mxShopFeaturesIDF_normalized = normalizeData(processedData_JIRAComments_mxShopFeaturesIDF)\n",
    "\n",
    "processedData_SVN_mxShopFeaturesICTF_normalized = normalizeData(processedData_SVN_mxShopFeaturesICTF)\n",
    "processedData_SVNLogs_mxShopFeaturesICTF_normalized = normalizeData(processedData_SVNLogs_mxShopFeaturesICTF)\n",
    "processedData_SVNUnitNames_mxShopFeaturesICTF_normalized = normalizeData(processedData_SVNUnitNames_mxShopFeaturesICTF)\n",
    "processedData_JIRA_mxShopFeaturesICTF_normalized = normalizeData(processedData_JIRA_mxShopFeaturesICTF)\n",
    "processedData_JIRASummaries_mxShopFeaturesICTF_normalized = normalizeData(processedData_JIRASummaries_mxShopFeaturesICTF)\n",
    "processedData_JIRADescriptions_mxShopFeaturesICTF_normalized = normalizeData(processedData_JIRADescriptions_mxShopFeaturesICTF)\n",
    "#processedData_JIRAComments_mxShopFeaturesICTF_normalized = normalizeData(processedData_JIRAComments_mxShopFeaturesICTF)\n",
    "\n",
    "processedData_SVN_mxShopFeaturesEntropy_normalized = normalizeData(processedData_SVN_mxShopFeaturesEntropy)\n",
    "processedData_SVNLogs_mxShopFeaturesEntropy_normalized = normalizeData(processedData_SVNLogs_mxShopFeaturesEntropy)\n",
    "processedData_SVNUnitNames_mxShopFeaturesEntropy_normalized = normalizeData(processedData_SVNUnitNames_mxShopFeaturesEntropy)\n",
    "processedData_JIRA_mxShopFeaturesEntropy_normalized = normalizeData(processedData_JIRA_mxShopFeaturesEntropy)\n",
    "processedData_JIRASummaries_mxShopFeaturesEntropy_normalized = normalizeData(processedData_JIRASummaries_mxShopFeaturesEntropy)\n",
    "processedData_JIRADescriptions_mxShopFeaturesEntropy_normalized = normalizeData(processedData_JIRADescriptions_mxShopFeaturesEntropy)\n",
    "#processedData_JIRAComments_mxShopFeaturesEntropy_normalized = normalizeData(processedData_JIRAComments_mxShopFeaturesEntropy)\n",
    "\n",
    "processedData_SVN_mxShopFeaturesQueryScope_normalized = normalizeData(processedData_SVN_mxShopFeaturesQueryScope)\n",
    "processedData_SVNLogs_mxShopFeaturesQueryScope_normalized = normalizeData(processedData_SVNLogs_mxShopFeaturesQueryScope)\n",
    "processedData_SVNUnitNames_mxShopFeaturesQueryScope_normalized = normalizeData(processedData_SVNUnitNames_mxShopFeaturesQueryScope)\n",
    "processedData_JIRA_mxShopFeaturesQueryScope_normalized = normalizeData(processedData_JIRA_mxShopFeaturesQueryScope)\n",
    "processedData_JIRASummaries_mxShopFeaturesQueryScope_normalized = normalizeData(processedData_JIRASummaries_mxShopFeaturesQueryScope)\n",
    "processedData_JIRADescriptions_mxShopFeaturesQueryScope_normalized = normalizeData(processedData_JIRADescriptions_mxShopFeaturesQueryScope)\n",
    "#processedData_JIRAComments_mxShopFeaturesQueryScope_normalized = normalizeData(processedData_JIRAComments_mxShopFeaturesQueryScope)\n",
    "\n",
    "processedData_SVN_mxShopFeaturesSCS_normalized = normalizeData(processedData_SVN_mxShopFeaturesSCS)\n",
    "processedData_SVNLogs_mxShopFeaturesSCS_normalized = normalizeData(processedData_SVNLogs_mxShopFeaturesSCS)\n",
    "processedData_SVNUnitNames_mxShopFeaturesSCS_normalized = normalizeData(processedData_SVNUnitNames_mxShopFeaturesSCS)\n",
    "processedData_JIRA_mxShopFeaturesSCS_normalized = normalizeData(processedData_JIRA_mxShopFeaturesSCS)\n",
    "processedData_JIRASummaries_mxShopFeaturesSCS_normalized = normalizeData(processedData_JIRASummaries_mxShopFeaturesSCS)\n",
    "processedData_JIRADescriptions_mxShopFeaturesSCS_normalized = normalizeData(processedData_JIRADescriptions_mxShopFeaturesSCS)\n",
    "#processedData_JIRAComments_mxShopFeaturesSCS_normalized = normalizeData(processedData_JIRAComments_mxShopFeaturesSCS)\n",
    "\n",
    "processedData_SVN_mxShopFeaturesSCQ_normalized = normalizeData(processedData_SVN_mxShopFeaturesSCQ)\n",
    "processedData_SVNLogs_mxShopFeaturesSCQ_normalized = normalizeData(processedData_SVNLogs_mxShopFeaturesSCQ)\n",
    "processedData_SVNUnitNames_mxShopFeaturesSCQ_normalized = normalizeData(processedData_SVNUnitNames_mxShopFeaturesSCQ)\n",
    "processedData_JIRA_mxShopFeaturesSCQ_normalized = normalizeData(processedData_JIRA_mxShopFeaturesSCQ)\n",
    "processedData_JIRASummaries_mxShopFeaturesSCQ_normalized = normalizeData(processedData_JIRASummaries_mxShopFeaturesSCQ)\n",
    "processedData_JIRADescriptions_mxShopFeaturesSCQ_normalized = normalizeData(processedData_JIRADescriptions_mxShopFeaturesSCQ)\n",
    "#processedData_JIRAComments_mxShopFeaturesSCQ_normalized = normalizeData(processedData_JIRAComments_mxShopFeaturesSCQ)\n",
    "\n",
    "#processedData_SVN_mxShopFeaturesPMI_normalized = normalizeData(processedData_SVN_mxShopFeaturesPMI)\n",
    "processedData_SVNLogs_mxShopFeaturesPMI_normalized = normalizeData(processedData_SVNLogs_mxShopFeaturesPMI)\n",
    "#processedData_SVNUnitNames_mxShopFeaturesPMI_normalized = normalizeData(processedData_SVNUnitNames_mxShopFeaturesPMI)\n",
    "#processedData_JIRA_mxShopFeaturesPMI_normalized = normalizeData(processedData_JIRA_mxShopFeaturesPMI)\n",
    "processedData_JIRASummaries_mxShopFeaturesPMI_normalized = normalizeData(processedData_JIRASummaries_mxShopFeaturesPMI)\n",
    "#processedData_JIRADescriptions_mxShopFeaturesPMI_normalized = normalizeData(processedData_JIRADescriptions_mxShopFeaturesPMI)\n",
    "#processedData_JIRAComments_mxShopFeaturesPMI_normalized = normalizeData(processedData_JIRAComments_mxShopFeaturesPMI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-material",
   "metadata": {},
   "source": [
    "## 3.8 Preprocess Data - Load and transform feature families needed for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "chicken-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Merge features into 1 dataframe\n",
    "processedData_mxShopFeatures_normalized = pd.concat([processedData_mxShopFeaturesTime_normalized,\n",
    "                                                  processedData_mxShopFeaturesStakeholder_normalized,\n",
    "                                                  #IR-based\n",
    "                                                  processedData_mxShop_features_VsmLogsJiraAsQuery_normalized,\n",
    "                                                  processedData_mxShop_features_VsmLogsLogAsQuery_normalized,\n",
    "                                                  processedData_mxShop_features_VsmUnitNamesJiraAsQuery_normalized,\n",
    "                                                  processedData_mxShop_features_VsmUnitNamesUnitNamesAsQuery_normalized,\n",
    "                                                #  processedData_mxShop_features_VsmUnitNamesCommentsCommentsAsQuery_normalized,\n",
    "                                                #  processedData_mxShop_features_VsmUnitNamesCommentsUnitNamesAsQuery_normalized,\n",
    "                                                  processedData_mxShop_features_VsmUnitNamesDescriptionDescriptionAsQuery_normalized,\n",
    "                                                  processedData_mxShop_features_VsmUnitNamesDescriptionUnitNamesAsQuery_normalized,\n",
    "                                                  processedData_mxShop_features_VsmSummaryLogsSummaryAsQuery_normalized,\n",
    "                                                  processedData_mxShop_features_VsmSummaryLogsLogsAsQuery_normalized,\n",
    "                                                  processedData_mxShop_features_VsmSummaryUnitNamesSummaryAsQuery_normalized,\n",
    "                                                  processedData_mxShop_features_VsmSummaryUnitNamesUnitNamesAsQuery_normalized,\n",
    "                                                  processedData_mxShop_features_VsmDescriptionDescriptionAsQuery_normalized,\n",
    "                                                  processedData_mxShop_features_VsmDescriptionLogsAsQuery_normalized,\n",
    "                                                 # processedData_mxShop_features_VsmCommentsCommentsAsQuery_normalized,\n",
    "                                                #  processedData_mxShop_features_VsmCommentsLogsAsQuery_normalized,\n",
    "                                                 # processedData_mxShop_features_VsmLogsJiraAsQuery_2gram_normalized,\n",
    "                                                 # processedData_mxShop_features_VsmLogsLogAsQuery_2gram_normalized,\n",
    "                                                 # processedData_mxShop_features_VsmUnitNamesJiraAsQuery_2gram_normalized,\n",
    "                                                 # processedData_mxShop_features_VsmUnitNamesUnitNamesAsQuery_2gram_normalized,\n",
    "                                                  #processedData_mxShop_features_VsmVerbPruningUnitNamesJiraAsQuery_normalized,\n",
    "                                                 # processedData_mxShop_features_VsmVerbPruningUnitNamesUnitNamesAsQuery_normalized,\n",
    "                                                  processedData_mxShop_features_VsmSvnJiraJiraAsQuery_normalized,\n",
    "                                                  processedData_mxShop_features_VsmSvnJiraSvnAsQuery_normalized,\n",
    "                                                  processedData_mxShop_features_VsmSvnSummarySvnAsQuery_normalized,\n",
    "                                                  processedData_mxShop_features_VsmSvnSummarySummaryAsQuery_normalized,\n",
    "                                                  processedData_mxShop_features_VsmSvnDescriptionSvnAsQuery_normalized,\n",
    "                                                  processedData_mxShop_features_VsmSvnDescriptionDescriptionAsQuery_normalized,\n",
    "                                                #  processedData_mxShop_features_VsmSvnCommentsSvnAsQuery_normalized,\n",
    "                                                #  processedData_mxShop_features_VsmSvnCommentsCommentsAsQuery_normalized,\n",
    "\n",
    "                                                  \n",
    "                                                  #Document Statistics\n",
    "                                                  processedData_JIRA_mxShopFeaturesUniqueWordCount_normalized,\n",
    "                                                  processedData_SVN_mxShopFeaturesUniqueWordCount_normalized,\n",
    "                                                  processedData_JIRA_mxShopFeaturesTotalWordCount_normalized,\n",
    "                                                  processedData_SVN_mxShopFeaturesTotalWordCount_normalized,\n",
    "                                                  processedData_JIRA_mxShopFeaturesOverlapPercentage_normalized,\n",
    "                                                  processedData_SVN_mxShopFeaturesOverlapPercentage_normalized,\n",
    "                                                  processedData_UNION_mxShopFeaturesOverlapPercentage_normalized,\n",
    "                                                 #Query Quality\n",
    "                                                  processedData_SVN_mxShopFeaturesIDF_normalized['SvnAsQuery_avgIDF'],\n",
    "                                                  processedData_SVN_mxShopFeaturesIDF_normalized['SvnAsQuery_maxIDF'],\n",
    "                                                  processedData_SVN_mxShopFeaturesIDF_normalized['SvnAsQuery_devIDF'],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesIDF_normalized['SvnLogsAsQuery_avgIDF'],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesIDF_normalized['SvnLogsAsQuery_maxIDF'],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesIDF_normalized['SvnLogsAsQuery_devIDF'],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesIDF_normalized['SvnUnitNamesAsQuery_avgIDF'],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesIDF_normalized['SvnUnitNamesAsQuery_maxIDF'],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesIDF_normalized['SvnUnitNamesAsQuery_devIDF'],\n",
    "                                                  processedData_JIRA_mxShopFeaturesIDF_normalized['JiraAsQuery_avgIDF'],\n",
    "                                                  processedData_JIRA_mxShopFeaturesIDF_normalized['JiraAsQuery_maxIDF'],\n",
    "                                                  processedData_JIRA_mxShopFeaturesIDF_normalized['JiraAsQuery_devIDF'],  \n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesIDF_normalized['JiraSummariesAsQuery_avgIDF'],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesIDF_normalized['JiraSummariesAsQuery_maxIDF'],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesIDF_normalized['JiraSummariesAsQuery_devIDF'],  \n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesIDF_normalized['JiraDescriptionsAsQuery_avgIDF'],\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesIDF_normalized['JiraDescriptionsAsQuery_maxIDF'],\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesIDF_normalized['JiraDescriptionsAsQuery_devIDF'],  \n",
    "                                                #  processedData_JIRAComments_mxShopFeaturesIDF_normalized['JiraCommentsAsQuery_avgIDF'],\n",
    "                                                #  processedData_JIRAComments_mxShopFeaturesIDF_normalized['JiraCommentsAsQuery_maxIDF'],\n",
    "                                                #  processedData_JIRAComments_mxShopFeaturesIDF_normalized['JiraCommentsAsQuery_devIDF'],  \n",
    "                                                  \n",
    "                                                  processedData_SVN_mxShopFeaturesICTF_normalized[\"SvnAsQuery_avgICTF\"],\n",
    "                                                  processedData_SVN_mxShopFeaturesICTF_normalized[\"SvnAsQuery_maxICTF\"],\n",
    "                                                  processedData_SVN_mxShopFeaturesICTF_normalized[\"SvnAsQuery_devICTF\"],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesICTF_normalized[\"SvnLogsAsQuery_avgICTF\"],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesICTF_normalized[\"SvnLogsAsQuery_maxICTF\"],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesICTF_normalized[\"SvnLogsAsQuery_devICTF\"],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesICTF_normalized[\"SvnUnitNamesAsQuery_avgICTF\"],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesICTF_normalized[\"SvnUnitNamesAsQuery_maxICTF\"],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesICTF_normalized[\"SvnUnitNamesAsQuery_devICTF\"],\n",
    "                                                  processedData_JIRA_mxShopFeaturesICTF_normalized[\"JiraAsQuery_avgICTF\"],\n",
    "                                                  processedData_JIRA_mxShopFeaturesICTF_normalized[\"JiraAsQuery_maxICTF\"],\n",
    "                                                  processedData_JIRA_mxShopFeaturesICTF_normalized[\"JiraAsQuery_devICTF\"],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesICTF_normalized[\"JiraSummariesAsQuery_avgICTF\"],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesICTF_normalized[\"JiraSummariesAsQuery_maxICTF\"],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesICTF_normalized[\"JiraSummariesAsQuery_devICTF\"],\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesICTF_normalized[\"JiraDescriptionsAsQuery_avgICTF\"],\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesICTF_normalized[\"JiraDescriptionsAsQuery_maxICTF\"],\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesICTF_normalized[\"JiraDescriptionsAsQuery_devICTF\"],\n",
    "                                              #    processedData_JIRAComments_mxShopFeaturesICTF_normalized[\"JiraCommentsAsQuery_avgICTF\"],\n",
    "                                              #    processedData_JIRAComments_mxShopFeaturesICTF_normalized[\"JiraCommentsAsQuery_maxICTF\"],\n",
    "                                              #    processedData_JIRAComments_mxShopFeaturesICTF_normalized[\"JiraCommentsAsQuery_devICTF\"],\n",
    "                                                  \n",
    "                                                  processedData_SVN_mxShopFeaturesEntropy_normalized[\"SvnAsQuery_avgEntropy\"],\n",
    "                                                  processedData_SVN_mxShopFeaturesEntropy_normalized[\"SvnAsQuery_medEntropy\"],\n",
    "                                                  processedData_SVN_mxShopFeaturesEntropy_normalized[\"SvnAsQuery_maxEntropy\"],\n",
    "                                                  processedData_SVN_mxShopFeaturesEntropy_normalized[\"SvnAsQuery_devEntropy\"],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesEntropy_normalized[\"SvnLogsAsQuery_avgEntropy\"],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesEntropy_normalized[\"SvnLogsAsQuery_medEntropy\"],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesEntropy_normalized[\"SvnLogsAsQuery_maxEntropy\"],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesEntropy_normalized[\"SvnLogsAsQuery_devEntropy\"],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesEntropy_normalized[\"SvnUnitNamesAsQuery_avgEntropy\"],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesEntropy_normalized[\"SvnUnitNamesAsQuery_medEntropy\"],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesEntropy_normalized[\"SvnUnitNamesAsQuery_maxEntropy\"],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesEntropy_normalized[\"SvnUnitNamesAsQuery_devEntropy\"],\n",
    "                                                  processedData_JIRA_mxShopFeaturesEntropy_normalized[\"JiraAsQuery_avgEntropy\"],\n",
    "                                                  processedData_JIRA_mxShopFeaturesEntropy_normalized[\"JiraAsQuery_medEntropy\"],\n",
    "                                                  processedData_JIRA_mxShopFeaturesEntropy_normalized[\"JiraAsQuery_maxEntropy\"],\n",
    "                                                  processedData_JIRA_mxShopFeaturesEntropy_normalized[\"JiraAsQuery_devEntropy\"],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesEntropy_normalized[\"JiraSummariesAsQuery_avgEntropy\"],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesEntropy_normalized[\"JiraSummariesAsQuery_medEntropy\"],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesEntropy_normalized[\"JiraSummariesAsQuery_maxEntropy\"],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesEntropy_normalized[\"JiraSummariesAsQuery_devEntropy\"],\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesEntropy_normalized[\"JiraDescriptionsAsQuery_avgEntropy\"],\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesEntropy_normalized[\"JiraDescriptionsAsQuery_medEntropy\"],\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesEntropy_normalized[\"JiraDescriptionsAsQuery_maxEntropy\"],\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesEntropy_normalized[\"JiraDescriptionsAsQuery_devEntropy\"],\n",
    "                                               #   processedData_JIRAComments_mxShopFeaturesEntropy_normalized[\"JiraCommentsAsQuery_avgEntropy\"],\n",
    "                                               #   processedData_JIRAComments_mxShopFeaturesEntropy_normalized[\"JiraCommentsAsQuery_medEntropy\"],\n",
    "                                               #   processedData_JIRAComments_mxShopFeaturesEntropy_normalized[\"JiraCommentsAsQuery_maxEntropy\"],\n",
    "                                               #   processedData_JIRAComments_mxShopFeaturesEntropy_normalized[\"JiraCommentsAsQuery_devEntropy\"],\n",
    "                                                  \n",
    "                                                  processedData_SVN_mxShopFeaturesQueryScope_normalized,\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesQueryScope_normalized,\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesQueryScope_normalized,\n",
    "                                                  processedData_JIRA_mxShopFeaturesQueryScope_normalized,\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesQueryScope_normalized,\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesQueryScope_normalized,\n",
    "                                                #  processedData_JIRAComments_mxShopFeaturesQueryScope_normalized,\n",
    "                                                  \n",
    "                                                  processedData_SVN_mxShopFeaturesSCS_normalized,\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesSCS_normalized,\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesSCS_normalized,\n",
    "                                                  processedData_JIRA_mxShopFeaturesSCS_normalized,\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesSCS_normalized,\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesSCS_normalized,\n",
    "                                                #  processedData_JIRAComments_mxShopFeaturesSCS_normalized,\n",
    "                                                  \n",
    "                                                  processedData_SVN_mxShopFeaturesSCQ_normalized[\"SvnAsQuery_avgSCQ\"],\n",
    "                                                  processedData_SVN_mxShopFeaturesSCQ_normalized[\"SvnAsQuery_maxSCQ\"],\n",
    "                                                  processedData_SVN_mxShopFeaturesSCQ_normalized[\"SvnAsQuery_sumSCQ\"],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesSCQ_normalized[\"SvnLogsAsQuery_avgSCQ\"],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesSCQ_normalized[\"SvnLogsAsQuery_maxSCQ\"],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesSCQ_normalized[\"SvnLogsAsQuery_sumSCQ\"],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesSCQ_normalized[\"SvnUnitNamesAsQuery_avgSCQ\"],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesSCQ_normalized[\"SvnUnitNamesAsQuery_maxSCQ\"],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesSCQ_normalized[\"SvnUnitNamesAsQuery_sumSCQ\"],\n",
    "                                                  processedData_JIRA_mxShopFeaturesSCQ_normalized[\"JiraAsQuery_avgSCQ\"],\n",
    "                                                  processedData_JIRA_mxShopFeaturesSCQ_normalized[\"JiraAsQuery_maxSCQ\"],\n",
    "                                                  processedData_JIRA_mxShopFeaturesSCQ_normalized[\"JiraAsQuery_sumSCQ\"],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesSCQ_normalized[\"JiraSummariesAsQuery_avgSCQ\"],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesSCQ_normalized[\"JiraSummariesAsQuery_maxSCQ\"],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesSCQ_normalized[\"JiraSummariesAsQuery_sumSCQ\"],\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesSCQ_normalized[\"JiraDescriptionsAsQuery_avgSCQ\"],\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesSCQ_normalized[\"JiraDescriptionsAsQuery_maxSCQ\"],\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesSCQ_normalized[\"JiraDescriptionsAsQuery_sumSCQ\"],\n",
    "                                                 # processedData_JIRAComments_mxShopFeaturesSCQ_normalized[\"JiraCommentsAsQuery_avgSCQ\"],\n",
    "                                                #  processedData_JIRAComments_mxShopFeaturesSCQ_normalized[\"JiraCommentsAsQuery_maxSCQ\"],\n",
    "                                                #  processedData_JIRAComments_mxShopFeaturesSCQ_normalized[\"JiraCommentsAsQuery_sumSCQ\"],\n",
    "                                                  \n",
    "                                                 # processedData_SVN_mxShopFeaturesPMI_normalized[\"SvnAsQuery_avgPMI\"],\n",
    "                                                 # processedData_SVN_mxShopFeaturesPMI_normalized[\"SvnAsQuery_maxPMI\"],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesPMI_normalized[\"SvnLogsAsQuery_avgPMI\"],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesPMI_normalized[\"SvnLogsAsQuery_maxPMI\"],\n",
    "                                                 # processedData_SVNUnitNames_mxShopFeaturesPMI_normalized[\"SvnUnitNamesAsQuery_avgPMI\"],\n",
    "                                                 # processedData_SVNUnitNames_mxShopFeaturesPMI_normalized[\"SvnUnitNamesAsQuery_maxPMI\"],\n",
    "                                                 # processedData_JIRA_mxShopFeaturesPMI_normalized[\"JiraAsQuery_avgPMI\"],\n",
    "                                                 # processedData_JIRA_mxShopFeaturesPMI_normalized[\"JiraAsQuery_maxPMI\"],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesPMI_normalized[\"JiraSummariesAsQuery_avgPMI\"],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesPMI_normalized[\"JiraSummariesAsQuery_maxPMI\"],\n",
    "                                                 # processedData_JIRADescriptions_mxShopFeaturesPMI_normalized[\"JiraDescriptionsAsQuery_avgPMI\"],\n",
    "                                                 # processedData_JIRADescriptions_mxShopFeaturesPMI_normalized[\"JiraDescriptionsAsQuery_maxPMI\"],\n",
    "                                                #  processedData_JIRAComments_mxShopFeaturesPMI_normalized[\"JiraCommentsAsQuery_avgPMI\"],\n",
    "                                               #   processedData_JIRAComments_mxShopFeaturesPMI_normalized[\"JiraCommentssAsQuery_maxPMI\"],                                                  \n",
    "                                                 ], axis=1)\n",
    "#Set the NaN to 0\n",
    "processedData_mxShopFeatures_normalized = processedData_mxShopFeatures_normalized.fillna(0)\n",
    "\n",
    "#Saving feature names for later use\n",
    "processedData_mxShopFeatureNames_normalized = list(processedData_mxShopFeatures_normalized.columns)\n",
    "\n",
    "#Transform pandas data frame into numpy arrays\n",
    "processedData_mxShopFeatures_normalized = np.array(processedData_mxShopFeatures_normalized)\n",
    "\n",
    "#Load labels\n",
    "processedData_mxShopLabels_normalized = pd.read_pickle(r'../data/03_processed/processedData_mxShopLabels.pkl')\n",
    "processedData_mxShopLabels_normalized = np.array(processedData_mxShopLabels_normalized[\"is_valid\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "convertible-devon",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Merge features into 1 dataframe\n",
    "processedData_mxShopFeatures = pd.concat([processedData_mxShopFeaturesTime,\n",
    "                                                  processedData_mxShopFeaturesStakeholder,\n",
    "                                                  #IR-based\n",
    "                                                  processedData_mxShop_features_VsmLogsJiraAsQuery,\n",
    "                                                  processedData_mxShop_features_VsmLogsLogAsQuery,\n",
    "                                                  processedData_mxShop_features_VsmUnitNamesJiraAsQuery,\n",
    "                                                  processedData_mxShop_features_VsmUnitNamesUnitNamesAsQuery,\n",
    "                                                 # processedData_mxShop_features_VsmUnitNamesCommentsCommentsAsQuery,\n",
    "                                                 # processedData_mxShop_features_VsmUnitNamesCommentsUnitNamesAsQuery,\n",
    "                                                  processedData_mxShop_features_VsmUnitNamesDescriptionDescriptionAsQuery,\n",
    "                                                  processedData_mxShop_features_VsmUnitNamesDescriptionUnitNamesAsQuery,\n",
    "                                                  processedData_mxShop_features_VsmSummaryLogsSummaryAsQuery,\n",
    "                                                  processedData_mxShop_features_VsmSummaryLogsLogsAsQuery,\n",
    "                                                  processedData_mxShop_features_VsmSummaryUnitNamesSummaryAsQuery,\n",
    "                                                  processedData_mxShop_features_VsmSummaryUnitNamesUnitNamesAsQuery,\n",
    "                                                  processedData_mxShop_features_VsmDescriptionDescriptionAsQuery,\n",
    "                                                  processedData_mxShop_features_VsmDescriptionLogsAsQuery,\n",
    "                                                 # processedData_mxShop_features_VsmLogsJiraAsQuery_2gram,\n",
    "                                                 # processedData_mxShop_features_VsmLogsLogAsQuery_2gram,\n",
    "                                                 # processedData_mxShop_features_VsmUnitNamesJiraAsQuery_2gram,\n",
    "                                                 # processedData_mxShop_features_VsmUnitNamesUnitNamesAsQuery_2gram,\n",
    "                                                 # processedData_mxShop_features_VsmVerbPruningUnitNamesJiraAsQuery,\n",
    "                                                 # processedData_mxShop_features_VsmVerbPruningUnitNamesUnitNamesAsQuery,\n",
    "                                                  processedData_mxShop_features_VsmSvnJiraJiraAsQuery,\n",
    "                                                  processedData_mxShop_features_VsmSvnJiraSvnAsQuery,\n",
    "                                                  processedData_mxShop_features_VsmSvnSummarySvnAsQuery,\n",
    "                                                  processedData_mxShop_features_VsmSvnSummarySummaryAsQuery,\n",
    "                                                  processedData_mxShop_features_VsmSvnDescriptionSvnAsQuery,\n",
    "                                                  processedData_mxShop_features_VsmSvnDescriptionDescriptionAsQuery,\n",
    "                                                #  processedData_mxShop_features_VsmSvnCommentsSvnAsQuery,\n",
    "                                                #  processedData_mxShop_features_VsmSvnCommentsCommentsAsQuery,\n",
    "\n",
    "                                                  \n",
    "                                                  #Document Statistics\n",
    "                                                  processedData_JIRA_mxShopFeaturesUniqueWordCount,\n",
    "                                                  processedData_SVN_mxShopFeaturesUniqueWordCount,\n",
    "                                                  processedData_JIRA_mxShopFeaturesTotalWordCount,\n",
    "                                                  processedData_SVN_mxShopFeaturesTotalWordCount,\n",
    "                                                  processedData_JIRA_mxShopFeaturesOverlapPercentage,\n",
    "                                                  processedData_SVN_mxShopFeaturesOverlapPercentage,\n",
    "                                                  processedData_UNION_mxShopFeaturesOverlapPercentage,\n",
    "                                                 #Query Quality\n",
    "                                                  processedData_SVN_mxShopFeaturesIDF['SvnAsQuery_avgIDF'],\n",
    "                                                  processedData_SVN_mxShopFeaturesIDF['SvnAsQuery_maxIDF'],\n",
    "                                                  processedData_SVN_mxShopFeaturesIDF['SvnAsQuery_devIDF'],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesIDF['SvnLogsAsQuery_avgIDF'],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesIDF['SvnLogsAsQuery_maxIDF'],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesIDF['SvnLogsAsQuery_devIDF'],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesIDF['SvnUnitNamesAsQuery_avgIDF'],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesIDF['SvnUnitNamesAsQuery_maxIDF'],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesIDF['SvnUnitNamesAsQuery_devIDF'],\n",
    "                                                  processedData_JIRA_mxShopFeaturesIDF['JiraAsQuery_avgIDF'],\n",
    "                                                  processedData_JIRA_mxShopFeaturesIDF['JiraAsQuery_maxIDF'],\n",
    "                                                  processedData_JIRA_mxShopFeaturesIDF['JiraAsQuery_devIDF'], \n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesIDF['JiraSummariesAsQuery_avgIDF'],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesIDF['JiraSummariesAsQuery_maxIDF'],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesIDF['JiraSummariesAsQuery_devIDF'], \n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesIDF['JiraDescriptionsAsQuery_avgIDF'],\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesIDF['JiraDescriptionsAsQuery_maxIDF'],\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesIDF['JiraDescriptionsAsQuery_devIDF'], \n",
    "                                                #  processedData_JIRAComments_mxShopFeaturesIDF['JiraCommentsAsQuery_avgIDF'],\n",
    "                                               #   processedData_JIRAComments_mxShopFeaturesIDF['JiraCommentsAsQuery_maxIDF'],\n",
    "                                               #   processedData_JIRAComments_mxShopFeaturesIDF['JiraCommentsAsQuery_devIDF'], \n",
    "                                                  \n",
    "                                                  processedData_SVN_mxShopFeaturesICTF[\"SvnAsQuery_avgICTF\"],\n",
    "                                                  processedData_SVN_mxShopFeaturesICTF[\"SvnAsQuery_maxICTF\"],\n",
    "                                                  processedData_SVN_mxShopFeaturesICTF[\"SvnAsQuery_devICTF\"],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesICTF[\"SvnLogsAsQuery_avgICTF\"],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesICTF[\"SvnLogsAsQuery_maxICTF\"],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesICTF[\"SvnLogsAsQuery_devICTF\"],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesICTF[\"SvnUnitNamesAsQuery_avgICTF\"],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesICTF[\"SvnUnitNamesAsQuery_maxICTF\"],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesICTF[\"SvnUnitNamesAsQuery_devICTF\"],\n",
    "                                                  processedData_JIRA_mxShopFeaturesICTF[\"JiraAsQuery_avgICTF\"],\n",
    "                                                  processedData_JIRA_mxShopFeaturesICTF[\"JiraAsQuery_maxICTF\"],\n",
    "                                                  processedData_JIRA_mxShopFeaturesICTF[\"JiraAsQuery_devICTF\"],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesICTF[\"JiraSummariesAsQuery_avgICTF\"],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesICTF[\"JiraSummariesAsQuery_maxICTF\"],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesICTF[\"JiraSummariesAsQuery_devICTF\"],\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesICTF[\"JiraDescriptionsAsQuery_avgICTF\"],\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesICTF[\"JiraDescriptionsAsQuery_maxICTF\"],\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesICTF[\"JiraDescriptionsAsQuery_devICTF\"],\n",
    "                                                 # processedData_JIRAComments_mxShopFeaturesICTF[\"JiraCommentsAsQuery_avgICTF\"],\n",
    "                                                #  processedData_JIRAComments_mxShopFeaturesICTF[\"JiraCommentsAsQuery_maxICTF\"],\n",
    "                                               #   processedData_JIRAComments_mxShopFeaturesICTF[\"JiraCommentsAsQuery_devICTF\"],\n",
    "                                                  \n",
    "                                                  processedData_SVN_mxShopFeaturesEntropy[\"SvnAsQuery_avgEntropy\"],\n",
    "                                                  processedData_SVN_mxShopFeaturesEntropy[\"SvnAsQuery_medEntropy\"],\n",
    "                                                  processedData_SVN_mxShopFeaturesEntropy[\"SvnAsQuery_maxEntropy\"],\n",
    "                                                  processedData_SVN_mxShopFeaturesEntropy[\"SvnAsQuery_devEntropy\"],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesEntropy[\"SvnLogsAsQuery_avgEntropy\"],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesEntropy[\"SvnLogsAsQuery_medEntropy\"],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesEntropy[\"SvnLogsAsQuery_maxEntropy\"],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesEntropy[\"SvnLogsAsQuery_devEntropy\"],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesEntropy[\"SvnUnitNamesAsQuery_avgEntropy\"],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesEntropy[\"SvnUnitNamesAsQuery_medEntropy\"],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesEntropy[\"SvnUnitNamesAsQuery_maxEntropy\"],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesEntropy[\"SvnUnitNamesAsQuery_devEntropy\"],\n",
    "                                                  processedData_JIRA_mxShopFeaturesEntropy[\"JiraAsQuery_avgEntropy\"],\n",
    "                                                  processedData_JIRA_mxShopFeaturesEntropy[\"JiraAsQuery_medEntropy\"],\n",
    "                                                  processedData_JIRA_mxShopFeaturesEntropy[\"JiraAsQuery_maxEntropy\"],\n",
    "                                                  processedData_JIRA_mxShopFeaturesEntropy[\"JiraAsQuery_devEntropy\"],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesEntropy[\"JiraSummariesAsQuery_avgEntropy\"],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesEntropy[\"JiraSummariesAsQuery_medEntropy\"],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesEntropy[\"JiraSummariesAsQuery_maxEntropy\"],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesEntropy[\"JiraSummariesAsQuery_devEntropy\"],\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesEntropy[\"JiraDescriptionsAsQuery_avgEntropy\"],\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesEntropy[\"JiraDescriptionsAsQuery_medEntropy\"],\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesEntropy[\"JiraDescriptionsAsQuery_maxEntropy\"],\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesEntropy[\"JiraDescriptionsAsQuery_devEntropy\"],\n",
    "                                                #  processedData_JIRAComments_mxShopFeaturesEntropy[\"JiraCommentsAsQuery_avgEntropy\"],\n",
    "                                                 # processedData_JIRAComments_mxShopFeaturesEntropy[\"JiraCommentsAsQuery_medEntropy\"],\n",
    "                                                 # processedData_JIRAComments_mxShopFeaturesEntropy[\"JiraCommentsAsQuery_maxEntropy\"],\n",
    "                                                 # processedData_JIRAComments_mxShopFeaturesEntropy[\"JiraCommentsAsQuery_devEntropy\"],\n",
    "                                                  \n",
    "                                                  processedData_SVN_mxShopFeaturesQueryScope,\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesQueryScope,\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesQueryScope,\n",
    "                                                  processedData_JIRA_mxShopFeaturesQueryScope,\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesQueryScope,\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesQueryScope,\n",
    "                                                #  processedData_JIRAComments_mxShopFeaturesQueryScope,\n",
    "                                                  \n",
    "                                                  processedData_SVN_mxShopFeaturesSCS,\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesSCS,\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesSCS,\n",
    "                                                  processedData_JIRA_mxShopFeaturesSCS,\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesSCS,\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesSCS,\n",
    "                                                 # processedData_JIRAComments_mxShopFeaturesSCS,\n",
    "                                                  \n",
    "                                                  processedData_SVN_mxShopFeaturesSCQ[\"SvnAsQuery_avgSCQ\"],\n",
    "                                                  processedData_SVN_mxShopFeaturesSCQ[\"SvnAsQuery_maxSCQ\"],\n",
    "                                                  processedData_SVN_mxShopFeaturesSCQ[\"SvnAsQuery_sumSCQ\"],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesSCQ[\"SvnLogsAsQuery_avgSCQ\"],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesSCQ[\"SvnLogsAsQuery_maxSCQ\"],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesSCQ[\"SvnLogsAsQuery_sumSCQ\"],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesSCQ[\"SvnUnitNamesAsQuery_avgSCQ\"],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesSCQ[\"SvnUnitNamesAsQuery_maxSCQ\"],\n",
    "                                                  processedData_SVNUnitNames_mxShopFeaturesSCQ[\"SvnUnitNamesAsQuery_sumSCQ\"],\n",
    "                                                  processedData_JIRA_mxShopFeaturesSCQ[\"JiraAsQuery_avgSCQ\"],\n",
    "                                                  processedData_JIRA_mxShopFeaturesSCQ[\"JiraAsQuery_maxSCQ\"],\n",
    "                                                  processedData_JIRA_mxShopFeaturesSCQ[\"JiraAsQuery_sumSCQ\"],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesSCQ[\"JiraSummariesAsQuery_avgSCQ\"],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesSCQ[\"JiraSummariesAsQuery_maxSCQ\"],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesSCQ[\"JiraSummariesAsQuery_sumSCQ\"],\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesSCQ[\"JiraDescriptionsAsQuery_avgSCQ\"],\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesSCQ[\"JiraDescriptionsAsQuery_maxSCQ\"],\n",
    "                                                  processedData_JIRADescriptions_mxShopFeaturesSCQ[\"JiraDescriptionsAsQuery_sumSCQ\"],\n",
    "                                                 # processedData_JIRAComments_mxShopFeaturesSCQ[\"JiraCommentsAsQuery_avgSCQ\"],\n",
    "                                                 # processedData_JIRAComments_mxShopFeaturesSCQ[\"JiraCommentsAsQuery_maxSCQ\"],\n",
    "                                                 # processedData_JIRAComments_mxShopFeaturesSCQ[\"JiraCommentsAsQuery_sumSCQ\"],\n",
    "                                                  \n",
    "                                                  #processedData_SVN_mxShopFeaturesPMI[\"SvnAsQuery_avgPMI\"],\n",
    "                                                  #processedData_SVN_mxShopFeaturesPMI[\"SvnAsQuery_maxPMI\"],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesPMI[\"SvnLogsAsQuery_avgPMI\"],\n",
    "                                                  processedData_SVNLogs_mxShopFeaturesPMI[\"SvnLogsAsQuery_maxPMI\"],\n",
    "                                                 # processedData_SVNUnitNames_mxShopFeaturesPMI[\"SvnUnitNamesAsQuery_avgPMI\"],\n",
    "                                                 # processedData_SVNUnitNames_mxShopFeaturesPMI[\"SvnUnitNamesAsQuery_maxPMI\"],\n",
    "                                                 # processedData_JIRA_mxShopFeaturesPMI[\"JiraAsQuery_avgPMI\"],\n",
    "                                                 # processedData_JIRA_mxShopFeaturesPMI[\"JiraAsQuery_maxPMI\"],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesPMI[\"JiraSummariesAsQuery_avgPMI\"],\n",
    "                                                  processedData_JIRASummaries_mxShopFeaturesPMI[\"JiraSummariesAsQuery_maxPMI\"],\n",
    "                                                #  processedData_JIRADescriptions_mxShopFeaturesPMI[\"JiraDescriptionsAsQuery_avgPMI\"],\n",
    "                                                #  processedData_JIRADescriptions_mxShopFeaturesPMI[\"JiraDescriptionsAsQuery_maxPMI\"],\n",
    "                                                  #processedData_JIRAComments_mxShopFeaturesPMI[\"JiraCommentsAsQuery_avgPMI\"],\n",
    "                                                  #processedData_JIRAComments_mxShopFeaturesPMI[\"JiraCommentssAsQuery_maxPMI\"],\n",
    "                                                 ], axis=1)\n",
    "#Set the NaN to 0\n",
    "processedData_mxShopFeatures = processedData_mxShopFeatures.fillna(0)\n",
    "\n",
    "#Saving feature names for later use\n",
    "processedData_mxShopFeatureNames = list(processedData_mxShopFeatures.columns)\n",
    "\n",
    "#Transform pandas data frame into numpy arrays\n",
    "processedData_mxShopFeatures = np.array(processedData_mxShopFeatures)\n",
    "\n",
    "#Load labels\n",
    "processedData_mxShopLabels = pd.read_pickle(r'../data/03_processed/processedData_mxShopLabels.pkl')\n",
    "processedData_mxShopLabels = np.array(processedData_mxShopLabels[\"is_valid\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-location",
   "metadata": {},
   "source": [
    "# 4. Modeling - Normalization\n",
    "First select which data set to train:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "emotional-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "\n",
    "\n",
    "def showModelPerformance(trainedModel, testFeatures, testLabels):\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictionLabels = trainedModel.predict(testFeatures)\n",
    "    \n",
    "    accuracyValue = accuracy_score(testLabels.astype(bool), predictionLabels)\n",
    "    precisionValue = precision_score(testLabels.astype(bool), predictionLabels, average='binary')\n",
    "    f1Value = f1_score(testLabels.astype(bool), predictionLabels)\n",
    "    f2Value = fbeta_score(testLabels.astype(bool), predictionLabels, beta=2.0)\n",
    "    f05Value = fbeta_score(testLabels.astype(bool), predictionLabels, beta=0.5)\n",
    "    recallValue = recall_score(testLabels.astype(bool), predictionLabels)\n",
    "    averagePrecisionValue = average_precision_score(testLabels.astype(bool), predictionLabels)\n",
    "          \n",
    "    performanceData = {'Accuracy':  [accuracyValue],\n",
    "                       'Precision': [precisionValue],\n",
    "                       'Recall': [recallValue],\n",
    "                       'F1': [f1Value],\n",
    "                       'F2': [f2Value],\n",
    "                       'F0.5': [f05Value],\n",
    "                       'Average Precision': [averagePrecisionValue]\n",
    "                      }\n",
    "    performanceDf = pd.DataFrame(performanceData)\n",
    "    return(performanceDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "after-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_normalized = processedData_mxShopFeatures_normalized\n",
    "labels_normalized = processedData_mxShopLabels_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-recruitment",
   "metadata": {},
   "source": [
    "## 4.1 Rebalancing Strategy - None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-belize",
   "metadata": {},
   "source": [
    "### 4.1.1 Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "colored-belief",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "none_randomforest_normalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized,\n",
    "                                                    labels_normalized,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels_normalized)\n",
    "\n",
    "\n",
    "    pipeline = Pipeline(steps = [#['smote', SMOTE(sampling_strategy = 0.5, n_jobs=2)],\n",
    "                              #['under', RandomUnderSampler()],\n",
    "                                ['classifier', RandomForestClassifier(n_jobs=-1)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    spaceEmpty = dict() \n",
    "\n",
    "    search = RandomizedSearchCV(estimator = pipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring='f1', \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedRFModel = search.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    #print(f\"Elapsed time to compute best fit: \"\n",
    "      #f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedRFModel.best_score_\n",
    "    test_score = optimizedRFModel.score(X_test, y_test)\n",
    "    #print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    #print('Best Hyperparameters: %s' % optimizedRFModel.best_params_)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedRFModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    \n",
    "    none_randomforest_normalized_performance_df = pd.concat([none_randomforest_normalized_performance_df, new_performance_df])\n",
    "    \n",
    "none_randomforest_normalized_performance_df.to_csv(\"../data/05_model_output/none_randomforest_normalized_performance_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-flesh",
   "metadata": {},
   "source": [
    "### 4.1.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "specified-karen",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:27:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 42.650 seconds\n",
      "Cross-validation score: 0.8341419037698655\n",
      "Test score: 0.7692307692307693\n",
      "Best Hyperparameters: {}\n",
      "0.012228564\n",
      "0.019170862\n",
      "0.026953243\n",
      "0.009952978\n",
      "0.008801372\n",
      "0.009699399\n",
      "0.0011389386\n",
      "0.0033750439\n",
      "0.008673984\n",
      "0.0\n",
      "0.010198673\n",
      "0.004564193\n",
      "0.0\n",
      "0.0\n",
      "0.0075401184\n",
      "0.0\n",
      "0.03717987\n",
      "0.0\n",
      "0.008521208\n",
      "0.0\n",
      "0.0\n",
      "0.028367655\n",
      "0.008758058\n",
      "0.0002223952\n",
      "0.0\n",
      "0.0\n",
      "0.014965369\n",
      "0.011723049\n",
      "0.005344078\n",
      "0.0004998682\n",
      "0.005712581\n",
      "0.0\n",
      "0.0023494223\n",
      "0.0004588325\n",
      "0.008093835\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.008597786\n",
      "0.02668507\n",
      "0.0005602176\n",
      "0.006347892\n",
      "0.006112002\n",
      "0.013015379\n",
      "0.043249637\n",
      "0.022014841\n",
      "0.0045908173\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0042753513\n",
      "0.0066141896\n",
      "0.00401093\n",
      "0.004970064\n",
      "0.0\n",
      "0.0\n",
      "0.005062527\n",
      "0.0029188928\n",
      "0.0025466953\n",
      "0.028163878\n",
      "0.09012046\n",
      "0.01524282\n",
      "0.0\n",
      "0.00025091766\n",
      "0.00066783297\n",
      "0.003341364\n",
      "0.011569835\n",
      "0.0\n",
      "0.003471371\n",
      "0.009439608\n",
      "0.0026332904\n",
      "0.0\n",
      "0.011789735\n",
      "0.024387343\n",
      "0.010277577\n",
      "0.0\n",
      "0.012582472\n",
      "0.017902827\n",
      "0.011028543\n",
      "0.0\n",
      "0.021434665\n",
      "0.024097007\n",
      "0.02349047\n",
      "0.015579472\n",
      "0.015984721\n",
      "0.041625027\n",
      "0.0054291994\n",
      "0.0\n",
      "0.010853317\n",
      "0.0\n",
      "0.0046234364\n",
      "0.0\n",
      "0.0016820941\n",
      "0.0063228374\n",
      "0.016693473\n",
      "0.004617806\n",
      "0.0015483438\n",
      "0.025110196\n",
      "0.003617842\n",
      "0.0050710677\n",
      "0.0030938322\n",
      "0.0\n",
      "0.0017873937\n",
      "0.0\n",
      "0.004745351\n",
      "0.012290233\n",
      "0.0\n",
      "0.0\n",
      "0.008177517\n",
      "0.0\n",
      "0.0065209675\n",
      "0.004435613\n",
      "0.0\n",
      "0.006890502\n",
      "0.017600914\n",
      "0.0\n",
      "0.0037336927\n",
      "0.0046821106\n",
      "0.0\n",
      "0.0025449174\n",
      "0.0077441507\n",
      "0.016165797\n",
      "0.0028702498\n",
      "   Accuracy  Precision    Recall        F1     F2      F0.5  Average Precision\n",
      "0  0.998662   0.833333  0.588235  0.689655  0.625  0.769231           0.491237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:27:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 45.387 seconds\n",
      "Cross-validation score: 0.6612160263042377\n",
      "Test score: 0.7971014492753623\n",
      "Best Hyperparameters: {}\n",
      "0.010550992\n",
      "0.0173457\n",
      "0.02191594\n",
      "0.004862453\n",
      "0.016443752\n",
      "0.012961326\n",
      "0.007224841\n",
      "0.011604335\n",
      "0.0027283991\n",
      "0.0\n",
      "0.0023683377\n",
      "0.008392187\n",
      "0.0\n",
      "0.0\n",
      "0.015398836\n",
      "0.0\n",
      "0.015069008\n",
      "0.005809098\n",
      "0.007952512\n",
      "0.0\n",
      "0.009508084\n",
      "0.023192804\n",
      "0.027669823\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.010608269\n",
      "0.012945175\n",
      "0.0060088974\n",
      "0.0025891683\n",
      "0.0025414177\n",
      "0.0087549\n",
      "0.012710208\n",
      "0.0029325094\n",
      "0.0054501165\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.01907633\n",
      "0.0303574\n",
      "0.00089866424\n",
      "0.0039161933\n",
      "0.001426032\n",
      "0.006237233\n",
      "0.018492829\n",
      "0.020592999\n",
      "0.0034507266\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0031988586\n",
      "0.005475687\n",
      "0.004523924\n",
      "0.0057225255\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0045942077\n",
      "0.0040495563\n",
      "0.050616927\n",
      "0.07503493\n",
      "0.013206641\n",
      "0.0018101815\n",
      "0.0013848457\n",
      "0.0016782044\n",
      "0.007608237\n",
      "0.0017118109\n",
      "0.0\n",
      "0.014196197\n",
      "0.0067736125\n",
      "0.0035676332\n",
      "0.049769666\n",
      "0.008421653\n",
      "0.016839167\n",
      "0.0066485303\n",
      "0.0\n",
      "0.006237633\n",
      "0.013944476\n",
      "0.009118189\n",
      "6.735275e-05\n",
      "0.013905747\n",
      "0.020069517\n",
      "0.006821035\n",
      "0.0055797435\n",
      "0.012645075\n",
      "0.037552122\n",
      "0.0066348193\n",
      "0.0\n",
      "0.020349964\n",
      "0.0\n",
      "0.004637901\n",
      "0.000582899\n",
      "0.005005305\n",
      "0.008656689\n",
      "0.007865064\n",
      "0.0023710076\n",
      "0.007828971\n",
      "0.0\n",
      "0.008092932\n",
      "0.017747613\n",
      "0.005503139\n",
      "0.0\n",
      "0.0115355905\n",
      "0.0\n",
      "0.0032167034\n",
      "0.0026514833\n",
      "0.0\n",
      "0.0\n",
      "0.015561366\n",
      "0.0\n",
      "0.009749145\n",
      "0.009310968\n",
      "0.0\n",
      "0.009322027\n",
      "0.014672102\n",
      "0.0\n",
      "0.00036863488\n",
      "0.004552002\n",
      "0.0\n",
      "0.0064178975\n",
      "0.0023308275\n",
      "0.01086295\n",
      "0.0014107149\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998811   0.846154  0.647059  0.733333  0.679012  0.797101   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.548403  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:28:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 43.257 seconds\n",
      "Cross-validation score: 0.8325026050562985\n",
      "Test score: 0.7547169811320755\n",
      "Best Hyperparameters: {}\n",
      "0.009003392\n",
      "0.016323853\n",
      "0.024962414\n",
      "0.011971093\n",
      "0.015089925\n",
      "0.0074241445\n",
      "0.017063564\n",
      "0.010385249\n",
      "0.011783623\n",
      "0.008028326\n",
      "0.015591399\n",
      "0.0071042366\n",
      "0.0\n",
      "0.0\n",
      "0.016379677\n",
      "0.0\n",
      "0.020037804\n",
      "0.003239592\n",
      "0.014929795\n",
      "0.009378338\n",
      "0.0064311214\n",
      "0.040816657\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0012841895\n",
      "0.0\n",
      "0.002648632\n",
      "0.006355933\n",
      "0.0032127358\n",
      "0.006869059\n",
      "0.019532163\n",
      "0.0034083473\n",
      "0.009486755\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.009301976\n",
      "0.010609784\n",
      "0.0019660196\n",
      "0.0135606835\n",
      "0.0016884361\n",
      "0.009281832\n",
      "0.014489251\n",
      "0.024719514\n",
      "0.00452188\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.005434637\n",
      "0.009982665\n",
      "0.005863155\n",
      "0.004996587\n",
      "0.0\n",
      "0.0\n",
      "0.0025524346\n",
      "0.0039953575\n",
      "0.011105046\n",
      "0.027961679\n",
      "0.07089165\n",
      "0.016341092\n",
      "0.0038222698\n",
      "0.0\n",
      "0.005022746\n",
      "0.009196888\n",
      "0.002209331\n",
      "0.0\n",
      "0.00717081\n",
      "0.0064737955\n",
      "0.009934136\n",
      "0.057269473\n",
      "0.004330831\n",
      "0.0\n",
      "0.004278482\n",
      "0.0\n",
      "0.0\n",
      "0.0043033357\n",
      "0.0065777204\n",
      "0.0014887408\n",
      "0.000599727\n",
      "0.022587683\n",
      "0.011626467\n",
      "0.0\n",
      "0.008356714\n",
      "0.07006611\n",
      "0.001118985\n",
      "0.0\n",
      "0.0016988752\n",
      "0.0\n",
      "0.0034822116\n",
      "0.0\n",
      "0.022716483\n",
      "0.011314622\n",
      "0.012487862\n",
      "0.005485266\n",
      "0.005284273\n",
      "0.0\n",
      "0.003601209\n",
      "0.009039934\n",
      "0.0010023583\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.003130576\n",
      "0.0037203878\n",
      "0.0\n",
      "0.0\n",
      "0.016334511\n",
      "0.0\n",
      "0.0051606908\n",
      "0.016368777\n",
      "0.0\n",
      "0.0043371017\n",
      "0.017861495\n",
      "0.0\n",
      "0.00090682914\n",
      "0.006394663\n",
      "0.0\n",
      "0.008474752\n",
      "0.0018941907\n",
      "0.029561572\n",
      "0.00530135\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998513   0.888889  0.470588  0.615385  0.519481  0.754717   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.419639  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:29:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 45.188 seconds\n",
      "Cross-validation score: 0.8158310449887919\n",
      "Test score: 0.7317073170731707\n",
      "Best Hyperparameters: {}\n",
      "0.011125234\n",
      "0.014020649\n",
      "0.021344291\n",
      "0.028206564\n",
      "0.010332156\n",
      "0.011456816\n",
      "0.0006217239\n",
      "0.0007767027\n",
      "0.00029315075\n",
      "0.002472238\n",
      "0.03324229\n",
      "0.0074401814\n",
      "0.0\n",
      "0.0\n",
      "0.02674804\n",
      "0.0\n",
      "0.017620798\n",
      "0.0008208221\n",
      "0.0038854687\n",
      "0.009448831\n",
      "0.006486795\n",
      "0.0\n",
      "0.0023135038\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.019179007\n",
      "0.00091538305\n",
      "0.0052986997\n",
      "0.019312927\n",
      "0.0066827037\n",
      "0.008246149\n",
      "0.013883646\n",
      "0.004502901\n",
      "0.0040976787\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.016130958\n",
      "0.029689172\n",
      "0.020051928\n",
      "0.007833417\n",
      "0.0017124253\n",
      "0.0031412335\n",
      "0.025344223\n",
      "0.020580277\n",
      "0.0029055516\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0032357113\n",
      "0.0008191733\n",
      "0.0053392826\n",
      "0.003549958\n",
      "0.0\n",
      "0.028123558\n",
      "0.0033660969\n",
      "0.0\n",
      "0.0048371004\n",
      "0.028351527\n",
      "0.06496283\n",
      "0.0010045345\n",
      "0.0014837548\n",
      "0.0\n",
      "0.0\n",
      "0.01670592\n",
      "0.0\n",
      "0.0\n",
      "0.0030248102\n",
      "0.007733674\n",
      "0.0002318904\n",
      "0.0\n",
      "0.01059629\n",
      "0.031201057\n",
      "0.0\n",
      "0.0\n",
      "0.014804638\n",
      "0.017345892\n",
      "0.009885111\n",
      "0.0\n",
      "0.028211419\n",
      "0.014907254\n",
      "0.008714273\n",
      "0.012845662\n",
      "0.00870401\n",
      "0.020095248\n",
      "0.0007546274\n",
      "0.0\n",
      "0.04640842\n",
      "0.0\n",
      "0.004697606\n",
      "0.0018762037\n",
      "0.010792092\n",
      "0.013195626\n",
      "0.0071249167\n",
      "0.002004906\n",
      "0.005228841\n",
      "0.0\n",
      "0.005130908\n",
      "0.008679501\n",
      "0.00608293\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0022426802\n",
      "0.0041179694\n",
      "0.0\n",
      "0.010743312\n",
      "0.0063358136\n",
      "0.0\n",
      "0.0045082932\n",
      "0.00997249\n",
      "0.0\n",
      "0.00965035\n",
      "0.02386898\n",
      "0.0\n",
      "0.00094577105\n",
      "0.02097712\n",
      "0.0\n",
      "0.0026413708\n",
      "0.00792246\n",
      "0.014674154\n",
      "0.0011774456\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998365        1.0  0.352941  0.521739  0.405405  0.731707   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.354577  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:29:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 43.030 seconds\n",
      "Cross-validation score: 0.7300437083045779\n",
      "Test score: 0.8695652173913044\n",
      "Best Hyperparameters: {}\n",
      "0.01211472\n",
      "0.020381404\n",
      "0.028940106\n",
      "0.0056606177\n",
      "0.021113252\n",
      "0.009666185\n",
      "0.0059688324\n",
      "0.0\n",
      "0.009934168\n",
      "0.015234734\n",
      "0.008811954\n",
      "0.009269865\n",
      "0.0\n",
      "0.0\n",
      "0.012179034\n",
      "0.0\n",
      "0.014711999\n",
      "0.0\n",
      "0.011347707\n",
      "0.0046165762\n",
      "0.0\n",
      "0.022449214\n",
      "0.005391961\n",
      "0.0\n",
      "0.009136768\n",
      "0.0\n",
      "0.00814556\n",
      "0.001679176\n",
      "0.005820093\n",
      "0.01911259\n",
      "0.008730111\n",
      "0.013854803\n",
      "0.017293664\n",
      "0.0036870616\n",
      "0.0067263218\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0037581238\n",
      "0.01698125\n",
      "0.005030531\n",
      "0.015014482\n",
      "0.0027007503\n",
      "0.006972624\n",
      "0.020497067\n",
      "0.009625497\n",
      "0.0011635287\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.010485126\n",
      "0.0028258504\n",
      "0.006792065\n",
      "0.006968472\n",
      "0.0\n",
      "0.00033873526\n",
      "0.0\n",
      "0.002791823\n",
      "0.009080712\n",
      "0.044162326\n",
      "0.0753794\n",
      "0.005452938\n",
      "0.0018711446\n",
      "0.0\n",
      "0.0\n",
      "0.011766604\n",
      "0.0\n",
      "0.0\n",
      "0.0030229478\n",
      "0.011023517\n",
      "0.0027372679\n",
      "0.0\n",
      "0.007822015\n",
      "0.0\n",
      "0.019110825\n",
      "0.0\n",
      "0.018225536\n",
      "0.009215665\n",
      "0.01130613\n",
      "0.0039001927\n",
      "0.0\n",
      "0.032177947\n",
      "0.024507789\n",
      "0.004950484\n",
      "0.0020159003\n",
      "0.041644372\n",
      "0.006884367\n",
      "0.008435181\n",
      "0.028337127\n",
      "0.006754486\n",
      "0.007652363\n",
      "0.0\n",
      "0.00199605\n",
      "0.0075636157\n",
      "0.0056620557\n",
      "0.0050464375\n",
      "0.0070268833\n",
      "0.0\n",
      "0.0058414037\n",
      "0.016083129\n",
      "0.007244452\n",
      "0.0\n",
      "0.0058668107\n",
      "0.0\n",
      "0.0045364345\n",
      "0.0048682657\n",
      "0.0\n",
      "0.0\n",
      "0.012456132\n",
      "0.0\n",
      "0.0033726932\n",
      "0.007301105\n",
      "0.0\n",
      "0.0013959061\n",
      "0.01710762\n",
      "0.0\n",
      "0.0\n",
      "0.0107456\n",
      "0.0\n",
      "0.0061457395\n",
      "0.013508722\n",
      "0.025600279\n",
      "0.009269059\n",
      "   Accuracy  Precision    Recall   F1        F2      F0.5  Average Precision\n",
      "0  0.999108   0.923077  0.705882  0.8  0.740741  0.869565           0.652327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:30:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 39.075 seconds\n",
      "Cross-validation score: 0.7746226212676348\n",
      "Test score: 0.7017543859649122\n",
      "Best Hyperparameters: {}\n",
      "0.008658035\n",
      "0.018874666\n",
      "0.022550307\n",
      "0.0053999093\n",
      "0.007876027\n",
      "0.008297283\n",
      "0.0049379035\n",
      "0.0\n",
      "0.0\n",
      "0.020243235\n",
      "0.0069214604\n",
      "0.0059805787\n",
      "0.012938502\n",
      "0.0\n",
      "0.027508482\n",
      "0.0\n",
      "0.0077244593\n",
      "0.0\n",
      "0.0054288823\n",
      "0.007848156\n",
      "0.012457435\n",
      "0.008030687\n",
      "0.0063105184\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.009578541\n",
      "0.004047825\n",
      "0.0043755593\n",
      "0.0\n",
      "0.010638586\n",
      "0.011036479\n",
      "0.004679921\n",
      "0.001522556\n",
      "0.005950683\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0029458217\n",
      "0.04804856\n",
      "0.00899598\n",
      "0.0054859845\n",
      "0.03058131\n",
      "0.0025272055\n",
      "0.006541555\n",
      "0.013585571\n",
      "0.002032358\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.004295366\n",
      "0.0048517366\n",
      "0.0032115413\n",
      "0.0062693125\n",
      "0.0\n",
      "0.0065036034\n",
      "0.0045397053\n",
      "0.013854858\n",
      "0.0060548\n",
      "0.028422177\n",
      "0.060668845\n",
      "0.0113762235\n",
      "0.0041955416\n",
      "0.0\n",
      "0.001384743\n",
      "0.005461734\n",
      "0.0018103047\n",
      "0.0\n",
      "0.013425813\n",
      "0.0055713393\n",
      "0.019162683\n",
      "0.0\n",
      "0.009088417\n",
      "0.034285404\n",
      "0.012421733\n",
      "0.0\n",
      "0.01723191\n",
      "0.010811589\n",
      "0.0058481484\n",
      "0.0006623114\n",
      "0.003345061\n",
      "0.012396528\n",
      "0.011024162\n",
      "0.03586006\n",
      "0.01151154\n",
      "0.01578081\n",
      "0.0020776235\n",
      "0.0\n",
      "0.02873122\n",
      "0.012260757\n",
      "0.004952376\n",
      "0.0\n",
      "0.00036564286\n",
      "0.0068334127\n",
      "0.01643568\n",
      "0.0016626512\n",
      "0.0040925727\n",
      "0.0\n",
      "0.0074582393\n",
      "0.012085369\n",
      "0.02666474\n",
      "0.0\n",
      "0.009746377\n",
      "0.0\n",
      "0.001843753\n",
      "0.003241505\n",
      "0.0\n",
      "0.0\n",
      "0.004896301\n",
      "0.0\n",
      "0.0042785793\n",
      "0.006534455\n",
      "0.0\n",
      "0.0054482045\n",
      "0.010451021\n",
      "0.0\n",
      "0.0\n",
      "0.020178024\n",
      "0.0\n",
      "0.0030866624\n",
      "0.013312392\n",
      "0.02895588\n",
      "0.012517622\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998365        0.8  0.470588  0.592593  0.512821  0.701754   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.377809  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:31:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 41.816 seconds\n",
      "Cross-validation score: 0.8040103915943584\n",
      "Test score: 0.5737704918032787\n",
      "Best Hyperparameters: {}\n",
      "0.01478439\n",
      "0.01868653\n",
      "0.029357512\n",
      "0.008204864\n",
      "0.013506077\n",
      "0.010734365\n",
      "0.012415424\n",
      "0.0\n",
      "0.016003076\n",
      "0.0\n",
      "0.02318282\n",
      "0.0066181235\n",
      "0.0\n",
      "0.0\n",
      "0.012591824\n",
      "0.0\n",
      "0.01839143\n",
      "0.0\n",
      "0.0\n",
      "0.010774457\n",
      "0.0\n",
      "0.028666995\n",
      "0.00249246\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.006266033\n",
      "0.00065287505\n",
      "0.005111158\n",
      "0.032010708\n",
      "0.013673333\n",
      "0.0030348473\n",
      "0.0\n",
      "0.005645075\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007758796\n",
      "0.033075005\n",
      "0.0056986837\n",
      "0.0042673727\n",
      "0.0046503735\n",
      "0.008238447\n",
      "0.023696678\n",
      "0.0009812128\n",
      "0.0010039848\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00377359\n",
      "0.0056610648\n",
      "0.0062753526\n",
      "0.009016009\n",
      "0.0061939587\n",
      "0.0\n",
      "0.009697615\n",
      "0.005401705\n",
      "0.008751186\n",
      "0.029093126\n",
      "0.080260746\n",
      "0.01935077\n",
      "0.0059155393\n",
      "0.0\n",
      "0.005017015\n",
      "0.018384093\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007557544\n",
      "0.0014234277\n",
      "0.016585479\n",
      "0.0077911997\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.011156594\n",
      "0.008172295\n",
      "0.0\n",
      "0.010127972\n",
      "0.02601666\n",
      "0.0067719147\n",
      "0.027590321\n",
      "0.0074146492\n",
      "0.08043464\n",
      "0.0021787644\n",
      "0.0\n",
      "0.0018290557\n",
      "0.0\n",
      "0.009882329\n",
      "0.0026428376\n",
      "0.0018854163\n",
      "0.018007718\n",
      "0.00017253053\n",
      "0.0022162963\n",
      "0.003934098\n",
      "0.0\n",
      "0.006920767\n",
      "0.023811333\n",
      "0.0073852823\n",
      "0.0\n",
      "0.006188228\n",
      "0.0\n",
      "0.003559598\n",
      "0.0039419606\n",
      "0.0\n",
      "0.0\n",
      "0.016427673\n",
      "0.0\n",
      "0.0058391434\n",
      "0.008127496\n",
      "0.0\n",
      "0.010974481\n",
      "0.014311844\n",
      "0.0\n",
      "0.0\n",
      "0.023740206\n",
      "0.0\n",
      "0.0041062403\n",
      "0.004691867\n",
      "0.008726197\n",
      "0.0024891498\n",
      "   Accuracy  Precision    Recall   F1        F2     F0.5  Average Precision\n",
      "0  0.997919   0.636364  0.411765  0.5  0.443038  0.57377           0.263519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:32:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 42.047 seconds\n",
      "Cross-validation score: 0.7322131688891858\n",
      "Test score: 0.7017543859649122\n",
      "Best Hyperparameters: {}\n",
      "0.012295647\n",
      "0.017284079\n",
      "0.020103116\n",
      "0.003314327\n",
      "0.015173593\n",
      "0.0060303397\n",
      "0.005296063\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0048977765\n",
      "0.008510091\n",
      "0.021906054\n",
      "0.0\n",
      "0.013350504\n",
      "0.0\n",
      "0.006140752\n",
      "0.0050420146\n",
      "0.0063554524\n",
      "0.040676005\n",
      "0.0070619616\n",
      "0.04844212\n",
      "0.0015201742\n",
      "0.01193672\n",
      "0.031302847\n",
      "0.0\n",
      "0.009207697\n",
      "0.014782674\n",
      "0.012813505\n",
      "0.007133014\n",
      "0.0049680034\n",
      "0.0125612635\n",
      "0.007899394\n",
      "0.0031191206\n",
      "0.007606575\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0029081905\n",
      "0.031740688\n",
      "0.0032231186\n",
      "0.02756071\n",
      "0.019297747\n",
      "0.00713392\n",
      "0.022624781\n",
      "0.0142835695\n",
      "0.0038181802\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0033282344\n",
      "0.0025985984\n",
      "0.0044923113\n",
      "0.0\n",
      "0.0\n",
      "0.02161863\n",
      "0.0076349624\n",
      "0.0\n",
      "0.009699884\n",
      "0.024016073\n",
      "0.09189797\n",
      "0.0062682386\n",
      "0.0057602692\n",
      "0.0003296506\n",
      "0.001553378\n",
      "0.005920414\n",
      "0.0069744545\n",
      "0.0\n",
      "0.0051399968\n",
      "0.004411718\n",
      "0.009554505\n",
      "0.01062572\n",
      "0.008209712\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0048375484\n",
      "0.007606753\n",
      "0.00085542514\n",
      "0.0062654824\n",
      "0.020075213\n",
      "0.009139486\n",
      "0.0\n",
      "0.00065323873\n",
      "0.033310834\n",
      "0.016443787\n",
      "0.0\n",
      "0.0058075227\n",
      "0.0\n",
      "0.0030812006\n",
      "0.0\n",
      "0.0005840928\n",
      "0.0075341268\n",
      "0.0038090802\n",
      "0.0017860674\n",
      "0.0031496612\n",
      "0.02259138\n",
      "0.004359256\n",
      "0.006250601\n",
      "0.0033671213\n",
      "0.0\n",
      "0.0023013107\n",
      "0.0\n",
      "0.004356384\n",
      "0.00560993\n",
      "0.0\n",
      "0.0060282885\n",
      "0.0\n",
      "0.0\n",
      "0.008947754\n",
      "0.004506769\n",
      "0.0\n",
      "0.013305175\n",
      "0.013775484\n",
      "0.0\n",
      "0.00082055846\n",
      "0.010483035\n",
      "0.0\n",
      "0.0040038233\n",
      "0.008120937\n",
      "0.018937394\n",
      "0.007938766\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998365        0.8  0.470588  0.592593  0.512821  0.701754   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.377809  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:32:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 42.666 seconds\n",
      "Cross-validation score: 0.7777552225584999\n",
      "Test score: 0.8461538461538461\n",
      "Best Hyperparameters: {}\n",
      "0.010352809\n",
      "0.01514303\n",
      "0.031843614\n",
      "0.0068449783\n",
      "0.03106093\n",
      "0.015779687\n",
      "0.012176016\n",
      "0.003864885\n",
      "0.004865995\n",
      "0.0\n",
      "0.03599157\n",
      "0.0061678113\n",
      "0.0\n",
      "0.0\n",
      "0.016144749\n",
      "0.0\n",
      "0.009102401\n",
      "0.0017549427\n",
      "0.0035374246\n",
      "0.010135564\n",
      "0.0040404233\n",
      "0.033175632\n",
      "0.032010473\n",
      "0.006697269\n",
      "0.0\n",
      "0.0\n",
      "0.010673931\n",
      "0.0\n",
      "0.0016206389\n",
      "0.0025234108\n",
      "0.011670655\n",
      "0.0063330424\n",
      "0.013017224\n",
      "0.0038407503\n",
      "0.0051505845\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0029368203\n",
      "0.031308025\n",
      "0.023632368\n",
      "0.027164597\n",
      "0.0102034025\n",
      "0.013328801\n",
      "0.018205652\n",
      "0.007311018\n",
      "0.0051753377\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0031890257\n",
      "0.0007878121\n",
      "0.004141328\n",
      "0.009998143\n",
      "0.0\n",
      "0.0\n",
      "0.0137623865\n",
      "0.0018643958\n",
      "0.0010638549\n",
      "0.029625399\n",
      "0.06580569\n",
      "0.00878427\n",
      "0.003960582\n",
      "0.0025548239\n",
      "0.0\n",
      "0.006879912\n",
      "0.0061763753\n",
      "0.0\n",
      "0.002631038\n",
      "0.007613806\n",
      "0.022369757\n",
      "0.008992025\n",
      "0.0069477474\n",
      "0.0\n",
      "0.0051034526\n",
      "0.0\n",
      "0.03134311\n",
      "0.0045742085\n",
      "0.0139627885\n",
      "0.0\n",
      "0.0048550703\n",
      "0.027391195\n",
      "0.008980514\n",
      "0.0045517916\n",
      "0.00772842\n",
      "0.03540309\n",
      "0.0073109125\n",
      "0.0\n",
      "0.022277113\n",
      "0.0\n",
      "0.0052743396\n",
      "0.0\n",
      "0.0015033433\n",
      "0.008948137\n",
      "0.0\n",
      "0.0031822901\n",
      "0.0047686603\n",
      "0.0\n",
      "0.0027429922\n",
      "0.005481771\n",
      "0.0075690593\n",
      "0.0\n",
      "0.0052018436\n",
      "0.0\n",
      "0.0065065\n",
      "0.005948591\n",
      "0.0\n",
      "0.0\n",
      "0.0029221543\n",
      "0.0\n",
      "0.003938928\n",
      "0.012864173\n",
      "0.0\n",
      "0.0038185029\n",
      "0.014031134\n",
      "0.0\n",
      "0.0030370282\n",
      "0.0063344566\n",
      "0.0\n",
      "0.005291071\n",
      "0.0014626941\n",
      "0.015164275\n",
      "0.008591602\n",
      "   Accuracy  Precision    Recall        F1      F2      F0.5  \\\n",
      "0  0.998959   0.916667  0.647059  0.758621  0.6875  0.846154   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.594029  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:33:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 47.092 seconds\n",
      "Cross-validation score: 0.7324036797499557\n",
      "Test score: 0.8695652173913044\n",
      "Best Hyperparameters: {}\n",
      "0.010493156\n",
      "0.01643008\n",
      "0.0262185\n",
      "0.013597927\n",
      "0.012505095\n",
      "0.005320818\n",
      "0.0070627136\n",
      "0.0011268076\n",
      "0.008754879\n",
      "0.0\n",
      "0.014640837\n",
      "0.0062982477\n",
      "0.0\n",
      "0.0\n",
      "0.013498715\n",
      "0.0\n",
      "0.07123045\n",
      "0.005720919\n",
      "0.0\n",
      "0.011442257\n",
      "0.0048508374\n",
      "0.020327352\n",
      "0.006021073\n",
      "0.0055451198\n",
      "0.025023691\n",
      "0.0003001139\n",
      "0.009697591\n",
      "0.0017745695\n",
      "0.00113559\n",
      "0.007788213\n",
      "0.0002719309\n",
      "0.006430195\n",
      "0.0100052515\n",
      "0.019256271\n",
      "0.0037769487\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.008792576\n",
      "0.02876882\n",
      "0.0011243348\n",
      "0.01328817\n",
      "0.006070504\n",
      "0.0075423038\n",
      "0.018354971\n",
      "0.006896194\n",
      "0.00230652\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0033214833\n",
      "0.005109654\n",
      "0.0050105653\n",
      "0.0\n",
      "0.0\n",
      "0.0033826379\n",
      "0.007262656\n",
      "0.00021050128\n",
      "0.0067146644\n",
      "0.037421316\n",
      "0.05018918\n",
      "0.012130837\n",
      "0.0030963733\n",
      "0.03838454\n",
      "0.00040441568\n",
      "0.013808992\n",
      "0.00058049907\n",
      "0.0\n",
      "0.03897402\n",
      "0.005193815\n",
      "0.008948113\n",
      "0.02390014\n",
      "0.0089642545\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.016090019\n",
      "0.003914511\n",
      "0.0058863303\n",
      "0.00661938\n",
      "0.005997262\n",
      "0.019012783\n",
      "0.0042740474\n",
      "0.011380419\n",
      "0.02231882\n",
      "0.038117543\n",
      "0.0060971193\n",
      "0.0\n",
      "0.013525224\n",
      "0.002327138\n",
      "0.0011091294\n",
      "0.0\n",
      "0.0049064266\n",
      "0.010935339\n",
      "0.0061849905\n",
      "0.004719493\n",
      "0.0060505737\n",
      "0.0\n",
      "0.0046356865\n",
      "0.019506257\n",
      "0.003018531\n",
      "0.0\n",
      "0.0069150366\n",
      "0.0\n",
      "0.002368317\n",
      "0.006514274\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.004289745\n",
      "0.0061610597\n",
      "0.0\n",
      "0.0023306669\n",
      "0.011669253\n",
      "0.0\n",
      "0.0010908613\n",
      "0.0011940692\n",
      "0.0\n",
      "0.0017907714\n",
      "0.0\n",
      "0.018504554\n",
      "0.007845201\n",
      "   Accuracy  Precision    Recall   F1        F2      F0.5  Average Precision\n",
      "0  0.999108   0.923077  0.705882  0.8  0.740741  0.869565           0.652327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:34:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 43.207 seconds\n",
      "Cross-validation score: 0.6628741027869987\n",
      "Test score: 0.8904109589041096\n",
      "Best Hyperparameters: {}\n",
      "0.00951845\n",
      "0.022327114\n",
      "0.030138854\n",
      "0.008453278\n",
      "0.013251146\n",
      "0.007850234\n",
      "0.0\n",
      "0.003785334\n",
      "0.0\n",
      "0.0\n",
      "0.010387564\n",
      "0.005045023\n",
      "0.0\n",
      "0.0\n",
      "0.018672725\n",
      "0.0\n",
      "0.005443323\n",
      "0.007097171\n",
      "0.0\n",
      "0.0076004695\n",
      "0.0033145521\n",
      "0.013404222\n",
      "0.041243713\n",
      "0.008693137\n",
      "0.007844322\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0069509004\n",
      "0.002142909\n",
      "0.0014847108\n",
      "0.01520574\n",
      "0.024528364\n",
      "0.00083804264\n",
      "0.009792321\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0044960734\n",
      "0.03251848\n",
      "0.012065133\n",
      "0.012198351\n",
      "0.0\n",
      "0.0058570304\n",
      "0.013564979\n",
      "0.026586974\n",
      "0.0034465496\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.004395222\n",
      "0.0019275832\n",
      "0.006086932\n",
      "0.0111108245\n",
      "0.0\n",
      "0.011095805\n",
      "0.019503932\n",
      "0.014476624\n",
      "0.00781818\n",
      "0.027131626\n",
      "0.09141183\n",
      "0.011426582\n",
      "0.010988382\n",
      "0.0020313172\n",
      "0.0057068556\n",
      "0.012594849\n",
      "0.002848728\n",
      "0.0\n",
      "0.00053141586\n",
      "0.0070068613\n",
      "0.0019328373\n",
      "0.0\n",
      "0.0075451587\n",
      "0.0\n",
      "0.0068566375\n",
      "0.0\n",
      "0.025279587\n",
      "0.007616758\n",
      "0.008085877\n",
      "0.0\n",
      "0.0027213925\n",
      "0.020151712\n",
      "0.010271828\n",
      "0.017715085\n",
      "0.0015545319\n",
      "0.027071754\n",
      "0.006063586\n",
      "0.0\n",
      "0.013050532\n",
      "0.0062726974\n",
      "0.0029153975\n",
      "0.0\n",
      "0.012256479\n",
      "0.009861456\n",
      "0.018001206\n",
      "0.0022238516\n",
      "0.00395647\n",
      "0.0\n",
      "0.0028342914\n",
      "0.009857141\n",
      "0.02868448\n",
      "0.0\n",
      "0.016441572\n",
      "0.0\n",
      "0.0016482114\n",
      "0.004506547\n",
      "0.0\n",
      "0.0\n",
      "0.0065616993\n",
      "0.0\n",
      "0.002712786\n",
      "0.007517874\n",
      "0.0\n",
      "0.0015955992\n",
      "0.015011916\n",
      "0.0\n",
      "0.0\n",
      "0.005632979\n",
      "0.0\n",
      "0.0064097242\n",
      "0.0028273547\n",
      "0.02734181\n",
      "0.0051705027\n",
      "   Accuracy  Precision    Recall       F1        F2      F0.5  \\\n",
      "0  0.999257   0.928571  0.764706  0.83871  0.792683  0.890411   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.710679  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:34:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 41.820 seconds\n",
      "Cross-validation score: 0.7225603807651493\n",
      "Test score: 0.7377049180327868\n",
      "Best Hyperparameters: {}\n",
      "0.010526815\n",
      "0.017015513\n",
      "0.019705158\n",
      "0.0\n",
      "0.007802283\n",
      "0.006611669\n",
      "0.006338298\n",
      "0.005565669\n",
      "0.006678721\n",
      "0.011450321\n",
      "0.006061277\n",
      "0.010400152\n",
      "0.000959272\n",
      "0.0\n",
      "0.010168946\n",
      "0.0\n",
      "0.026656348\n",
      "0.0014218271\n",
      "0.0\n",
      "0.0007600006\n",
      "0.0\n",
      "0.01607628\n",
      "0.010574974\n",
      "0.020040868\n",
      "0.002651426\n",
      "0.0006135309\n",
      "0.024603978\n",
      "0.027537514\n",
      "0.0074701346\n",
      "0.0044549084\n",
      "0.0036926402\n",
      "0.009437351\n",
      "0.013405123\n",
      "0.0047180406\n",
      "0.0041139834\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.016706575\n",
      "0.028168479\n",
      "0.0004937653\n",
      "0.011150004\n",
      "0.0017511366\n",
      "0.005360199\n",
      "0.021382648\n",
      "0.0022690028\n",
      "0.0031399867\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.006242591\n",
      "0.017083304\n",
      "0.0036201486\n",
      "0.005210423\n",
      "0.0\n",
      "0.0\n",
      "0.0019953959\n",
      "0.007926776\n",
      "0.011433073\n",
      "0.031193621\n",
      "0.06587001\n",
      "0.012662407\n",
      "0.0021447262\n",
      "0.0044105817\n",
      "0.006134775\n",
      "0.018164974\n",
      "0.0020673082\n",
      "0.0\n",
      "0.0043431385\n",
      "0.0076190536\n",
      "0.00058356446\n",
      "0.00363826\n",
      "0.005863908\n",
      "0.0\n",
      "0.0016838483\n",
      "0.0\n",
      "0.023328358\n",
      "0.0157647\n",
      "0.008696952\n",
      "0.005488141\n",
      "0.014094897\n",
      "0.02184786\n",
      "0.0023431194\n",
      "0.018001253\n",
      "0.0049392073\n",
      "0.05646666\n",
      "0.008197147\n",
      "0.0\n",
      "0.03475313\n",
      "0.01384587\n",
      "0.0019396124\n",
      "0.0\n",
      "0.0035438547\n",
      "0.019824628\n",
      "0.014245828\n",
      "0.005040869\n",
      "0.0044064545\n",
      "0.0\n",
      "0.0016617855\n",
      "0.016355617\n",
      "0.0032862164\n",
      "0.0011131426\n",
      "0.011632752\n",
      "0.0\n",
      "0.0015380335\n",
      "0.002823971\n",
      "0.0\n",
      "0.0\n",
      "0.01156288\n",
      "0.0\n",
      "0.004766051\n",
      "0.005818743\n",
      "0.0\n",
      "0.011220073\n",
      "0.013463497\n",
      "0.0\n",
      "0.0\n",
      "0.0016927774\n",
      "0.0\n",
      "0.006251741\n",
      "0.0\n",
      "0.018487172\n",
      "0.003730316\n",
      "   Accuracy  Precision    Recall        F1       F2      F0.5  \\\n",
      "0  0.998513   0.818182  0.529412  0.642857  0.56962  0.737705   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.434344  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:35:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 43.553 seconds\n",
      "Cross-validation score: 0.7640104666194713\n",
      "Test score: 0.6122448979591837\n",
      "Best Hyperparameters: {}\n",
      "0.00855232\n",
      "0.014194466\n",
      "0.028739242\n",
      "0.0005345571\n",
      "0.01894187\n",
      "0.0053196587\n",
      "0.0\n",
      "0.0\n",
      "0.0066252793\n",
      "0.020435456\n",
      "0.0065246415\n",
      "0.0039344644\n",
      "0.0\n",
      "0.0\n",
      "0.030813836\n",
      "0.0\n",
      "0.013339701\n",
      "0.0032883259\n",
      "0.0038670774\n",
      "0.0036989988\n",
      "0.0\n",
      "0.017667074\n",
      "0.0037226274\n",
      "0.009275878\n",
      "0.016409703\n",
      "0.0\n",
      "0.007282186\n",
      "0.0\n",
      "0.009808915\n",
      "0.008447783\n",
      "0.017050179\n",
      "0.0095872795\n",
      "0.0084166555\n",
      "0.0062340703\n",
      "0.0026377325\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0115352\n",
      "0.02196796\n",
      "0.0011125724\n",
      "0.018623572\n",
      "0.003935426\n",
      "0.014860428\n",
      "0.0012278163\n",
      "0.014191483\n",
      "0.0025873224\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.006453018\n",
      "0.0\n",
      "0.003685999\n",
      "0.0\n",
      "0.0\n",
      "0.0059073945\n",
      "0.01707485\n",
      "0.004220167\n",
      "0.00966819\n",
      "0.03623565\n",
      "0.11946038\n",
      "0.005138703\n",
      "0.006607486\n",
      "0.038580004\n",
      "0.0044893166\n",
      "0.001869883\n",
      "0.0\n",
      "0.0021535573\n",
      "0.004278402\n",
      "0.011369959\n",
      "0.0053940546\n",
      "0.014451214\n",
      "0.0074725836\n",
      "0.00021274373\n",
      "0.0047148885\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0123447385\n",
      "0.0\n",
      "0.0\n",
      "0.016212828\n",
      "0.0037283266\n",
      "0.0023965607\n",
      "0.011026313\n",
      "0.008360971\n",
      "0.012454933\n",
      "0.07159127\n",
      "0.0\n",
      "0.0\n",
      "0.0020179783\n",
      "0.0\n",
      "0.0009817387\n",
      "0.005908157\n",
      "0.0016288788\n",
      "0.0012568377\n",
      "0.008008563\n",
      "0.0\n",
      "0.007902439\n",
      "0.0057706484\n",
      "0.0053894855\n",
      "0.0\n",
      "0.0053391517\n",
      "0.0\n",
      "0.005014499\n",
      "0.009403201\n",
      "0.0\n",
      "0.0\n",
      "0.0011174959\n",
      "0.0\n",
      "0.0060025537\n",
      "0.0480667\n",
      "0.0\n",
      "0.0031878408\n",
      "0.014867035\n",
      "0.0\n",
      "0.0\n",
      "0.022975404\n",
      "0.0\n",
      "0.0037118024\n",
      "0.0\n",
      "0.01746459\n",
      "0.0010388497\n",
      "   Accuracy  Precision    Recall    F1        F2      F0.5  Average Precision\n",
      "0  0.998067       0.75  0.352941  0.48  0.394737  0.612245           0.266341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:36:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 40.626 seconds\n",
      "Cross-validation score: 0.7950156700359696\n",
      "Test score: 0.5660377358490566\n",
      "Best Hyperparameters: {}\n",
      "0.011405657\n",
      "0.014063366\n",
      "0.023746984\n",
      "0.0\n",
      "0.011542176\n",
      "0.004026883\n",
      "0.015857972\n",
      "0.0037674122\n",
      "0.0\n",
      "0.0\n",
      "0.0071047544\n",
      "0.008557441\n",
      "0.0\n",
      "0.0\n",
      "0.016151013\n",
      "0.0\n",
      "0.08232335\n",
      "0.0033881913\n",
      "0.011295832\n",
      "0.0\n",
      "0.0012937438\n",
      "0.019820748\n",
      "0.008741267\n",
      "0.0059407502\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0027784428\n",
      "0.027814608\n",
      "0.0052388036\n",
      "0.0\n",
      "0.014714971\n",
      "0.011037122\n",
      "0.0027589067\n",
      "0.0035327876\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.016305713\n",
      "0.0031015016\n",
      "0.0065376125\n",
      "0.041012913\n",
      "0.0069761416\n",
      "0.021838494\n",
      "0.015289097\n",
      "0.003166955\n",
      "0.0064001945\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00444138\n",
      "0.005200808\n",
      "0.005712921\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0017344016\n",
      "0.0\n",
      "0.010245814\n",
      "0.020946356\n",
      "0.0824195\n",
      "0.008062438\n",
      "0.0\n",
      "0.0\n",
      "0.0030269164\n",
      "0.012837352\n",
      "0.0010044551\n",
      "0.0\n",
      "0.0\n",
      "0.0082576135\n",
      "0.0\n",
      "0.0\n",
      "0.018266438\n",
      "0.0019030939\n",
      "0.010058427\n",
      "0.0\n",
      "0.018649422\n",
      "0.009122668\n",
      "0.010501803\n",
      "0.0038198712\n",
      "0.016943239\n",
      "0.019951764\n",
      "0.00782381\n",
      "0.019931871\n",
      "0.0023706052\n",
      "0.11169518\n",
      "0.0023608562\n",
      "0.0\n",
      "0.011040601\n",
      "0.0\n",
      "0.0038520084\n",
      "0.0\n",
      "0.0058091604\n",
      "0.010818452\n",
      "0.0028037052\n",
      "0.005785371\n",
      "0.0019659568\n",
      "0.0\n",
      "0.005539184\n",
      "0.009804415\n",
      "0.0035827467\n",
      "0.0021469714\n",
      "0.001769771\n",
      "0.0\n",
      "0.0010372595\n",
      "0.0017346662\n",
      "0.0\n",
      "0.012614069\n",
      "0.00048023724\n",
      "0.0\n",
      "0.005660731\n",
      "0.0049518957\n",
      "0.0\n",
      "0.008098874\n",
      "0.015471693\n",
      "0.0\n",
      "0.0019645537\n",
      "0.0031180093\n",
      "0.0\n",
      "0.003248793\n",
      "0.0\n",
      "0.021880107\n",
      "0.0\n",
      "   Accuracy  Precision    Recall        F1       F2      F0.5  \\\n",
      "0  0.997919   0.666667  0.352941  0.461538  0.38961  0.566038   \n",
      "\n",
      "   Average Precision  \n",
      "0            0.23693  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:37:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 41.105 seconds\n",
      "Cross-validation score: 0.8116773030370137\n",
      "Test score: 0.7971014492753623\n",
      "Best Hyperparameters: {}\n",
      "0.011667388\n",
      "0.01535947\n",
      "0.028241863\n",
      "0.0074495305\n",
      "0.013140726\n",
      "0.006434247\n",
      "0.008713411\n",
      "0.0017307419\n",
      "0.0027609048\n",
      "0.0\n",
      "0.01922621\n",
      "0.007531581\n",
      "0.0\n",
      "0.0\n",
      "0.010493385\n",
      "0.0\n",
      "0.017268334\n",
      "0.0022023094\n",
      "0.007157785\n",
      "0.0\n",
      "0.0\n",
      "0.023218049\n",
      "0.0022134269\n",
      "0.014118781\n",
      "0.010435532\n",
      "0.0\n",
      "0.0\n",
      "0.0055991076\n",
      "0.0077226893\n",
      "0.0045445203\n",
      "0.0033471445\n",
      "0.0\n",
      "0.0027117934\n",
      "0.0067736492\n",
      "0.0011606396\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.046729103\n",
      "0.019279847\n",
      "0.011298131\n",
      "0.020757223\n",
      "0.00011655003\n",
      "0.006585732\n",
      "0.013585857\n",
      "0.022687446\n",
      "0.005329133\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0033527517\n",
      "0.0006277848\n",
      "0.005024328\n",
      "0.0056089764\n",
      "0.0\n",
      "0.0\n",
      "0.011726756\n",
      "0.0012067604\n",
      "0.0022250107\n",
      "0.0189547\n",
      "0.077033445\n",
      "0.012438064\n",
      "0.00020025049\n",
      "0.033059105\n",
      "0.0\n",
      "0.01043499\n",
      "0.0073436713\n",
      "0.0\n",
      "0.0073627234\n",
      "0.0074374154\n",
      "0.017755982\n",
      "0.010166383\n",
      "0.009087982\n",
      "0.0\n",
      "0.013194274\n",
      "0.0\n",
      "0.016086195\n",
      "0.005846717\n",
      "0.009570783\n",
      "0.0008787535\n",
      "0.0\n",
      "0.023279544\n",
      "0.016838446\n",
      "0.0012215547\n",
      "0.0029544556\n",
      "0.048374366\n",
      "0.010163101\n",
      "0.053246837\n",
      "0.021017231\n",
      "0.0009563066\n",
      "0.007647361\n",
      "0.0\n",
      "0.0067316354\n",
      "0.012926873\n",
      "0.009918843\n",
      "0.01324997\n",
      "0.0019367831\n",
      "0.0\n",
      "0.007951604\n",
      "0.007653051\n",
      "0.0009858976\n",
      "0.00052637735\n",
      "0.005390157\n",
      "0.0\n",
      "0.0021179318\n",
      "0.002557227\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.005870487\n",
      "0.015355713\n",
      "0.0\n",
      "0.0025783333\n",
      "0.016101262\n",
      "0.0\n",
      "0.0\n",
      "0.0055474737\n",
      "0.0\n",
      "0.0053457255\n",
      "0.0034915672\n",
      "0.008020447\n",
      "0.0058273133\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998811   0.846154  0.647059  0.733333  0.679012  0.797101   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.548403  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:37:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 43.404 seconds\n",
      "Cross-validation score: 0.7200654911033592\n",
      "Test score: 0.7142857142857142\n",
      "Best Hyperparameters: {}\n",
      "0.008231029\n",
      "0.013994952\n",
      "0.029149478\n",
      "0.017309818\n",
      "0.022205494\n",
      "0.0041412283\n",
      "0.0\n",
      "0.0\n",
      "0.010747785\n",
      "0.0\n",
      "0.015371211\n",
      "0.007902787\n",
      "0.0\n",
      "0.0\n",
      "0.0059217177\n",
      "0.0\n",
      "0.027227473\n",
      "0.0\n",
      "0.003046976\n",
      "0.0\n",
      "0.0053060423\n",
      "0.0272896\n",
      "0.0009879341\n",
      "0.0005932183\n",
      "0.017575417\n",
      "0.0\n",
      "0.0\n",
      "0.0036145365\n",
      "0.0046985694\n",
      "0.00058735395\n",
      "0.0\n",
      "0.011725652\n",
      "0.011021469\n",
      "0.0068467516\n",
      "0.0019229448\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.015512116\n",
      "0.013309163\n",
      "0.0006990512\n",
      "0.008216397\n",
      "0.013545046\n",
      "0.00965277\n",
      "0.011136163\n",
      "0.02894397\n",
      "0.0069016237\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.005358437\n",
      "0.003469083\n",
      "0.0057936534\n",
      "0.0\n",
      "0.0\n",
      "0.007495089\n",
      "0.008540378\n",
      "0.0021918488\n",
      "0.0060166074\n",
      "0.057656407\n",
      "0.08020988\n",
      "0.009428467\n",
      "0.018320223\n",
      "0.0012032302\n",
      "0.0018410595\n",
      "0.014878135\n",
      "0.0038609093\n",
      "0.0\n",
      "0.013432366\n",
      "0.010658835\n",
      "0.0073628644\n",
      "0.0009701897\n",
      "0.013407317\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.017112788\n",
      "0.004753174\n",
      "0.0\n",
      "0.018950528\n",
      "0.028457442\n",
      "0.009192324\n",
      "0.0030791902\n",
      "0.0117311105\n",
      "0.031043021\n",
      "0.011083512\n",
      "0.0\n",
      "0.016908312\n",
      "0.0\n",
      "0.00090834143\n",
      "0.0059355013\n",
      "0.01644361\n",
      "0.022252725\n",
      "0.008120137\n",
      "0.0041073565\n",
      "0.0041727377\n",
      "0.0\n",
      "0.0032726587\n",
      "0.014217117\n",
      "0.008101884\n",
      "0.0013488897\n",
      "0.007518524\n",
      "0.0\n",
      "0.002095769\n",
      "0.0030750253\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.021115145\n",
      "0.01255292\n",
      "0.0\n",
      "0.012270436\n",
      "0.016476862\n",
      "0.0\n",
      "0.0\n",
      "0.026720997\n",
      "0.0\n",
      "0.0018884178\n",
      "0.007816736\n",
      "0.0036030763\n",
      "0.006243002\n",
      "   Accuracy  Precision    Recall    F1        F2      F0.5  Average Precision\n",
      "0  0.998365      0.875  0.411765  0.56  0.460526  0.714286           0.361781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:38:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 40.369 seconds\n",
      "Cross-validation score: 0.7616028148913658\n",
      "Test score: 0.7246376811594203\n",
      "Best Hyperparameters: {}\n",
      "0.010188787\n",
      "0.019308975\n",
      "0.02074275\n",
      "0.005383826\n",
      "0.011049906\n",
      "0.0079421075\n",
      "0.0057716104\n",
      "0.009187258\n",
      "0.0\n",
      "0.0036538003\n",
      "0.0052281874\n",
      "0.008378265\n",
      "0.0\n",
      "0.0\n",
      "0.022128511\n",
      "0.0\n",
      "0.023944039\n",
      "0.0056043887\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.017789308\n",
      "0.003316974\n",
      "0.0\n",
      "0.07260446\n",
      "0.0\n",
      "0.023351131\n",
      "0.017844325\n",
      "0.01077062\n",
      "0.0043616076\n",
      "0.0\n",
      "0.013945079\n",
      "0.010766294\n",
      "0.0027819357\n",
      "0.009047371\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0020742915\n",
      "0.010887655\n",
      "0.0009944862\n",
      "0.0078032715\n",
      "0.008506378\n",
      "0.0042598397\n",
      "0.021147653\n",
      "0.01886369\n",
      "0.012081091\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0037900785\n",
      "0.0022078012\n",
      "0.0038973298\n",
      "0.008132299\n",
      "0.0\n",
      "0.0026004245\n",
      "0.009197089\n",
      "0.0028900139\n",
      "0.007845872\n",
      "0.032997426\n",
      "0.07588517\n",
      "0.0095575405\n",
      "0.011085402\n",
      "0.0\n",
      "0.0027714288\n",
      "0.015111132\n",
      "0.019808384\n",
      "0.0\n",
      "0.009452142\n",
      "0.008010106\n",
      "0.010266198\n",
      "0.0\n",
      "0.008493598\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.008860958\n",
      "0.0005953388\n",
      "0.007346977\n",
      "0.0012461462\n",
      "0.0005424795\n",
      "0.021263056\n",
      "0.013909333\n",
      "0.0\n",
      "0.0057444973\n",
      "0.059981626\n",
      "0.008357913\n",
      "0.0\n",
      "0.0143084405\n",
      "0.0\n",
      "0.006762747\n",
      "0.0\n",
      "0.006055113\n",
      "0.009726977\n",
      "0.01312684\n",
      "0.0052887406\n",
      "0.0041318266\n",
      "0.0\n",
      "0.0049877926\n",
      "0.015338109\n",
      "0.0065835826\n",
      "0.0\n",
      "0.0045893146\n",
      "0.0\n",
      "0.0034820533\n",
      "0.003219175\n",
      "0.0\n",
      "0.0\n",
      "0.007179835\n",
      "0.0\n",
      "0.008463076\n",
      "0.010707924\n",
      "0.0\n",
      "0.008388445\n",
      "0.011163732\n",
      "0.0\n",
      "0.0\n",
      "0.0013043516\n",
      "0.0\n",
      "0.007816936\n",
      "0.00035759312\n",
      "0.034579378\n",
      "0.008880443\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998513   0.769231  0.588235  0.666667  0.617284  0.724638   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.453529  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:39:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 46.254 seconds\n",
      "Cross-validation score: 0.7178396747674078\n",
      "Test score: 0.8163265306122449\n",
      "Best Hyperparameters: {}\n",
      "0.010282041\n",
      "0.013645323\n",
      "0.027785389\n",
      "0.006916955\n",
      "0.008852898\n",
      "0.0050829337\n",
      "0.009790757\n",
      "0.002360281\n",
      "0.0022646494\n",
      "0.0\n",
      "0.018598381\n",
      "0.004617891\n",
      "0.004496858\n",
      "0.0\n",
      "0.0062821405\n",
      "0.0\n",
      "0.03611595\n",
      "0.0032953315\n",
      "0.0006661577\n",
      "0.0004598297\n",
      "0.0076642367\n",
      "0.022575857\n",
      "0.0041774414\n",
      "0.0\n",
      "0.05945244\n",
      "0.0\n",
      "0.050213728\n",
      "0.006631964\n",
      "0.0077623324\n",
      "0.005690782\n",
      "0.0\n",
      "0.0076585542\n",
      "0.013495715\n",
      "0.0034554417\n",
      "0.0039604073\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00575048\n",
      "0.013835553\n",
      "0.009999033\n",
      "0.0035445346\n",
      "0.018413614\n",
      "0.003997594\n",
      "0.010107297\n",
      "0.008003791\n",
      "0.0033293029\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.004108774\n",
      "0.0061571645\n",
      "0.0032646712\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0016205937\n",
      "0.005701529\n",
      "0.008235395\n",
      "0.032655925\n",
      "0.060001265\n",
      "0.0056816097\n",
      "0.0029990776\n",
      "0.0\n",
      "0.0010977583\n",
      "0.00951222\n",
      "0.0050010583\n",
      "0.0\n",
      "0.002872228\n",
      "0.008024441\n",
      "0.024437921\n",
      "0.0\n",
      "0.008604139\n",
      "0.03398419\n",
      "0.0074760253\n",
      "0.0\n",
      "0.01832272\n",
      "0.017403154\n",
      "0.01050955\n",
      "0.0\n",
      "0.0070215985\n",
      "0.013643368\n",
      "0.010033792\n",
      "0.0\n",
      "0.0040025897\n",
      "0.0059718946\n",
      "0.007983424\n",
      "0.049816523\n",
      "0.018134365\n",
      "0.018747017\n",
      "0.0013849761\n",
      "0.0\n",
      "0.0025807992\n",
      "0.005726449\n",
      "0.008666084\n",
      "0.0028344484\n",
      "0.0038265125\n",
      "0.0\n",
      "0.0034305162\n",
      "0.01673268\n",
      "0.014828654\n",
      "0.0006431484\n",
      "0.0050656395\n",
      "0.0\n",
      "0.0026486474\n",
      "0.0027897712\n",
      "0.0\n",
      "0.0\n",
      "0.004798898\n",
      "0.0\n",
      "0.005056821\n",
      "0.0077479803\n",
      "0.0\n",
      "0.001388555\n",
      "0.016101677\n",
      "0.0\n",
      "0.004582952\n",
      "0.0019236224\n",
      "0.0\n",
      "0.0034178307\n",
      "0.0056425985\n",
      "0.01889363\n",
      "0.015027226\n",
      "   Accuracy  Precision    Recall    F1        F2      F0.5  Average Precision\n",
      "0  0.998662        1.0  0.470588  0.64  0.526316  0.816327           0.471926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:39:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 40.043 seconds\n",
      "Cross-validation score: 0.7394045129595435\n",
      "Test score: 0.9016393442622951\n",
      "Best Hyperparameters: {}\n",
      "0.010890281\n",
      "0.0138263805\n",
      "0.031682342\n",
      "0.009159568\n",
      "0.0099332975\n",
      "0.0055988086\n",
      "0.009017366\n",
      "0.0011845347\n",
      "0.002800417\n",
      "0.0\n",
      "0.0067572426\n",
      "0.008843881\n",
      "0.0014116523\n",
      "0.0\n",
      "0.026725277\n",
      "0.0\n",
      "0.0020092372\n",
      "0.009481329\n",
      "0.0\n",
      "0.0037850807\n",
      "0.009589272\n",
      "0.021432482\n",
      "0.005970914\n",
      "0.00092937605\n",
      "0.0\n",
      "0.0\n",
      "0.015763048\n",
      "0.0039000139\n",
      "0.004323757\n",
      "0.0068079513\n",
      "0.0\n",
      "0.0007856752\n",
      "0.0036746222\n",
      "0.00057676533\n",
      "0.0024227998\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0021403704\n",
      "0.03813694\n",
      "0.0032245528\n",
      "0.0143087795\n",
      "0.02088472\n",
      "0.011132885\n",
      "0.033647723\n",
      "0.010548675\n",
      "0.017486159\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0043266\n",
      "0.0012406628\n",
      "0.005349192\n",
      "0.007385051\n",
      "0.0\n",
      "0.0\n",
      "0.00017548437\n",
      "0.0\n",
      "0.012450811\n",
      "0.03260148\n",
      "0.07265551\n",
      "0.009409074\n",
      "0.0017043807\n",
      "0.04140486\n",
      "0.005047284\n",
      "0.0101485485\n",
      "0.0024529092\n",
      "0.0\n",
      "0.00806446\n",
      "0.010754073\n",
      "0.0034052934\n",
      "0.034860216\n",
      "0.02008487\n",
      "0.0\n",
      "0.0014433543\n",
      "0.0\n",
      "0.010543939\n",
      "0.006894876\n",
      "0.0052808137\n",
      "0.0\n",
      "0.0027130407\n",
      "0.014507931\n",
      "0.013758212\n",
      "0.0\n",
      "0.0083932895\n",
      "0.053641133\n",
      "0.012573306\n",
      "0.0\n",
      "0.026525415\n",
      "0.0091745\n",
      "0.0030005467\n",
      "0.0\n",
      "0.024141748\n",
      "0.010033176\n",
      "0.0041237236\n",
      "0.0007536275\n",
      "0.003571075\n",
      "0.0\n",
      "0.00876136\n",
      "0.012374524\n",
      "0.013656766\n",
      "0.0\n",
      "0.004732448\n",
      "0.0\n",
      "0.0032788909\n",
      "0.0026844211\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0033508642\n",
      "0.012378426\n",
      "0.0\n",
      "0.0011870402\n",
      "0.017203731\n",
      "0.0\n",
      "0.0035867416\n",
      "0.007517876\n",
      "0.0\n",
      "0.0032810753\n",
      "0.0017600472\n",
      "0.023141589\n",
      "0.0057155695\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.999108        1.0  0.647059  0.785714  0.696203  0.901639   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.647951  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:40:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 41.814 seconds\n",
      "Cross-validation score: 0.7165735165402989\n",
      "Test score: 0.821917808219178\n",
      "Best Hyperparameters: {}\n",
      "0.011525464\n",
      "0.016505359\n",
      "0.029539801\n",
      "0.010914857\n",
      "0.0134520605\n",
      "0.006581482\n",
      "0.0\n",
      "0.0\n",
      "0.0022368724\n",
      "0.0\n",
      "0.04736298\n",
      "0.010250757\n",
      "0.0\n",
      "0.0\n",
      "0.0046098433\n",
      "0.0\n",
      "0.019234274\n",
      "0.0031700002\n",
      "0.0\n",
      "0.0\n",
      "0.0053899963\n",
      "0.024412228\n",
      "0.0381236\n",
      "0.0073613115\n",
      "0.0\n",
      "0.0016665083\n",
      "0.042787585\n",
      "0.0\n",
      "0.0034283076\n",
      "0.0047733583\n",
      "0.004365758\n",
      "0.0042943745\n",
      "0.006360003\n",
      "0.007301825\n",
      "0.009581855\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0044936663\n",
      "0.022038335\n",
      "0.011778563\n",
      "0.0055341497\n",
      "0.002108967\n",
      "0.006995315\n",
      "0.014851738\n",
      "0.014363623\n",
      "0.002080394\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0042799977\n",
      "0.007486862\n",
      "0.004876633\n",
      "0.009831582\n",
      "0.00440937\n",
      "0.011147792\n",
      "0.006753389\n",
      "0.0\n",
      "0.0095828585\n",
      "0.024382014\n",
      "0.08242265\n",
      "0.013860434\n",
      "0.010314092\n",
      "0.0\n",
      "0.012873463\n",
      "0.0047459407\n",
      "0.006250647\n",
      "0.0\n",
      "0.008079801\n",
      "0.011396819\n",
      "0.0024373573\n",
      "0.0\n",
      "0.0073082508\n",
      "0.0\n",
      "0.011710518\n",
      "0.0\n",
      "0.023879664\n",
      "0.007888774\n",
      "0.0101528\n",
      "0.0\n",
      "0.0006827653\n",
      "0.019252058\n",
      "0.00930165\n",
      "0.028805338\n",
      "0.010233661\n",
      "0.025899662\n",
      "0.009643638\n",
      "0.0\n",
      "0.010771959\n",
      "0.0\n",
      "0.00401448\n",
      "0.0\n",
      "0.010324884\n",
      "0.0076226364\n",
      "0.0\n",
      "0.003756029\n",
      "0.004243914\n",
      "0.0\n",
      "0.0067311977\n",
      "0.008610726\n",
      "0.0062962496\n",
      "0.0007026282\n",
      "0.0029721218\n",
      "0.0\n",
      "0.0037043302\n",
      "0.014209689\n",
      "0.0\n",
      "0.0\n",
      "0.008449137\n",
      "0.0\n",
      "0.0058248\n",
      "0.005640692\n",
      "0.0\n",
      "0.0024141406\n",
      "0.015854992\n",
      "0.0\n",
      "0.0\n",
      "0.008539229\n",
      "0.0\n",
      "0.0035058332\n",
      "0.0018458066\n",
      "0.039434653\n",
      "0.0051640538\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998959   0.857143  0.705882  0.774194  0.731707  0.821918   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.605785  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:41:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 45.676 seconds\n",
      "Cross-validation score: 0.7174612352917513\n",
      "Test score: 0.684931506849315\n",
      "Best Hyperparameters: {}\n",
      "0.00972527\n",
      "0.01724705\n",
      "0.027116364\n",
      "0.009509548\n",
      "0.033597402\n",
      "0.010903743\n",
      "0.0\n",
      "0.0\n",
      "0.004181042\n",
      "0.0018914804\n",
      "0.01768783\n",
      "0.0057351333\n",
      "0.0\n",
      "0.0\n",
      "0.024921842\n",
      "0.0\n",
      "0.02573236\n",
      "0.0\n",
      "0.0\n",
      "0.010206796\n",
      "0.0048376173\n",
      "0.01634466\n",
      "0.0021912686\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.013152027\n",
      "0.0132146645\n",
      "0.00744459\n",
      "0.005851276\n",
      "0.007977873\n",
      "0.00753957\n",
      "0.012271887\n",
      "0.018810103\n",
      "0.014320602\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007372533\n",
      "0.03927541\n",
      "0.020012662\n",
      "0.00429841\n",
      "0.0005411241\n",
      "0.008201815\n",
      "0.00287985\n",
      "0.028287102\n",
      "0.0047161104\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0060057966\n",
      "0.0\n",
      "0.005330769\n",
      "0.005426533\n",
      "0.0\n",
      "0.0\n",
      "0.0010623919\n",
      "0.0052896743\n",
      "0.0046653845\n",
      "0.025985846\n",
      "0.06278131\n",
      "0.010224945\n",
      "0.0021654156\n",
      "0.0\n",
      "0.0006749647\n",
      "0.009852226\n",
      "0.008944731\n",
      "0.0\n",
      "0.014058684\n",
      "0.0079189055\n",
      "0.0125801135\n",
      "0.0\n",
      "0.0062389914\n",
      "0.014838468\n",
      "0.0064568045\n",
      "0.0\n",
      "0.019596634\n",
      "0.010632863\n",
      "0.011317075\n",
      "0.0\n",
      "0.008113672\n",
      "0.018980077\n",
      "0.011792161\n",
      "0.005696738\n",
      "0.0068129343\n",
      "0.058704592\n",
      "0.012546373\n",
      "0.0\n",
      "0.033066977\n",
      "0.0\n",
      "0.0081277685\n",
      "0.0\n",
      "0.0025398084\n",
      "0.007779721\n",
      "0.005602137\n",
      "0.0031691429\n",
      "0.0016849901\n",
      "0.0\n",
      "0.007560701\n",
      "0.0087091485\n",
      "0.00059896754\n",
      "0.0005352603\n",
      "0.0\n",
      "0.0\n",
      "0.001875232\n",
      "0.0018623663\n",
      "0.0\n",
      "0.0\n",
      "0.005730081\n",
      "0.0\n",
      "0.004715492\n",
      "0.031238029\n",
      "0.0\n",
      "0.0\n",
      "0.014395661\n",
      "0.0\n",
      "0.0\n",
      "0.0057251863\n",
      "0.0\n",
      "0.0019879069\n",
      "0.0009559067\n",
      "0.031099217\n",
      "0.008348196\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998365   0.714286  0.588235  0.645161  0.609756  0.684932   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.421209  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:42:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 42.155 seconds\n",
      "Cross-validation score: 0.737544088308095\n",
      "Test score: 0.8490566037735848\n",
      "Best Hyperparameters: {}\n",
      "0.008668821\n",
      "0.02087013\n",
      "0.021564208\n",
      "0.002922771\n",
      "0.017330607\n",
      "0.007243484\n",
      "0.0073613278\n",
      "0.012245089\n",
      "0.0\n",
      "0.0\n",
      "0.008730785\n",
      "0.009682357\n",
      "0.0\n",
      "0.0\n",
      "0.01640282\n",
      "0.0\n",
      "0.015248054\n",
      "0.0065579466\n",
      "0.001102582\n",
      "0.0023403405\n",
      "0.0049631973\n",
      "0.02442596\n",
      "0.0\n",
      "0.0\n",
      "0.011087919\n",
      "0.0\n",
      "0.074304655\n",
      "0.0003718432\n",
      "0.0029323308\n",
      "0.006771672\n",
      "0.0\n",
      "0.005610142\n",
      "0.006313995\n",
      "0.024847407\n",
      "0.005344283\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.006429371\n",
      "0.011163792\n",
      "0.0055301846\n",
      "0.04334684\n",
      "0.002408832\n",
      "0.008933199\n",
      "0.00466743\n",
      "0.014683328\n",
      "0.007961077\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.004950038\n",
      "0.006018103\n",
      "0.0041947584\n",
      "0.005391531\n",
      "0.0\n",
      "0.0\n",
      "0.0026926622\n",
      "0.0\n",
      "0.008112574\n",
      "0.032254834\n",
      "0.08518776\n",
      "0.0075004073\n",
      "0.006649779\n",
      "0.0\n",
      "0.0006661088\n",
      "0.003928166\n",
      "0.005018614\n",
      "0.008196445\n",
      "0.011959688\n",
      "0.008471976\n",
      "0.0\n",
      "0.0019911053\n",
      "0.0067380182\n",
      "0.0\n",
      "0.011728461\n",
      "0.0\n",
      "0.017837254\n",
      "0.013263703\n",
      "0.00822121\n",
      "0.0\n",
      "0.006210012\n",
      "0.02525795\n",
      "0.015503418\n",
      "0.004996366\n",
      "0.010354973\n",
      "0.0011019232\n",
      "0.011860889\n",
      "0.035563376\n",
      "0.016632188\n",
      "0.0\n",
      "0.016845236\n",
      "0.0030287614\n",
      "0.0103755975\n",
      "0.0095786005\n",
      "0.00832599\n",
      "0.0024764233\n",
      "0.008905106\n",
      "0.0\n",
      "0.009424207\n",
      "0.009009669\n",
      "0.003689718\n",
      "0.0016991727\n",
      "0.0\n",
      "0.0\n",
      "0.0024279845\n",
      "0.0030804079\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007958981\n",
      "0.015690101\n",
      "0.0\n",
      "0.008637987\n",
      "0.014725317\n",
      "0.0\n",
      "0.0\n",
      "0.022309158\n",
      "0.0\n",
      "0.004776976\n",
      "0.0011708286\n",
      "0.015511954\n",
      "0.0015287037\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998811        1.0  0.529412  0.692308  0.584416  0.849057   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.530601  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:42:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 39.466 seconds\n",
      "Cross-validation score: 0.7498156721084307\n",
      "Test score: 0.7377049180327868\n",
      "Best Hyperparameters: {}\n",
      "0.013716867\n",
      "0.01914639\n",
      "0.027174376\n",
      "0.008160815\n",
      "0.012768126\n",
      "0.0066038463\n",
      "0.0\n",
      "0.0\n",
      "0.006556865\n",
      "0.004347281\n",
      "0.010355622\n",
      "0.0065778936\n",
      "0.0\n",
      "0.0\n",
      "0.018911198\n",
      "0.0\n",
      "0.016598703\n",
      "0.0\n",
      "0.0\n",
      "0.0008844395\n",
      "0.0\n",
      "0.014184306\n",
      "0.023855614\n",
      "0.006979996\n",
      "0.007452211\n",
      "0.0\n",
      "0.025010863\n",
      "0.00031416919\n",
      "0.0\n",
      "0.00595235\n",
      "0.005957407\n",
      "0.0079528745\n",
      "0.006942796\n",
      "0.003939406\n",
      "0.006044642\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.014346926\n",
      "0.016806303\n",
      "0.0\n",
      "0.0072915633\n",
      "0.0011234729\n",
      "0.0067787506\n",
      "0.01857387\n",
      "0.026448108\n",
      "0.0023631863\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0047268597\n",
      "0.0013322727\n",
      "0.005210915\n",
      "0.0\n",
      "0.011157118\n",
      "0.010072606\n",
      "0.013528702\n",
      "0.0026677737\n",
      "0.00819518\n",
      "0.036933906\n",
      "0.094382554\n",
      "0.012723631\n",
      "0.0034547448\n",
      "0.035992358\n",
      "0.00078773894\n",
      "0.0069957734\n",
      "0.0\n",
      "0.0\n",
      "0.0042353934\n",
      "0.011185387\n",
      "0.016928213\n",
      "0.0\n",
      "0.009624821\n",
      "0.0\n",
      "0.013181687\n",
      "0.0\n",
      "0.0\n",
      "0.009081892\n",
      "0.014366397\n",
      "0.0069106864\n",
      "0.011940045\n",
      "0.017562967\n",
      "0.017798511\n",
      "0.0\n",
      "0.011762829\n",
      "0.035203923\n",
      "0.00084655447\n",
      "0.0\n",
      "0.022614416\n",
      "0.00089543615\n",
      "0.013098055\n",
      "0.0\n",
      "0.002721071\n",
      "0.012063797\n",
      "0.0019633092\n",
      "0.008927867\n",
      "0.008064294\n",
      "0.0\n",
      "0.0031344474\n",
      "0.0038865807\n",
      "0.002078968\n",
      "0.0031002378\n",
      "0.0020345335\n",
      "0.0\n",
      "0.014949202\n",
      "0.0063819517\n",
      "0.0\n",
      "0.012446082\n",
      "0.0\n",
      "0.0\n",
      "0.021479798\n",
      "0.0050620986\n",
      "0.0\n",
      "0.0047960086\n",
      "0.013169135\n",
      "0.0\n",
      "0.007104139\n",
      "0.0058776923\n",
      "0.0\n",
      "0.008723705\n",
      "2.5385654e-05\n",
      "0.01706393\n",
      "0.009425237\n",
      "   Accuracy  Precision    Recall        F1       F2      F0.5  \\\n",
      "0  0.998513   0.818182  0.529412  0.642857  0.56962  0.737705   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.434344  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:43:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 44.444 seconds\n",
      "Cross-validation score: 0.7397484939486858\n",
      "Test score: 0.8461538461538461\n",
      "Best Hyperparameters: {}\n",
      "0.0138464775\n",
      "0.01735678\n",
      "0.019312726\n",
      "0.0054448796\n",
      "0.010738143\n",
      "0.0058412473\n",
      "0.013762767\n",
      "0.0012855078\n",
      "0.0052357665\n",
      "0.012158364\n",
      "0.016381828\n",
      "0.010768266\n",
      "0.002221802\n",
      "0.0\n",
      "0.014022471\n",
      "0.0\n",
      "0.042927664\n",
      "0.002434122\n",
      "0.005746772\n",
      "0.0\n",
      "0.0064102598\n",
      "0.014766381\n",
      "0.005430142\n",
      "0.0\n",
      "0.011425574\n",
      "0.0\n",
      "0.024125231\n",
      "0.0070492113\n",
      "0.015672324\n",
      "0.006370467\n",
      "0.012429546\n",
      "0.0075981864\n",
      "0.010471273\n",
      "0.0013563212\n",
      "0.0043546706\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0017645111\n",
      "0.009742621\n",
      "0.0002720808\n",
      "0.0030648536\n",
      "0.0010968706\n",
      "0.0037804395\n",
      "0.008604673\n",
      "0.008005961\n",
      "0.0048286\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.006586982\n",
      "0.0040650633\n",
      "0.0057196505\n",
      "0.0067463582\n",
      "0.0\n",
      "0.002098144\n",
      "0.004119302\n",
      "0.0017176128\n",
      "0.007921887\n",
      "0.036170978\n",
      "0.07122196\n",
      "0.017298853\n",
      "0.0016356213\n",
      "0.0\n",
      "0.0023491639\n",
      "0.008978797\n",
      "0.014306854\n",
      "0.0\n",
      "0.0\n",
      "0.008739441\n",
      "0.0061311265\n",
      "0.0\n",
      "0.0030379149\n",
      "0.01026303\n",
      "0.0057383534\n",
      "0.0\n",
      "0.0\n",
      "0.010820275\n",
      "0.007957981\n",
      "0.0\n",
      "0.012690229\n",
      "0.018969283\n",
      "0.010188897\n",
      "0.0054494264\n",
      "0.022524096\n",
      "0.10905986\n",
      "0.003455184\n",
      "0.030846965\n",
      "0.022177698\n",
      "0.00035443046\n",
      "0.0016987512\n",
      "0.0\n",
      "0.0010817726\n",
      "0.010479677\n",
      "0.0064822943\n",
      "0.0076207705\n",
      "0.0039741485\n",
      "0.0\n",
      "0.008566662\n",
      "0.015923558\n",
      "0.0062305103\n",
      "0.0002651495\n",
      "0.0059361607\n",
      "0.0\n",
      "0.002501487\n",
      "0.0036670165\n",
      "0.0\n",
      "0.0\n",
      "0.010392164\n",
      "0.0\n",
      "0.005682469\n",
      "0.009231468\n",
      "0.0\n",
      "0.0027361056\n",
      "0.012084723\n",
      "0.0\n",
      "0.0\n",
      "0.012391439\n",
      "0.0\n",
      "0.0031233514\n",
      "0.0010532162\n",
      "0.019693878\n",
      "0.0017359959\n",
      "   Accuracy  Precision    Recall        F1      F2      F0.5  \\\n",
      "0  0.998959   0.916667  0.647059  0.758621  0.6875  0.846154   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.594029  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:44:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 41.998 seconds\n",
      "Cross-validation score: 0.6873399229123744\n",
      "Test score: 0.7792207792207791\n",
      "Best Hyperparameters: {}\n",
      "0.010152374\n",
      "0.014418126\n",
      "0.022942903\n",
      "0.0024533414\n",
      "0.006077762\n",
      "0.006394593\n",
      "0.0025547545\n",
      "0.0062252153\n",
      "0.0070330394\n",
      "0.00684351\n",
      "0.033243608\n",
      "0.010376754\n",
      "0.0\n",
      "0.0\n",
      "0.013218881\n",
      "0.0\n",
      "0.04612215\n",
      "0.00036934577\n",
      "0.005017195\n",
      "0.0022651867\n",
      "0.009232837\n",
      "0.040610768\n",
      "0.0056543713\n",
      "0.0\n",
      "0.0002970271\n",
      "0.0\n",
      "0.0\n",
      "0.0038542424\n",
      "0.0073525785\n",
      "0.005699562\n",
      "0.0035736247\n",
      "0.018140193\n",
      "0.010590976\n",
      "0.00072639994\n",
      "0.007922509\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0029152452\n",
      "0.017875407\n",
      "0.014996083\n",
      "0.0042909114\n",
      "0.0046361648\n",
      "0.008217602\n",
      "0.010890139\n",
      "0.0444866\n",
      "0.0030684432\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.004408951\n",
      "0.0032539032\n",
      "0.0065076128\n",
      "0.0033940512\n",
      "0.0\n",
      "0.016991131\n",
      "0.015637938\n",
      "0.0037690087\n",
      "0.008873723\n",
      "0.02808262\n",
      "0.06866316\n",
      "0.008078716\n",
      "0.0\n",
      "0.0003664474\n",
      "0.0033660803\n",
      "0.0006017065\n",
      "0.0030469897\n",
      "0.009813603\n",
      "0.009436972\n",
      "0.007092061\n",
      "0.013996103\n",
      "0.0026529361\n",
      "0.003792302\n",
      "0.027612753\n",
      "0.009547023\n",
      "0.0\n",
      "0.022942694\n",
      "0.0073154336\n",
      "0.0082842335\n",
      "0.002838571\n",
      "0.0003682003\n",
      "0.02275021\n",
      "0.011552444\n",
      "0.0\n",
      "0.021313084\n",
      "0.036243916\n",
      "0.013677773\n",
      "0.0\n",
      "0.023272239\n",
      "0.014793275\n",
      "0.004211342\n",
      "0.0\n",
      "0.0060507273\n",
      "0.010709875\n",
      "0.0\n",
      "0.0027924161\n",
      "0.0030716741\n",
      "0.0\n",
      "0.0033935024\n",
      "0.011200236\n",
      "0.003961214\n",
      "0.0\n",
      "0.0062333043\n",
      "0.0\n",
      "0.001764761\n",
      "0.009240421\n",
      "0.0\n",
      "0.0\n",
      "0.0073318584\n",
      "0.0\n",
      "0.0040631234\n",
      "0.0068322266\n",
      "0.0\n",
      "0.003242121\n",
      "0.013291517\n",
      "0.0\n",
      "0.0\n",
      "0.011011755\n",
      "0.0\n",
      "0.0025425311\n",
      "0.012710944\n",
      "0.008935358\n",
      "0.0023309276\n",
      "   Accuracy  Precision    Recall    F1        F2      F0.5  Average Precision\n",
      "0  0.998811        0.8  0.705882  0.75  0.722892  0.779221           0.565449\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "fhalf_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "\n",
    "none_xgboost_normalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized,\n",
    "                                                    labels_normalized,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels_normalized)\n",
    "\n",
    "\n",
    "    GXBoostPipeline = Pipeline(steps = [#['smote', SMOTE()],\n",
    "                                    #['under', RandomUnderSampler()],\n",
    "                                ['classifier', xgb.XGBClassifier(n_jobs=2)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    space['classifier__learning_rate'] = [0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60]\n",
    "    space['classifier__max_depth'] = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "    space['classifier__min_child_weight'] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    space['classifier__gamma'] = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    space['classifier__colsample_bytree'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    spaceEmpty = dict()\n",
    "\n",
    "    GXBoostSearch = RandomizedSearchCV(estimator = GXBoostPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring=fhalf_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedGXBoostModel = GXBoostSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    \n",
    "    cv_score = optimizedGXBoostModel.best_score_\n",
    "    test_score = optimizedGXBoostModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedGXBoostModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedGXBoostModel.best_estimator_._final_estimator.feature_importances_\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedGXBoostModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    print(new_performance_df)\n",
    "    none_xgboost_normalized_performance_df = pd.concat([none_xgboost_normalized_performance_df, new_performance_df])\n",
    "    \n",
    "\n",
    "none_xgboost_normalized_performance_df.to_csv(\"../data/05_model_output/none_xgboost_normalized_performance_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-quebec",
   "metadata": {},
   "source": [
    "### 4.1.3 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "thick-genre",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 9.393 seconds\n",
      "Cross-validation score: 0.4274034802852089\n",
      "Test score: 0.4597701149425287\n",
      "Best Hyperparameters: {}\n",
      "19358.357289907974\n",
      "1066.2318802728212\n",
      "2184.771223795349\n",
      "40.01562132022809\n",
      "426.92896697705146\n",
      "741.0727856098783\n",
      "8.01636028289795\n",
      "3.8094589305110276\n",
      "5.099667012691498\n",
      "2.5833496497943997\n",
      "214.36890794348437\n",
      "380.84321096003987\n",
      "1.2827881556004286\n",
      "0.0\n",
      "9983.625742211472\n",
      "0.0\n",
      "164.51931641448755\n",
      "3.8278982397168875\n",
      "200.4046754837036\n",
      "552.0135145179229\n",
      "3.794600009918213\n",
      "120.66367342043668\n",
      "120.61710654280614\n",
      "1.4109914042055607\n",
      "0.0\n",
      "0.001443049986846745\n",
      "32155.086503187194\n",
      "97.46106833347585\n",
      "5619.926797780325\n",
      "0.4152690292103216\n",
      "0.6134156305342913\n",
      "15.658136096753879\n",
      "2.2163449563086033\n",
      "44.542726763058454\n",
      "13.873340241378173\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.7353170873248018\n",
      "2.930881917476654\n",
      "20.867895041243173\n",
      "12.083834967343137\n",
      "20.129794757580385\n",
      "35.60310989143909\n",
      "4.534453357919119\n",
      "6.627409934997559\n",
      "11.605404952948447\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "170.47663804411422\n",
      "3.160489805508405\n",
      "90.4862918369181\n",
      "6.870007286139298\n",
      "0.0\n",
      "0.10496920254081488\n",
      "49.49159418453928\n",
      "10.23235265002586\n",
      "10.566219056490809\n",
      "36.977245638670865\n",
      "4949.610369017231\n",
      "286.54940364835784\n",
      "494.15601670276374\n",
      "0.0\n",
      "0.01157220822587135\n",
      "0.6974424084182829\n",
      "0.03650110028684139\n",
      "0.0\n",
      "488.8329685940407\n",
      "122.66666312890094\n",
      "1.6721854003844783\n",
      "1.8998260386288166\n",
      "103.15110283088714\n",
      "0.0016256700037047267\n",
      "0.1692889928817749\n",
      "0.0\n",
      "2.5766763612627983\n",
      "1041.2594728547847\n",
      "1.7836720897175837\n",
      "2.0670508351176977\n",
      "3.606456347333733\n",
      "2237.5885398020655\n",
      "21.645811846479774\n",
      "186.5974123358028\n",
      "9.780432887142524\n",
      "18.932001820066944\n",
      "2.5966104441904463\n",
      "0.012576299719512463\n",
      "18.575424218783155\n",
      "0.12398825166746974\n",
      "751.8937311943737\n",
      "0.0\n",
      "84.274856421398\n",
      "19.27659100625897\n",
      "30.940837097950862\n",
      "0.3100291838636622\n",
      "155.4766494317447\n",
      "0.002738750074058771\n",
      "6.2936030398414005\n",
      "294.96730241540354\n",
      "20.538066767156124\n",
      "0.9435719712637365\n",
      "16.985218798508868\n",
      "0.0\n",
      "15409.034017104656\n",
      "2611.3566806509334\n",
      "0.0\n",
      "21.352893095463514\n",
      "1.8477731904713437\n",
      "0.0\n",
      "70.23446563724428\n",
      "2.48686555668246\n",
      "0.0\n",
      "190.6964893520344\n",
      "8989.778208086384\n",
      "0.0\n",
      "2352.9801428029314\n",
      "109.34551924321568\n",
      "0.0\n",
      "4.938924643793143\n",
      "4.859461458167061\n",
      "165.5625633195159\n",
      "21.876962592825294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 8.902 seconds\n",
      "Cross-validation score: 0.44168629125460235\n",
      "Test score: 0.14563106796116507\n",
      "Best Hyperparameters: {}\n",
      "1624675.333161028\n",
      "443880.22678431496\n",
      "9611090.491554156\n",
      "163.6456836797297\n",
      "15570579.767932462\n",
      "115964.31279408559\n",
      "534967.27306946\n",
      "422470.16086165607\n",
      "6071.674644794315\n",
      "1866.6841568350792\n",
      "65437.670234784484\n",
      "312.08788610994816\n",
      "140886.13452571072\n",
      "0.0\n",
      "403860.4970818646\n",
      "0.0\n",
      "104372.3896687217\n",
      "211577.38133520633\n",
      "1433196.0757862031\n",
      "72837.51339511946\n",
      "1271069.0012381747\n",
      "5151.054026000202\n",
      "13444.6218470335\n",
      "826475.7958046794\n",
      "3090.4388434253633\n",
      "0.47677698731422424\n",
      "928493.5338031594\n",
      "186137.8140154481\n",
      "44476623.451229095\n",
      "5665.598494514823\n",
      "391.90432051569223\n",
      "5301477.909718357\n",
      "77977.00731274486\n",
      "599.2633097171783\n",
      "32597.62021144852\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "388978.0307604894\n",
      "1091.657251894474\n",
      "29335702.77143255\n",
      "33189.28283891082\n",
      "339114.35349524766\n",
      "692892.8622858897\n",
      "10021406.481711693\n",
      "729124.2462360859\n",
      "4968.986891634762\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "364695.7872771807\n",
      "173614.91091805696\n",
      "744915.842208229\n",
      "981.1828908622265\n",
      "17014.419921875\n",
      "6374.859007835388\n",
      "236113.71735915542\n",
      "558.1104596853256\n",
      "136942.08387421444\n",
      "56562.63992699236\n",
      "222611.13472743332\n",
      "4833790.509686649\n",
      "5358.150572404265\n",
      "55.804100036621094\n",
      "257.0773598700762\n",
      "2307.761790227145\n",
      "198535.5595523715\n",
      "204.11317491531372\n",
      "3563.691141963005\n",
      "142139.77186802775\n",
      "6103584.158738745\n",
      "650.3193157017231\n",
      "60748.194793563336\n",
      "852035.9444420934\n",
      "124794.68540463969\n",
      "308.8479919433594\n",
      "0.0\n",
      "2540957.881144136\n",
      "3517007.525714673\n",
      "1949.8737547397614\n",
      "3592.6925354003906\n",
      "37590.835413753986\n",
      "228201.32013954967\n",
      "6898.4481164216995\n",
      "358999.05424393713\n",
      "4290.648050650954\n",
      "1986679.6469922066\n",
      "4824.237507581711\n",
      "63842.07062911801\n",
      "18847.552001953125\n",
      "3578.4107249714434\n",
      "6561.5498046875\n",
      "7327916.142582057\n",
      "252510.0794969648\n",
      "1347.4464464783669\n",
      "167923.19783765078\n",
      "193529.611863181\n",
      "266.6072000414133\n",
      "140419.40865105204\n",
      "78682.77589419857\n",
      "73688.9493944887\n",
      "541355.6924304962\n",
      "229939.79421880096\n",
      "0.0\n",
      "408953.7487575859\n",
      "6372679.267068561\n",
      "0.0\n",
      "945.2916132584214\n",
      "190300.31276893616\n",
      "0.0\n",
      "352302.0151301548\n",
      "22619.853096511215\n",
      "0.0\n",
      "1090090.2414574828\n",
      "2638691.6603465825\n",
      "0.0\n",
      "4092.9162272810936\n",
      "41929.37684611976\n",
      "0.0\n",
      "66309.20974630117\n",
      "4871.238909602165\n",
      "60234.45688196644\n",
      "11866.9180194363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 8.918 seconds\n",
      "Cross-validation score: 0.3713469332383494\n",
      "Test score: 0.6790123456790124\n",
      "Best Hyperparameters: {}\n",
      "846.1380249728536\n",
      "564.392340430175\n",
      "2256.4752879076404\n",
      "9.749629248399287\n",
      "286.9750401172787\n",
      "30.731885193730704\n",
      "178.1461882563308\n",
      "11.860803141491488\n",
      "2688.741007342702\n",
      "476.6775438282639\n",
      "156.85181436908897\n",
      "44.26317691989243\n",
      "2.245469693094492\n",
      "0.0\n",
      "21.8620600446593\n",
      "0.0\n",
      "140.51786149293184\n",
      "130.26027902262285\n",
      "5.238400959875435\n",
      "0.47736615198664367\n",
      "83.38187533710152\n",
      "3977.5384906493127\n",
      "156.2503947801888\n",
      "0.007512860000133514\n",
      "4.144392183050513\n",
      "2.7633399963378906\n",
      "41.38427887193393\n",
      "25.101091539254412\n",
      "31.721047923900187\n",
      "11.132158570922911\n",
      "0.23510629683732986\n",
      "29.4998172580963\n",
      "85.51444586622529\n",
      "19.31604258576408\n",
      "10.310268574161455\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "20.538711223751307\n",
      "20.96621331642382\n",
      "378.2404938992113\n",
      "424.30812303349376\n",
      "7.4466082556173205\n",
      "10.120338844135404\n",
      "7.115143787115812\n",
      "38.466278571635485\n",
      "1006.1891080574133\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "166.10994857246988\n",
      "4.117580220103264\n",
      "166.19997891120147\n",
      "6.897016952279955\n",
      "17.79068922996521\n",
      "69.60869628190994\n",
      "53.150175970979035\n",
      "1.810776000842452\n",
      "8.687622774392366\n",
      "13.161388832260855\n",
      "4477.571256425232\n",
      "5.813073059078306\n",
      "7.027708243113011\n",
      "17.599000930786133\n",
      "2.137939929962158\n",
      "23.639526679180562\n",
      "4.178250388009474\n",
      "0.0\n",
      "89.05351869761944\n",
      "132.94188141915947\n",
      "23.923454331234097\n",
      "9.557399031706154\n",
      "42.8236711549107\n",
      "1125.203853731975\n",
      "1.9225257895886898\n",
      "0.13423000276088715\n",
      "0.04559532133862376\n",
      "155.63927573454566\n",
      "96.41961458022706\n",
      "0.4134036982432008\n",
      "1048.1179628475802\n",
      "2073.9964099116623\n",
      "119.12432269728743\n",
      "5713.562069638632\n",
      "113.47349618934095\n",
      "7.651676036417484\n",
      "14.893022176111117\n",
      "11.325200080871582\n",
      "29.932569803437218\n",
      "3.162803777260706\n",
      "12.348804256180301\n",
      "0.0\n",
      "4.573102707974613\n",
      "100.38914064480923\n",
      "1.6130870776250958\n",
      "98.67162550403737\n",
      "20.241789082763717\n",
      "43.04460144042969\n",
      "53.32790012215264\n",
      "797.936966041103\n",
      "1.5093981176614761\n",
      "5.242256079567596\n",
      "307.63550021359697\n",
      "0.0\n",
      "137.0516332197003\n",
      "48.85624171094969\n",
      "0.0\n",
      "5.992765052826144\n",
      "8.169513754546642\n",
      "0.0\n",
      "73.79994279146194\n",
      "8.129308988689445\n",
      "0.0\n",
      "0.1758571439422667\n",
      "680.242466238793\n",
      "0.0\n",
      "0.027359829982742667\n",
      "76.26852570101619\n",
      "0.0\n",
      "26.826134791830555\n",
      "0.8037420720793307\n",
      "583.4412891990505\n",
      "484.97564292605966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 8.543 seconds\n",
      "Cross-validation score: 0.3439410710520768\n",
      "Test score: 0.6790123456790124\n",
      "Best Hyperparameters: {}\n",
      "572.7212364249281\n",
      "365.60214860219276\n",
      "2049.7217963217186\n",
      "44.94326278756489\n",
      "116.44616323942319\n",
      "174.79346244514454\n",
      "12.33129469351843\n",
      "0.052339598536491394\n",
      "0.5017719864845276\n",
      "1.0189741291105747\n",
      "175.16164994883002\n",
      "58.08203977253288\n",
      "34.78605270385742\n",
      "0.0\n",
      "5221.04226002068\n",
      "0.0\n",
      "20.357485836255364\n",
      "0.6904198117554188\n",
      "56.52241675090045\n",
      "153.0259866497945\n",
      "130.17468550172634\n",
      "67.66056502365973\n",
      "1.8878579323645681\n",
      "0.1486469954252243\n",
      "630.9520263671875\n",
      "1.1205799579620361\n",
      "26.849157568183728\n",
      "17.80919063091278\n",
      "91.44250765675679\n",
      "6.0672093607718125\n",
      "1.2588532192166895\n",
      "80.50266885827295\n",
      "76.53573717125983\n",
      "3.9892877250604215\n",
      "111.14531147369416\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "14.328068338538287\n",
      "4.087452799547464\n",
      "3889.8978839686606\n",
      "7.687266547000036\n",
      "65.21454518497922\n",
      "32.553193401312456\n",
      "4.239805219229311\n",
      "31.517480541020632\n",
      "1.785987614246551\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "65.89288897439837\n",
      "1519.4444653121955\n",
      "52.69900627975585\n",
      "24.988573344424367\n",
      "0.011930599808692932\n",
      "0.07010900229215622\n",
      "119.98094226053217\n",
      "3.0869823209941387\n",
      "23.78162869207917\n",
      "3719.0389116399456\n",
      "70.49259926640661\n",
      "88.66595249099191\n",
      "0.08835539012216032\n",
      "0.20048163796309382\n",
      "5.998614132637158\n",
      "1.3761175088584423\n",
      "0.004093539901077747\n",
      "0.0\n",
      "63.59973017960692\n",
      "1426.8458968523773\n",
      "8.852092858869582\n",
      "16.542320001404732\n",
      "89.17651364682955\n",
      "0.24534999579191208\n",
      "0.31180669367313385\n",
      "0.0017666600178927183\n",
      "7.91873000562191\n",
      "1.4617165811359882\n",
      "5.682940997337156\n",
      "16.426316326775122\n",
      "2.833785204682499\n",
      "2137.5355038057314\n",
      "23.086658456828445\n",
      "136.70668047806248\n",
      "1850.6631295424886\n",
      "34.48406278062612\n",
      "0.8387396140024066\n",
      "0.0\n",
      "16.029796434100717\n",
      "0.006506950128823519\n",
      "4.161424385296414\n",
      "0.0\n",
      "8.407947933766991\n",
      "8956.17415039381\n",
      "0.04125402244972065\n",
      "17.091650570277125\n",
      "117.47357428945543\n",
      "0.0\n",
      "40.07260399591178\n",
      "23.820742115960456\n",
      "3.84172488655895\n",
      "3.1453277053078637\n",
      "17.395745749236085\n",
      "0.0\n",
      "22.42675022885669\n",
      "18.12390286871232\n",
      "0.0\n",
      "1.2114100456237793\n",
      "0.04954973190615419\n",
      "0.0\n",
      "44.229601483326405\n",
      "0.8791228057750686\n",
      "0.0\n",
      "22.64587943814695\n",
      "567.4127759535284\n",
      "0.0\n",
      "0.07294469652697444\n",
      "77.83654009888414\n",
      "0.0\n",
      "105.68609167006798\n",
      "2.2049378424999304\n",
      "10.332999149279203\n",
      "0.0683848925109487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 8.499 seconds\n",
      "Cross-validation score: 0.3756819508106273\n",
      "Test score: 0.42168674698795183\n",
      "Best Hyperparameters: {}\n",
      "755.3154228683802\n",
      "1171.5589019214065\n",
      "3262.598945241247\n",
      "6.705395885393955\n",
      "154.3651340662036\n",
      "138.54547351918882\n",
      "3.574272698024288\n",
      "24.80320409394335\n",
      "0.726603867020458\n",
      "58.31697403267026\n",
      "6.200636005494744\n",
      "17.510283426381648\n",
      "0.7378199640661478\n",
      "0.0\n",
      "7.556820560595952\n",
      "0.0\n",
      "262.355666576419\n",
      "41.4297627042979\n",
      "10.918670177459717\n",
      "17.496859277947806\n",
      "3.188592902617529\n",
      "616.3160370341502\n",
      "3.4542074613273144\n",
      "0.9110519858077168\n",
      "18.062412244733423\n",
      "0.0\n",
      "4.8648428820306435\n",
      "14.301953974878415\n",
      "88.02491233637556\n",
      "21.30353321658913\n",
      "958.2453613316175\n",
      "20.365468418458477\n",
      "35.35650494339325\n",
      "3.191602465463802\n",
      "12.278374251374872\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "61.059026741888374\n",
      "7.92475725967779\n",
      "113.78380701498827\n",
      "9.027688281494193\n",
      "0.7885969890048727\n",
      "22.405536454636604\n",
      "3.8329618785646744\n",
      "19.390323529718444\n",
      "9.966981063538697\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "140.90981780274888\n",
      "22.066709247301333\n",
      "51.32534156940294\n",
      "2.2608907828107476\n",
      "0.0\n",
      "3.9858195781707764\n",
      "32.905122200842015\n",
      "7.1667808392085135\n",
      "4.971045558573678\n",
      "29.590008237573784\n",
      "5677.902277120855\n",
      "8.559628116898239\n",
      "20.57587686984334\n",
      "0.032940201461315155\n",
      "3.510505738435313\n",
      "14.52565581916133\n",
      "4.115221596322954\n",
      "0.0\n",
      "34.453534657135606\n",
      "180.47510442987894\n",
      "1.7981312035117298\n",
      "1.7715619634836912\n",
      "62.84578370972304\n",
      "0.0\n",
      "0.9962263570632786\n",
      "0.0\n",
      "7.951040148735046\n",
      "5.216614729259163\n",
      "7.849879886431154\n",
      "19.314320124700316\n",
      "16.48290149657987\n",
      "1551.948895482812\n",
      "189.7074474095134\n",
      "68.26912939734757\n",
      "15.118454147246666\n",
      "21.292180061340332\n",
      "4.88246342423372\n",
      "0.0\n",
      "13.590591829735786\n",
      "0.002248130040243268\n",
      "25.772694253828377\n",
      "0.0\n",
      "38.55522837175522\n",
      "582.8942951513454\n",
      "51.9555181064643\n",
      "7.0308964748401195\n",
      "57.39143231412426\n",
      "0.0\n",
      "47.09313833061606\n",
      "31.952335614711046\n",
      "16.115773236495443\n",
      "39.433474883204326\n",
      "7.800569333601743\n",
      "0.0\n",
      "12.15924989245832\n",
      "16.41680725896731\n",
      "0.0\n",
      "0.0\n",
      "0.0014558499678969383\n",
      "0.0\n",
      "68.44138383015525\n",
      "2.3280179160647094\n",
      "0.0\n",
      "4.569706060807221\n",
      "511.1838869785176\n",
      "0.0\n",
      "14.148118828423321\n",
      "263.7694769608788\n",
      "0.0\n",
      "76.19487478211522\n",
      "20.719734360231087\n",
      "8.6515404433012\n",
      "10.446710492600687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 8.577 seconds\n",
      "Cross-validation score: 0.48523677112386787\n",
      "Test score: 0.5194805194805195\n",
      "Best Hyperparameters: {}\n",
      "1451.1460869324312\n",
      "474.08988046192525\n",
      "4005.6761889901954\n",
      "23.633033884640536\n",
      "255.0916033817436\n",
      "7.900474810565356\n",
      "5.047500017221092\n",
      "26.907060947894934\n",
      "151.19670602784026\n",
      "405.7045157866087\n",
      "0.9858902166924963\n",
      "125.9893016214387\n",
      "0.27971210330724716\n",
      "0.0\n",
      "3.055078644887544\n",
      "0.0\n",
      "3.584781335456589\n",
      "0.5846588831627741\n",
      "16.067778396731228\n",
      "54.79072507924866\n",
      "13.368068280215084\n",
      "919.5115721902112\n",
      "0.6331770253394603\n",
      "0.0\n",
      "2.4084397897822782\n",
      "0.0\n",
      "28.23743147497139\n",
      "0.1073454499160107\n",
      "13.5150825381279\n",
      "0.9627705038292333\n",
      "3.065482974052429\n",
      "6.070265631729853\n",
      "32.11966222252037\n",
      "0.18384731630794704\n",
      "9.097337442959542\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "11.725394961395068\n",
      "0.9571680582594126\n",
      "27.049642659829352\n",
      "0.3872163529449608\n",
      "0.30120994412573054\n",
      "1.987796978734132\n",
      "76.29878928525945\n",
      "0.1185825327411294\n",
      "9.198721152946401\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "37.6371734109307\n",
      "10.193233714366215\n",
      "64.39914735247473\n",
      "2.941488442549791\n",
      "0.0\n",
      "7.128402065485716\n",
      "0.10482197976671159\n",
      "6.00633504476825\n",
      "4.543465361122406\n",
      "5.134791383519769\n",
      "5469.909906962174\n",
      "14.862242682547691\n",
      "19.207798696974972\n",
      "281.83630561828613\n",
      "15.349916404113173\n",
      "168.50420259858947\n",
      "0.9323185430839658\n",
      "2.0703599425131447e-12\n",
      "29.6915035774\n",
      "160.9200065112408\n",
      "1.963088582153432\n",
      "0.0\n",
      "102.68865093750647\n",
      "1.8624894233653322\n",
      "0.38835032301722094\n",
      "0.0\n",
      "11.406917575746775\n",
      "0.10104720812523738\n",
      "0.16337578278034925\n",
      "3.448461471591145\n",
      "19.285508707589543\n",
      "1512.6785695539565\n",
      "290.7828130617272\n",
      "76.1874523751528\n",
      "0.055332095181825025\n",
      "29.849004064395558\n",
      "0.05042909039184451\n",
      "0.01954060047864914\n",
      "34.41095972061157\n",
      "0.06549252747208811\n",
      "2.0783949815668166\n",
      "0.0\n",
      "21.255561270285398\n",
      "54.529664877743926\n",
      "5.051961627974379\n",
      "11.705680699155891\n",
      "30.92111066104553\n",
      "0.0\n",
      "161.17347253370372\n",
      "19.018138637074117\n",
      "4.815117133315653\n",
      "1.084189012646675\n",
      "8.9998611285056\n",
      "0.0\n",
      "62.16475473489845\n",
      "14.66405175626278\n",
      "0.0\n",
      "0.0011561999563127756\n",
      "0.01687423011753708\n",
      "0.0\n",
      "20.22817473072064\n",
      "2.83006281775113\n",
      "0.0\n",
      "185.20037725995644\n",
      "573.492118988069\n",
      "0.0\n",
      "3.8373698749843976e-13\n",
      "0.10156647709691481\n",
      "0.0\n",
      "15.049366932407308\n",
      "0.02446074011095334\n",
      "34.03291495628072\n",
      "0.005964886164292693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 10.614 seconds\n",
      "Cross-validation score: 0.5065561939553874\n",
      "Test score: 0.6707317073170732\n",
      "Best Hyperparameters: {}\n",
      "453.75089447264327\n",
      "3273.9776202343637\n",
      "383.1418073629029\n",
      "18.4560173896607\n",
      "17.77427224908024\n",
      "30.89120625378564\n",
      "2.1929604592733085\n",
      "0.26956230495125055\n",
      "4.019649982452393\n",
      "0.0369562990963459\n",
      "1.0974634978920221\n",
      "27.291631730622612\n",
      "4.965538619086146\n",
      "0.0\n",
      "3526.463613433414\n",
      "0.0\n",
      "1020.469688810641\n",
      "252.08312825486064\n",
      "2.921050483593717\n",
      "117.36399841308594\n",
      "18.82330067222938\n",
      "115.42128622718155\n",
      "2257.501432900317\n",
      "1.9392000436782837\n",
      "5.129896845668554\n",
      "0.0\n",
      "6.013675359310582\n",
      "2.367846821434796\n",
      "65.53227516124025\n",
      "4.166163232177496\n",
      "5.714223675429821\n",
      "14.075169774820097\n",
      "243.77299807127565\n",
      "0.33316961815580726\n",
      "20.80512679228559\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "95.4989230944775\n",
      "3.3060333942994475\n",
      "190.32987975445576\n",
      "1.8503624626901\n",
      "62.33843687851913\n",
      "47.870081779081374\n",
      "160.23107288428582\n",
      "197.5247651655227\n",
      "32.352908950764686\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "33.323927672579885\n",
      "0.5093458835035563\n",
      "49.48392750264611\n",
      "0.050203900784254074\n",
      "0.17843538988381624\n",
      "1.2552800178527832\n",
      "39.534968975931406\n",
      "6.333632091060281\n",
      "2.3425646133255213\n",
      "1740.8894702412654\n",
      "47.778167384909466\n",
      "5.170458398410119\n",
      "10.641392710618675\n",
      "0.0\n",
      "19.666886812308803\n",
      "17.825025209691375\n",
      "0.412106828764081\n",
      "0.0\n",
      "71.05790950777009\n",
      "176.3504338648636\n",
      "363.8151482435642\n",
      "1.9143870731350034\n",
      "61.91314002405852\n",
      "6.009973928332329\n",
      "0.2647580951452255\n",
      "0.0\n",
      "0.0\n",
      "4.912657228298485\n",
      "10.5558160552755\n",
      "8.905255023390055\n",
      "3.45054944884032\n",
      "1133.4025685028173\n",
      "28.727893474744633\n",
      "32.86343979649246\n",
      "9.885953188175336\n",
      "22.699490517377853\n",
      "8.236384267103858\n",
      "0.0\n",
      "23.012557941954583\n",
      "4.252277076244354\n",
      "21.013246559537947\n",
      "0.0\n",
      "6.232218828983605\n",
      "82.50827251700684\n",
      "13.48304901807569\n",
      "6.9738647770136595\n",
      "78.78041067032609\n",
      "0.0\n",
      "21.37889316433575\n",
      "333.63577330764383\n",
      "12.595228112768382\n",
      "7.277496289927512\n",
      "4.928451370215043\n",
      "0.0\n",
      "11.158890526392497\n",
      "11.517245030030608\n",
      "0.0\n",
      "0.0\n",
      "12.52946841326775\n",
      "0.0\n",
      "356.15504252910614\n",
      "21.513127821031958\n",
      "0.0\n",
      "734.6597809917293\n",
      "462.7762754478026\n",
      "0.0\n",
      "1.862293355166912\n",
      "60.12415167153813\n",
      "0.0\n",
      "17.463924282230437\n",
      "0.3254037422593683\n",
      "13.680017304606736\n",
      "5.410327631281689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 9.125 seconds\n",
      "Cross-validation score: 0.3058374302800299\n",
      "Test score: 0.9036144578313253\n",
      "Best Hyperparameters: {}\n",
      "684.2665081939194\n",
      "336.9944161361782\n",
      "1502.456330084009\n",
      "21.392213438637555\n",
      "38.489125105319545\n",
      "43.23614929849282\n",
      "7.955463164718822\n",
      "1.1292599439620972\n",
      "0.04086937056854367\n",
      "0.039349519880488515\n",
      "38.49693765491247\n",
      "5.4048382714390755\n",
      "25.703976311022416\n",
      "0.0\n",
      "26.522017368115485\n",
      "0.0\n",
      "368.92783681536093\n",
      "0.5897441280540079\n",
      "0.04588843043893576\n",
      "14.187179954256862\n",
      "26.681380953639746\n",
      "738.4117554561235\n",
      "114.23065155977383\n",
      "2.033623605268076\n",
      "1.2528975987806916\n",
      "0.0\n",
      "9.268417287268676\n",
      "4.574380177538842\n",
      "1.5334235316840932\n",
      "49.43039265507832\n",
      "6.926701440475881\n",
      "4.577456890139729\n",
      "7.812843198189512\n",
      "2.8018867168575525\n",
      "15.023761907592416\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "8.004560563713312\n",
      "1.74886354804039\n",
      "3.330017787637189\n",
      "62.888441065559164\n",
      "1.2504014279693365\n",
      "22.591512547340244\n",
      "15.06548113306053\n",
      "0.7813190221786499\n",
      "14.365186981391162\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "52.619224570924416\n",
      "5.8614235408604145\n",
      "72.47734262014274\n",
      "14.187739191576838\n",
      "0.0\n",
      "0.47329574916511774\n",
      "27.676843804772943\n",
      "98.16333507932723\n",
      "165.93634458072484\n",
      "521.2040759697556\n",
      "4171.4381800908595\n",
      "287.49608936184086\n",
      "19.040651843883097\n",
      "0.0\n",
      "1.0500400681048632\n",
      "28.200973947066814\n",
      "4.08123738784343\n",
      "0.0\n",
      "218.56424954719841\n",
      "93.9153453623876\n",
      "98.77099103620276\n",
      "433.32308304449543\n",
      "69.44534965767525\n",
      "0.0\n",
      "0.30191280087456107\n",
      "0.4090657904744148\n",
      "0.0\n",
      "20.064099400304258\n",
      "1.9229771217796952\n",
      "7.91786199901253\n",
      "0.6997953336685896\n",
      "2608.568086836254\n",
      "27.630967212375253\n",
      "73.00556031242013\n",
      "31.645612003048882\n",
      "0.00511199003085494\n",
      "34.256011054618284\n",
      "0.0\n",
      "8.370886380318552\n",
      "3.627020064741373\n",
      "23.025407925597392\n",
      "0.0\n",
      "42.062446925090626\n",
      "18.796555295120925\n",
      "0.0175206009298563\n",
      "148.8371447797399\n",
      "132.88881434639916\n",
      "0.05180459842085838\n",
      "22.24060667026788\n",
      "37.20380193227902\n",
      "4.086461293511093\n",
      "0.02537866961210966\n",
      "273.526767632924\n",
      "0.0\n",
      "14.30335881607607\n",
      "2.2197392410598695\n",
      "0.0\n",
      "5.5625702701509\n",
      "0.4252298641949892\n",
      "0.0\n",
      "27.641734570730478\n",
      "3.3235738510265946\n",
      "0.0\n",
      "32.82122101262212\n",
      "357.5127472705208\n",
      "0.0\n",
      "1.2265928192064166\n",
      "63.474171791924164\n",
      "0.0\n",
      "138.3376316607464\n",
      "2.6375530241057277\n",
      "0.43620290234684944\n",
      "4.032499713357538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 8.758 seconds\n",
      "Cross-validation score: 0.4524954952523193\n",
      "Test score: 0.5813953488372092\n",
      "Best Hyperparameters: {}\n",
      "924.2420122237354\n",
      "4625.258023472154\n",
      "571.706187255244\n",
      "13.88278710704617\n",
      "4325.167364738445\n",
      "373.2132919210999\n",
      "51.89241814240813\n",
      "0.0\n",
      "1.7605080008506775\n",
      "0.0\n",
      "171.9610707880929\n",
      "1049.1260751225054\n",
      "26.433951377868652\n",
      "0.0\n",
      "3382.27506125113\n",
      "0.0\n",
      "3.0071131485456135\n",
      "26.007340368349105\n",
      "2.6974534080945887\n",
      "15.968827903270721\n",
      "14.505802345462143\n",
      "209.00845339894295\n",
      "0.34532878268510103\n",
      "0.20879259705543518\n",
      "0.004004220012575388\n",
      "0.0\n",
      "116.826928444847\n",
      "17.792076801299118\n",
      "289.21597976237535\n",
      "58.38204234292789\n",
      "1.8759175785817206\n",
      "29.034294940531254\n",
      "912.6619125240759\n",
      "7.66302859427924\n",
      "157.23467475170037\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "12.996798814507201\n",
      "14.191017281613313\n",
      "32.984334692667176\n",
      "10.869381909724325\n",
      "2.1297760256566107\n",
      "50.42056097229943\n",
      "131.32041147863492\n",
      "5.700129570788704\n",
      "12.123118739342317\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "931.4420001937542\n",
      "0.8662289269268513\n",
      "78.01712770567974\n",
      "307.9168680049479\n",
      "0.0\n",
      "6.305276826955378\n",
      "3965.8258949254523\n",
      "8.374855128459753\n",
      "346.7942926561227\n",
      "1869.9083272801945\n",
      "140.02205729437992\n",
      "2.8579532600706443\n",
      "26.0688399579376\n",
      "3.3163399696350098\n",
      "2.170128755562473\n",
      "0.3377766301855445\n",
      "0.17588719725608826\n",
      "0.0\n",
      "33.60154897070606\n",
      "2842.280367098572\n",
      "11.516619781265035\n",
      "27.93165748217143\n",
      "338.92035497261935\n",
      "0.0\n",
      "284.447998046875\n",
      "0.0\n",
      "2.921099901199341\n",
      "62.90740389097482\n",
      "7.973197261337191\n",
      "15.461825685109943\n",
      "11.923146308399737\n",
      "7286.928938402212\n",
      "16.375265542475972\n",
      "61.31222529290244\n",
      "72.81265557557344\n",
      "23.800883278949186\n",
      "1.9722227946622297\n",
      "0.1900310069322586\n",
      "56.67999640852213\n",
      "0.0025184599217027426\n",
      "4.94851898169145\n",
      "0.0\n",
      "3.9444091559853405\n",
      "6.620238735456951\n",
      "1.2792217461392283\n",
      "175.5841828074772\n",
      "21.887682069151197\n",
      "0.0\n",
      "411.938054835191\n",
      "3877.7354587978916\n",
      "1.5822772673564032\n",
      "2.8005923596210778\n",
      "33.217861553886905\n",
      "0.0\n",
      "41.42363198000067\n",
      "886.975541145599\n",
      "0.0\n",
      "0.5227220429806039\n",
      "0.05505878406984266\n",
      "0.0\n",
      "16057.017821404384\n",
      "1.1022490470204502\n",
      "0.0\n",
      "17.692006864584982\n",
      "499.2186062505607\n",
      "0.0\n",
      "0.0025792699307203293\n",
      "25.047010044032504\n",
      "0.0\n",
      "1437.7923462814651\n",
      "38.94179925695062\n",
      "50.277691289384165\n",
      "1.2965228522662073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 8.780 seconds\n",
      "Cross-validation score: 0.4444764956903128\n",
      "Test score: 0.29166666666666663\n",
      "Best Hyperparameters: {}\n",
      "2900178.4269496948\n",
      "17767494.44973468\n",
      "1461971.5517889932\n",
      "1610.5780941098928\n",
      "4250.284656427801\n",
      "332102.4421657771\n",
      "2034.7503758519888\n",
      "4029.8662990778685\n",
      "590327.2554594129\n",
      "5693.14735981822\n",
      "164742.05922937393\n",
      "500.22701854258776\n",
      "602.392041772604\n",
      "0.0\n",
      "45291.783168785274\n",
      "0.0\n",
      "115102.875307329\n",
      "58534.162990517914\n",
      "4279.983585298061\n",
      "318.96275770664215\n",
      "359290.84495574236\n",
      "1039443.7407529354\n",
      "200104.4159618616\n",
      "37115.685474038124\n",
      "752233.2707974613\n",
      "12715.90485431254\n",
      "113916.68089237809\n",
      "1480045.0249959826\n",
      "11510.221686169505\n",
      "105048.44281828403\n",
      "1541.1792960762978\n",
      "281374.5935536325\n",
      "642190.15523839\n",
      "27905.4843814373\n",
      "399450.66315199435\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2274.68102286011\n",
      "6332.539360880852\n",
      "78606.43558035791\n",
      "929057.1981867105\n",
      "71586.41663369536\n",
      "192950.06047199667\n",
      "81611.24946567416\n",
      "7341.678629986942\n",
      "285511.19293889403\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "5154193.158563919\n",
      "531097.8832993358\n",
      "306971.8838627413\n",
      "1521.5558095872402\n",
      "17561.06044769287\n",
      "333.56859946250916\n",
      "144767.35612936318\n",
      "1086.8988805413246\n",
      "5944476.65513514\n",
      "9717797.114178985\n",
      "59725.85844682157\n",
      "6333924.028167561\n",
      "179726.82516102493\n",
      "15618.396404623985\n",
      "2235809.859706372\n",
      "117418.80564428121\n",
      "1718892.3375968933\n",
      "29.243192553520203\n",
      "105406.45383319259\n",
      "2158217.7008163705\n",
      "587736.5707659796\n",
      "159960.33266735077\n",
      "815870.4655888453\n",
      "125296.16400146484\n",
      "1713424.9437570572\n",
      "0.0\n",
      "139739.17806625366\n",
      "1967278.2474283725\n",
      "2634586.2758844197\n",
      "43542.72586673498\n",
      "226930.82360455394\n",
      "4750930.981558338\n",
      "418175.1066208407\n",
      "12992.588891625404\n",
      "1292918.8916126788\n",
      "3556.115844592452\n",
      "464840.57865543664\n",
      "0.6300989985466003\n",
      "9299059.375555351\n",
      "2059.623652756214\n",
      "106563.04697517306\n",
      "0.0\n",
      "804615.8852723911\n",
      "337893.56373247504\n",
      "61262.66024598479\n",
      "23557.0987739861\n",
      "752966.6078886017\n",
      "1.850479006767273\n",
      "101491.47655207664\n",
      "1511921.8441007212\n",
      "1756725.166017443\n",
      "98.41845209896564\n",
      "340746.967044428\n",
      "0.0\n",
      "989770.560014084\n",
      "32621.477736711502\n",
      "0.0\n",
      "4629.789402931929\n",
      "2882.9395593106747\n",
      "0.0\n",
      "716863.3751998246\n",
      "280214.7123615965\n",
      "0.0\n",
      "4373546.413854048\n",
      "1778483.2748009488\n",
      "0.0\n",
      "26603.854498118162\n",
      "1221534.6152677387\n",
      "0.0\n",
      "504347.38616903126\n",
      "19418.877000629902\n",
      "1464010.9717775583\n",
      "55885.164039462805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 8.670 seconds\n",
      "Cross-validation score: 0.4895807654465149\n",
      "Test score: 0.7142857142857143\n",
      "Best Hyperparameters: {}\n",
      "3235.6562954735186\n",
      "8125.520552871865\n",
      "1818.5847306548385\n",
      "19.84989339549793\n",
      "41.72784303750086\n",
      "27.483687849715352\n",
      "145.40120101813227\n",
      "1.100159777328372\n",
      "8.150197790004313\n",
      "19.320598040736513\n",
      "40.47051831171848\n",
      "81.55164908338338\n",
      "0.01766970008611679\n",
      "0.0\n",
      "12.448929007630795\n",
      "0.0\n",
      "316.3659714530222\n",
      "12.976998791098595\n",
      "17.760339736938477\n",
      "50.28778957843315\n",
      "3.892024554195814\n",
      "151.3748836054001\n",
      "47.591350212926045\n",
      "8.96347339823842\n",
      "62.75661134254187\n",
      "0.02356809936463833\n",
      "1.2600956400856376\n",
      "128.5601910952828\n",
      "8.02798531355802\n",
      "48.13592708110809\n",
      "9.859880454139784\n",
      "381.58602902293205\n",
      "23.210887884139083\n",
      "0.8801901841070503\n",
      "17.360647469293326\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "69.49163759639487\n",
      "9.208242940250784\n",
      "22.727754453982925\n",
      "85.80584883433767\n",
      "12.167092656716704\n",
      "6.758194142370485\n",
      "3.502652413677424\n",
      "2.4861131595098414\n",
      "50.276572031667456\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "160.4058175771867\n",
      "43.52314708183985\n",
      "1302.4388420703058\n",
      "3.5838331943377852\n",
      "0.0012412900105118752\n",
      "16.131739497184753\n",
      "0.07821415464832171\n",
      "311.4370210490815\n",
      "14.314599904348142\n",
      "4454.5738427072065\n",
      "2322.249528201879\n",
      "6.6027449580142274\n",
      "0.7821078011766076\n",
      "87.0248031616211\n",
      "3.291209941380657e-05\n",
      "0.028056799434125423\n",
      "1.2163411031942815\n",
      "0.004478720016777515\n",
      "28.858827089192346\n",
      "299.214937787332\n",
      "60.454193823446985\n",
      "4.297619819641113\n",
      "287.70017688837834\n",
      "24.922658391296864\n",
      "0.08859249763190746\n",
      "0.0\n",
      "2.864243771880865\n",
      "2652.784713631496\n",
      "9.717308523599058\n",
      "50.95580477360636\n",
      "18.48113236404606\n",
      "105.47672694199719\n",
      "23.96919541573152\n",
      "73.71698928705882\n",
      "235.41306417935994\n",
      "27.78312422556337\n",
      "3.840097821317613\n",
      "0.0\n",
      "21.578247235971503\n",
      "0.0\n",
      "141.42906547768507\n",
      "72.14350128173828\n",
      "19.26509154320229\n",
      "182.22825016395655\n",
      "1.615286506479606\n",
      "25.46407669200562\n",
      "151.358827768825\n",
      "0.002297739963978529\n",
      "175.45423897076398\n",
      "39.04498933022842\n",
      "13.296757125470322\n",
      "293.93835807498544\n",
      "14.226899755583872\n",
      "0.0\n",
      "8.998486410360783\n",
      "451.71028938284144\n",
      "0.0\n",
      "0.0\n",
      "1.2764576952904463\n",
      "0.0\n",
      "25.055242534726858\n",
      "7.3672375831520185\n",
      "0.0\n",
      "2.999117694736924\n",
      "9371.981200242182\n",
      "0.0\n",
      "3.6220200061798096\n",
      "54.925594688393176\n",
      "0.0\n",
      "15.631727074156515\n",
      "8.597655838937499\n",
      "31.312161040026695\n",
      "0.811473808484152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 8.993 seconds\n",
      "Cross-validation score: 0.3857331020294771\n",
      "Test score: 0.6111111111111112\n",
      "Best Hyperparameters: {}\n",
      "31040.505790536925\n",
      "11785.155476269283\n",
      "245.55976164340973\n",
      "32.89726905571297\n",
      "3041.8236269650515\n",
      "929.1060735270148\n",
      "36.71136356052011\n",
      "1030.816976159811\n",
      "1572.2914000749588\n",
      "3.4601455722004175\n",
      "8.063764145364985\n",
      "17.909323198720813\n",
      "222.75634113699198\n",
      "0.0\n",
      "834.1693525710143\n",
      "0.0\n",
      "72363.36099457182\n",
      "340.31780739175156\n",
      "61.903753846883774\n",
      "9.440853697480634\n",
      "1566.5328149910783\n",
      "4404.892629531678\n",
      "2279.4695579484105\n",
      "222.2530059814453\n",
      "0.47460717847570777\n",
      "55692.83158111572\n",
      "103.32223140820861\n",
      "4.476118119433522\n",
      "1717.945420175558\n",
      "21.66838059667498\n",
      "12.655381111428142\n",
      "11.872321950271726\n",
      "31.055328879505396\n",
      "20.541186735092197\n",
      "27.873351158574224\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "283.56065892885636\n",
      "15.722672488540411\n",
      "38.82503578206524\n",
      "37197.457317100256\n",
      "3.390371387824416\n",
      "49.66578319930704\n",
      "26.652732582762837\n",
      "4.90942195430398\n",
      "19.032889974303544\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "575.5561179760844\n",
      "3.1072097588330507\n",
      "45.133674277109094\n",
      "6056.894009873271\n",
      "0.0\n",
      "2286.889892578125\n",
      "502.5523642101325\n",
      "10.31748492422048\n",
      "15.335473664104939\n",
      "9309.588641802431\n",
      "84.03198543214239\n",
      "4.57987292483449\n",
      "53.383307015523314\n",
      "0.2753550112247467\n",
      "2.5745903812348843\n",
      "32.74759979778901\n",
      "0.04105492006056011\n",
      "0.0\n",
      "1461.1070449566469\n",
      "125.83590134758015\n",
      "11.906380936037749\n",
      "2.531239189207554\n",
      "2882.779097978957\n",
      "6.752086725551635\n",
      "0.0\n",
      "0.0018873499939218163\n",
      "0.8094203062355518\n",
      "56.20007962617092\n",
      "3.7453976104734465\n",
      "3.077193590812385\n",
      "16.85501398704946\n",
      "1799.2728583386634\n",
      "447.86615306022577\n",
      "12410.077507004142\n",
      "65.90665834629908\n",
      "11.532819509506226\n",
      "9.553170210681856\n",
      "0.293628990650177\n",
      "2.9474924746900797\n",
      "8362.898575882718\n",
      "3.672521138563752\n",
      "0.0\n",
      "1266.8032198951114\n",
      "1386.8872511438094\n",
      "11.655746007338166\n",
      "459.13844400423113\n",
      "21.400891756638885\n",
      "2.9122648464981467\n",
      "40.3056198975537\n",
      "1277.8475105858524\n",
      "35.97573269356508\n",
      "6441.976278256159\n",
      "20.515637730248272\n",
      "0.0\n",
      "1244.7556735507678\n",
      "537.9648795308894\n",
      "0.0\n",
      "18.20064364373684\n",
      "51.58574315905571\n",
      "0.0\n",
      "4172.954780012369\n",
      "326.30217042099684\n",
      "0.0\n",
      "1685.423345880583\n",
      "6223.549154952401\n",
      "0.0\n",
      "0.4593311995267868\n",
      "15.84442424797453\n",
      "0.0\n",
      "15.989780465257354\n",
      "0.389400627464056\n",
      "15.219807287678123\n",
      "2.0069605614989996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 8.273 seconds\n",
      "Cross-validation score: 0.35374671964745497\n",
      "Test score: 0.5194805194805195\n",
      "Best Hyperparameters: {}\n",
      "895.9999798284948\n",
      "528.766225308136\n",
      "5522.526934866895\n",
      "37.26043741183821\n",
      "11.930454634480297\n",
      "36.45041148294695\n",
      "3.2516867062076926\n",
      "1.2581947724102065\n",
      "0.024584469851106405\n",
      "206.516478813719\n",
      "47.928672729525715\n",
      "22.168308568710927\n",
      "4.053864414803684\n",
      "0.0\n",
      "0.07595139695331454\n",
      "0.0\n",
      "72.87407064437866\n",
      "45.674732636748786\n",
      "180.37403145992357\n",
      "20.71125030517578\n",
      "3.0718627483583987\n",
      "1102.8101916055894\n",
      "100.25636896223295\n",
      "0.0\n",
      "17.000253590755165\n",
      "0.0\n",
      "1.1439750310964882\n",
      "0.24175995914265513\n",
      "20.8539181293163\n",
      "10.138975008856505\n",
      "0.23782403208315372\n",
      "10.020754350000276\n",
      "209.89076098260387\n",
      "21.31341452759807\n",
      "20.064161959029068\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.5673701244668337\n",
      "18.490720494208198\n",
      "2.150783502622499\n",
      "2.7271306932499826\n",
      "6.151269021676853\n",
      "93.51533746218777\n",
      "255.46722477218282\n",
      "0.041621800512075424\n",
      "2.7025336503818096\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "44.30243811871736\n",
      "130.78602319431957\n",
      "20.707515335259153\n",
      "20.467984488233924\n",
      "0.0\n",
      "10.843340540770441\n",
      "9.483532143756747\n",
      "1.1618701068800874\n",
      "57.65456511023393\n",
      "4.7906780721386895\n",
      "4791.336717398817\n",
      "6.061195736634545\n",
      "11.902489560830873\n",
      "0.004776437999680638\n",
      "2.561351463198662\n",
      "0.497082443209365\n",
      "0.10715476737823337\n",
      "0.004330319818109274\n",
      "5.373573393095285\n",
      "129.89118120053047\n",
      "0.4429820928724624\n",
      "0.006781629752367735\n",
      "23.94238926198289\n",
      "0.11745413357857615\n",
      "0.014719909988343716\n",
      "0.006066485104383901\n",
      "0.0\n",
      "5.817689005962816\n",
      "1.9362843522103503\n",
      "17.060771444335412\n",
      "0.0063455598428845406\n",
      "1809.4316521106666\n",
      "1.3118503594951108\n",
      "39.02453852246981\n",
      "11.299936125054955\n",
      "3.1068775192834437\n",
      "1.3882923314813524\n",
      "17.791011914610863\n",
      "12.561429999768734\n",
      "0.0026927499566227198\n",
      "5.267282187531237\n",
      "0.0\n",
      "1.7715689609758556\n",
      "21.328483156627044\n",
      "0.8320472541090567\n",
      "37.83980266637809\n",
      "76.58790529174958\n",
      "0.002605479909107089\n",
      "23.21459378511645\n",
      "20.55792860497604\n",
      "172.8596702637151\n",
      "0.011371519998647273\n",
      "3.793157142587006\n",
      "0.0\n",
      "3.445392843335867\n",
      "26.647520212165546\n",
      "0.0\n",
      "0.47710244730114937\n",
      "0.061192691791802645\n",
      "0.0\n",
      "730.3552196040691\n",
      "60.00349262834061\n",
      "0.0\n",
      "29.707523966652104\n",
      "471.6520015352705\n",
      "0.0\n",
      "0.11395200341940159\n",
      "11.507930882740766\n",
      "0.0\n",
      "24.574297884770203\n",
      "12.46558037714189\n",
      "85.0483164018633\n",
      "0.6628118114313111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 8.873 seconds\n",
      "Cross-validation score: 0.39354515837948034\n",
      "Test score: 0.3703703703703704\n",
      "Best Hyperparameters: {}\n",
      "14105982.458549805\n",
      "337519.1254254244\n",
      "4847856.956440773\n",
      "35.48788568004966\n",
      "212368.26122635603\n",
      "624308.0284835435\n",
      "1770.8233267441392\n",
      "219559.3334083557\n",
      "3400.81151586771\n",
      "61.494590640068054\n",
      "1045.3108433783054\n",
      "2258.255370646715\n",
      "753.7194003462791\n",
      "0.0\n",
      "7594.42300209403\n",
      "0.0\n",
      "1625553.0404793322\n",
      "1226846.9382504523\n",
      "338.18321265280247\n",
      "775783.230849266\n",
      "80300.56682503223\n",
      "77992.28895898163\n",
      "14168.21606875956\n",
      "5995.686225384474\n",
      "171272.27315482497\n",
      "331.1992273032665\n",
      "5046781.871184319\n",
      "297871.66399490833\n",
      "49052.16701622307\n",
      "1210642.4792374596\n",
      "5042.922462403774\n",
      "687467.0139428079\n",
      "6988.0624009519815\n",
      "645660.5587330759\n",
      "96481.0243203938\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "11618233.290851008\n",
      "57258.690423965454\n",
      "9092196.020943962\n",
      "283815.49410274625\n",
      "144606.89886799455\n",
      "94906.54754783958\n",
      "53263.50995284319\n",
      "932.7019958496094\n",
      "862017.6178025156\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2534354.334701862\n",
      "5022914.474261783\n",
      "11192.197560135275\n",
      "27159.476104207337\n",
      "2148.564155101776\n",
      "10224.081464357674\n",
      "83738.06166050583\n",
      "149633.61111541092\n",
      "3072.2903583310544\n",
      "1090625.9266522862\n",
      "10151354.552104544\n",
      "22154.22465018928\n",
      "242549.29135221243\n",
      "39503.97303771973\n",
      "34379.819232203066\n",
      "7712.266934797168\n",
      "139449.42614126205\n",
      "0.0\n",
      "2445.1837232112885\n",
      "1083586.1053925827\n",
      "12445.383818432689\n",
      "135.34198743104935\n",
      "2247717.322466992\n",
      "0.12717899680137634\n",
      "8329.737471029162\n",
      "0.0\n",
      "307.50497394800186\n",
      "4745294.971762091\n",
      "888596.1458341777\n",
      "29631.980173274875\n",
      "641527.322683692\n",
      "4130.618575397879\n",
      "2202318.1744488366\n",
      "2945.021963465959\n",
      "448821.38005829975\n",
      "238579.16176652908\n",
      "105823260.76933156\n",
      "0.0\n",
      "156101.09801853448\n",
      "497.79161381721497\n",
      "148938.38206626475\n",
      "164471.20137310028\n",
      "15500.561827681959\n",
      "2991574.2163043357\n",
      "294769.1751238704\n",
      "293256.84520385414\n",
      "144339.1660276763\n",
      "15955.489095211029\n",
      "69180.42020676658\n",
      "1237080.7842349187\n",
      "59048.38592450693\n",
      "88108.18156516552\n",
      "81661.41668579727\n",
      "0.0\n",
      "20857.59893465042\n",
      "2492201.8915675916\n",
      "0.0\n",
      "501.2060260474682\n",
      "35986.9949789606\n",
      "0.0\n",
      "6979371.090161033\n",
      "11213.704969204962\n",
      "0.0\n",
      "15701.78614564985\n",
      "628198.6680412665\n",
      "0.0\n",
      "258.4961606860161\n",
      "228616.86299895495\n",
      "0.0\n",
      "936.7616829499602\n",
      "1167.6338601261377\n",
      "7806014.165295795\n",
      "118308.08052416146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 8.575 seconds\n",
      "Cross-validation score: 0.4139327915100015\n",
      "Test score: 0.220125786163522\n",
      "Best Hyperparameters: {}\n",
      "185603267.02109087\n",
      "651551.2253352441\n",
      "462140.3558697775\n",
      "177176.35724949092\n",
      "8322.60516441986\n",
      "2843509.030653432\n",
      "6294.955882456154\n",
      "6316.734221410006\n",
      "819630.0956128389\n",
      "36.233584344387054\n",
      "1962577.2828539908\n",
      "149548.96730009466\n",
      "18420.005647301674\n",
      "0.0\n",
      "11267.904762011021\n",
      "0.0\n",
      "3662.30286443606\n",
      "61673.73219373822\n",
      "472.8465398028493\n",
      "201.52183342725039\n",
      "7977.233492668718\n",
      "127.76993750408292\n",
      "24587.187049165368\n",
      "1733.1390898525715\n",
      "21924.563330173492\n",
      "38.27399826049805\n",
      "988051.4763478786\n",
      "8961.808311998844\n",
      "4206.054371267557\n",
      "249432.2999989502\n",
      "201.77440440654755\n",
      "64556.378609761596\n",
      "966938.4505990297\n",
      "11828.85967001319\n",
      "2194182.614275111\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "181800.7852461487\n",
      "29.862447518855333\n",
      "6894.608890846372\n",
      "5063024.889171436\n",
      "25723.971176862717\n",
      "29049.835700575262\n",
      "9260.076185878366\n",
      "649.3854040205479\n",
      "624548.7712826729\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "852515.2242609486\n",
      "6002681.363031551\n",
      "46724470.36251596\n",
      "1512.0524187237024\n",
      "86.13082436472178\n",
      "8063.422313690186\n",
      "6771.07095355913\n",
      "432.6617237254977\n",
      "269441.93314899504\n",
      "186257.2292598635\n",
      "1063390.9553303346\n",
      "226585.89843070507\n",
      "337031.23522197455\n",
      "1038080.5900249928\n",
      "51284199.17349879\n",
      "4795.3481745272875\n",
      "12500.889474213123\n",
      "0.7661509811878204\n",
      "1295.910667449236\n",
      "581247.9843778759\n",
      "1434082.994522661\n",
      "5018.254934005439\n",
      "44106.24892663583\n",
      "44.251885041594505\n",
      "4.553233973681927\n",
      "0.0\n",
      "57.15558362752199\n",
      "3821.9256151095033\n",
      "100934.29629451036\n",
      "6570.282911896706\n",
      "64.862213909626\n",
      "57169.92356751859\n",
      "29302.309692412615\n",
      "32591931.95002646\n",
      "1035875.5152343512\n",
      "42.36034831404686\n",
      "2386.4230619966984\n",
      "0.0\n",
      "27.454178899526596\n",
      "141.1709936708212\n",
      "19300.624324008822\n",
      "33.900901794433594\n",
      "151733.35015267134\n",
      "916245.2670850977\n",
      "8351.837798446417\n",
      "1815297.293596983\n",
      "112216.99620120227\n",
      "931.083984375\n",
      "36450.357759311795\n",
      "741651.5398532599\n",
      "4201.710454314947\n",
      "131044.67716321349\n",
      "65798.15298602358\n",
      "0.0\n",
      "260516.13322354853\n",
      "22903.197765219957\n",
      "0.0\n",
      "44389.250383377075\n",
      "61385.2853262648\n",
      "0.0\n",
      "775961.9368132949\n",
      "389379.21193062514\n",
      "0.0\n",
      "25770.384640350938\n",
      "285498.30321037397\n",
      "0.0\n",
      "830.7941823005676\n",
      "547491.0372910164\n",
      "0.0\n",
      "383833.5889980644\n",
      "59494755.34373912\n",
      "11765.725127168\n",
      "14647.251949608326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 9.149 seconds\n",
      "Cross-validation score: 0.39187811800877576\n",
      "Test score: 0.5487804878048781\n",
      "Best Hyperparameters: {}\n",
      "2134.453344375128\n",
      "9486.062721958093\n",
      "392.92964290175587\n",
      "10.817170931492\n",
      "158.75035654986277\n",
      "59.087984281766694\n",
      "63.828439072705805\n",
      "44.595921482658014\n",
      "682.9640650749207\n",
      "33.47442571120337\n",
      "144.9535878810566\n",
      "135.9884923766367\n",
      "62.101491656620055\n",
      "0.0\n",
      "184.7201963365078\n",
      "0.0\n",
      "319.11852513439953\n",
      "79.7595592327416\n",
      "292.45789925806525\n",
      "124.42759504308924\n",
      "165.7043453590013\n",
      "8461.11877691932\n",
      "4.266419264022261\n",
      "0.00965133961290121\n",
      "365.92733228206635\n",
      "0.0016194699564948678\n",
      "355.3366325062234\n",
      "2917.527576504275\n",
      "1.4291372944135219\n",
      "8.429414874874055\n",
      "0.0021378500387072563\n",
      "10.436158266849816\n",
      "28.20212321780855\n",
      "55.232631638878956\n",
      "26.505370556144044\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "7.51124687329866\n",
      "13.784032776020467\n",
      "1344.6676663709804\n",
      "18.208740429894533\n",
      "0.026624280028045177\n",
      "5.511084296973422\n",
      "100.43757660314441\n",
      "1.646129951812327\n",
      "258.46425273432396\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "64.83520762861008\n",
      "1.7914788217749447\n",
      "428.52359741786495\n",
      "0.9156311000697315\n",
      "0.0\n",
      "66.34400177001953\n",
      "68.73663076909725\n",
      "13.725542094325647\n",
      "12.699578146566637\n",
      "1617.661487294361\n",
      "32.963301135692745\n",
      "11.231128417421132\n",
      "0.8186328755691648\n",
      "0.7516011307016015\n",
      "0.4538922985084355\n",
      "21.78277681255713\n",
      "0.7933434649603441\n",
      "0.0\n",
      "3.9571675328188576\n",
      "169.06512661511078\n",
      "0.4314206037670374\n",
      "5.982648067176342\n",
      "194.17733041744214\n",
      "0.03148460015654564\n",
      "0.19172130152583122\n",
      "0.0\n",
      "9.334581196308136\n",
      "1.7573029877385125\n",
      "91.8573345746845\n",
      "2.4411940849386156\n",
      "12.129262957721949\n",
      "1962.8405143852578\n",
      "96.58459094678983\n",
      "3444.9520139355445\n",
      "10558.635767178668\n",
      "0.14838081260677427\n",
      "0.8650249075144529\n",
      "0.0\n",
      "32.556086260359734\n",
      "0.2078918544575572\n",
      "85.18413542420603\n",
      "0.06413300335407257\n",
      "6.676146175246686\n",
      "94.99520474753808\n",
      "18.837723238859326\n",
      "3.027517509588506\n",
      "43.99870473018382\n",
      "0.0\n",
      "74.1534251589328\n",
      "436.2860643612221\n",
      "1137.5576616476756\n",
      "126.72172665596008\n",
      "0.946388493059203\n",
      "0.0\n",
      "225.19714741129428\n",
      "10.622419152292423\n",
      "0.0\n",
      "45.7643210417591\n",
      "0.02727614063769579\n",
      "0.0\n",
      "188.15790390060283\n",
      "6.115350170759484\n",
      "0.0\n",
      "64.4649923541001\n",
      "533.23143333802\n",
      "0.0\n",
      "0.2384428959339857\n",
      "10.595685246400535\n",
      "0.0\n",
      "1345.2571580142248\n",
      "4.004960109828971\n",
      "45.73547728871927\n",
      "17.344144497532398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 8.988 seconds\n",
      "Cross-validation score: 0.4813325730386353\n",
      "Test score: 0.49999999999999994\n",
      "Best Hyperparameters: {}\n",
      "147.01836062538496\n",
      "3899.033251684713\n",
      "639.16144945407\n",
      "6.225263393716887\n",
      "5.2143679773435\n",
      "45.82161884353263\n",
      "3.440382554894313\n",
      "0.17791107948869467\n",
      "34.49221949186176\n",
      "4.342022001743317\n",
      "12.195237343898043\n",
      "49.64574346737936\n",
      "0.19461939856410027\n",
      "0.0\n",
      "1831.2852150778053\n",
      "0.0\n",
      "12.360877687402535\n",
      "0.6449542531045154\n",
      "1.040670461487025\n",
      "0.026677200570702553\n",
      "0.3002954199910164\n",
      "3.7677807079744525\n",
      "3120.0404670910066\n",
      "0.06683240085840225\n",
      "0.0747976831626147\n",
      "0.0\n",
      "29.067180208512582\n",
      "5.3541277593467385\n",
      "21.844322552671656\n",
      "1.8443546798080206\n",
      "9.710740069276653\n",
      "2.837667643732857\n",
      "55.01971672020393\n",
      "6.330629211575975\n",
      "24.624064726172946\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "12.49790983920684\n",
      "15.841155737638474\n",
      "11.823258816148154\n",
      "4.601631111232564\n",
      "10.06020637328038\n",
      "26.124796127784066\n",
      "9.745027757599019\n",
      "3.356135935432614\n",
      "8.821380025008693\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "48.20599532854976\n",
      "4.16903391899541\n",
      "77.43101591178493\n",
      "2.488288554828614\n",
      "0.0005478630191646516\n",
      "1.012204997939989\n",
      "1.4957367937313393\n",
      "63.65310708829202\n",
      "4.458847495785449\n",
      "2539.323908959981\n",
      "426.4162758295424\n",
      "3.796514115703758\n",
      "5.71297314716503\n",
      "0.0\n",
      "0.44904119428247213\n",
      "94.56694861128926\n",
      "5.335689147934318\n",
      "0.0\n",
      "4.900683812331408\n",
      "121.39623434159148\n",
      "123.85700804973021\n",
      "3.0021460740827024\n",
      "52.76766470985532\n",
      "1.2508759945631027\n",
      "0.0\n",
      "0.00010933900193776935\n",
      "40.773836619977374\n",
      "10.771971795940772\n",
      "21.77378858125303\n",
      "0.25584549084305763\n",
      "64.6532989947591\n",
      "659.243042500224\n",
      "40.47544819093309\n",
      "11.96546443644911\n",
      "7.020668107899837\n",
      "21.95314697152935\n",
      "3.3882027387153357\n",
      "0.0\n",
      "16.477841671556234\n",
      "1.195087418309413\n",
      "2.0181518194876844\n",
      "0.0\n",
      "7.322879597079009\n",
      "1462.8819782714709\n",
      "12.039060891082045\n",
      "1.59270134055987\n",
      "425.0082043890725\n",
      "0.0\n",
      "169.56159906770336\n",
      "39.82534474116983\n",
      "125.73292818665504\n",
      "0.0808619987219572\n",
      "1.1767140112933703\n",
      "0.0\n",
      "11.518059447997075\n",
      "5.969243088620715\n",
      "0.0\n",
      "18.8274926841259\n",
      "0.314212727593258\n",
      "0.0\n",
      "492.8692797107715\n",
      "94.52408715407364\n",
      "0.0\n",
      "12.284096915274858\n",
      "630.5551708447456\n",
      "0.0\n",
      "0.06435987958684564\n",
      "55.9301929899957\n",
      "0.0\n",
      "10.506908438168466\n",
      "0.57924436180474\n",
      "1.215667781594675\n",
      "1.1586218066513538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 8.862 seconds\n",
      "Cross-validation score: 0.4475965862884744\n",
      "Test score: 0.6470588235294119\n",
      "Best Hyperparameters: {}\n",
      "1027.9070783619586\n",
      "3872.069871279502\n",
      "6075.888558750041\n",
      "26.14097791397944\n",
      "993.9665954267839\n",
      "111.37025085417554\n",
      "18.312059081159532\n",
      "0.058099535293877125\n",
      "226.70352288731374\n",
      "0.21669116197153926\n",
      "80.24261890084017\n",
      "25.29976020939648\n",
      "1.22380529390648\n",
      "0.0\n",
      "5.1015221499837935\n",
      "0.0\n",
      "1079.853389975382\n",
      "33.800564562901855\n",
      "321.0701664456283\n",
      "14.682510375976562\n",
      "5.548839092254639\n",
      "921.8135953751625\n",
      "36.73339259807835\n",
      "1.8074244138551876\n",
      "0.006638769991695881\n",
      "0.0090002998476848\n",
      "21.425247369450517\n",
      "144.43070115242153\n",
      "6.3387064163107425\n",
      "108.2290805359203\n",
      "0.1744117183261551\n",
      "58.95640118204756\n",
      "182.0766547130188\n",
      "4.0846100294729695\n",
      "69.69866009462203\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "86.17235773976427\n",
      "21.764344409108162\n",
      "3356.163372035371\n",
      "0.7891578925773501\n",
      "4.625841837259941\n",
      "9.718102671322413\n",
      "224.88606747006997\n",
      "46.85763427661732\n",
      "12.579436446618274\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2538.5190121975775\n",
      "1.4914121681358665\n",
      "58.81240459368564\n",
      "5.435435265302658\n",
      "0.00900570978410542\n",
      "0.4705530107021332\n",
      "61.62352384807309\n",
      "107.24624100991059\n",
      "33.699532770841415\n",
      "1900.780564984103\n",
      "69.62350593641168\n",
      "20.76528050750494\n",
      "96.19064139237162\n",
      "141.41600036621094\n",
      "0.274896742310375\n",
      "41.28356906346744\n",
      "0.6498799026012421\n",
      "0.0\n",
      "0.0\n",
      "91.57808871746238\n",
      "78.00023539317772\n",
      "0.0\n",
      "58.58668860149919\n",
      "1.6283208813983947\n",
      "0.0008774980087764561\n",
      "0.0\n",
      "0.0\n",
      "0.7495388898532838\n",
      "293.89093059301376\n",
      "6.364281383808702\n",
      "221.47820212179795\n",
      "1690.5300073118415\n",
      "11.588683615904301\n",
      "68.23933729436249\n",
      "32.450154398800805\n",
      "59.66229552216828\n",
      "57.23242557689082\n",
      "1313.68994140625\n",
      "8.553099989891052\n",
      "0.10117845912463963\n",
      "97.65762127918424\n",
      "0.017000079853460193\n",
      "18.12843274671468\n",
      "78.05978298303671\n",
      "0.046150101348757744\n",
      "42.25823391787708\n",
      "587.797817870276\n",
      "0.0\n",
      "286.64909445805824\n",
      "153.8739597838321\n",
      "5.375885951507371\n",
      "0.0013691600179299712\n",
      "6.545082748983987\n",
      "0.0\n",
      "20.27126893377863\n",
      "25.21399849955924\n",
      "0.0\n",
      "2.7818435218650848\n",
      "6.46516896225512\n",
      "0.0\n",
      "19.667913371797113\n",
      "113.51658287626924\n",
      "0.0\n",
      "61.0887747243396\n",
      "934.1141451190924\n",
      "0.0\n",
      "0.04811704426538199\n",
      "101.27660164562985\n",
      "0.0\n",
      "15.35091342841406\n",
      "21.875255584251136\n",
      "7.736256932606921\n",
      "1.6728958545718342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 9.130 seconds\n",
      "Cross-validation score: 0.4066561233743896\n",
      "Test score: 0.7142857142857143\n",
      "Best Hyperparameters: {}\n",
      "497.8233084775309\n",
      "125.13177638337947\n",
      "2163.7239046691684\n",
      "6.777554863132536\n",
      "58.09686915553175\n",
      "58.39941246248782\n",
      "8.153759391279891\n",
      "7.202554464805871\n",
      "0.0\n",
      "343.2014076411724\n",
      "2.0601869830861688\n",
      "22.216406332328916\n",
      "9.359263839200139\n",
      "0.0\n",
      "137.41560539545026\n",
      "0.0\n",
      "235.46407641540281\n",
      "49.208593174116686\n",
      "79.74551323265769\n",
      "0.003557560034096241\n",
      "197.6783811391797\n",
      "854.5224811807275\n",
      "163.02317934599705\n",
      "3.543405693024397\n",
      "151.23670620052144\n",
      "0.0014590299688279629\n",
      "7.755926320096478\n",
      "9.295071442378685\n",
      "459.41280197142623\n",
      "5.019051385228522\n",
      "6.51782895589713\n",
      "3.7298400928266346\n",
      "95.32634841099207\n",
      "2.3140727448044345\n",
      "32.88509578362573\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "52.88092863583006\n",
      "6.260505647631362\n",
      "4.682803524658084\n",
      "0.6274601102340966\n",
      "3.283461461775005\n",
      "8.893001911696047\n",
      "35.739245629054494\n",
      "7.348714475752786\n",
      "8.690501095727086\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "15.786201651324518\n",
      "12.316374071873724\n",
      "71.51898400799837\n",
      "0.6531830132007599\n",
      "0.010958899743855\n",
      "0.325874999165535\n",
      "34.566555770579726\n",
      "1.648828395176679\n",
      "8.911355657503009\n",
      "9.086623774841428\n",
      "4902.383006199263\n",
      "6.321304599870928\n",
      "0.8371005262015387\n",
      "0.2281706053763628\n",
      "2.7459119888953865\n",
      "17.70712304720655\n",
      "192.13427588995546\n",
      "0.0\n",
      "57.55511192046106\n",
      "107.66262617195025\n",
      "3.2849073061952367\n",
      "17.241855633212253\n",
      "108.77114235179033\n",
      "0.0\n",
      "0.034364099614322186\n",
      "0.0\n",
      "0.8835552465170622\n",
      "23.271047713933513\n",
      "7.758090938557871\n",
      "2.2959070769138634\n",
      "11.89843202874033\n",
      "1987.78903105692\n",
      "28.62209643656388\n",
      "103.55060560209677\n",
      "19.32062070549\n",
      "14.21030044555664\n",
      "4.979287271387875\n",
      "0.0\n",
      "45.15280094370246\n",
      "0.014145450084470212\n",
      "127.60981093929149\n",
      "0.0\n",
      "26.5529514006339\n",
      "229.1485605216585\n",
      "7.138297265395522\n",
      "299.8933872389607\n",
      "63.46092330177203\n",
      "0.07354690134525299\n",
      "3.7858439434785396\n",
      "127.14823477854952\n",
      "16.572900853585452\n",
      "0.48484210669994354\n",
      "8.10725816944614\n",
      "0.0\n",
      "20.876228292123415\n",
      "32.02838812279515\n",
      "0.0\n",
      "0.022423350252211094\n",
      "0.15039999783039093\n",
      "0.0\n",
      "36.009438627865165\n",
      "14.264911609934643\n",
      "0.0\n",
      "9.633692341623828\n",
      "429.54939446004573\n",
      "0.0\n",
      "0.5601239996030927\n",
      "63.43940123496577\n",
      "0.0\n",
      "11.892058377736248\n",
      "1.162227880093269\n",
      "35.31458811741322\n",
      "0.20533299446105957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 10.067 seconds\n",
      "Cross-validation score: 0.47924082473418333\n",
      "Test score: 0.6707317073170732\n",
      "Best Hyperparameters: {}\n",
      "469.4535660077818\n",
      "4222.807704459177\n",
      "576.3025247352198\n",
      "9.372171313036233\n",
      "14.862963788211346\n",
      "28.101907127420418\n",
      "0.22284296434372663\n",
      "10.052466616034508\n",
      "43.23640060424805\n",
      "0.21733838645741343\n",
      "383.6568797889631\n",
      "1.3864119849167764\n",
      "12.346569425426424\n",
      "0.0\n",
      "488.4398972140625\n",
      "0.0\n",
      "12.304819200187922\n",
      "0.016703189467079937\n",
      "13.739535958040506\n",
      "0.07932113984134048\n",
      "0.9107085019350052\n",
      "58.129743778379634\n",
      "2804.527044169605\n",
      "0.0\n",
      "0.3006550073623657\n",
      "0.2285660058259964\n",
      "10.372266709338874\n",
      "1.828159002121538\n",
      "3.1175306601217017\n",
      "4.718780644237995\n",
      "13.403055309318006\n",
      "97.62089100398589\n",
      "285.3461492541246\n",
      "10.007376952562481\n",
      "15.862998275319114\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "5.152005904354155\n",
      "3.6764461013954133\n",
      "21.972910373006016\n",
      "1.3019863161025569\n",
      "73.16824383870699\n",
      "27.366619946900755\n",
      "12.68507551215589\n",
      "0.0008463769918307662\n",
      "9.756152757909149\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "19.35807737626601\n",
      "1.281122470740229\n",
      "69.94869664404541\n",
      "15.34161201119423\n",
      "0.0\n",
      "63.78732085227966\n",
      "1.2037680433131754\n",
      "0.05511646997183561\n",
      "6.135818104376085\n",
      "2552.987660340965\n",
      "98.94457671814598\n",
      "5.802108388044871\n",
      "4.538665814325213\n",
      "0.0\n",
      "16.331156369298697\n",
      "9.173243011115119\n",
      "2.805799961090088\n",
      "33.19630177272484\n",
      "56.06515020271763\n",
      "180.4077509167837\n",
      "22.087724071694538\n",
      "1.8988562636077404\n",
      "66.49454717815388\n",
      "0.0\n",
      "0.1709855783265084\n",
      "0.0\n",
      "0.0\n",
      "0.17098799860104918\n",
      "6.114828075980768\n",
      "3.2345150066539645\n",
      "12.938278406858444\n",
      "447.0016144567635\n",
      "1.340105721494183\n",
      "33.77126898791175\n",
      "33.31819117674604\n",
      "7.764810085296631\n",
      "24.012153521645814\n",
      "0.02207281021401286\n",
      "1.631333849625662\n",
      "0.0748262032866478\n",
      "0.25614552246406674\n",
      "0.0\n",
      "3.601859051734209\n",
      "10.241325532551855\n",
      "0.23242930322885513\n",
      "3.179112012963742\n",
      "38.72470694500953\n",
      "0.0\n",
      "39.560741145163774\n",
      "43.70891109853983\n",
      "1.1730120433494449\n",
      "0.39355931512545794\n",
      "10.463266583159566\n",
      "0.0\n",
      "18.52158954180777\n",
      "16.38186052441597\n",
      "0.0\n",
      "0.03823300078511238\n",
      "0.003851229907013476\n",
      "0.0\n",
      "111.51709303073585\n",
      "13.31160878832452\n",
      "0.0\n",
      "25.736689121462405\n",
      "658.0563982697204\n",
      "0.0\n",
      "1.1390730966813862\n",
      "10.903854561736807\n",
      "0.0\n",
      "15.83552740002051\n",
      "0.15223531611263752\n",
      "95.68670612736605\n",
      "46.104341198690236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 9.132 seconds\n",
      "Cross-validation score: 0.392435181328547\n",
      "Test score: 0.46666666666666656\n",
      "Best Hyperparameters: {}\n",
      "753.2531728976454\n",
      "1326.4690980219998\n",
      "2457.9497245778693\n",
      "35.584883007686585\n",
      "76.353748014546\n",
      "63.09868562326301\n",
      "3.021861999470275\n",
      "0.45099003589712083\n",
      "29.62953335610655\n",
      "17.69547222170513\n",
      "165.4267426802544\n",
      "54.53271780931391\n",
      "3.7187430411577225\n",
      "0.0\n",
      "6036.435647641425\n",
      "0.0\n",
      "38.392551671131514\n",
      "64.18063758313656\n",
      "23.3761911066249\n",
      "1947.8439170001075\n",
      "119.86550481675658\n",
      "301.1636536461865\n",
      "0.3521686904132366\n",
      "0.042581929825246334\n",
      "4.6716291308403015\n",
      "0.0\n",
      "2.939469392877072\n",
      "132.2227270903968\n",
      "27.35009159008041\n",
      "0.23283361364156008\n",
      "0.19870400428771973\n",
      "29.074343874363695\n",
      "565.3408607900849\n",
      "1.19190426095156\n",
      "9.16527042912848\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "109.06974583669155\n",
      "0.6540256175212562\n",
      "65.38873482769122\n",
      "457.93301308713853\n",
      "1.5427758671576157\n",
      "6.770582900580492\n",
      "153.61694890634573\n",
      "0.049070101231336594\n",
      "74.64962183129683\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "171.5502770021867\n",
      "3.2429161196505447\n",
      "469.89086374239395\n",
      "0.006552924925927073\n",
      "0.0\n",
      "11.196301966910584\n",
      "21.392744099837728\n",
      "3.0247010837774724\n",
      "8.06240330642322\n",
      "40.61558834218886\n",
      "5892.539125745665\n",
      "9.817870371043682\n",
      "6.219242300168844\n",
      "0.9007160067558289\n",
      "0.9313618386222515\n",
      "415.1683028215775\n",
      "150.8178360524471\n",
      "0.0\n",
      "4.229181925067678\n",
      "301.0159401047487\n",
      "24.135851108423424\n",
      "182.6580621454923\n",
      "217.65501457127618\n",
      "1.4477549940347672\n",
      "587.5133659099229\n",
      "0.0\n",
      "38.69918817281723\n",
      "7.41548090451397\n",
      "17.93744857798447\n",
      "0.4160774052143097\n",
      "20.972297090105712\n",
      "2482.3495904764513\n",
      "24.7945319187711\n",
      "34.64248109329492\n",
      "19.48723420809256\n",
      "1.107724979519844\n",
      "6.756700549973175\n",
      "0.0\n",
      "37.819196969270706\n",
      "0.08952719904482365\n",
      "117.71061215101099\n",
      "0.0\n",
      "103.55273963534273\n",
      "12091.815046467527\n",
      "0.30997745461769455\n",
      "53.7099785929895\n",
      "562.5834059909141\n",
      "16.978200912475586\n",
      "157.33533146907575\n",
      "84.14496663067257\n",
      "0.0\n",
      "2.258828939900395\n",
      "4.57127628615126\n",
      "0.0\n",
      "26.14529865651275\n",
      "5.6968964078696445\n",
      "0.0\n",
      "0.6253237921046093\n",
      "0.0\n",
      "0.0\n",
      "87.24644199525937\n",
      "4.8185800212668255\n",
      "0.0\n",
      "238.10284325599483\n",
      "954.7750051144988\n",
      "0.0\n",
      "0.0\n",
      "58.16373712383211\n",
      "0.0\n",
      "8.475210142554715\n",
      "0.818661002818995\n",
      "3.9602971335407346\n",
      "0.034329799469560385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 8.683 seconds\n",
      "Cross-validation score: 0.42111975533126245\n",
      "Test score: 0.5128205128205128\n",
      "Best Hyperparameters: {}\n",
      "276.0349899454896\n",
      "3196.5937418274116\n",
      "747.3212952771573\n",
      "75.58464227349032\n",
      "158.47900454181945\n",
      "114.98932474153116\n",
      "168.2444329727441\n",
      "0.9438859969377518\n",
      "10.722267284989357\n",
      "23.69444441248197\n",
      "399.83391722256783\n",
      "282.67780989117455\n",
      "33.31344613083638\n",
      "0.0\n",
      "1348.1247972629499\n",
      "0.0\n",
      "92.77492614183575\n",
      "11.810742821689928\n",
      "29.896173669258133\n",
      "2.383596721221693\n",
      "44.034966297098435\n",
      "109.33243425190449\n",
      "2351.2836418121005\n",
      "0.015725539764389396\n",
      "0.016080200672149658\n",
      "0.0\n",
      "3.594968358054757\n",
      "8.064570527058095\n",
      "9.2006033831276\n",
      "0.8695529517135583\n",
      "10.622540522832423\n",
      "26.36588060320355\n",
      "19.18320109578781\n",
      "35.13111356156878\n",
      "35.05680914002005\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "98.84646232961677\n",
      "0.3927512955851853\n",
      "5.7061686692759395\n",
      "22.904047266580164\n",
      "4.1708123796852306\n",
      "23.66704964870587\n",
      "21.19003203464672\n",
      "0.24395511578768492\n",
      "4.571806931344327\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "69.36012980510714\n",
      "7.7218184705707245\n",
      "108.16355420218315\n",
      "7.4098192770034075\n",
      "0.0\n",
      "0.027165689738467336\n",
      "343.7878475767211\n",
      "0.3569796627853066\n",
      "342.1620388917287\n",
      "2788.1634444259107\n",
      "34.378669060862194\n",
      "13.839965332299471\n",
      "20.50145009857806\n",
      "4.692850112915039\n",
      "0.11012270115315914\n",
      "605.6625495310582\n",
      "0.017686769599094987\n",
      "0.0\n",
      "3.853574365377426\n",
      "53.86519731713623\n",
      "5.31368617922999\n",
      "23.806559808086604\n",
      "38.14242121276038\n",
      "0.0\n",
      "12.527666682843119\n",
      "0.0\n",
      "32.76199902035296\n",
      "1.6341690870467573\n",
      "170.27706640656106\n",
      "0.06457796110771596\n",
      "55.25710656680167\n",
      "102.02391004236415\n",
      "17.905001091014128\n",
      "75.71789626218379\n",
      "1.9380522712599486\n",
      "25.393892084539402\n",
      "8.531977327074856\n",
      "0.0\n",
      "40.38806104660034\n",
      "8.158821924473159\n",
      "16.33012886159122\n",
      "0.0\n",
      "15.762594767438713\n",
      "61.88492911902722\n",
      "8.568518473766744\n",
      "0.5722308558179066\n",
      "89.9489862092305\n",
      "0.010677560232579708\n",
      "165.98816321976483\n",
      "62.28926358721219\n",
      "253.814962635166\n",
      "0.1052346988581121\n",
      "34.04411834757775\n",
      "0.0\n",
      "36.149851818045136\n",
      "34.69523080391809\n",
      "0.0\n",
      "5.017714619403705\n",
      "0.021919810096733272\n",
      "0.0\n",
      "508.85625786334276\n",
      "1287.0180097949924\n",
      "0.0\n",
      "47.98619663901627\n",
      "418.3906798273347\n",
      "0.0\n",
      "0.025595500329280638\n",
      "51.83889938471839\n",
      "0.0\n",
      "16.28062003199011\n",
      "0.02460919041186571\n",
      "0.35655610787216574\n",
      "0.07861304731341079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 8.574 seconds\n",
      "Cross-validation score: 0.45852333725706107\n",
      "Test score: 0.3076923076923077\n",
      "Best Hyperparameters: {}\n",
      "3321.6234407760203\n",
      "791.2603412680328\n",
      "14070.72145092301\n",
      "230.71816372172907\n",
      "2332.364963606\n",
      "192.13403091114014\n",
      "170.1259242463857\n",
      "69.01255751773715\n",
      "73.928785353899\n",
      "20.309267356060445\n",
      "3832.600660048425\n",
      "2740.818578599021\n",
      "127.45075577311218\n",
      "0.0\n",
      "92789.25502318144\n",
      "0.0\n",
      "333.5755908600986\n",
      "129.31627123057842\n",
      "60.69210374355316\n",
      "0.6134232133626938\n",
      "1.8806846365332603\n",
      "2.3773264456540346\n",
      "46.02016140893102\n",
      "98.85432753432542\n",
      "17.474599838256836\n",
      "9.822679102420807\n",
      "40701.28861001041\n",
      "232.14564761146903\n",
      "43.92376667819917\n",
      "470915.173019981\n",
      "3.2528384253382683\n",
      "46.48856668174267\n",
      "26.76118437666446\n",
      "24.257747836411\n",
      "3686422.0709873773\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "425.539523165673\n",
      "261.2358227642253\n",
      "405.544557065703\n",
      "190668.45985237416\n",
      "1037.712847309187\n",
      "263056.99751964584\n",
      "237332.16245634668\n",
      "1.7768077086657286\n",
      "416.7150203473866\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "26076.564593391493\n",
      "6248.332430148497\n",
      "71571.90688864607\n",
      "574.1717774122953\n",
      "37.21384732425213\n",
      "4615646.786887207\n",
      "452.0865740198642\n",
      "108.595871578902\n",
      "282771.87876687385\n",
      "20064.372220035642\n",
      "7950.563661206514\n",
      "514.1682404810563\n",
      "240.53124661557376\n",
      "104.81920571438968\n",
      "1867337.6807974055\n",
      "3387.265637619421\n",
      "22633.807396609336\n",
      "0.14342600107192993\n",
      "107.73489883635193\n",
      "7178.072864240967\n",
      "5658.130174076185\n",
      "1.738708034157753\n",
      "2435.171843007207\n",
      "916.3289794921875\n",
      "0.0\n",
      "0.0\n",
      "17.101303294301033\n",
      "146.614936362952\n",
      "1263.8089234996587\n",
      "162.81848222017288\n",
      "399.21386883128434\n",
      "16252.203775421716\n",
      "688.5937122404575\n",
      "68.7107007112354\n",
      "14949.227278465405\n",
      "2429.4479775233194\n",
      "19223.652363449335\n",
      "0.10268739983439445\n",
      "76702.13459912129\n",
      "1327.6285903053358\n",
      "3.8527579698711634\n",
      "889.64501953125\n",
      "389.64435200206935\n",
      "13374.592157591134\n",
      "647.350910524372\n",
      "862.5963059943169\n",
      "507.4970154846087\n",
      "30652.99320046231\n",
      "18.256896315608174\n",
      "1420.6750983614475\n",
      "14.054946169257164\n",
      "38.217138543725014\n",
      "51.6633910164237\n",
      "0.0\n",
      "1002.214302899316\n",
      "431414.0292762406\n",
      "0.0\n",
      "0.9518882911652327\n",
      "95.72129821777344\n",
      "0.0\n",
      "1319.6900380542502\n",
      "332941.92988675646\n",
      "0.0\n",
      "19.260486925952137\n",
      "1190663.3524426874\n",
      "0.0\n",
      "39.82028070837259\n",
      "18730.82332580164\n",
      "0.0\n",
      "8099395.338377189\n",
      "889.5274201110005\n",
      "165089.9923437722\n",
      "3.5718002673238516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 8.627 seconds\n",
      "Cross-validation score: 0.4478288680909648\n",
      "Test score: 0.3684210526315789\n",
      "Best Hyperparameters: {}\n",
      "42608.64693221124\n",
      "19871.500897537568\n",
      "39747.19051216252\n",
      "22.814906931715086\n",
      "47.24540195777081\n",
      "9285.405965894694\n",
      "79.30057513527572\n",
      "153.19563517952338\n",
      "173.48018587450497\n",
      "23.368799209594727\n",
      "2.341177335008979\n",
      "34.89628139999695\n",
      "531.3934638297651\n",
      "0.0\n",
      "118.92466987110674\n",
      "0.0\n",
      "555.5493074059486\n",
      "111.12943044304848\n",
      "177.8392009846866\n",
      "110.7118849735707\n",
      "23104.556702136993\n",
      "4680.006585597992\n",
      "3.564275039359927\n",
      "3.848471999168396\n",
      "226.48095677420497\n",
      "0.0\n",
      "267.1515848846175\n",
      "15857.381247468758\n",
      "2802.598868639907\n",
      "479.1498081609607\n",
      "32.71949118375778\n",
      "484.34852242609486\n",
      "361.6873117014766\n",
      "56.59015233628452\n",
      "129.13165074400604\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "47.72566350409761\n",
      "29.33363946992904\n",
      "3039.275676297955\n",
      "315.18442866392434\n",
      "790.3854960487224\n",
      "99.70451168669388\n",
      "729.7474466974381\n",
      "13.1040014680475\n",
      "422.726488979999\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "45.902719784295186\n",
      "6.616619568318129\n",
      "195.24891638197005\n",
      "10.597626618109643\n",
      "13.008000373840332\n",
      "168.77165879076347\n",
      "6316.010706893634\n",
      "8130.367127561942\n",
      "235.04211624222808\n",
      "7345.539633761859\n",
      "31.58909004344605\n",
      "671.051213953644\n",
      "14.754098643083125\n",
      "45.575038366019726\n",
      "0.0393226002342999\n",
      "211.1354836174287\n",
      "10168.278624719707\n",
      "0.0\n",
      "8.058566202875227\n",
      "5669.686366668437\n",
      "5.014762782026082\n",
      "15.970325777539983\n",
      "53356.62291062996\n",
      "0.0\n",
      "0.7513855588622391\n",
      "0.0\n",
      "0.9894369840621948\n",
      "10571.63127823919\n",
      "2.0126557797193527\n",
      "0.37591099739074707\n",
      "181.38043671287596\n",
      "5522.691385125741\n",
      "75.36147186229937\n",
      "12802.829109370708\n",
      "1559.2747978465632\n",
      "73.16819763183594\n",
      "571.7077627368271\n",
      "0.07761339843273163\n",
      "27330.341413343325\n",
      "33.19540023803711\n",
      "2695.536766528152\n",
      "0.0\n",
      "17.949250189587474\n",
      "586.424565476831\n",
      "17.63473841850646\n",
      "4.45823295856826\n",
      "173842.86341058929\n",
      "4.231587886810303\n",
      "11653.195650852285\n",
      "33619.5626362412\n",
      "3.547001587226987\n",
      "45.764952793717384\n",
      "9722.79655267112\n",
      "0.0\n",
      "16.043565049301833\n",
      "3.873036338016391\n",
      "0.0\n",
      "0.0\n",
      "308.1449890136719\n",
      "0.0\n",
      "838.4659329997376\n",
      "0.8520313971675932\n",
      "0.0\n",
      "550.5278871038463\n",
      "3045.382400628645\n",
      "0.0\n",
      "68762.5277312845\n",
      "185.12368794251233\n",
      "0.0\n",
      "609.141847842373\n",
      "7.511326260399073\n",
      "19.407923858147115\n",
      "9.649754870682955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 8.508 seconds\n",
      "Cross-validation score: 0.3909834088180989\n",
      "Test score: 0.4878048780487805\n",
      "Best Hyperparameters: {}\n",
      "19277.793200466054\n",
      "3801.2480355016887\n",
      "2433.4257569704205\n",
      "19.83459572866559\n",
      "505.3685979240108\n",
      "141.08163641527062\n",
      "51.75737887993455\n",
      "14.018725043162704\n",
      "34.67283998336643\n",
      "288.9496304700151\n",
      "16.08793698064983\n",
      "210.42194707936142\n",
      "88.70225470584009\n",
      "0.0\n",
      "285.84425510372967\n",
      "0.0\n",
      "6.645598469302058\n",
      "0.10446214023977518\n",
      "228.96500447485596\n",
      "48.200023628771305\n",
      "876.1628263154998\n",
      "81698.11150639204\n",
      "2.5377910137176514\n",
      "0.49748913245275617\n",
      "0.11270214919932187\n",
      "4.920228717848659\n",
      "23.979755487293005\n",
      "2.166584622580558\n",
      "78.89363231509924\n",
      "60.528057099319994\n",
      "4.163093408569694\n",
      "1048.2944479162106\n",
      "80.77135817264207\n",
      "174.3090056705987\n",
      "100.79082374786958\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "362.8763755109394\n",
      "13.803159393370152\n",
      "36.77075656980742\n",
      "66.38718267553486\n",
      "41.70991993928328\n",
      "31.234377443324775\n",
      "28.815507846185938\n",
      "0.14347320050001144\n",
      "8938.360324102454\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "122.6077156161191\n",
      "7.650285602307122\n",
      "116.2918998520181\n",
      "1.2319150273688138\n",
      "0.0\n",
      "4.15629541547969\n",
      "55.40919267758727\n",
      "2160.5516161620617\n",
      "23.184752474538982\n",
      "2914.3201093967073\n",
      "41.90706873615272\n",
      "26.524177357088774\n",
      "14.929538569864235\n",
      "143.88400268554688\n",
      "15.43521330342628\n",
      "545.4533579852432\n",
      "430.37764101848006\n",
      "0.0\n",
      "4.8222583015449345\n",
      "781.4231165685924\n",
      "2.767542219022289\n",
      "0.7564300000667572\n",
      "126.02431042655371\n",
      "0.0\n",
      "0.2735860012471676\n",
      "0.0\n",
      "7.288150414824486\n",
      "8.812056204595137\n",
      "14.263033328112215\n",
      "0.0\n",
      "0.043987300246953964\n",
      "1982.3402248555794\n",
      "52.00261905742809\n",
      "87.88902665185742\n",
      "9846.606797570828\n",
      "45.740161176770926\n",
      "2.733442008495331\n",
      "0.0\n",
      "10.385444172425196\n",
      "4.545262154191732\n",
      "6.371091122739017\n",
      "192.2050018310547\n",
      "3.831753619015217\n",
      "80.01056952961517\n",
      "122.53099822998047\n",
      "297.5564680697862\n",
      "62.218920779647306\n",
      "81.0636978149414\n",
      "68.38790137763135\n",
      "151.58562884491403\n",
      "0.41954837972298265\n",
      "116.45162130892277\n",
      "28.26427108119242\n",
      "0.0\n",
      "19.43481938773766\n",
      "19.556419786065817\n",
      "0.0\n",
      "0.870203117839992\n",
      "8.52668908238411\n",
      "0.0\n",
      "2617.6616537366062\n",
      "16.287384594557807\n",
      "0.0\n",
      "9.272309824824333\n",
      "529.4989306379284\n",
      "0.0\n",
      "0.38952499628067017\n",
      "79.14407967310399\n",
      "0.0\n",
      "125.91096449736506\n",
      "60.06764323450625\n",
      "70.88231825991534\n",
      "5.48460094712209\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "\n",
    "#Import feature selection stuff\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "\n",
    "# Import the model we are using\n",
    "import lightgbm as lgb\n",
    "\n",
    "none_lightgbm_performance_normalized_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "\n",
    "    ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized,\n",
    "                                                    labels_normalized,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels_normalized)\n",
    "\n",
    "\n",
    "    LightGBMPipeline = Pipeline(steps = [#['smote', SMOTE(sampling_strategy = 0.5, n_jobs=2)],\n",
    "                                    #['under', RandomUnderSampler()],\n",
    "                                ['classifier', lgb.LGBMClassifier(n_jobs=-1, importance_type='gain')]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "# define search space\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    spaceEmpty = dict()\n",
    "    space['classifier__num_leaves'] = [11, 16, 21, 26, 31, 36, 41, 46, 51, 56]\n",
    "    space['classifier__min_data_in_leaf'] =  [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__max_depth'] = [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__learning_rate'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9, 1.0]\n",
    "    space['classifier__max_bin'] = [50, 100, 150, 200, 255, 300, 350, 400, 450, 500]\n",
    "\n",
    "    LightGBMSearch = RandomizedSearchCV(estimator = LightGBMPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring= ftwo_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedLightGBMModel = LightGBMSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedLightGBMModel.best_score_\n",
    "    test_score = optimizedLightGBMModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedLightGBMModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedLightGBMModel.best_estimator_._final_estimator.booster_.feature_importance(importance_type='gain')\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedLightGBMModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    none_lightgbm_performance_normalized_df = pd.concat([none_lightgbm_performance_normalized_df, new_performance_df])\n",
    "    \n",
    "\n",
    "none_lightgbm_performance_normalized_df.to_csv(\"../data/05_model_output/none_lightgbm_performance_normalized_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-addition",
   "metadata": {},
   "source": [
    "## 4.2 Rebalancing Strategy - SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-nashville",
   "metadata": {},
   "source": [
    "### 4.2.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "hispanic-native",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "smote_randomforest_normalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized,\n",
    "                                                    labels_normalized,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels_normalized)\n",
    "\n",
    "\n",
    "    pipeline = Pipeline(steps = [['smote', SMOTE()],\n",
    "                              #['under', RandomUnderSampler()],\n",
    "                                ['classifier', RandomForestClassifier(n_jobs=-1)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    spaceEmpty = dict() \n",
    "\n",
    "    search = RandomizedSearchCV(estimator = pipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring='f1', \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedRFModel = search.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    #print(f\"Elapsed time to compute best fit: \"\n",
    "      #f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedRFModel.best_score_\n",
    "    test_score = optimizedRFModel.score(X_test, y_test)\n",
    "    #print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    #print('Best Hyperparameters: %s' % optimizedRFModel.best_params_)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedRFModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    \n",
    "    smote_randomforest_normalized_performance_df = pd.concat([smote_randomforest_normalized_performance_df, new_performance_df])\n",
    "    \n",
    "smote_randomforest_normalized_performance_df.to_csv(\"../data/05_model_output/smote_randomforest_normalized_performance_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-accessory",
   "metadata": {},
   "source": [
    "### 4.2.3 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "complex-aquatic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:28:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 171.558 seconds\n",
      "Cross-validation score: 0.6829939371865903\n",
      "Test score: 0.5376344086021505\n",
      "Best Hyperparameters: {}\n",
      "0.0012632151\n",
      "0.0026860863\n",
      "0.21351153\n",
      "0.0012933743\n",
      "0.007498932\n",
      "0.00335979\n",
      "0.00010213029\n",
      "0.004531991\n",
      "0.0014391512\n",
      "0.00747503\n",
      "0.011523111\n",
      "0.017502245\n",
      "0.0012311807\n",
      "0.0\n",
      "0.0015607664\n",
      "0.0\n",
      "0.0016828056\n",
      "0.0\n",
      "4.013467e-05\n",
      "0.000101640566\n",
      "0.0020916879\n",
      "0.0013208446\n",
      "0.0021349944\n",
      "0.007486115\n",
      "0.00040294733\n",
      "0.00018696218\n",
      "0.0007930987\n",
      "0.0\n",
      "0.0006565838\n",
      "0.0006227448\n",
      "0.00024765483\n",
      "0.006991868\n",
      "0.0027575304\n",
      "0.0016260133\n",
      "0.0015202677\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0038348327\n",
      "0.041022137\n",
      "0.002458049\n",
      "0.0013259711\n",
      "0.0008312207\n",
      "0.008222012\n",
      "0.009213648\n",
      "0.01026367\n",
      "0.006267072\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0004430507\n",
      "0.00019737265\n",
      "0.0025648407\n",
      "0.0\n",
      "0.0\n",
      "0.004833041\n",
      "0.027205873\n",
      "0.00024191258\n",
      "0.0002800438\n",
      "0.020501468\n",
      "0.020448305\n",
      "0.008618679\n",
      "0.00023236763\n",
      "0.0010046936\n",
      "0.0013657542\n",
      "0.000931295\n",
      "0.00027058867\n",
      "0.00037398798\n",
      "0.0\n",
      "0.0015910923\n",
      "0.0029364163\n",
      "0.000106747684\n",
      "0.11063352\n",
      "0.0011928573\n",
      "0.13221534\n",
      "0.0\n",
      "0.004422908\n",
      "0.010312678\n",
      "0.0024693736\n",
      "0.00087578065\n",
      "0.00047903843\n",
      "0.011747296\n",
      "0.0021265468\n",
      "0.0030153345\n",
      "0.08663204\n",
      "9.4052615e-05\n",
      "0.0011052435\n",
      "0.00019190543\n",
      "0.00017948599\n",
      "0.0005575374\n",
      "0.0008113776\n",
      "0.0\n",
      "0.00046466553\n",
      "0.022529911\n",
      "0.00024803143\n",
      "0.00014833844\n",
      "0.0005421702\n",
      "0.0\n",
      "0.0026671041\n",
      "0.029972179\n",
      "0.007835246\n",
      "6.3395346e-05\n",
      "0.00016625828\n",
      "0.0\n",
      "0.010787787\n",
      "0.00016197548\n",
      "0.0\n",
      "0.0012638537\n",
      "0.0011484621\n",
      "0.0\n",
      "0.002200311\n",
      "0.021834247\n",
      "0.0\n",
      "0.0019834838\n",
      "0.020702934\n",
      "0.0\n",
      "0.00069801736\n",
      "0.002737261\n",
      "0.0\n",
      "0.00033903928\n",
      "0.00033486742\n",
      "0.00048263406\n",
      "0.018396864\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997621   0.526316  0.588235  0.555556  0.574713  0.537634   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.310638  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:30:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 163.937 seconds\n",
      "Cross-validation score: 0.7104039208559904\n",
      "Test score: 0.7971014492753623\n",
      "Best Hyperparameters: {}\n",
      "0.011157926\n",
      "0.018490335\n",
      "0.23179235\n",
      "0.0034348876\n",
      "0.06509443\n",
      "0.019928433\n",
      "0.0071628606\n",
      "0.00068076106\n",
      "0.00021643934\n",
      "0.001432767\n",
      "0.02063085\n",
      "0.019780718\n",
      "0.0\n",
      "0.0\n",
      "5.4429256e-05\n",
      "0.0\n",
      "0.026073558\n",
      "0.00086721056\n",
      "0.0037270454\n",
      "1.7057542e-05\n",
      "0.00075876224\n",
      "0.0011308693\n",
      "0.0028333154\n",
      "0.025954852\n",
      "0.0010750202\n",
      "0.0\n",
      "5.189227e-05\n",
      "0.0001555719\n",
      "0.00037689132\n",
      "0.024593482\n",
      "7.105544e-05\n",
      "0.0027398155\n",
      "0.0034097338\n",
      "0.00088419946\n",
      "0.0075677135\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0020656083\n",
      "0.053948827\n",
      "0.0064349035\n",
      "0.0017347098\n",
      "0.006558943\n",
      "0.003327324\n",
      "0.0026384199\n",
      "0.0015947993\n",
      "0.0013087732\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00045524107\n",
      "0.0013996896\n",
      "0.00049331615\n",
      "0.00015463591\n",
      "0.00028194537\n",
      "0.0\n",
      "0.008477716\n",
      "0.0053675105\n",
      "5.325359e-06\n",
      "0.0070933793\n",
      "0.0064643165\n",
      "0.0034371482\n",
      "0.023890574\n",
      "0.00010020094\n",
      "0.0012474457\n",
      "0.0030462341\n",
      "0.0019970548\n",
      "0.0009029932\n",
      "0.0009380542\n",
      "0.0015332452\n",
      "0.0008579856\n",
      "0.00022214474\n",
      "0.05820913\n",
      "0.0\n",
      "0.00019176627\n",
      "0.0\n",
      "0.00077225466\n",
      "0.0064384146\n",
      "0.0024372193\n",
      "4.430321e-05\n",
      "0.0006584164\n",
      "0.04648549\n",
      "0.025849374\n",
      "0.004893367\n",
      "0.0072847493\n",
      "0.0050435066\n",
      "0.008315917\n",
      "0.00016666042\n",
      "0.0017000458\n",
      "0.00041005522\n",
      "0.00861639\n",
      "0.0\n",
      "0.002346122\n",
      "0.02661874\n",
      "0.0017581946\n",
      "0.00017947632\n",
      "0.041889913\n",
      "0.0\n",
      "0.004209186\n",
      "0.036795918\n",
      "0.0020963459\n",
      "3.9650236e-05\n",
      "0.007062558\n",
      "0.0\n",
      "0.00025446442\n",
      "0.00017087325\n",
      "0.0\n",
      "0.00038727143\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.019071465\n",
      "0.0\n",
      "0.0040364894\n",
      "0.011282515\n",
      "0.0\n",
      "0.00046172368\n",
      "0.0058160815\n",
      "0.0\n",
      "0.0010988507\n",
      "0.00049099245\n",
      "0.0035813663\n",
      "0.0027109513\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998811   0.846154  0.647059  0.733333  0.679012  0.797101   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.548403  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:33:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 164.983 seconds\n",
      "Cross-validation score: 0.7319978729259757\n",
      "Test score: 0.7058823529411765\n",
      "Best Hyperparameters: {}\n",
      "0.013643945\n",
      "0.056364343\n",
      "0.18806452\n",
      "0.002695596\n",
      "0.022772176\n",
      "0.0010303314\n",
      "0.0027918406\n",
      "0.0\n",
      "0.0\n",
      "0.00046790775\n",
      "0.011737842\n",
      "0.013948659\n",
      "0.0\n",
      "0.0\n",
      "0.01556035\n",
      "0.0\n",
      "0.006728285\n",
      "0.00036595573\n",
      "0.003748533\n",
      "0.020487474\n",
      "0.000432512\n",
      "0.0004712439\n",
      "0.008857213\n",
      "0.0018746811\n",
      "8.744141e-05\n",
      "0.00010626595\n",
      "0.0\n",
      "4.827974e-05\n",
      "0.0016064642\n",
      "0.0032466636\n",
      "0.0002276529\n",
      "0.0021767218\n",
      "0.001894756\n",
      "0.0028141045\n",
      "0.006525116\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0009319895\n",
      "0.024223464\n",
      "0.00700873\n",
      "0.0018410715\n",
      "0.000524911\n",
      "0.002811042\n",
      "0.0035219775\n",
      "0.0010058342\n",
      "0.0056953114\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0006869894\n",
      "0.0014407763\n",
      "0.00049388054\n",
      "0.00040687594\n",
      "0.0\n",
      "0.0014976287\n",
      "0.0005483194\n",
      "0.00068824826\n",
      "0.0012497628\n",
      "0.009788587\n",
      "0.012182653\n",
      "0.013659434\n",
      "0.00017614367\n",
      "0.0\n",
      "0.00058492244\n",
      "0.00024028569\n",
      "0.0016558355\n",
      "9.516592e-05\n",
      "0.0010919005\n",
      "0.0019504846\n",
      "0.041084964\n",
      "0.00080708996\n",
      "0.110581435\n",
      "0.00039871447\n",
      "0.0028017329\n",
      "0.0\n",
      "0.0\n",
      "0.0071845246\n",
      "0.010551313\n",
      "0.0008720208\n",
      "0.0003003497\n",
      "0.0017718084\n",
      "0.02785285\n",
      "0.0061850757\n",
      "0.017155966\n",
      "0.001956217\n",
      "0.0022762248\n",
      "0.005931828\n",
      "0.0013890641\n",
      "8.409348e-05\n",
      "0.06499882\n",
      "0.0\n",
      "0.0052768355\n",
      "0.020699952\n",
      "0.00074492564\n",
      "0.0034433492\n",
      "0.0051811957\n",
      "0.0\n",
      "0.0022811713\n",
      "0.07918504\n",
      "0.0072677587\n",
      "0.0\n",
      "0.004412559\n",
      "0.0\n",
      "0.00093462085\n",
      "0.00043533323\n",
      "0.0\n",
      "0.011249123\n",
      "0.0001791829\n",
      "0.0\n",
      "0.004552058\n",
      "0.018487373\n",
      "0.0\n",
      "0.004972562\n",
      "0.014853811\n",
      "0.0\n",
      "0.00051119353\n",
      "0.0014784831\n",
      "0.0\n",
      "0.0006504594\n",
      "0.016037824\n",
      "0.00040033265\n",
      "0.005801674\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998513   0.705882  0.705882  0.705882  0.705882  0.705882   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.499013  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:36:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 176.324 seconds\n",
      "Cross-validation score: 0.6866785051642966\n",
      "Test score: 0.6470588235294119\n",
      "Best Hyperparameters: {}\n",
      "0.0012242434\n",
      "0.0023637041\n",
      "0.22454922\n",
      "0.0012913293\n",
      "0.009094653\n",
      "6.542515e-05\n",
      "0.00038629211\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.020965708\n",
      "0.014263156\n",
      "0.0065247705\n",
      "0.0\n",
      "0.0025746508\n",
      "0.0\n",
      "0.0027175555\n",
      "0.00026975834\n",
      "0.0\n",
      "0.10680144\n",
      "0.00020388757\n",
      "0.00024300255\n",
      "0.0029247862\n",
      "0.0022796048\n",
      "0.0013164446\n",
      "0.0\n",
      "0.0014023208\n",
      "7.2951384e-06\n",
      "0.000115828334\n",
      "0.00071612955\n",
      "0.00032489435\n",
      "0.0051432815\n",
      "0.0011280503\n",
      "0.0033024033\n",
      "0.004086172\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0031142237\n",
      "0.037643\n",
      "0.0122552095\n",
      "0.00043878713\n",
      "0.0007902184\n",
      "0.0061298404\n",
      "0.0010689938\n",
      "0.0005381937\n",
      "0.012153267\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0007199805\n",
      "0.003161383\n",
      "0.0005291564\n",
      "0.0015848647\n",
      "0.001530304\n",
      "0.0\n",
      "0.0031361016\n",
      "0.003295708\n",
      "0.0005874213\n",
      "0.007532723\n",
      "0.0057336255\n",
      "0.018625734\n",
      "0.0006024569\n",
      "0.00025402717\n",
      "0.0016183935\n",
      "6.692757e-05\n",
      "3.135281e-05\n",
      "0.008510174\n",
      "0.0043304274\n",
      "0.0041932943\n",
      "0.03220889\n",
      "0.002300228\n",
      "0.14015442\n",
      "0.00040868006\n",
      "0.00014549751\n",
      "0.0\n",
      "0.0\n",
      "0.0069629163\n",
      "0.020015191\n",
      "0.00036481177\n",
      "0.0006417623\n",
      "0.008247937\n",
      "0.0057166764\n",
      "0.0008395788\n",
      "0.010918438\n",
      "0.00021483806\n",
      "0.0032426177\n",
      "0.008634786\n",
      "0.005631791\n",
      "0.0\n",
      "0.00021042684\n",
      "0.0\n",
      "0.00074877485\n",
      "0.020807406\n",
      "0.016619425\n",
      "2.00668e-05\n",
      "0.0004613031\n",
      "0.0\n",
      "0.0047992053\n",
      "0.075149775\n",
      "0.0024275347\n",
      "0.0\n",
      "0.0022248612\n",
      "0.0\n",
      "0.0056548608\n",
      "0.001157787\n",
      "0.0\n",
      "0.016793635\n",
      "0.0\n",
      "0.0\n",
      "0.00038413197\n",
      "0.011755579\n",
      "0.0\n",
      "0.0032634137\n",
      "0.009364198\n",
      "0.0\n",
      "0.00026753888\n",
      "0.00038172217\n",
      "0.0\n",
      "0.00043484676\n",
      "0.0165338\n",
      "0.0012992785\n",
      "0.00612963\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998216   0.647059  0.647059  0.647059  0.647059  0.647059   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.419577  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:39:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 159.139 seconds\n",
      "Cross-validation score: 0.7749413365039138\n",
      "Test score: 0.5504587155963303\n",
      "Best Hyperparameters: {}\n",
      "0.0076431218\n",
      "0.013276364\n",
      "0.24518722\n",
      "0.0011157411\n",
      "0.025268937\n",
      "0.016097285\n",
      "0.001108968\n",
      "0.0010442869\n",
      "0.00045875815\n",
      "0.0006145394\n",
      "0.007881338\n",
      "6.1844104e-05\n",
      "0.00034549646\n",
      "0.0\n",
      "0.00054999033\n",
      "0.0\n",
      "0.0077029597\n",
      "7.3904805e-05\n",
      "0.0007603867\n",
      "0.0005686502\n",
      "0.00027749187\n",
      "0.00066386716\n",
      "0.0013971005\n",
      "0.0549582\n",
      "0.0093496125\n",
      "0.006899382\n",
      "1.111576e-06\n",
      "0.00057205267\n",
      "0.0101761585\n",
      "0.0047519417\n",
      "0.0001322216\n",
      "0.0017131792\n",
      "0.004590817\n",
      "0.0009108182\n",
      "0.0026635753\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00048201001\n",
      "0.029686889\n",
      "0.0039493022\n",
      "0.0013336382\n",
      "0.001957217\n",
      "0.0027322175\n",
      "0.0006574952\n",
      "0.0027558645\n",
      "0.0044718264\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0012745573\n",
      "0.0023921323\n",
      "0.00052368216\n",
      "0.00019923034\n",
      "0.0\n",
      "0.0008844494\n",
      "0.0010707182\n",
      "0.0014396872\n",
      "0.011629831\n",
      "0.043095995\n",
      "0.0025567552\n",
      "0.0013429524\n",
      "0.0003562689\n",
      "3.4937322e-05\n",
      "0.00011738548\n",
      "4.4780412e-05\n",
      "5.163489e-05\n",
      "0.0028096412\n",
      "0.003146378\n",
      "0.003951558\n",
      "0.0018402413\n",
      "0.0016601196\n",
      "0.06346387\n",
      "0.0051187803\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.008562631\n",
      "0.004463715\n",
      "0.0014439119\n",
      "0.023305275\n",
      "0.0063796146\n",
      "0.0044687456\n",
      "0.046247054\n",
      "0.0148236975\n",
      "0.00045912748\n",
      "0.0027970956\n",
      "0.00045354257\n",
      "5.7197096e-05\n",
      "0.0\n",
      "0.0041625574\n",
      "0.0\n",
      "0.0012696121\n",
      "0.01638841\n",
      "0.0031368448\n",
      "0.0038634134\n",
      "0.04590345\n",
      "0.0\n",
      "0.0023936597\n",
      "0.046907187\n",
      "0.008549076\n",
      "0.00023889485\n",
      "0.00064712984\n",
      "0.0\n",
      "0.001500244\n",
      "0.0015076799\n",
      "0.0\n",
      "0.012483558\n",
      "0.0\n",
      "0.0\n",
      "0.0017249899\n",
      "0.018218307\n",
      "0.0\n",
      "0.00855902\n",
      "0.056378752\n",
      "0.0\n",
      "0.0011769596\n",
      "0.004357398\n",
      "0.0\n",
      "0.0014283558\n",
      "0.00021875706\n",
      "0.007834611\n",
      "0.011840211\n",
      "   Accuracy  Precision    Recall   F1        F2      F0.5  Average Precision\n",
      "0  0.997621   0.521739  0.705882  0.6  0.659341  0.550459            0.36903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:41:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 155.094 seconds\n",
      "Cross-validation score: 0.757444760593059\n",
      "Test score: 0.5194805194805195\n",
      "Best Hyperparameters: {}\n",
      "0.010835961\n",
      "0.02880401\n",
      "0.30166465\n",
      "0.0020007326\n",
      "0.0053446274\n",
      "0.00010896732\n",
      "0.00080234534\n",
      "0.00033407044\n",
      "0.001700724\n",
      "0.0048831687\n",
      "0.0052155894\n",
      "0.003544738\n",
      "0.00012992424\n",
      "0.0\n",
      "0.0060554002\n",
      "0.0\n",
      "0.0007538506\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0006663445\n",
      "0.00026133825\n",
      "0.0033744038\n",
      "0.000483404\n",
      "0.0027564168\n",
      "0.00018436549\n",
      "0.0006951678\n",
      "0.0013222661\n",
      "0.00017376283\n",
      "0.00042938447\n",
      "0.00025521175\n",
      "0.0018267578\n",
      "0.0081132585\n",
      "0.0030591397\n",
      "0.006986633\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.013227204\n",
      "0.008277743\n",
      "0.0044483184\n",
      "0.00094815256\n",
      "2.8988641e-05\n",
      "0.0006449918\n",
      "0.002052152\n",
      "0.00049940357\n",
      "0.0032371068\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0020530603\n",
      "0.0003177395\n",
      "0.00031457533\n",
      "0.0009927896\n",
      "0.00091646\n",
      "0.00012675957\n",
      "0.0017990462\n",
      "0.012829889\n",
      "0.0001460889\n",
      "0.0075041372\n",
      "0.0127702365\n",
      "0.0013566755\n",
      "0.0\n",
      "0.00019806465\n",
      "0.003039703\n",
      "0.00084240665\n",
      "0.00021801311\n",
      "0.0\n",
      "0.0017652597\n",
      "0.00040467\n",
      "0.0057541598\n",
      "7.399129e-05\n",
      "0.08914538\n",
      "0.002915232\n",
      "0.000259308\n",
      "0.0\n",
      "0.0021515528\n",
      "0.011479276\n",
      "0.0060839187\n",
      "0.00010749336\n",
      "0.00032896054\n",
      "0.097141005\n",
      "0.037810758\n",
      "0.0036109667\n",
      "0.02727053\n",
      "0.00060310314\n",
      "0.0035004988\n",
      "0.00011653758\n",
      "3.5659836e-05\n",
      "0.00010277101\n",
      "0.005477256\n",
      "0.0005292792\n",
      "0.0016984954\n",
      "0.015279219\n",
      "0.0014595444\n",
      "0.00017257775\n",
      "0.050621983\n",
      "0.0\n",
      "0.022093168\n",
      "0.024923222\n",
      "0.018736286\n",
      "0.00025712387\n",
      "0.0011751505\n",
      "0.0\n",
      "0.0015424476\n",
      "0.00014985172\n",
      "0.0\n",
      "0.01431153\n",
      "8.255799e-05\n",
      "0.0\n",
      "0.001095366\n",
      "0.037630513\n",
      "0.0\n",
      "0.0003190035\n",
      "0.011550641\n",
      "0.0\n",
      "0.0014106001\n",
      "0.002236734\n",
      "0.0\n",
      "0.006381079\n",
      "0.0002135494\n",
      "0.0033170832\n",
      "0.005118398\n",
      "   Accuracy  Precision    Recall   F1        F2      F0.5  Average Precision\n",
      "0  0.997621   0.533333  0.470588  0.5  0.481928  0.519481           0.252318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:44:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 167.312 seconds\n",
      "Cross-validation score: 0.6993083276393233\n",
      "Test score: 0.8235294117647058\n",
      "Best Hyperparameters: {}\n",
      "0.019683499\n",
      "0.05057385\n",
      "0.19740346\n",
      "0.0024159977\n",
      "0.02636961\n",
      "0.007867991\n",
      "0.0014258219\n",
      "0.0\n",
      "0.0004232656\n",
      "0.000929463\n",
      "0.013201684\n",
      "0.0015186119\n",
      "0.00029958895\n",
      "0.0\n",
      "0.0004366235\n",
      "0.0\n",
      "0.00037213095\n",
      "0.0007255813\n",
      "0.0017714631\n",
      "0.00021087182\n",
      "0.0005190813\n",
      "0.0016997702\n",
      "0.005457236\n",
      "0.0014185514\n",
      "0.0003448831\n",
      "0.0\n",
      "0.0006518351\n",
      "0.0036708647\n",
      "0.00011862275\n",
      "0.0005106709\n",
      "0.0015590453\n",
      "0.00075797125\n",
      "0.0012656687\n",
      "0.0010796797\n",
      "0.0006879573\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0024967557\n",
      "0.061568983\n",
      "0.013187214\n",
      "0.002545549\n",
      "0.0014139983\n",
      "0.0006548275\n",
      "0.004677866\n",
      "0.0028808848\n",
      "0.022116464\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00039481817\n",
      "0.0011062543\n",
      "0.00024353612\n",
      "0.0004410275\n",
      "0.0\n",
      "0.00023854012\n",
      "0.028988\n",
      "0.0015585073\n",
      "0.0038288385\n",
      "0.008007306\n",
      "0.009291061\n",
      "0.0052045053\n",
      "1.0571625e-05\n",
      "0.0\n",
      "0.0015309873\n",
      "0.00012879811\n",
      "0.00020152376\n",
      "0.0\n",
      "0.0034938988\n",
      "0.0005984684\n",
      "0.0017720795\n",
      "0.000111414876\n",
      "0.10406253\n",
      "0.0\n",
      "0.00095021055\n",
      "0.0\n",
      "0.0\n",
      "0.009813075\n",
      "0.0011844687\n",
      "0.0031417992\n",
      "0.002959542\n",
      "0.015392254\n",
      "0.02235416\n",
      "0.009037012\n",
      "0.05454726\n",
      "0.013588704\n",
      "0.005292396\n",
      "0.00079254573\n",
      "0.00025429123\n",
      "0.0026150055\n",
      "0.088782646\n",
      "0.0\n",
      "0.0014118052\n",
      "0.026502252\n",
      "0.0010590884\n",
      "0.0005013492\n",
      "0.0010487732\n",
      "0.0\n",
      "0.0029758227\n",
      "0.02755266\n",
      "0.007975785\n",
      "7.937522e-05\n",
      "0.0014052802\n",
      "0.0\n",
      "0.015150158\n",
      "0.00024539357\n",
      "0.0\n",
      "0.0025887867\n",
      "0.0005927173\n",
      "0.0\n",
      "0.00023918996\n",
      "0.01846318\n",
      "0.0\n",
      "0.0049143517\n",
      "0.011352299\n",
      "0.0\n",
      "0.00067010924\n",
      "0.007048944\n",
      "0.0\n",
      "0.0011407849\n",
      "0.004545434\n",
      "0.0008078078\n",
      "0.0028966938\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.999108   0.823529  0.823529  0.823529  0.823529  0.823529   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.678647  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:47:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 156.193 seconds\n",
      "Cross-validation score: 0.704498667870425\n",
      "Test score: 0.5797101449275363\n",
      "Best Hyperparameters: {}\n",
      "0.014265009\n",
      "0.0636156\n",
      "0.1754567\n",
      "0.0009700424\n",
      "0.06128678\n",
      "0.0024415222\n",
      "0.00040481248\n",
      "0.0019889562\n",
      "0.0032605669\n",
      "0.000986417\n",
      "0.019814277\n",
      "0.00046665376\n",
      "0.0\n",
      "0.0\n",
      "0.0017832505\n",
      "0.0\n",
      "0.023532275\n",
      "0.0\n",
      "0.06177144\n",
      "0.002726712\n",
      "0.003538386\n",
      "0.00021279667\n",
      "0.013409089\n",
      "0.00051283755\n",
      "0.0002981815\n",
      "0.00040840427\n",
      "0.056902587\n",
      "0.0013328496\n",
      "0.00022943839\n",
      "0.0034502964\n",
      "0.00024737464\n",
      "0.00076772633\n",
      "0.0008789106\n",
      "0.0023519595\n",
      "0.0014617381\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0039254855\n",
      "0.04279853\n",
      "0.0024876085\n",
      "0.003240601\n",
      "0.0013341403\n",
      "0.0087447185\n",
      "0.00057550496\n",
      "0.0011929794\n",
      "0.0013335947\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0015369206\n",
      "0.0007190431\n",
      "0.00026685485\n",
      "0.0002254673\n",
      "0.00030115808\n",
      "0.00021709102\n",
      "0.013228998\n",
      "0.002631764\n",
      "0.0044496018\n",
      "0.003804747\n",
      "0.0086597605\n",
      "0.0036330034\n",
      "0.00039219548\n",
      "0.00013249945\n",
      "0.0004910174\n",
      "0.00015926616\n",
      "8.509884e-05\n",
      "0.0\n",
      "0.0\n",
      "0.049966965\n",
      "0.006328994\n",
      "0.0\n",
      "0.024941716\n",
      "0.00050222914\n",
      "0.0009979985\n",
      "0.0\n",
      "0.0009917406\n",
      "0.0046168608\n",
      "0.014242102\n",
      "0.0013119931\n",
      "5.571107e-05\n",
      "0.012270709\n",
      "0.05382002\n",
      "0.0013995869\n",
      "0.033135206\n",
      "0.0026699903\n",
      "0.008656728\n",
      "0.0\n",
      "0.00023381591\n",
      "0.0005934131\n",
      "0.059855863\n",
      "0.0\n",
      "0.0016400296\n",
      "0.010398243\n",
      "0.0002590046\n",
      "0.0016176006\n",
      "0.0034913241\n",
      "0.0\n",
      "0.0024236334\n",
      "0.01736335\n",
      "0.004173739\n",
      "4.9084283e-05\n",
      "0.00039497766\n",
      "0.0\n",
      "0.0047381045\n",
      "0.00023506607\n",
      "0.0\n",
      "0.0\n",
      "0.010628855\n",
      "0.0\n",
      "0.0010904565\n",
      "0.011394193\n",
      "0.0\n",
      "0.0010217339\n",
      "0.012010781\n",
      "0.0\n",
      "0.00066549896\n",
      "0.006835473\n",
      "0.0\n",
      "0.00015985614\n",
      "0.00053756364\n",
      "0.0013337482\n",
      "0.0036047045\n",
      "   Accuracy  Precision    Recall        F1        F2     F0.5  \\\n",
      "0  0.997919   0.615385  0.470588  0.533333  0.493827  0.57971   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.290931  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:50:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 169.962 seconds\n",
      "Cross-validation score: 0.7236825070552095\n",
      "Test score: 0.7792207792207791\n",
      "Best Hyperparameters: {}\n",
      "0.007400464\n",
      "0.04062427\n",
      "0.19127932\n",
      "0.0015128795\n",
      "0.026946472\n",
      "0.008015093\n",
      "0.0\n",
      "0.000895075\n",
      "0.00024749618\n",
      "0.0009899542\n",
      "0.0059941728\n",
      "0.0037194903\n",
      "4.6926125e-05\n",
      "0.0\n",
      "0.0001899323\n",
      "0.0\n",
      "0.020370543\n",
      "0.0001215678\n",
      "0.0012286203\n",
      "4.3529162e-05\n",
      "0.0003760278\n",
      "0.0012074453\n",
      "0.005993031\n",
      "0.010250601\n",
      "0.0025781146\n",
      "0.0031761075\n",
      "0.0003722101\n",
      "0.0006593478\n",
      "0.0007576594\n",
      "0.0004419008\n",
      "0.00042351676\n",
      "0.00064687734\n",
      "0.0013354085\n",
      "0.0009044342\n",
      "0.0009556451\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0031253959\n",
      "0.009179933\n",
      "0.004337828\n",
      "0.0032944183\n",
      "0.0013707726\n",
      "0.011967231\n",
      "0.0017780676\n",
      "0.0021732117\n",
      "0.0065140054\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0006505035\n",
      "0.0012797972\n",
      "0.00032670575\n",
      "0.00056366494\n",
      "0.0003491224\n",
      "0.0\n",
      "0.006816286\n",
      "0.0012646724\n",
      "0.00027298622\n",
      "0.012160964\n",
      "0.011202006\n",
      "0.007810002\n",
      "0.0018394565\n",
      "0.0007155893\n",
      "0.00091937213\n",
      "0.0008269143\n",
      "0.0009221454\n",
      "0.0\n",
      "8.244995e-05\n",
      "0.0036478355\n",
      "0.02516005\n",
      "8.739159e-05\n",
      "0.107261986\n",
      "0.007907916\n",
      "0.0007246576\n",
      "0.0\n",
      "0.00077924243\n",
      "0.005507795\n",
      "0.0067044003\n",
      "0.015041701\n",
      "0.00017257039\n",
      "0.08991284\n",
      "0.029282374\n",
      "0.0022628526\n",
      "0.0064411317\n",
      "0.0015183949\n",
      "0.009039534\n",
      "0.0004651058\n",
      "0.00061896595\n",
      "0.0019593958\n",
      "0.04776228\n",
      "0.0023329773\n",
      "0.0062613036\n",
      "0.023314256\n",
      "0.00026389182\n",
      "0.00064804655\n",
      "0.0010771926\n",
      "0.00031299607\n",
      "0.0027773925\n",
      "0.033719555\n",
      "0.008086665\n",
      "6.337727e-05\n",
      "0.00053069985\n",
      "0.0\n",
      "0.0046297214\n",
      "0.0002021934\n",
      "0.0\n",
      "0.0052951486\n",
      "0.00031281\n",
      "0.0\n",
      "0.0003340903\n",
      "0.016702155\n",
      "0.0\n",
      "0.0012830199\n",
      "0.025260258\n",
      "0.0\n",
      "0.00071139255\n",
      "0.00995457\n",
      "0.0\n",
      "0.0013336987\n",
      "0.036514826\n",
      "0.0013607692\n",
      "0.023010818\n",
      "   Accuracy  Precision    Recall    F1        F2      F0.5  Average Precision\n",
      "0  0.998811        0.8  0.705882  0.75  0.722892  0.779221           0.565449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:52:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 159.532 seconds\n",
      "Cross-validation score: 0.7007469700316825\n",
      "Test score: 0.7407407407407408\n",
      "Best Hyperparameters: {}\n",
      "0.009003203\n",
      "0.12403091\n",
      "0.17472206\n",
      "0.0019273749\n",
      "0.021348007\n",
      "0.026618682\n",
      "0.0013796622\n",
      "0.00014614227\n",
      "0.001928089\n",
      "0.0005856636\n",
      "0.005457681\n",
      "0.032078978\n",
      "0.005585317\n",
      "0.0\n",
      "0.0052368515\n",
      "0.0\n",
      "0.012157777\n",
      "0.0\n",
      "0.0\n",
      "0.00036479544\n",
      "0.00026604475\n",
      "2.7858863e-05\n",
      "0.0042191553\n",
      "0.0\n",
      "0.016746338\n",
      "0.0\n",
      "0.0009726098\n",
      "0.0024164876\n",
      "0.0015447786\n",
      "0.0012249292\n",
      "0.00039948843\n",
      "0.0033288298\n",
      "0.0008756016\n",
      "0.0024560222\n",
      "0.0012355773\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.009468633\n",
      "0.05948573\n",
      "0.0016963558\n",
      "0.0005101266\n",
      "0.00884617\n",
      "0.005667561\n",
      "0.0012881735\n",
      "0.00047595118\n",
      "0.0032026616\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0012849269\n",
      "0.004761287\n",
      "0.0002015388\n",
      "0.0008226762\n",
      "6.449994e-05\n",
      "0.0\n",
      "0.004471002\n",
      "0.0023920042\n",
      "0.0003161318\n",
      "0.01021012\n",
      "0.0064510023\n",
      "0.008859868\n",
      "6.7476496e-05\n",
      "0.0\n",
      "0.005653501\n",
      "0.0007112382\n",
      "0.004086054\n",
      "0.0\n",
      "0.00096829626\n",
      "0.0006976933\n",
      "0.0020383492\n",
      "0.0033606046\n",
      "0.094668694\n",
      "0.0\n",
      "0.00029077055\n",
      "0.0\n",
      "0.00010809041\n",
      "0.0070253657\n",
      "0.0031346837\n",
      "0.011349672\n",
      "0.0012004953\n",
      "0.017963985\n",
      "0.026269954\n",
      "0.0016440687\n",
      "0.011545605\n",
      "0.0036650756\n",
      "0.0010147244\n",
      "0.0077762757\n",
      "0.002096947\n",
      "1.2937131e-05\n",
      "0.002974784\n",
      "0.0\n",
      "0.00040201217\n",
      "0.019444114\n",
      "0.00047391525\n",
      "0.0016252841\n",
      "0.039249517\n",
      "0.0\n",
      "0.001673698\n",
      "0.062300388\n",
      "0.005095193\n",
      "0.0009431546\n",
      "0.0023921102\n",
      "0.0\n",
      "0.02418028\n",
      "0.00030169386\n",
      "0.0\n",
      "0.0053003235\n",
      "0.00034967015\n",
      "0.0\n",
      "8.9625464e-05\n",
      "0.018749475\n",
      "0.0\n",
      "0.0029217636\n",
      "0.00633619\n",
      "0.0\n",
      "0.00042679333\n",
      "0.0038107238\n",
      "0.0\n",
      "0.001058664\n",
      "0.0004617186\n",
      "0.0013221197\n",
      "0.002004913\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998662       0.75  0.705882  0.727273  0.714286  0.740741   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.530155  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:55:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 155.318 seconds\n",
      "Cross-validation score: 0.7588577372994588\n",
      "Test score: 0.8163265306122449\n",
      "Best Hyperparameters: {}\n",
      "0.025761154\n",
      "0.06840255\n",
      "0.19122203\n",
      "0.002219155\n",
      "0.017485125\n",
      "0.0016800048\n",
      "0.00018707603\n",
      "0.0009755887\n",
      "0.00013881498\n",
      "7.4029704e-05\n",
      "0.0047929143\n",
      "0.006828228\n",
      "0.0\n",
      "0.0\n",
      "0.004109274\n",
      "0.0\n",
      "0.023478268\n",
      "4.528798e-05\n",
      "0.0\n",
      "0.0015937894\n",
      "0.010251414\n",
      "0.0\n",
      "0.0022472695\n",
      "0.0\n",
      "0.00012956669\n",
      "0.000120293626\n",
      "0.000797911\n",
      "0.0\n",
      "0.00042011033\n",
      "0.004681367\n",
      "0.00031589757\n",
      "0.006863706\n",
      "0.0020376462\n",
      "0.0028625226\n",
      "0.00015970254\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0034760719\n",
      "0.08475206\n",
      "0.0073166303\n",
      "0.0011994711\n",
      "0.014633176\n",
      "0.0033326403\n",
      "0.0012842464\n",
      "0.0023886552\n",
      "0.0037115002\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0007799804\n",
      "0.0002572608\n",
      "0.00057947484\n",
      "0.0\n",
      "0.00012582965\n",
      "0.00032150294\n",
      "0.0036866004\n",
      "0.0023340667\n",
      "0.0005101495\n",
      "0.0073110666\n",
      "0.008662514\n",
      "0.017869696\n",
      "0.0009884614\n",
      "0.0\n",
      "0.0009756503\n",
      "0.0\n",
      "0.0003301575\n",
      "0.0\n",
      "0.00097490405\n",
      "0.0007026926\n",
      "0.0015668743\n",
      "0.004620589\n",
      "0.10742164\n",
      "0.000862825\n",
      "0.079071164\n",
      "0.0\n",
      "0.0020179774\n",
      "0.032840896\n",
      "0.0047435784\n",
      "2.8038407e-05\n",
      "3.600222e-05\n",
      "0.0083981\n",
      "0.012034887\n",
      "0.0030220102\n",
      "0.015862852\n",
      "0.0016923625\n",
      "0.0017182637\n",
      "0.008450015\n",
      "0.0012235909\n",
      "0.00348905\n",
      "0.0046186172\n",
      "0.0\n",
      "0.0007641532\n",
      "0.018777149\n",
      "0.0060771084\n",
      "0.00023464672\n",
      "0.00045241124\n",
      "0.0\n",
      "0.0012894497\n",
      "0.055235095\n",
      "0.0006572417\n",
      "0.00048222492\n",
      "0.0018234848\n",
      "0.0\n",
      "0.01628277\n",
      "0.00063739694\n",
      "0.0\n",
      "0.00091936614\n",
      "0.0038742507\n",
      "0.0\n",
      "0.0\n",
      "0.016684731\n",
      "0.0\n",
      "0.003400116\n",
      "0.015674928\n",
      "0.0\n",
      "0.0007705906\n",
      "0.0020916248\n",
      "0.0\n",
      "0.0016204919\n",
      "0.009077629\n",
      "0.00014096712\n",
      "0.00092772866\n",
      "   Accuracy  Precision    Recall    F1        F2      F0.5  Average Precision\n",
      "0  0.998662        1.0  0.470588  0.64  0.526316  0.816327           0.471926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:58:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 168.669 seconds\n",
      "Cross-validation score: 0.6403155294164374\n",
      "Test score: 0.8024691358024691\n",
      "Best Hyperparameters: {}\n",
      "0.0071936487\n",
      "0.046541546\n",
      "0.17216165\n",
      "0.004049442\n",
      "0.03281278\n",
      "0.008651014\n",
      "0.0005264871\n",
      "0.0027955296\n",
      "0.00041594097\n",
      "0.0013481907\n",
      "0.005575743\n",
      "0.037586655\n",
      "0.0\n",
      "0.0\n",
      "0.0006313011\n",
      "0.0\n",
      "0.0010196121\n",
      "0.0\n",
      "0.00047964256\n",
      "0.003174096\n",
      "0.0003928839\n",
      "0.0034980143\n",
      "0.0007123968\n",
      "0.043482505\n",
      "0.0006337634\n",
      "0.0\n",
      "0.00058147626\n",
      "0.0028357464\n",
      "0.00055111485\n",
      "0.021943925\n",
      "0.00012011396\n",
      "0.0012415429\n",
      "0.0043769274\n",
      "0.0019622247\n",
      "0.0047239456\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0028010532\n",
      "0.023750313\n",
      "0.0051334407\n",
      "0.00271329\n",
      "0.0018584495\n",
      "0.003868472\n",
      "0.0047108703\n",
      "0.0012567389\n",
      "0.019593911\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0005342586\n",
      "0.0016218907\n",
      "0.0017898475\n",
      "0.0005781889\n",
      "0.00024078619\n",
      "0.005661436\n",
      "0.015867377\n",
      "0.0030725335\n",
      "0.00030853605\n",
      "0.009388215\n",
      "0.011032406\n",
      "0.011617587\n",
      "3.241789e-05\n",
      "2.071075e-05\n",
      "0.0015032272\n",
      "0.00035612675\n",
      "0.0003623233\n",
      "0.00033657407\n",
      "0.0\n",
      "0.0051180413\n",
      "0.00066067505\n",
      "0.00224535\n",
      "0.08686642\n",
      "0.00045275543\n",
      "0.00055078027\n",
      "0.0\n",
      "0.002165212\n",
      "0.0031458328\n",
      "0.003476689\n",
      "0.0001870069\n",
      "9.588955e-06\n",
      "0.08911278\n",
      "0.0146868285\n",
      "0.0064792875\n",
      "0.0036522457\n",
      "0.0030655025\n",
      "0.0041644233\n",
      "0.0\n",
      "2.3417519e-05\n",
      "0.0012149701\n",
      "0.0022762222\n",
      "0.0\n",
      "0.002256242\n",
      "0.024151748\n",
      "9.144017e-05\n",
      "0.00019233764\n",
      "0.037825797\n",
      "0.0\n",
      "0.0016308696\n",
      "0.046599947\n",
      "0.0023790072\n",
      "0.00016527304\n",
      "0.00034400198\n",
      "0.0\n",
      "0.00022940972\n",
      "0.0005218644\n",
      "0.0\n",
      "0.01212103\n",
      "0.00037203086\n",
      "0.0\n",
      "0.000159841\n",
      "0.01741104\n",
      "0.0\n",
      "0.0025422575\n",
      "0.023247113\n",
      "0.0\n",
      "0.0018216013\n",
      "0.013780285\n",
      "0.0\n",
      "0.006054303\n",
      "0.025410598\n",
      "0.0018135738\n",
      "0.0072933934\n",
      "   Accuracy  Precision    Recall        F1       F2      F0.5  \\\n",
      "0  0.998959     0.8125  0.764706  0.787879  0.77381  0.802469   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.621918  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:00:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 167.181 seconds\n",
      "Cross-validation score: 0.6520119225552163\n",
      "Test score: 0.8235294117647058\n",
      "Best Hyperparameters: {}\n",
      "0.014329912\n",
      "0.041512415\n",
      "0.17464706\n",
      "0.0025166392\n",
      "0.056102566\n",
      "0.008750484\n",
      "0.00031870374\n",
      "0.00018051217\n",
      "0.00011909289\n",
      "6.9602385e-05\n",
      "0.01220383\n",
      "0.00014300435\n",
      "0.0\n",
      "0.0\n",
      "0.0014385036\n",
      "0.0\n",
      "0.037247214\n",
      "0.00024435917\n",
      "0.021176193\n",
      "0.004872392\n",
      "0.00024503484\n",
      "0.0013952781\n",
      "0.0043904437\n",
      "0.006614105\n",
      "0.0030553255\n",
      "0.0\n",
      "0.00027446472\n",
      "0.005656125\n",
      "0.00038622651\n",
      "0.0005740764\n",
      "0.00026019086\n",
      "0.001752649\n",
      "9.028015e-05\n",
      "0.0002567769\n",
      "0.001067532\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0047304663\n",
      "0.012529137\n",
      "0.0034196703\n",
      "0.0006373951\n",
      "0.0002358745\n",
      "0.006769032\n",
      "0.0040482096\n",
      "0.0020911833\n",
      "0.0020401583\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0010566091\n",
      "0.0033627807\n",
      "0.00013458822\n",
      "0.0011537141\n",
      "0.0\n",
      "0.0012361063\n",
      "0.014636746\n",
      "0.0031928127\n",
      "0.0012719642\n",
      "0.008562111\n",
      "0.019056823\n",
      "0.003740825\n",
      "0.0007614889\n",
      "0.00022473036\n",
      "0.00069155084\n",
      "0.0048600812\n",
      "0.0\n",
      "0.0\n",
      "1.8470697e-05\n",
      "0.0027741126\n",
      "0.013063083\n",
      "0.0\n",
      "0.073830314\n",
      "0.012712156\n",
      "0.00035437456\n",
      "0.0\n",
      "0.0\n",
      "0.007111432\n",
      "0.0026914144\n",
      "7.9897865e-05\n",
      "0.00048456306\n",
      "0.013022327\n",
      "0.027371434\n",
      "0.0033439358\n",
      "0.08504984\n",
      "0.0139293745\n",
      "0.002634291\n",
      "0.0\n",
      "0.0017283857\n",
      "0.013261813\n",
      "0.04449493\n",
      "0.0\n",
      "0.0040535694\n",
      "0.020339672\n",
      "0.0\n",
      "0.00010676882\n",
      "0.0058786855\n",
      "0.0\n",
      "0.0018249045\n",
      "0.040286023\n",
      "0.0092951795\n",
      "2.4596702e-05\n",
      "0.00042561907\n",
      "0.0\n",
      "0.0026636592\n",
      "0.0003819873\n",
      "0.0\n",
      "0.0013182176\n",
      "0.00047338195\n",
      "0.0\n",
      "0.006309234\n",
      "0.012489781\n",
      "0.0\n",
      "0.0020923947\n",
      "0.0116141625\n",
      "0.0\n",
      "0.0005090978\n",
      "0.008996876\n",
      "0.0\n",
      "0.005296411\n",
      "0.030004317\n",
      "0.0018350987\n",
      "0.013489165\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.999108   0.823529  0.823529  0.823529  0.823529  0.823529   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.678647  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:03:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 158.190 seconds\n",
      "Cross-validation score: 0.7280162735767258\n",
      "Test score: 0.7246376811594203\n",
      "Best Hyperparameters: {}\n",
      "0.0076630563\n",
      "0.0685367\n",
      "0.21445386\n",
      "0.0021206697\n",
      "0.023925964\n",
      "0.0013446863\n",
      "0.00095773774\n",
      "0.00040201802\n",
      "0.0002586174\n",
      "0.0002632246\n",
      "0.015504688\n",
      "0.0016548508\n",
      "0.0\n",
      "0.0\n",
      "0.0021313324\n",
      "0.0\n",
      "0.006330862\n",
      "0.0005481647\n",
      "0.013755022\n",
      "0.0149203045\n",
      "0.000117449665\n",
      "0.011132345\n",
      "0.004460703\n",
      "0.0011807774\n",
      "0.0025608751\n",
      "0.0\n",
      "0.0039487802\n",
      "0.00011787983\n",
      "0.00030764626\n",
      "0.0026614077\n",
      "0.0001272844\n",
      "0.0057008187\n",
      "0.0006695096\n",
      "0.0020154733\n",
      "0.0012334541\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.009218753\n",
      "0.0644906\n",
      "0.0038863404\n",
      "0.0021812685\n",
      "0.00085588085\n",
      "0.0043194075\n",
      "0.0053514736\n",
      "0.0037500504\n",
      "0.0114572\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.000968309\n",
      "0.0035457541\n",
      "0.00025548838\n",
      "0.00019371498\n",
      "0.00011299785\n",
      "0.0\n",
      "0.0007983639\n",
      "0.0034795986\n",
      "0.0068157897\n",
      "0.0072273775\n",
      "0.017913194\n",
      "0.0007695191\n",
      "0.00011522344\n",
      "4.3907985e-05\n",
      "0.002260025\n",
      "0.00010966837\n",
      "0.0\n",
      "0.0036446443\n",
      "0.0001952761\n",
      "0.0006035433\n",
      "0.0019439667\n",
      "0.011341613\n",
      "0.09658513\n",
      "0.0\n",
      "0.0005458664\n",
      "0.0\n",
      "0.00042424936\n",
      "0.009476696\n",
      "0.01887764\n",
      "0.009754027\n",
      "8.920625e-05\n",
      "0.007409766\n",
      "0.02496402\n",
      "0.0015254403\n",
      "0.02484272\n",
      "0.0059501855\n",
      "0.0008496561\n",
      "0.0\n",
      "0.00011076477\n",
      "0.00016130356\n",
      "0.019686852\n",
      "4.3122104e-06\n",
      "0.0025018023\n",
      "0.01708999\n",
      "0.0053897086\n",
      "0.00083206163\n",
      "0.030981308\n",
      "3.7296174e-06\n",
      "0.002648563\n",
      "0.045338795\n",
      "0.004258218\n",
      "0.0\n",
      "0.0018399076\n",
      "0.0\n",
      "0.030562071\n",
      "0.0003925548\n",
      "0.0\n",
      "0.000728329\n",
      "0.0\n",
      "0.0\n",
      "0.00075329066\n",
      "0.024957823\n",
      "0.0\n",
      "0.006075769\n",
      "0.018334\n",
      "0.0\n",
      "0.00015119817\n",
      "0.0027937521\n",
      "0.0\n",
      "0.00089335616\n",
      "0.0003496802\n",
      "0.0004574369\n",
      "0.0025536248\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998513   0.769231  0.588235  0.666667  0.617284  0.724638   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.453529  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:06:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 171.777 seconds\n",
      "Cross-validation score: 0.6536110230882096\n",
      "Test score: 0.8441558441558442\n",
      "Best Hyperparameters: {}\n",
      "0.005496952\n",
      "0.051603023\n",
      "0.186569\n",
      "0.0029048696\n",
      "0.019498099\n",
      "0.0012527531\n",
      "0.0013183415\n",
      "0.001724542\n",
      "9.102521e-05\n",
      "0.0\n",
      "0.004577682\n",
      "0.0019597865\n",
      "0.0\n",
      "0.0\n",
      "0.010389037\n",
      "0.0\n",
      "0.0019636832\n",
      "0.0010854981\n",
      "0.0007564573\n",
      "0.0003657381\n",
      "0.000616804\n",
      "0.00021269952\n",
      "0.00067710364\n",
      "0.002658773\n",
      "0.00048739213\n",
      "0.0013682189\n",
      "0.00023843512\n",
      "0.0\n",
      "0.00027921458\n",
      "0.016565826\n",
      "2.6742484e-05\n",
      "0.001998264\n",
      "0.0039252336\n",
      "0.0029186266\n",
      "0.009573412\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.016085584\n",
      "0.034758244\n",
      "0.0055349274\n",
      "0.013029811\n",
      "4.953232e-05\n",
      "0.0046667494\n",
      "0.0003478169\n",
      "0.0002113924\n",
      "0.027984262\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00058717176\n",
      "0.002091402\n",
      "0.00072992704\n",
      "0.0033857431\n",
      "0.00024629265\n",
      "0.0\n",
      "0.0029319688\n",
      "0.0018476065\n",
      "0.005396772\n",
      "0.014084321\n",
      "0.008702814\n",
      "0.0026158511\n",
      "0.00021420525\n",
      "0.0003226066\n",
      "0.0018930666\n",
      "0.00030601805\n",
      "0.001783257\n",
      "7.248777e-05\n",
      "0.00061563955\n",
      "0.0034377684\n",
      "0.019459207\n",
      "0.0009495911\n",
      "0.11046316\n",
      "0.006570854\n",
      "0.020421373\n",
      "0.0\n",
      "0.0009815864\n",
      "0.003750951\n",
      "0.0033394084\n",
      "0.0006474533\n",
      "0.00024432872\n",
      "0.0005111825\n",
      "0.008835205\n",
      "0.0066842902\n",
      "0.044933252\n",
      "0.042210445\n",
      "0.0010442514\n",
      "2.1524238e-05\n",
      "9.4163166e-05\n",
      "0.00055898266\n",
      "0.0007472968\n",
      "0.0\n",
      "0.0024862757\n",
      "0.027253646\n",
      "0.0030879865\n",
      "0.0006532992\n",
      "0.03345556\n",
      "2.3224884e-05\n",
      "0.0027333584\n",
      "0.07521458\n",
      "0.004062632\n",
      "0.00027372097\n",
      "7.384336e-05\n",
      "0.0\n",
      "0.003479069\n",
      "7.175795e-05\n",
      "0.0\n",
      "0.016485713\n",
      "0.00039678634\n",
      "0.0\n",
      "0.006683912\n",
      "0.01480296\n",
      "0.0\n",
      "0.003566231\n",
      "0.014154182\n",
      "0.0\n",
      "0.0019489755\n",
      "0.0047376184\n",
      "0.0\n",
      "0.0103256535\n",
      "0.010580523\n",
      "0.0032225384\n",
      "0.0007209953\n",
      "   Accuracy  Precision    Recall      F1        F2      F0.5  \\\n",
      "0  0.999108   0.866667  0.764706  0.8125  0.783133  0.844156   \n",
      "\n",
      "   Average Precision  \n",
      "0            0.66334  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:09:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 172.024 seconds\n",
      "Cross-validation score: 0.635041285886612\n",
      "Test score: 0.7534246575342465\n",
      "Best Hyperparameters: {}\n",
      "0.0076004756\n",
      "0.02183623\n",
      "0.24537812\n",
      "0.003025986\n",
      "0.032852117\n",
      "0.0020132896\n",
      "0.0\n",
      "0.0\n",
      "0.00040433285\n",
      "0.0005369068\n",
      "0.013952306\n",
      "0.000914774\n",
      "0.0010037349\n",
      "0.0\n",
      "0.00061583257\n",
      "0.0\n",
      "0.017531708\n",
      "0.0001643285\n",
      "0.0003043938\n",
      "5.1927076e-05\n",
      "0.00038538268\n",
      "0.0020144063\n",
      "0.0014133794\n",
      "0.00093227345\n",
      "0.01364812\n",
      "0.0011170362\n",
      "0.015252543\n",
      "0.0009302929\n",
      "9.529187e-05\n",
      "0.00027505646\n",
      "0.00052285194\n",
      "0.005475295\n",
      "0.0011002717\n",
      "0.005106135\n",
      "0.0010004045\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007466073\n",
      "0.066572316\n",
      "0.008034795\n",
      "0.00092904666\n",
      "0.004979811\n",
      "0.0034560072\n",
      "0.0039022628\n",
      "0.0014992167\n",
      "0.02245624\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.002502523\n",
      "0.003230266\n",
      "0.0003304958\n",
      "0.00031744246\n",
      "0.0\n",
      "0.0005795165\n",
      "0.014548042\n",
      "0.00022942602\n",
      "0.0011968834\n",
      "0.0041763885\n",
      "0.008944746\n",
      "0.0026769203\n",
      "0.0009330793\n",
      "1.33239955e-05\n",
      "0.00513178\n",
      "6.42579e-05\n",
      "0.0023480563\n",
      "3.7922287e-05\n",
      "0.00340843\n",
      "0.003061215\n",
      "0.022962783\n",
      "0.0005753398\n",
      "0.11486493\n",
      "0.0009968955\n",
      "0.0\n",
      "0.0\n",
      "0.0045626266\n",
      "0.0008950755\n",
      "0.0063131363\n",
      "0.00047473563\n",
      "6.81395e-05\n",
      "0.0044697705\n",
      "0.026524717\n",
      "0.0030754223\n",
      "0.08241722\n",
      "0.0015048515\n",
      "0.0007278896\n",
      "9.583532e-05\n",
      "0.0\n",
      "0.0024324218\n",
      "0.0003088772\n",
      "4.1943906e-05\n",
      "0.001358424\n",
      "0.01822771\n",
      "0.00037004618\n",
      "0.00055160426\n",
      "0.04709657\n",
      "6.866402e-05\n",
      "0.003101186\n",
      "0.029919857\n",
      "0.0036183898\n",
      "0.00016270461\n",
      "0.0009839524\n",
      "0.0\n",
      "0.0022109705\n",
      "0.00047534634\n",
      "0.0\n",
      "0.0022635858\n",
      "0.00070500385\n",
      "0.0\n",
      "0.0\n",
      "0.020614563\n",
      "0.0\n",
      "0.0006168701\n",
      "0.007297898\n",
      "0.0\n",
      "0.00046004858\n",
      "0.0030356627\n",
      "0.0\n",
      "0.0011387394\n",
      "0.004697218\n",
      "0.0054217563\n",
      "0.0018090378\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998662   0.785714  0.647059  0.709677  0.670732  0.753425   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.509295  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:12:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 164.723 seconds\n",
      "Cross-validation score: 0.707932968802534\n",
      "Test score: 0.7647058823529411\n",
      "Best Hyperparameters: {}\n",
      "0.017227268\n",
      "0.057499975\n",
      "0.2353024\n",
      "0.0019451395\n",
      "0.02062976\n",
      "0.00017976937\n",
      "0.0017607097\n",
      "0.00034413015\n",
      "0.0\n",
      "0.00015658782\n",
      "0.0065315384\n",
      "0.0002459912\n",
      "4.1937154e-05\n",
      "0.0\n",
      "0.00018636567\n",
      "0.0\n",
      "0.011169391\n",
      "0.0\n",
      "0.0019408903\n",
      "0.00029683564\n",
      "0.00024686247\n",
      "8.66436e-05\n",
      "0.0017597945\n",
      "0.00034265104\n",
      "0.0029953488\n",
      "0.00013052704\n",
      "0.0012594503\n",
      "0.0\n",
      "0.0010241357\n",
      "0.0011537517\n",
      "0.000138464\n",
      "0.0014301174\n",
      "0.0010353129\n",
      "0.0019648985\n",
      "0.0034276657\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.011781971\n",
      "0.02993098\n",
      "0.0021499966\n",
      "0.0031721701\n",
      "0.0016901675\n",
      "0.009318773\n",
      "0.0004155154\n",
      "0.00041830735\n",
      "0.013399434\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0027449604\n",
      "0.0040865033\n",
      "0.0008848533\n",
      "0.00022601552\n",
      "0.00028568902\n",
      "0.0007132266\n",
      "0.0015993975\n",
      "0.012461253\n",
      "0.006455642\n",
      "0.013500776\n",
      "0.011044244\n",
      "0.002993649\n",
      "0.00020797076\n",
      "0.0\n",
      "0.0015964278\n",
      "0.0077232756\n",
      "1.2480213e-05\n",
      "0.0002988969\n",
      "0.004241675\n",
      "0.0008145412\n",
      "0.0014223508\n",
      "0.0004514005\n",
      "0.089896284\n",
      "0.0073104245\n",
      "0.0005765168\n",
      "0.0002116955\n",
      "0.0024862662\n",
      "0.0112360995\n",
      "0.0037127237\n",
      "0.0\n",
      "5.9124774e-05\n",
      "0.0048036543\n",
      "0.05408878\n",
      "0.0014324143\n",
      "0.026533598\n",
      "0.0051584058\n",
      "0.0016379359\n",
      "0.0\n",
      "0.0008139039\n",
      "0.0\n",
      "0.068247564\n",
      "0.0\n",
      "0.0010635661\n",
      "0.01830428\n",
      "0.0009915576\n",
      "0.00028264942\n",
      "0.004910619\n",
      "0.0\n",
      "0.001141346\n",
      "0.07006053\n",
      "0.003231831\n",
      "0.0004492664\n",
      "0.007877114\n",
      "0.0\n",
      "0.015235196\n",
      "0.00014754171\n",
      "0.0\n",
      "0.0009535042\n",
      "0.00086087285\n",
      "0.0\n",
      "0.0061215973\n",
      "0.021023264\n",
      "0.0\n",
      "0.0014306174\n",
      "0.016324798\n",
      "0.0\n",
      "0.00050412316\n",
      "0.010558228\n",
      "0.0\n",
      "0.006561973\n",
      "0.0068174745\n",
      "0.00081892806\n",
      "0.007626789\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998811   0.764706  0.764706  0.764706  0.764706  0.764706   \n",
      "\n",
      "   Average Precision  \n",
      "0            0.58537  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:14:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 169.438 seconds\n",
      "Cross-validation score: 0.7154026669277413\n",
      "Test score: 0.5913978494623656\n",
      "Best Hyperparameters: {}\n",
      "0.0020819798\n",
      "0.0051672496\n",
      "0.19393241\n",
      "0.0006944343\n",
      "0.07200536\n",
      "0.0005147148\n",
      "0.00014270387\n",
      "0.0038859348\n",
      "0.0010459548\n",
      "0.0074672773\n",
      "0.011753056\n",
      "0.0075186035\n",
      "0.0005658043\n",
      "0.0\n",
      "0.0008452559\n",
      "0.0\n",
      "0.017407294\n",
      "0.00020919897\n",
      "0.006577905\n",
      "0.0039402125\n",
      "0.0009767201\n",
      "0.0\n",
      "0.00055103964\n",
      "0.0026185554\n",
      "2.4840429e-05\n",
      "0.0\n",
      "0.006267213\n",
      "2.3788245e-05\n",
      "0.0012916556\n",
      "0.01148581\n",
      "0.00011607157\n",
      "0.00049359\n",
      "0.017365584\n",
      "0.0031752023\n",
      "0.008702925\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0037965772\n",
      "0.035933234\n",
      "0.004735696\n",
      "0.0012990871\n",
      "0.0029715197\n",
      "0.0025977902\n",
      "0.0052547036\n",
      "0.00054237025\n",
      "0.0034492535\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0017693274\n",
      "0.0011387512\n",
      "0.0002979264\n",
      "0.00023459579\n",
      "0.00026670806\n",
      "0.00095179136\n",
      "0.0060798205\n",
      "0.0\n",
      "0.0046673724\n",
      "0.019215608\n",
      "0.00751978\n",
      "0.004860203\n",
      "0.0006340451\n",
      "0.0\n",
      "0.00022449066\n",
      "0.00069523026\n",
      "0.00044272566\n",
      "0.010665816\n",
      "0.0018779804\n",
      "0.004994734\n",
      "0.00027243703\n",
      "0.0042351894\n",
      "0.099397324\n",
      "0.0021305655\n",
      "0.029455265\n",
      "0.0\n",
      "0.0031362625\n",
      "0.0050900374\n",
      "0.008053926\n",
      "0.001579799\n",
      "3.0613104e-05\n",
      "0.0072544594\n",
      "0.04258193\n",
      "0.005571239\n",
      "0.076518945\n",
      "0.009470104\n",
      "0.00078311417\n",
      "9.090001e-05\n",
      "0.00012174761\n",
      "0.0025463018\n",
      "0.0010238524\n",
      "0.00933822\n",
      "0.00072911\n",
      "0.020889632\n",
      "0.00040373753\n",
      "0.0010371706\n",
      "0.00048232466\n",
      "0.0\n",
      "0.019773126\n",
      "0.035941936\n",
      "0.0076512913\n",
      "0.0\n",
      "0.0020903358\n",
      "0.0\n",
      "0.00081800285\n",
      "0.000113845905\n",
      "0.0\n",
      "0.015008339\n",
      "5.300011e-05\n",
      "0.0\n",
      "7.8281984e-05\n",
      "0.012271506\n",
      "0.0\n",
      "0.0014550884\n",
      "0.01681582\n",
      "0.0\n",
      "0.0007283711\n",
      "0.0021686843\n",
      "0.0\n",
      "0.0013400335\n",
      "0.026895173\n",
      "0.0016373956\n",
      "0.006970116\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.578947  0.647059  0.611111  0.632184  0.591398   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.375505  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:17:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 161.457 seconds\n",
      "Cross-validation score: 0.7815140402830804\n",
      "Test score: 0.5670103092783505\n",
      "Best Hyperparameters: {}\n",
      "0.015563577\n",
      "0.050042022\n",
      "0.18665105\n",
      "0.0005994955\n",
      "0.0044075334\n",
      "0.00025487368\n",
      "0.000116375464\n",
      "0.00087923394\n",
      "3.38367e-05\n",
      "0.0008452688\n",
      "0.005776503\n",
      "0.045858677\n",
      "6.210409e-05\n",
      "0.0\n",
      "0.0024835358\n",
      "0.0\n",
      "0.001676617\n",
      "0.00020717668\n",
      "0.011521974\n",
      "8.7606815e-05\n",
      "0.00040522526\n",
      "0.007203845\n",
      "0.001355207\n",
      "0.0011227046\n",
      "0.00012190735\n",
      "0.0\n",
      "0.0003094742\n",
      "0.0014227224\n",
      "0.0010307218\n",
      "0.020277664\n",
      "0.00031039183\n",
      "0.0011779402\n",
      "0.0017087845\n",
      "0.0033784567\n",
      "0.010568133\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00040673724\n",
      "0.0021416852\n",
      "0.0059227524\n",
      "0.0009346655\n",
      "0.0049011884\n",
      "0.002251216\n",
      "0.0017075704\n",
      "0.00014634439\n",
      "0.002141389\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00050573575\n",
      "0.00075835706\n",
      "0.0052279984\n",
      "0.0\n",
      "0.00077820127\n",
      "0.00023338856\n",
      "0.017866995\n",
      "0.011622583\n",
      "0.00025881405\n",
      "0.006744593\n",
      "0.014640015\n",
      "0.0017735444\n",
      "0.000779618\n",
      "0.00020968809\n",
      "0.00076408364\n",
      "0.0005124972\n",
      "5.0629224e-05\n",
      "8.552784e-05\n",
      "0.003171303\n",
      "0.00021596828\n",
      "0.0013795947\n",
      "0.0002783361\n",
      "0.109116726\n",
      "0.0008865502\n",
      "0.0\n",
      "0.0\n",
      "0.00044201617\n",
      "0.007073927\n",
      "0.012586291\n",
      "2.0977996e-05\n",
      "0.0058246115\n",
      "0.009974193\n",
      "0.037403315\n",
      "0.09277123\n",
      "0.02147549\n",
      "0.0005339259\n",
      "0.0075440016\n",
      "0.00028666217\n",
      "9.462286e-05\n",
      "0.0002733207\n",
      "0.068090826\n",
      "0.0\n",
      "0.002384429\n",
      "0.028987482\n",
      "0.00011746519\n",
      "9.512336e-05\n",
      "0.007564681\n",
      "0.0\n",
      "0.0008609478\n",
      "0.045202304\n",
      "0.0022044887\n",
      "5.8036276e-05\n",
      "0.001383508\n",
      "0.0\n",
      "0.0023050557\n",
      "8.9231515e-05\n",
      "0.0\n",
      "0.008477094\n",
      "0.00030895605\n",
      "0.0\n",
      "0.00021980121\n",
      "0.013883854\n",
      "0.0\n",
      "0.0026478434\n",
      "0.03863331\n",
      "0.0\n",
      "0.00019665417\n",
      "0.001331777\n",
      "0.0\n",
      "0.00022768413\n",
      "0.00049515656\n",
      "0.0013276112\n",
      "0.00072716613\n",
      "   Accuracy  Precision    Recall        F1     F2     F0.5  Average Precision\n",
      "0   0.99777       0.55  0.647059  0.594595  0.625  0.56701           0.356774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:20:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 166.394 seconds\n",
      "Cross-validation score: 0.678799391351986\n",
      "Test score: 0.7303370786516854\n",
      "Best Hyperparameters: {}\n",
      "0.0032109222\n",
      "0.01645048\n",
      "0.21264467\n",
      "0.0012176207\n",
      "0.029980741\n",
      "0.0039243475\n",
      "0.0\n",
      "8.111239e-05\n",
      "0.00020174882\n",
      "0.0007770683\n",
      "0.016590424\n",
      "2.0100279e-05\n",
      "0.00017939639\n",
      "0.0\n",
      "0.0031137571\n",
      "0.0\n",
      "0.009154167\n",
      "0.009859879\n",
      "0.023292031\n",
      "0.0006326627\n",
      "0.0020319715\n",
      "0.0\n",
      "0.0049601477\n",
      "0.0\n",
      "0.0009068572\n",
      "0.0\n",
      "0.00073819724\n",
      "0.0\n",
      "0.00050050544\n",
      "0.00042241937\n",
      "0.00015673427\n",
      "0.011633765\n",
      "0.0007569268\n",
      "0.0034921565\n",
      "0.00091143994\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0011947844\n",
      "0.051361658\n",
      "0.0034643696\n",
      "0.0012861742\n",
      "0.01413576\n",
      "0.007159135\n",
      "0.0006953813\n",
      "0.007608806\n",
      "0.0064125583\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0013495742\n",
      "0.0008647872\n",
      "0.00014571319\n",
      "0.0005805389\n",
      "0.0\n",
      "0.00036125715\n",
      "0.01281196\n",
      "0.0019154638\n",
      "0.0002802361\n",
      "0.008230609\n",
      "0.010097191\n",
      "0.0066917962\n",
      "0.07238583\n",
      "0.0027361684\n",
      "0.001292316\n",
      "0.00011401802\n",
      "0.00014803764\n",
      "0.010553323\n",
      "0.00022282376\n",
      "0.00033571466\n",
      "0.0026362357\n",
      "0.0001671049\n",
      "0.08508154\n",
      "0.0015467294\n",
      "0.04438241\n",
      "0.0\n",
      "0.002708421\n",
      "0.0012430802\n",
      "0.004887779\n",
      "3.987451e-05\n",
      "0.005817776\n",
      "0.0026355723\n",
      "0.018366266\n",
      "0.0031876685\n",
      "0.046525076\n",
      "0.009577163\n",
      "0.0024719995\n",
      "0.0003186333\n",
      "0.0035652725\n",
      "0.0026977358\n",
      "0.0004292112\n",
      "0.0\n",
      "0.014018367\n",
      "0.021132927\n",
      "0.00022862943\n",
      "0.00016272336\n",
      "0.0020482074\n",
      "0.0\n",
      "0.0040421854\n",
      "0.02645783\n",
      "0.0038716742\n",
      "0.0\n",
      "0.00067362055\n",
      "0.0\n",
      "0.025373338\n",
      "0.0007984041\n",
      "0.0\n",
      "0.00093841\n",
      "0.0054674903\n",
      "0.0\n",
      "7.3367526e-05\n",
      "0.021144938\n",
      "0.0\n",
      "0.0011322077\n",
      "0.041323062\n",
      "0.0\n",
      "0.0001585413\n",
      "0.006507113\n",
      "0.0\n",
      "0.000713809\n",
      "0.00063301646\n",
      "0.0009671921\n",
      "0.0015692024\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998662   0.722222  0.764706  0.742857  0.755814  0.730337   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.552882  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:23:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 162.851 seconds\n",
      "Cross-validation score: 0.6858975246225865\n",
      "Test score: 0.660377358490566\n",
      "Best Hyperparameters: {}\n",
      "0.02587617\n",
      "0.010686289\n",
      "0.21258968\n",
      "0.0025830157\n",
      "0.024364058\n",
      "0.00017712779\n",
      "0.0008512601\n",
      "6.8026704e-05\n",
      "0.0004094102\n",
      "0.0036051727\n",
      "0.01610727\n",
      "0.01572614\n",
      "0.0007086565\n",
      "0.0\n",
      "0.0025029043\n",
      "0.0\n",
      "0.019498972\n",
      "0.0\n",
      "0.04694494\n",
      "0.0\n",
      "0.00041350344\n",
      "0.0015185208\n",
      "0.0006325481\n",
      "0.0\n",
      "0.0013159133\n",
      "2.4265139e-05\n",
      "0.0007336869\n",
      "0.000844777\n",
      "6.0057377e-05\n",
      "0.0021764613\n",
      "0.00014073437\n",
      "0.0014039498\n",
      "0.0035651524\n",
      "0.004819386\n",
      "0.0004610732\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.010841316\n",
      "0.06749079\n",
      "0.008427755\n",
      "0.0024382435\n",
      "0.0083076535\n",
      "0.003981981\n",
      "0.0013221055\n",
      "0.0023619141\n",
      "0.0030487475\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00084947573\n",
      "0.0012107745\n",
      "0.00016138009\n",
      "0.003676087\n",
      "0.0\n",
      "0.008555282\n",
      "0.012096112\n",
      "0.008997931\n",
      "0.0022936324\n",
      "0.0061293654\n",
      "0.013474395\n",
      "0.0037644666\n",
      "0.028851585\n",
      "0.0013438606\n",
      "0.00061783526\n",
      "0.0025114086\n",
      "0.0\n",
      "0.0064788167\n",
      "0.010482696\n",
      "0.0002281713\n",
      "0.0030174942\n",
      "0.000876721\n",
      "0.09060545\n",
      "0.003630519\n",
      "0.00040537407\n",
      "0.0\n",
      "0.000108615\n",
      "0.0010008428\n",
      "0.0050212042\n",
      "0.0017314227\n",
      "0.0007525292\n",
      "0.005825591\n",
      "0.048844878\n",
      "0.0011663378\n",
      "0.061628714\n",
      "0.0035613053\n",
      "0.003623841\n",
      "0.004446752\n",
      "0.006086664\n",
      "0.0043205614\n",
      "0.021509439\n",
      "0.0\n",
      "0.00020684283\n",
      "0.015311843\n",
      "5.1051076e-05\n",
      "0.00036478468\n",
      "0.0022857438\n",
      "0.0\n",
      "0.0024224052\n",
      "0.01721379\n",
      "0.006993759\n",
      "0.0002824375\n",
      "0.0016537838\n",
      "0.0\n",
      "0.0019165677\n",
      "0.0003956573\n",
      "0.0\n",
      "0.001991746\n",
      "0.012150876\n",
      "0.0\n",
      "0.00076038024\n",
      "0.020466011\n",
      "0.0\n",
      "0.0020949189\n",
      "0.0132039115\n",
      "0.0\n",
      "0.00083954935\n",
      "0.005329872\n",
      "0.0\n",
      "0.0012229637\n",
      "3.368599e-05\n",
      "0.0017350919\n",
      "0.0021550513\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998216   0.777778  0.411765  0.538462  0.454545  0.660377   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.321748  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:25:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 167.058 seconds\n",
      "Cross-validation score: 0.6911051875947513\n",
      "Test score: 0.8024691358024691\n",
      "Best Hyperparameters: {}\n",
      "0.011273596\n",
      "0.07972467\n",
      "0.16552445\n",
      "0.00091042294\n",
      "0.02019884\n",
      "0.003739257\n",
      "9.56433e-05\n",
      "0.0\n",
      "8.2910956e-05\n",
      "0.0012963898\n",
      "0.0065156007\n",
      "0.016627943\n",
      "0.0\n",
      "0.0\n",
      "0.0013737101\n",
      "0.0\n",
      "0.01437448\n",
      "3.1033625e-05\n",
      "0.019317362\n",
      "0.0051233717\n",
      "0.00016128027\n",
      "0.005309683\n",
      "0.002014728\n",
      "0.013635592\n",
      "0.002205663\n",
      "0.0\n",
      "0.0023589807\n",
      "0.00035987052\n",
      "0.0\n",
      "0.0005614964\n",
      "0.00021550154\n",
      "0.00068963476\n",
      "0.00060929835\n",
      "0.0016468371\n",
      "0.0025613518\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0013961045\n",
      "0.029884111\n",
      "0.009396741\n",
      "0.00076847314\n",
      "5.0517585e-05\n",
      "0.0035666882\n",
      "0.0005149878\n",
      "0.0016525022\n",
      "0.0018818564\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0003153422\n",
      "0.0003303336\n",
      "0.0003894319\n",
      "0.0006100826\n",
      "0.0\n",
      "0.00049541635\n",
      "0.00206448\n",
      "0.00784878\n",
      "0.00019915607\n",
      "0.0070555042\n",
      "0.012938573\n",
      "0.0074089393\n",
      "0.0002421473\n",
      "0.021758236\n",
      "0.0019389229\n",
      "0.00021550228\n",
      "0.00019404799\n",
      "0.0\n",
      "0.001620094\n",
      "0.0007100578\n",
      "0.00025776686\n",
      "0.004405137\n",
      "0.111938566\n",
      "0.001580103\n",
      "0.0012118007\n",
      "0.0\n",
      "0.0004974944\n",
      "0.0019061699\n",
      "0.0038341556\n",
      "0.00046105892\n",
      "0.0006170033\n",
      "0.0047403104\n",
      "0.047881056\n",
      "0.0068453574\n",
      "0.012385939\n",
      "0.002771318\n",
      "0.014924088\n",
      "2.5654821e-05\n",
      "0.0\n",
      "7.9355545e-05\n",
      "0.041409325\n",
      "0.0\n",
      "0.00210327\n",
      "0.016412476\n",
      "0.00042759735\n",
      "0.00035724908\n",
      "0.0034809243\n",
      "0.052478608\n",
      "0.0010358521\n",
      "0.086365856\n",
      "0.007787161\n",
      "2.5409094e-05\n",
      "0.00037841502\n",
      "0.0\n",
      "0.017493807\n",
      "0.000274865\n",
      "0.0\n",
      "0.0049952883\n",
      "0.00019390124\n",
      "0.0\n",
      "0.00019072052\n",
      "0.015292744\n",
      "0.0\n",
      "0.0013648476\n",
      "0.013603641\n",
      "0.0\n",
      "0.00059393083\n",
      "0.0037202954\n",
      "0.0\n",
      "0.0004690367\n",
      "0.016149051\n",
      "0.00034730087\n",
      "0.002699402\n",
      "   Accuracy  Precision    Recall        F1       F2      F0.5  \\\n",
      "0  0.998959     0.8125  0.764706  0.787879  0.77381  0.802469   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.621918  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:28:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 163.099 seconds\n",
      "Cross-validation score: 0.7551913957944814\n",
      "Test score: 0.6140350877192984\n",
      "Best Hyperparameters: {}\n",
      "0.0012736616\n",
      "0.030655708\n",
      "0.23460752\n",
      "0.0033281115\n",
      "0.05489099\n",
      "0.0011241701\n",
      "0.00023502142\n",
      "0.0053272867\n",
      "0.013568881\n",
      "0.00035858364\n",
      "0.014437988\n",
      "0.0017138554\n",
      "2.0660102e-05\n",
      "0.0\n",
      "0.008970211\n",
      "0.0\n",
      "0.021149898\n",
      "0.0\n",
      "0.0006850739\n",
      "0.00095144066\n",
      "0.00014371575\n",
      "0.0007331372\n",
      "0.002214817\n",
      "0.0\n",
      "0.0007771407\n",
      "0.0\n",
      "0.0118025085\n",
      "0.0\n",
      "0.0022905306\n",
      "0.00011651815\n",
      "0.0001555091\n",
      "0.0020275062\n",
      "0.0024998784\n",
      "0.0002371874\n",
      "0.0011976726\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.006824778\n",
      "0.06927701\n",
      "0.00363976\n",
      "0.00060233555\n",
      "5.7419864e-05\n",
      "0.009982263\n",
      "0.0061983056\n",
      "0.0005790529\n",
      "0.00213898\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0013842096\n",
      "0.0012778132\n",
      "0.0002521595\n",
      "0.0\n",
      "0.0048772194\n",
      "0.00030372335\n",
      "0.018930513\n",
      "0.008417008\n",
      "0.0030604925\n",
      "0.006544716\n",
      "0.011472313\n",
      "0.0054002153\n",
      "8.3391e-05\n",
      "0.0\n",
      "0.00079546444\n",
      "0.00015041298\n",
      "3.3190227e-06\n",
      "0.0\n",
      "0.008116613\n",
      "0.0034007956\n",
      "0.0026973581\n",
      "0.0\n",
      "0.07839715\n",
      "0.0017456233\n",
      "0.00043703103\n",
      "0.0\n",
      "0.00036229563\n",
      "0.000103194034\n",
      "0.004212515\n",
      "0.0010346095\n",
      "2.3171644e-05\n",
      "0.01852597\n",
      "0.032192815\n",
      "0.003102421\n",
      "0.050752927\n",
      "0.014302983\n",
      "0.0016948595\n",
      "0.0\n",
      "0.0031900818\n",
      "2.865595e-05\n",
      "0.00016384602\n",
      "0.0\n",
      "0.0015724092\n",
      "0.024898954\n",
      "0.0005253597\n",
      "0.0010712935\n",
      "0.000259806\n",
      "0.0\n",
      "0.0027071654\n",
      "0.058420133\n",
      "0.007752336\n",
      "0.0\n",
      "8.5092346e-05\n",
      "0.0\n",
      "0.00087618094\n",
      "7.571866e-05\n",
      "0.0\n",
      "0.0021282763\n",
      "0.027853923\n",
      "0.0\n",
      "0.001275382\n",
      "0.01768837\n",
      "0.0\n",
      "0.012387615\n",
      "0.0066249985\n",
      "0.0\n",
      "3.897478e-05\n",
      "0.015866095\n",
      "0.0\n",
      "0.0025861133\n",
      "0.009194823\n",
      "0.00024944622\n",
      "0.0016286458\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998067        0.7  0.411765  0.518519  0.448718  0.614035   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.289722  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:31:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 163.143 seconds\n",
      "Cross-validation score: 0.722054441664499\n",
      "Test score: 0.617283950617284\n",
      "Best Hyperparameters: {}\n",
      "0.0021561563\n",
      "0.0027155906\n",
      "0.20299774\n",
      "0.0016341092\n",
      "0.019170225\n",
      "0.014062781\n",
      "0.0005106709\n",
      "0.003066655\n",
      "0.0020524536\n",
      "0.0056485673\n",
      "0.010396501\n",
      "0.11823026\n",
      "0.0\n",
      "0.0\n",
      "5.083599e-05\n",
      "0.0\n",
      "0.019254342\n",
      "0.0\n",
      "0.002404436\n",
      "0.0\n",
      "0.00013757969\n",
      "0.0002892722\n",
      "0.0023119603\n",
      "0.0004913092\n",
      "0.0\n",
      "0.0\n",
      "0.00017052719\n",
      "0.0\n",
      "0.0005057025\n",
      "0.00019072683\n",
      "7.9250625e-05\n",
      "0.0025963348\n",
      "0.00047904233\n",
      "0.0054240646\n",
      "0.00027238214\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0042728307\n",
      "0.07163693\n",
      "0.00086305354\n",
      "0.00063152827\n",
      "0.0065078293\n",
      "0.010311868\n",
      "0.0012028794\n",
      "0.0006687393\n",
      "0.014729775\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.002004142\n",
      "0.0022141947\n",
      "0.00016405487\n",
      "0.0017277941\n",
      "0.00066343386\n",
      "0.0035814105\n",
      "0.010903325\n",
      "0.0009007043\n",
      "0.0017297048\n",
      "0.0055373297\n",
      "0.009186581\n",
      "0.0063913665\n",
      "0.052782215\n",
      "3.7304137e-05\n",
      "0.002314012\n",
      "0.00045369574\n",
      "0.00018997933\n",
      "0.0\n",
      "0.0037544975\n",
      "0.00016337584\n",
      "0.0017331574\n",
      "0.0003592109\n",
      "0.09673753\n",
      "0.0\n",
      "0.044519924\n",
      "0.0\n",
      "0.0037740788\n",
      "0.0012858768\n",
      "0.0019538843\n",
      "1.7611763e-05\n",
      "0.0034332252\n",
      "0.014461088\n",
      "0.01942306\n",
      "0.0059665362\n",
      "0.041372888\n",
      "0.006041069\n",
      "0.00081010954\n",
      "0.0012794202\n",
      "0.003108781\n",
      "1.3168019e-05\n",
      "0.00019614695\n",
      "0.0008560495\n",
      "0.0011230808\n",
      "0.018822296\n",
      "0.0009282621\n",
      "0.00069312786\n",
      "0.00027559727\n",
      "0.0\n",
      "0.0022582754\n",
      "0.027935628\n",
      "0.006979492\n",
      "0.0002160595\n",
      "3.0499354e-05\n",
      "0.0\n",
      "0.0171671\n",
      "9.324364e-05\n",
      "0.0\n",
      "0.00031990386\n",
      "0.0014621816\n",
      "0.0\n",
      "0.0\n",
      "0.019412939\n",
      "0.0\n",
      "0.002811962\n",
      "0.009551078\n",
      "0.0\n",
      "0.00072035415\n",
      "0.004184434\n",
      "0.0\n",
      "0.0010451945\n",
      "6.3188e-05\n",
      "0.0018177968\n",
      "0.0019215062\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998067      0.625  0.588235  0.606061  0.595238  0.617284   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.368688  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:34:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 169.442 seconds\n",
      "Cross-validation score: 0.7160621641874678\n",
      "Test score: 0.6521739130434784\n",
      "Best Hyperparameters: {}\n",
      "0.0027283854\n",
      "0.0051106773\n",
      "0.2560087\n",
      "0.0025422964\n",
      "0.00918829\n",
      "0.008106589\n",
      "0.0004271708\n",
      "0.00040267644\n",
      "0.0002803911\n",
      "0.0043414696\n",
      "0.006138473\n",
      "0.03181493\n",
      "0.0001651565\n",
      "0.0\n",
      "0.0005513756\n",
      "0.0\n",
      "0.00021099126\n",
      "0.0002629465\n",
      "0.0\n",
      "0.0009651582\n",
      "0.0018273795\n",
      "0.00049252884\n",
      "0.0026113843\n",
      "0.002351661\n",
      "0.002480201\n",
      "0.0\n",
      "0.00021885087\n",
      "0.021009369\n",
      "0.0001170642\n",
      "0.04774177\n",
      "0.00044006846\n",
      "0.0024375345\n",
      "0.0029857159\n",
      "0.004326265\n",
      "0.008808946\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.013445112\n",
      "0.015091332\n",
      "0.00538034\n",
      "0.00318756\n",
      "0.00068194565\n",
      "0.004009177\n",
      "0.0005924244\n",
      "0.0029945804\n",
      "0.0045628077\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0029086412\n",
      "0.000523289\n",
      "0.00070938055\n",
      "0.0010845595\n",
      "0.00035057915\n",
      "0.0\n",
      "0.0025457102\n",
      "0.0011537847\n",
      "0.0026525347\n",
      "0.012016008\n",
      "0.018726096\n",
      "0.012221257\n",
      "0.00035416207\n",
      "1.31515535e-05\n",
      "0.0010845575\n",
      "0.0012234041\n",
      "5.180735e-05\n",
      "0.0\n",
      "0.00025092612\n",
      "0.0033480267\n",
      "0.0046966407\n",
      "0.0012272391\n",
      "0.09585945\n",
      "0.00050834066\n",
      "0.022750508\n",
      "5.4055476e-05\n",
      "0.0041163447\n",
      "0.017872777\n",
      "0.00060316495\n",
      "0.00013717641\n",
      "0.0027820165\n",
      "0.014309708\n",
      "0.006793103\n",
      "0.0064291423\n",
      "0.08699062\n",
      "0.00037098164\n",
      "0.0011293605\n",
      "0.0011439507\n",
      "0.0005271774\n",
      "1.0622317e-05\n",
      "0.0012703335\n",
      "0.0030860535\n",
      "0.002300718\n",
      "0.023926588\n",
      "0.001299767\n",
      "0.0022768069\n",
      "0.00051958207\n",
      "0.0\n",
      "0.0019046087\n",
      "0.071387045\n",
      "0.0057148864\n",
      "2.0183745e-05\n",
      "0.0016035902\n",
      "0.0\n",
      "0.0044395784\n",
      "0.00031315925\n",
      "0.0\n",
      "0.0003359568\n",
      "0.0005559652\n",
      "0.0\n",
      "0.006377646\n",
      "0.01804315\n",
      "0.0\n",
      "0.0016353186\n",
      "0.018941227\n",
      "0.0\n",
      "0.00014660232\n",
      "0.012015724\n",
      "0.0\n",
      "0.00011065946\n",
      "9.286796e-05\n",
      "0.0042313985\n",
      "0.010880556\n",
      "   Accuracy  Precision    Recall   F1        F2      F0.5  Average Precision\n",
      "0  0.998216   0.692308  0.529412  0.6  0.555556  0.652174           0.367705\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "fhalf_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "\n",
    "smote_xgboost_normalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized,\n",
    "                                                    labels_normalized,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels_normalized)\n",
    "\n",
    "\n",
    "    GXBoostPipeline = Pipeline(steps = [['smote', SMOTE()],\n",
    "                                    #['under', RandomUnderSampler()],\n",
    "                                ['classifier', xgb.XGBClassifier(n_jobs=2)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    space['classifier__learning_rate'] = [0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60]\n",
    "    space['classifier__max_depth'] = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "    space['classifier__min_child_weight'] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    space['classifier__gamma'] = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    space['classifier__colsample_bytree'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    spaceEmpty = dict()\n",
    "\n",
    "    GXBoostSearch = RandomizedSearchCV(estimator = GXBoostPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring=fhalf_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedGXBoostModel = GXBoostSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    \n",
    "    cv_score = optimizedGXBoostModel.best_score_\n",
    "    test_score = optimizedGXBoostModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedGXBoostModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedGXBoostModel.best_estimator_._final_estimator.feature_importances_\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedGXBoostModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    print(new_performance_df)\n",
    "    smote_xgboost_normalized_performance_df = pd.concat([smote_xgboost_normalized_performance_df, new_performance_df])\n",
    "    \n",
    "\n",
    "smote_xgboost_normalized_performance_df.to_csv(\"../data/05_model_output/smote_xgboost_normalized_performance_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-solution",
   "metadata": {},
   "source": [
    "### 4.2.4 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "handled-cheat",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 17.977 seconds\n",
      "Cross-validation score: 0.6478313899269782\n",
      "Test score: 0.625\n",
      "Best Hyperparameters: {}\n",
      "576.4752591475844\n",
      "349.404090821743\n",
      "252579.0217320323\n",
      "601.2854906022549\n",
      "5342.544023141265\n",
      "101.9560319930315\n",
      "43.65105962753296\n",
      "20.24705122411251\n",
      "31.152516797184944\n",
      "60.09578540921211\n",
      "7461.215315878391\n",
      "5.700392097234726\n",
      "38.33645099401474\n",
      "0.0\n",
      "584.9842336475849\n",
      "0.0\n",
      "1402.4229783117771\n",
      "1.8639030456542969\n",
      "238.01068305969238\n",
      "0.0\n",
      "14.596330717206001\n",
      "16.0382179915905\n",
      "437.33563685417175\n",
      "668.9706163406372\n",
      "290.0269349217415\n",
      "2.2240580320358276\n",
      "1041.8391308784485\n",
      "133.50049023330212\n",
      "0.0\n",
      "355.36679531633854\n",
      "0.0\n",
      "830.8654995337129\n",
      "391.0983234345913\n",
      "42.68209584057331\n",
      "186.05083779990673\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "757.9659666419029\n",
      "23645.122568786144\n",
      "415.7213468849659\n",
      "91.05732667446136\n",
      "181.71677693724632\n",
      "593.5867144614458\n",
      "90.2975746691227\n",
      "31.793057054281235\n",
      "4690.253316551447\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "762.5631597489119\n",
      "98.25919863581657\n",
      "250.01959343254566\n",
      "11.65743713080883\n",
      "3.36798894405365\n",
      "3.5871429443359375\n",
      "843.7920146137476\n",
      "234.5917428508401\n",
      "6.2122780084609985\n",
      "1826.5991901308298\n",
      "1121.1210620328784\n",
      "514.0577123165131\n",
      "6.815969944000244\n",
      "0.37541699409484863\n",
      "148.8065679371357\n",
      "0.0\n",
      "181.56278851628304\n",
      "119.11034342646599\n",
      "17.99119046330452\n",
      "2503.0829970389605\n",
      "286.8030931428075\n",
      "9.837458074092865\n",
      "30593.25714262575\n",
      "1.6371040344238281\n",
      "0.0\n",
      "0.0\n",
      "2.8934069871902466\n",
      "29.54878333210945\n",
      "1946.63428068161\n",
      "6.4373279213905334\n",
      "94.21160793304443\n",
      "1343.8377184271812\n",
      "8375.494914889336\n",
      "391.73600697517395\n",
      "11767.682706177235\n",
      "340.80862951278687\n",
      "362.91832864284515\n",
      "0.0\n",
      "0.0\n",
      "33.62687110900879\n",
      "13.858173549175262\n",
      "1.5286439657211304\n",
      "70.08500909805298\n",
      "7054.070116594434\n",
      "16.559665948152542\n",
      "113.8456820845604\n",
      "19.140316858887672\n",
      "0.0\n",
      "473.9512050151825\n",
      "8285.739606440067\n",
      "578.9967558979988\n",
      "0.0\n",
      "128.40446510910988\n",
      "0.0\n",
      "71.82857802510262\n",
      "56.72274571657181\n",
      "0.0\n",
      "6.684314996004105\n",
      "11.884776949882507\n",
      "0.0\n",
      "5.360569953918457\n",
      "1426.8517539650202\n",
      "0.0\n",
      "88.20278484374285\n",
      "3070.792890101671\n",
      "0.0\n",
      "16.640549808740616\n",
      "245.03303635120392\n",
      "0.0\n",
      "207.24179416894913\n",
      "142.0094895362854\n",
      "225.58015260100365\n",
      "195.26907289028168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 18.353 seconds\n",
      "Cross-validation score: 0.6395820511919583\n",
      "Test score: 0.7738095238095238\n",
      "Best Hyperparameters: {}\n",
      "3503.3836790695786\n",
      "25257.74428524077\n",
      "218935.23399932683\n",
      "943.8711154460907\n",
      "2374.3121305406094\n",
      "42.60192368924618\n",
      "0.37687599658966064\n",
      "4.156311094760895\n",
      "2.2442910075187683\n",
      "8.337868988513947\n",
      "1665.5939106345177\n",
      "2901.6986568272114\n",
      "32.32501682639122\n",
      "0.0\n",
      "328.2240951061249\n",
      "0.0\n",
      "697.0571072399616\n",
      "2.064389944076538\n",
      "123.98169922828674\n",
      "192.24351200461388\n",
      "1.2183020263910294\n",
      "3.0310999900102615\n",
      "225.56849424540997\n",
      "0.0\n",
      "63.44833183288574\n",
      "0.0\n",
      "138.0767457485199\n",
      "56.92337127029896\n",
      "1.3231160044670105\n",
      "37.75169096887112\n",
      "5.127279102802277\n",
      "65.87256099283695\n",
      "747.5848411023617\n",
      "106.50099329650402\n",
      "185.74198929965496\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1341.2316480875015\n",
      "2709.126498669386\n",
      "92.37466591596603\n",
      "132.06278079748154\n",
      "9.403199672698975\n",
      "492.0797907114029\n",
      "17.507320128381252\n",
      "90.50483739376068\n",
      "2639.3007326200604\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "776.4948011040688\n",
      "1055.364976093173\n",
      "97.1090797483921\n",
      "9.554615244269371\n",
      "1.373641014099121\n",
      "1.8488540053367615\n",
      "115.9215418100357\n",
      "114.14857985079288\n",
      "30.34980407357216\n",
      "3103.6864329129457\n",
      "4202.101086705923\n",
      "700.0620195865631\n",
      "56.0057812333107\n",
      "15.930469989776611\n",
      "61.09991177916527\n",
      "17.904388144612312\n",
      "3.6867209672927856\n",
      "0.18194399774074554\n",
      "189.54743120074272\n",
      "382.46584314107895\n",
      "2588.6651468724012\n",
      "5.9691649079322815\n",
      "32076.19388616085\n",
      "606.6860113739967\n",
      "24.33870954811573\n",
      "57.013999938964844\n",
      "3.0090270340442657\n",
      "423.3146328032017\n",
      "873.5160472542048\n",
      "134.90973237156868\n",
      "25.865047305822372\n",
      "992.3929485827684\n",
      "10932.677949741483\n",
      "261.9385501742363\n",
      "1823.2875533103943\n",
      "5.269224047660828\n",
      "2116.5660004615784\n",
      "131.13001191616058\n",
      "64.34418725967407\n",
      "5.422778941690922\n",
      "1834.0020451247692\n",
      "2.072681039571762\n",
      "162.18659003078938\n",
      "10479.423872947693\n",
      "10.004876136779785\n",
      "20.519862353801727\n",
      "138.96205796301365\n",
      "0.0\n",
      "477.56721879541874\n",
      "24443.464305222034\n",
      "811.5876429527998\n",
      "4.101973056793213\n",
      "119.37098631262779\n",
      "0.0\n",
      "2001.4236793518066\n",
      "32.64775390923023\n",
      "0.0\n",
      "141.37535631656647\n",
      "48.55971838533878\n",
      "0.0\n",
      "130.09122133255005\n",
      "2757.230857387185\n",
      "0.0\n",
      "1293.6995628625154\n",
      "14169.278263092041\n",
      "0.0\n",
      "48.97452963888645\n",
      "272.7578181922436\n",
      "0.0\n",
      "159.70179365575314\n",
      "165.34767761826515\n",
      "208.87324602901936\n",
      "908.9377285689116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 18.413 seconds\n",
      "Cross-validation score: 0.688354547877007\n",
      "Test score: 0.49382716049382713\n",
      "Best Hyperparameters: {}\n",
      "420.23783012479544\n",
      "68930.7995047681\n",
      "209297.98262968287\n",
      "617.3385882712901\n",
      "2872.436333730817\n",
      "236.1015997827053\n",
      "150.58089517056942\n",
      "1257.1802129745483\n",
      "733.2431507110596\n",
      "11.927540063858032\n",
      "2055.828304708004\n",
      "14.7431001663208\n",
      "6.338703654706478\n",
      "0.0\n",
      "26.130438186228275\n",
      "0.0\n",
      "67.47609455883503\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "55.080501556396484\n",
      "747.8048178851604\n",
      "30.780250072479248\n",
      "511.7727565765381\n",
      "4.776468962430954\n",
      "64.20629933476448\n",
      "56.73638787120581\n",
      "1.2010664194822311\n",
      "21.541627883911133\n",
      "4.523070938885212\n",
      "399.7696149498224\n",
      "129.55877164006233\n",
      "45.06243039667606\n",
      "56.45728686451912\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1286.6535835713148\n",
      "434.837385751307\n",
      "134.1966567710042\n",
      "37.540977761149406\n",
      "82.49221393465996\n",
      "777.9463832452893\n",
      "861.8416229784489\n",
      "304.14842611551285\n",
      "4242.504178233445\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "495.847625374794\n",
      "3326.7605529874563\n",
      "92.18969846516848\n",
      "3.7258939892053604\n",
      "0.0\n",
      "0.0\n",
      "337.7682174295187\n",
      "620.0682176351547\n",
      "40.84090754389763\n",
      "1886.9130077809095\n",
      "2340.578113332391\n",
      "962.8424794189632\n",
      "41.01986086368561\n",
      "107.92145097255707\n",
      "6.8800060749053955\n",
      "31.38900551199913\n",
      "0.0\n",
      "0.0\n",
      "125.3438029885292\n",
      "23.775193572044373\n",
      "475.9669619202614\n",
      "138.53620147705078\n",
      "27063.40260218829\n",
      "324.178270816803\n",
      "11.357207581400871\n",
      "0.0\n",
      "15.691505879163742\n",
      "24.380776897072792\n",
      "91.11311844363809\n",
      "2.8609530106186867\n",
      "11.791074931621552\n",
      "25232.134412162006\n",
      "489.30078291893005\n",
      "108.55371528863907\n",
      "376.44129072874784\n",
      "478.4075059890747\n",
      "1107.1043453291059\n",
      "0.0\n",
      "105.41272538900375\n",
      "3.1126690953969955\n",
      "55.319890432059765\n",
      "0.0\n",
      "39.59734242409468\n",
      "10230.493300966918\n",
      "1.1063571125268936\n",
      "25.843434751033783\n",
      "268.3639356866479\n",
      "0.0\n",
      "261.00048042088747\n",
      "12328.239169560373\n",
      "102.23719086498022\n",
      "0.363685704767704\n",
      "24.817944653332233\n",
      "0.0\n",
      "254.2279950082302\n",
      "40.43405652791262\n",
      "0.0\n",
      "0.5184710025787354\n",
      "0.2174035981297493\n",
      "0.0\n",
      "42.64970651268959\n",
      "980.5744769126177\n",
      "0.0\n",
      "69.02903167158365\n",
      "2265.982287593186\n",
      "0.0\n",
      "4.685114040970802\n",
      "243.8435558900237\n",
      "0.0\n",
      "171.47692589461803\n",
      "103.1767941787839\n",
      "47.30481606721878\n",
      "87.8906819447875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 17.708 seconds\n",
      "Cross-validation score: 0.6192751929013539\n",
      "Test score: 0.5421686746987953\n",
      "Best Hyperparameters: {}\n",
      "1473.828272253275\n",
      "681.1381671875715\n",
      "251851.38852401078\n",
      "1113.3301742747426\n",
      "3099.3312845528126\n",
      "143.13421808183193\n",
      "0.19399599730968475\n",
      "10.885136008262634\n",
      "0.801367998123169\n",
      "2.4878959506750107\n",
      "661.7657155543566\n",
      "33.09458176791668\n",
      "23.33043944835663\n",
      "0.0\n",
      "6.571510076522827\n",
      "0.0\n",
      "182.96895956993103\n",
      "0.09897319972515106\n",
      "0.559101015329361\n",
      "0.2676370143890381\n",
      "24.149303406476974\n",
      "2.1864499747753143\n",
      "280.3301686644554\n",
      "0.7205270081758499\n",
      "5.3362399488687515\n",
      "14.260839700698853\n",
      "34.67191034555435\n",
      "15.352289289236069\n",
      "1.1443599462509155\n",
      "41.71886044740677\n",
      "9.834512084722519\n",
      "500.3788673877716\n",
      "90.48726896941662\n",
      "950.3781797885895\n",
      "277.9112190231681\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "17.026750087738037\n",
      "28963.8771302104\n",
      "299.05430722236633\n",
      "113.85877095162868\n",
      "17.046829342842102\n",
      "356.53315183520317\n",
      "2.3281079828739166\n",
      "129.4595597088337\n",
      "3891.7453852668405\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "155.65989197045565\n",
      "1814.130115777254\n",
      "78.83052311837673\n",
      "573.837201423943\n",
      "0.8167830109596252\n",
      "54.91959508508444\n",
      "120.34785163402557\n",
      "30.510783940553665\n",
      "64.99033072590828\n",
      "1115.2806752100587\n",
      "1642.4540610462427\n",
      "174.39414652436972\n",
      "29.67478656768799\n",
      "5.967422112822533\n",
      "14.104874432086945\n",
      "90.44940185546875\n",
      "16.635290428996086\n",
      "0.0\n",
      "43.6414597928524\n",
      "358.9393097832799\n",
      "1605.8482672199607\n",
      "25.54572081565857\n",
      "38780.90005071461\n",
      "2.995050072669983\n",
      "9.826440989971161\n",
      "0.0\n",
      "146.63002961874008\n",
      "308.5767112225294\n",
      "476.0923601090908\n",
      "56.93394108116627\n",
      "0.5310639888048172\n",
      "1220.1045272946358\n",
      "9504.516949117184\n",
      "963.5121023058891\n",
      "1076.5468152463436\n",
      "1.372696965932846\n",
      "358.22907415777445\n",
      "4.252246975898743\n",
      "60.38417184352875\n",
      "3.087479904294014\n",
      "61.08459497988224\n",
      "0.0\n",
      "23.43594580888748\n",
      "8004.883839450777\n",
      "6.285070866346359\n",
      "91.11739972233772\n",
      "120.9328269213438\n",
      "67.92747662216425\n",
      "310.3293691575527\n",
      "16531.868816524744\n",
      "149.15638403594494\n",
      "10.087950944900513\n",
      "126.68836791813374\n",
      "0.0\n",
      "2206.0556260570884\n",
      "75.05569868534803\n",
      "0.0\n",
      "73.75428691506386\n",
      "257.10823372006416\n",
      "0.0\n",
      "0.0\n",
      "2527.0296228677034\n",
      "0.0\n",
      "94.83242177218199\n",
      "3737.9389313161373\n",
      "0.0\n",
      "2.9575270414352417\n",
      "21.835153251886368\n",
      "0.0\n",
      "27.033181957900524\n",
      "63.65990690886974\n",
      "124.3291704878211\n",
      "89.86480587720871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 17.869 seconds\n",
      "Cross-validation score: 0.7253931755706603\n",
      "Test score: 0.4819277108433735\n",
      "Best Hyperparameters: {}\n",
      "12067.558545924723\n",
      "14418.701659455895\n",
      "240361.54768187553\n",
      "560.7416771166027\n",
      "522.5942799597979\n",
      "971.1418785899878\n",
      "4.0590440183877945\n",
      "0.6188300102949142\n",
      "2.065700627863407\n",
      "2.3251900672912598\n",
      "1612.6842490583658\n",
      "1925.8912301957607\n",
      "6.4581298828125\n",
      "0.0\n",
      "82.7106616050005\n",
      "0.0\n",
      "9.487277075648308\n",
      "2.0941898822784424\n",
      "257.6215780079365\n",
      "20.33523279428482\n",
      "0.2229573056101799\n",
      "4.007456064224243\n",
      "173.04597778618336\n",
      "7.149620056152344\n",
      "44.00489068031311\n",
      "0.0\n",
      "286.7402131855488\n",
      "7.074027016758919\n",
      "130.73995184898376\n",
      "5.739513523876667\n",
      "23.815289437770844\n",
      "617.1150010153651\n",
      "143.77915190160275\n",
      "575.1333554536104\n",
      "941.7072785943747\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "96.71337553858757\n",
      "4983.018971309066\n",
      "985.3902162909508\n",
      "113.06239636987448\n",
      "53.66259089112282\n",
      "22.16927633434534\n",
      "700.7261248826981\n",
      "1.3712062686681747\n",
      "3190.9870450124145\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "652.3177565857768\n",
      "595.5455489382148\n",
      "174.46608579158783\n",
      "16.557559728622437\n",
      "1.521939992904663\n",
      "4.550067871809006\n",
      "302.8856543004513\n",
      "273.94200486689806\n",
      "10.076079040765762\n",
      "1776.8890279233456\n",
      "3358.7619090415537\n",
      "70.71024252474308\n",
      "0.0\n",
      "69.99548313766718\n",
      "16.89849926531315\n",
      "15.425170190632343\n",
      "17.580308608710766\n",
      "729.0670197308064\n",
      "921.2602628469467\n",
      "987.8362748995423\n",
      "371.17892114818096\n",
      "11.382521092891693\n",
      "32681.685664892197\n",
      "22.09785085916519\n",
      "0.0\n",
      "0.0\n",
      "224.43037834763527\n",
      "39.99323034286499\n",
      "31.895197808742523\n",
      "54.79610115289688\n",
      "186.8587425649166\n",
      "1030.1652269363403\n",
      "4014.828927524388\n",
      "186.71803617477417\n",
      "26101.154186710715\n",
      "1.7181899547576904\n",
      "2198.2655992656946\n",
      "34.8911999464035\n",
      "0.0\n",
      "3.3864979669451714\n",
      "3327.461532652378\n",
      "0.0\n",
      "200.53051184862852\n",
      "4797.476025026292\n",
      "275.0212236866355\n",
      "1232.5220003128052\n",
      "1818.4710202515125\n",
      "0.0\n",
      "1287.6037260219455\n",
      "6642.521703414619\n",
      "1377.1017268747091\n",
      "0.1458429992198944\n",
      "102.02385060489178\n",
      "0.0\n",
      "28.327990397810936\n",
      "190.68381840735674\n",
      "0.0\n",
      "1.3727099895477295\n",
      "10.329048343002796\n",
      "0.0\n",
      "7.328729078173637\n",
      "1543.1553537100554\n",
      "0.0\n",
      "18.895164117217064\n",
      "3378.5388737022877\n",
      "0.0\n",
      "7.0729270577430725\n",
      "275.1989609673619\n",
      "0.0\n",
      "76.40231604129076\n",
      "412.5812227204442\n",
      "54.88892378658056\n",
      "941.0055165588856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 17.435 seconds\n",
      "Cross-validation score: 0.6378626366317367\n",
      "Test score: 0.6097560975609756\n",
      "Best Hyperparameters: {}\n",
      "4878.2675434798\n",
      "50789.70801113546\n",
      "194312.50130966306\n",
      "1151.1376697719097\n",
      "3945.674787223339\n",
      "754.7233621180058\n",
      "37.006347209215164\n",
      "104.93205258250237\n",
      "73.63026869297028\n",
      "36.0893270522356\n",
      "3060.543601155281\n",
      "431.9964965879917\n",
      "66.78973507881165\n",
      "0.0\n",
      "1132.141613587737\n",
      "0.0\n",
      "765.896692276001\n",
      "0.0\n",
      "0.0\n",
      "10.260002106428146\n",
      "2.3872060328722\n",
      "2.7813360393047333\n",
      "192.08928360044956\n",
      "29.09501051902771\n",
      "19.254622280597687\n",
      "0.0\n",
      "0.2471970021724701\n",
      "0.0\n",
      "0.19053499400615692\n",
      "94.15251070261002\n",
      "167.74579095840454\n",
      "398.2251587584615\n",
      "1066.0729636698961\n",
      "478.15104925632477\n",
      "1176.6882704943419\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "217.84045600891113\n",
      "12961.035878151655\n",
      "845.545717895031\n",
      "125.45133632421494\n",
      "55.969984248280525\n",
      "2809.7757381796837\n",
      "69.00154159963131\n",
      "23.197062969207764\n",
      "1869.7130879759789\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "37.09028919041157\n",
      "1320.4075767993927\n",
      "388.91823092103004\n",
      "2.6866399347782135\n",
      "2.043910026550293\n",
      "56.76066130399704\n",
      "91.99080911278725\n",
      "120.23361671715975\n",
      "100.77230060100555\n",
      "923.643829986453\n",
      "7693.610063105822\n",
      "209.1563863158226\n",
      "10.988229632377625\n",
      "22.96308381855488\n",
      "14.774861007928848\n",
      "30.895390033721924\n",
      "5.08794504404068\n",
      "9.913179874420166\n",
      "6.078355848789215\n",
      "249.26357190310955\n",
      "10890.162293866277\n",
      "144.36519607901573\n",
      "28038.509584464133\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.1542800664901733\n",
      "37.74520817399025\n",
      "5272.941672742367\n",
      "11.141587108373642\n",
      "3.7666889429092407\n",
      "143.8299352824688\n",
      "2438.2082234844565\n",
      "1053.7951559722424\n",
      "1402.1727488785982\n",
      "404.41823922097683\n",
      "720.9669703096151\n",
      "1.2063550353050232\n",
      "25.70397412776947\n",
      "10.686998933553696\n",
      "1103.467326760292\n",
      "15.127900123596191\n",
      "324.48854453861713\n",
      "4203.204941406846\n",
      "48.2836129963398\n",
      "171.3254642188549\n",
      "956.5761981979012\n",
      "13.923310041427612\n",
      "317.1606863439083\n",
      "24899.1881814152\n",
      "675.8739742934704\n",
      "1.1917999982833862\n",
      "445.7952404394746\n",
      "0.0\n",
      "3579.8437316566706\n",
      "73.75309711694717\n",
      "0.0\n",
      "369.66357949376106\n",
      "0.0\n",
      "0.0\n",
      "1.5150359869003296\n",
      "1283.3924302756786\n",
      "0.0\n",
      "348.5129335820675\n",
      "2806.6412377655506\n",
      "0.0\n",
      "8.748624756932259\n",
      "521.1106745153666\n",
      "0.0\n",
      "347.2741678133607\n",
      "1966.907908514142\n",
      "93.1276832818985\n",
      "482.7955244779587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 18.073 seconds\n",
      "Cross-validation score: 0.6887332328508798\n",
      "Test score: 0.5813953488372092\n",
      "Best Hyperparameters: {}\n",
      "9641.661763608456\n",
      "8915.601171292365\n",
      "234321.00942850858\n",
      "689.3119438290596\n",
      "3186.4379846453667\n",
      "204.04837465286255\n",
      "15.456091612577438\n",
      "27.44659924507141\n",
      "2.2063871175050735\n",
      "9.597830832004547\n",
      "1399.5137174129486\n",
      "1.3330740183591843\n",
      "58.0473964959383\n",
      "0.0\n",
      "78.82053545117378\n",
      "0.0\n",
      "225.0755060017109\n",
      "0.0\n",
      "11.49316681921482\n",
      "0.0\n",
      "2.9557100534439087\n",
      "23.24349895119667\n",
      "1044.0935441702604\n",
      "381.0093570947647\n",
      "83.23694199323654\n",
      "3.8646320551633835\n",
      "29.50133255124092\n",
      "2.3250259906053543\n",
      "1.0896999835968018\n",
      "673.1623801290989\n",
      "0.4754129946231842\n",
      "41.892365515232086\n",
      "387.1411154419184\n",
      "273.7555994167924\n",
      "501.38993473351\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2063.4002088606358\n",
      "13737.736178547144\n",
      "564.334350168705\n",
      "8.532391183078289\n",
      "102.6489518135786\n",
      "815.4709562957287\n",
      "37.96275568008423\n",
      "39.05953513085842\n",
      "3208.96655228734\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "344.1909644752741\n",
      "115.55041306465864\n",
      "806.9745433479548\n",
      "47.71994125843048\n",
      "0.0\n",
      "0.4903769940137863\n",
      "206.3717037588358\n",
      "200.13200652599335\n",
      "725.9409098029137\n",
      "4098.135449394584\n",
      "2317.003680638969\n",
      "129.08355262875557\n",
      "0.0\n",
      "220.05634593963623\n",
      "480.99764081835747\n",
      "4.537704065442085\n",
      "0.0\n",
      "1.6112300157546997\n",
      "179.89918397367\n",
      "536.9687859341502\n",
      "522.7389661669731\n",
      "146.813766553998\n",
      "29464.837068013847\n",
      "0.0\n",
      "0.7533869743347168\n",
      "0.0\n",
      "2.2319520115852356\n",
      "3.2494829297065735\n",
      "511.9012757316232\n",
      "15.658504635095596\n",
      "14.752419143915176\n",
      "1728.8127185702324\n",
      "5346.189004004002\n",
      "240.97434785962105\n",
      "5391.223837509751\n",
      "5.400342047214508\n",
      "408.96900245547295\n",
      "87.92209641635418\n",
      "445.3523642271757\n",
      "7.021999835968018\n",
      "2517.9839839041233\n",
      "0.11949300020933151\n",
      "267.33155331015587\n",
      "7763.4004532545805\n",
      "52.331619277596474\n",
      "18.032865278422832\n",
      "1046.3132364600897\n",
      "0.0\n",
      "640.9454761520028\n",
      "26564.83839944005\n",
      "438.05227936059237\n",
      "2.625433027744293\n",
      "50.562076061964035\n",
      "0.0\n",
      "1951.1930186897516\n",
      "180.09667585790157\n",
      "0.0\n",
      "25.167539060115814\n",
      "2.684115044772625\n",
      "0.0\n",
      "0.0\n",
      "2693.032200410962\n",
      "0.0\n",
      "289.108604490757\n",
      "7532.129381641746\n",
      "0.0\n",
      "13.964640140533447\n",
      "389.2802723646164\n",
      "0.0\n",
      "342.6632685959339\n",
      "490.14236921817064\n",
      "86.96957957744598\n",
      "189.0353546962142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 19.247 seconds\n",
      "Cross-validation score: 0.6831106029635442\n",
      "Test score: 0.5555555555555556\n",
      "Best Hyperparameters: {}\n",
      "3451.6802864670753\n",
      "19449.702880509198\n",
      "228233.01398558915\n",
      "463.28496462106705\n",
      "4900.82343237102\n",
      "50.05701553821564\n",
      "2.314816951751709\n",
      "27.599117398262024\n",
      "34.46066749095917\n",
      "189.69152255356312\n",
      "1991.0446843206882\n",
      "23.789648592472076\n",
      "16.900959730148315\n",
      "0.0\n",
      "174.01079440116882\n",
      "0.0\n",
      "1214.8862934112549\n",
      "0.0\n",
      "3.072568342089653\n",
      "24.68231299519539\n",
      "2.6554540246725082\n",
      "1.3860979974269867\n",
      "94.47012101113796\n",
      "314.41650223731995\n",
      "13.207486405968666\n",
      "0.0\n",
      "54.929901123046875\n",
      "116.68492349982262\n",
      "0.12484200298786163\n",
      "475.2835760861635\n",
      "1.107723981142044\n",
      "31.764226853847504\n",
      "1072.1397577375174\n",
      "1023.9931215643883\n",
      "1722.247280806303\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "103.94186900556087\n",
      "9846.783102989197\n",
      "637.8104243278503\n",
      "80.70727328956127\n",
      "173.39579105377197\n",
      "1195.6472957357764\n",
      "0.34589600563049316\n",
      "1.748804971575737\n",
      "687.1104683578014\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "435.3718399554491\n",
      "415.2934074178338\n",
      "195.37370561808348\n",
      "107.40761238336563\n",
      "1.65516996383667\n",
      "1.5956599712371826\n",
      "12.891790270805359\n",
      "711.9555211663246\n",
      "2.4484899044036865\n",
      "1094.1447830796242\n",
      "1259.859179854393\n",
      "368.7916267365217\n",
      "54.19667428731918\n",
      "2.900610089302063\n",
      "19.119591519236565\n",
      "44.5764017701149\n",
      "20.847519278526306\n",
      "42.8067102432251\n",
      "482.605589389801\n",
      "116.47999487817287\n",
      "3317.9527424424887\n",
      "652.7782559841871\n",
      "30264.771228812635\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "6.902369037270546\n",
      "40.27563953399658\n",
      "67.32722669839859\n",
      "13.951139867305756\n",
      "0.0\n",
      "5004.651715323329\n",
      "4803.876584880054\n",
      "475.3197742551565\n",
      "1694.0741202533245\n",
      "602.5421507060528\n",
      "1058.8984477370977\n",
      "310.33861750364304\n",
      "18.768019676208496\n",
      "12.058335199952126\n",
      "726.2609163299203\n",
      "1.6380150318145752\n",
      "393.8340120688081\n",
      "5852.3534768894315\n",
      "101.4224408492446\n",
      "25.697225883603096\n",
      "12750.985561721027\n",
      "0.0\n",
      "853.5241897553205\n",
      "27695.918456315994\n",
      "121.69133335351944\n",
      "5.7998849749565125\n",
      "302.4625148624182\n",
      "0.0\n",
      "160.76239974051714\n",
      "199.53725235909224\n",
      "0.0\n",
      "16.570130586624146\n",
      "0.0\n",
      "0.0\n",
      "19.128279447555542\n",
      "1461.8525825217366\n",
      "0.0\n",
      "374.7761828005314\n",
      "3208.239249318838\n",
      "0.0\n",
      "3.622320055961609\n",
      "15.70117487758398\n",
      "0.0\n",
      "1528.0711717680097\n",
      "3508.441760018468\n",
      "135.00214536488056\n",
      "21.334281235933304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 18.045 seconds\n",
      "Cross-validation score: 0.6633287955868601\n",
      "Test score: 0.6626506024096386\n",
      "Best Hyperparameters: {}\n",
      "2980.6993339955807\n",
      "12276.402185335755\n",
      "232808.39892058074\n",
      "807.5997948274016\n",
      "5635.380112826824\n",
      "560.1336581408978\n",
      "2.760930061340332\n",
      "46.51848649978638\n",
      "9.182279706001282\n",
      "0.9464969784021378\n",
      "1751.3796660006046\n",
      "586.3483016937971\n",
      "0.0\n",
      "0.0\n",
      "57.86039161682129\n",
      "0.0\n",
      "482.62408995628357\n",
      "0.0\n",
      "5.243092089891434\n",
      "1.4224349856376648\n",
      "3.7542919665575027\n",
      "8.438218042254448\n",
      "241.5416143834591\n",
      "263.2409973144531\n",
      "196.22867718338966\n",
      "30.413799285888672\n",
      "5.858369797468185\n",
      "637.4035810232162\n",
      "0.0\n",
      "2011.839421480894\n",
      "2.772001028060913\n",
      "345.5090760588646\n",
      "226.00262799859047\n",
      "877.1573034226894\n",
      "3934.6964554339647\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "835.5627666711807\n",
      "2015.5971185415983\n",
      "646.0026807039976\n",
      "6.644865900278091\n",
      "28.007638245821\n",
      "1566.9786123335361\n",
      "1336.3391485065222\n",
      "13.192569017410278\n",
      "2177.3969959765673\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "788.2892444133759\n",
      "1421.2531101107597\n",
      "294.8760190978646\n",
      "44.635469645261765\n",
      "1.6033989936113358\n",
      "0.0\n",
      "321.9696843624115\n",
      "224.79810082912445\n",
      "9.731781274080276\n",
      "1849.3309752494097\n",
      "7291.857992947102\n",
      "1671.824584722519\n",
      "100.85789084434509\n",
      "0.763221025466919\n",
      "80.31892931461334\n",
      "76.38979759812355\n",
      "1.9967480152845383\n",
      "253.65449488162994\n",
      "153.2860022559762\n",
      "1166.6572703272104\n",
      "968.297420501709\n",
      "170.51387771964073\n",
      "21967.853807285428\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "72.29650768637657\n",
      "32.98190373182297\n",
      "957.3441545218229\n",
      "10.098854929208755\n",
      "462.78600796312094\n",
      "2499.376393735409\n",
      "3477.4143391773105\n",
      "214.1182780265808\n",
      "17895.863301113248\n",
      "782.5140614509583\n",
      "147.01938720047474\n",
      "9.648819103837013\n",
      "4.315960049629211\n",
      "43.667848110198975\n",
      "168.53248654305935\n",
      "0.0\n",
      "506.7040213495493\n",
      "7023.7322813645005\n",
      "70.8833386823535\n",
      "8.721152938902378\n",
      "11424.33951883018\n",
      "0.0\n",
      "1190.0944732427597\n",
      "12929.960388362408\n",
      "1196.461487069726\n",
      "26.36242452263832\n",
      "204.998476177454\n",
      "0.0\n",
      "89.56796295940876\n",
      "11.960293114185333\n",
      "0.0\n",
      "46.92441074550152\n",
      "2.3246939182281494\n",
      "0.0\n",
      "42.509455382823944\n",
      "1979.4450533688068\n",
      "0.0\n",
      "28.21737551689148\n",
      "7918.892857894301\n",
      "0.0\n",
      "53.330644860863686\n",
      "67.17786121368408\n",
      "0.0\n",
      "739.2734527438879\n",
      "3586.575095385313\n",
      "3.2886590659618378\n",
      "908.1251060068607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 18.615 seconds\n",
      "Cross-validation score: 0.5530852973867679\n",
      "Test score: 0.8620689655172415\n",
      "Best Hyperparameters: {}\n",
      "6798.558663204312\n",
      "12936.428010836244\n",
      "224926.9740922451\n",
      "477.83089013397694\n",
      "3657.62834918499\n",
      "63.024099349975586\n",
      "130.69394099712372\n",
      "118.11543709039688\n",
      "140.17698007822037\n",
      "9.597193986177444\n",
      "1014.9952217638493\n",
      "343.35188269615173\n",
      "27.206069946289062\n",
      "0.0\n",
      "3.1743910908699036\n",
      "0.0\n",
      "1181.0795148313046\n",
      "6.532089054584503\n",
      "97.20221608877182\n",
      "52.66110038757324\n",
      "8.126150965690613\n",
      "4.218022882938385\n",
      "82.88495230674744\n",
      "7.361268162727356\n",
      "353.3509665131569\n",
      "21.608920574188232\n",
      "285.22139543294907\n",
      "4.462147012352943\n",
      "4.933020114898682\n",
      "274.66133269667625\n",
      "292.7307337075472\n",
      "552.7448235303164\n",
      "202.2937426865101\n",
      "210.80026631057262\n",
      "891.5293359607458\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1137.134358227253\n",
      "15568.437703251839\n",
      "137.22695633769035\n",
      "194.35771790146828\n",
      "97.41605082154274\n",
      "699.7849950790405\n",
      "47.28383922576904\n",
      "9.476456850767136\n",
      "606.0806111395359\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "301.97285006940365\n",
      "1005.5784030407667\n",
      "546.8355002701283\n",
      "99.99303251504898\n",
      "4.016449064016342\n",
      "57.107929944992065\n",
      "599.864106580615\n",
      "1391.06474801898\n",
      "93.05645905435085\n",
      "2924.5858065783978\n",
      "1590.3346656560898\n",
      "472.93935096263885\n",
      "30.080875009298325\n",
      "79.47850227355957\n",
      "246.3862652182579\n",
      "7.910138875246048\n",
      "133.3478104174137\n",
      "0.0\n",
      "373.21795508265495\n",
      "206.89767190814018\n",
      "164.66520082950592\n",
      "538.9425568580627\n",
      "30138.777605608106\n",
      "205.5475959777832\n",
      "265.63203178346157\n",
      "3.9640700817108154\n",
      "86.38646486401558\n",
      "74.19637060165405\n",
      "1012.0438475012779\n",
      "215.0413409769535\n",
      "1.7593200206756592\n",
      "817.2006969153881\n",
      "8479.36692237854\n",
      "773.0345622599125\n",
      "5826.396651133895\n",
      "4.989019870758057\n",
      "835.3173012137413\n",
      "324.93010330200195\n",
      "367.82238817214966\n",
      "55.506728768348694\n",
      "10265.33916324377\n",
      "16.38730362057686\n",
      "157.09163227677345\n",
      "9969.041812628508\n",
      "98.92566539347172\n",
      "98.67237038910389\n",
      "386.0762528479099\n",
      "0.0\n",
      "398.9507338106632\n",
      "20572.74046856165\n",
      "640.4093591272831\n",
      "0.19058899581432343\n",
      "384.8949418067932\n",
      "0.0\n",
      "2532.3178088515997\n",
      "73.71508583426476\n",
      "0.0\n",
      "30.969258040189743\n",
      "547.848866045475\n",
      "0.0\n",
      "101.42869234085083\n",
      "3149.875129967928\n",
      "0.0\n",
      "506.3729168921709\n",
      "3143.6189125031233\n",
      "0.0\n",
      "6.269754871726036\n",
      "374.3157232105732\n",
      "0.0\n",
      "71.78982692956924\n",
      "870.7889072597027\n",
      "14.736158967018127\n",
      "2632.422469139099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 19.043 seconds\n",
      "Cross-validation score: 0.6085831555785917\n",
      "Test score: 0.6896551724137931\n",
      "Best Hyperparameters: {}\n",
      "2984.822212189436\n",
      "47081.310090348125\n",
      "184858.37793247402\n",
      "1434.4105114787817\n",
      "2745.5791583657265\n",
      "235.88749885559082\n",
      "21.424006208777428\n",
      "1.1376410126686096\n",
      "0.6114659905433655\n",
      "15.017168015241623\n",
      "2808.1811570227146\n",
      "404.0474805831909\n",
      "20.51078987121582\n",
      "0.0\n",
      "4.790399044752121\n",
      "0.0\n",
      "274.871489033103\n",
      "0.0\n",
      "4.7194148898124695\n",
      "6.0501598715782166\n",
      "15.214598998427391\n",
      "10.783550083637238\n",
      "518.3696303963661\n",
      "1.3875800371170044\n",
      "349.09407609701157\n",
      "0.0\n",
      "4.442186057567596\n",
      "31.132856786251068\n",
      "1.5924160182476044\n",
      "143.505438670516\n",
      "4.6739639937877655\n",
      "464.6362189203501\n",
      "970.2972297370434\n",
      "697.6677759885788\n",
      "2320.3754616975784\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1572.6600537002087\n",
      "12701.517331928015\n",
      "762.0280020385981\n",
      "73.41354481875896\n",
      "54.74424394965172\n",
      "1264.140475153923\n",
      "543.1227328777313\n",
      "24.451710522174835\n",
      "3725.498514354229\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "450.6755714863539\n",
      "754.6612172424793\n",
      "430.6484344601631\n",
      "24.377915024757385\n",
      "2.50819993019104\n",
      "53.60992181301117\n",
      "466.9001500606537\n",
      "116.96491873264313\n",
      "38.83831137418747\n",
      "3436.0961049348116\n",
      "3635.4902614057064\n",
      "416.0750990509987\n",
      "0.20822100341320038\n",
      "109.37485074996948\n",
      "61.28282864391804\n",
      "28.904864937067032\n",
      "63.36898651719093\n",
      "0.0\n",
      "2.7998099327087402\n",
      "135.7348753809929\n",
      "2124.118647918105\n",
      "59.651334047317505\n",
      "34497.35057348013\n",
      "0.0\n",
      "954.5908234715462\n",
      "0.0\n",
      "7.0780599266290665\n",
      "13.43000677227974\n",
      "1012.12125441432\n",
      "72.12544628977776\n",
      "161.7361125946045\n",
      "235.7996146082878\n",
      "2669.1014260053635\n",
      "293.10251247882843\n",
      "7171.680181711912\n",
      "107.88128238916397\n",
      "123.91825333237648\n",
      "288.178481310606\n",
      "351.1903108358383\n",
      "32.25598865747452\n",
      "996.0580162107944\n",
      "4.9677310436964035\n",
      "1395.8812252730131\n",
      "7173.435933828354\n",
      "26.299907863140106\n",
      "195.13226401805878\n",
      "398.39442832767963\n",
      "0.38687199354171753\n",
      "800.2887721061707\n",
      "25307.485268324614\n",
      "527.3548539578915\n",
      "7.849590063095093\n",
      "201.13372953236103\n",
      "0.0\n",
      "3247.3199586868286\n",
      "52.40252295136452\n",
      "0.0\n",
      "44.691174149513245\n",
      "754.3880073428154\n",
      "0.0\n",
      "5.992285996675491\n",
      "2707.0844545662403\n",
      "0.0\n",
      "1129.9817604720592\n",
      "14126.835802972317\n",
      "0.0\n",
      "52.899178981781006\n",
      "91.84822443127632\n",
      "0.0\n",
      "380.98729936778545\n",
      "684.7945721894503\n",
      "122.69730731844902\n",
      "1078.9754511713982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 19.079 seconds\n",
      "Cross-validation score: 0.6376372022163097\n",
      "Test score: 0.7058823529411765\n",
      "Best Hyperparameters: {}\n",
      "4061.9866207391024\n",
      "18519.34640520811\n",
      "209396.94324208796\n",
      "710.570310972631\n",
      "4688.249624282122\n",
      "0.0\n",
      "9.916061043739319\n",
      "2.6633999347686768\n",
      "7.304684937000275\n",
      "0.0\n",
      "4564.786121085286\n",
      "1240.6741273924708\n",
      "7.051608219742775\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2018.0395778417587\n",
      "4.044310092926025\n",
      "91.2682991027832\n",
      "0.34671899676322937\n",
      "0.0\n",
      "1.5938260108232498\n",
      "225.4403556585312\n",
      "0.5846280008554459\n",
      "15.566411033272743\n",
      "0.0\n",
      "238.44696587324142\n",
      "0.0\n",
      "4.463850021362305\n",
      "217.56950767338276\n",
      "10.012145906686783\n",
      "44.742054745554924\n",
      "2215.8803570866585\n",
      "455.75501368939877\n",
      "2311.1644409894943\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "387.0115033984184\n",
      "23408.608678124845\n",
      "1656.0354181826115\n",
      "133.9187355041504\n",
      "157.77169781923294\n",
      "182.08470702171326\n",
      "157.81255087256432\n",
      "62.10242947936058\n",
      "3748.731559202075\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "660.153126090765\n",
      "693.1768585145473\n",
      "360.09594006836414\n",
      "13.15904588997364\n",
      "10.411832869052887\n",
      "5.728659018874168\n",
      "1072.772583246231\n",
      "221.69974741339684\n",
      "46.8795482814312\n",
      "2047.1095934659243\n",
      "753.6285023540258\n",
      "1203.1284048259258\n",
      "6.537584096193314\n",
      "65.07039642333984\n",
      "36.79648604989052\n",
      "32.08253341913223\n",
      "3.4978179931640625\n",
      "1.5912699699401855\n",
      "162.43864844739437\n",
      "1398.1816613301635\n",
      "3349.750781685114\n",
      "228.2207987755537\n",
      "34130.507792152464\n",
      "366.45560455322266\n",
      "0.34029099345207214\n",
      "0.0\n",
      "164.5500168800354\n",
      "0.9136680066585541\n",
      "1808.3315481692553\n",
      "10.109941869974136\n",
      "32.21674332022667\n",
      "124.60572481155396\n",
      "16357.504545360804\n",
      "230.97968518733978\n",
      "11134.70413224399\n",
      "611.1418941020966\n",
      "926.033586204052\n",
      "20.21263360977173\n",
      "147.6454986333847\n",
      "41.68796855211258\n",
      "228.07236424088478\n",
      "44.29059982299805\n",
      "174.13897101581097\n",
      "6411.6519331038\n",
      "19.909991949796677\n",
      "133.26527535915375\n",
      "7209.395579099655\n",
      "0.3965350091457367\n",
      "501.9462735801935\n",
      "5209.351410008967\n",
      "77.95971716940403\n",
      "6.526255890727043\n",
      "145.03771436214447\n",
      "0.0\n",
      "180.76476810872555\n",
      "110.83824150264263\n",
      "0.0\n",
      "114.93132191896439\n",
      "37.2458601295948\n",
      "0.0\n",
      "58.0942438095808\n",
      "2760.982794433832\n",
      "0.0\n",
      "190.42067939043045\n",
      "6182.928162038326\n",
      "0.0\n",
      "96.97525131702423\n",
      "162.93524323403835\n",
      "0.0\n",
      "1157.96762701869\n",
      "176.2751073539257\n",
      "46.07752102613449\n",
      "227.12090092897415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 19.219 seconds\n",
      "Cross-validation score: 0.65208632097177\n",
      "Test score: 0.6395348837209303\n",
      "Best Hyperparameters: {}\n",
      "7597.624492175877\n",
      "18113.16142399609\n",
      "234124.38143837452\n",
      "1573.0765276625752\n",
      "2773.7478093504906\n",
      "1140.3564783036709\n",
      "16.96931004524231\n",
      "1.3811399936676025\n",
      "13.215018048882484\n",
      "17.144359782338142\n",
      "1907.899138316512\n",
      "21.90009744465351\n",
      "13.976680159568787\n",
      "0.0\n",
      "8.089642882347107\n",
      "0.0\n",
      "362.55539183318615\n",
      "0.0\n",
      "0.0\n",
      "0.22630099952220917\n",
      "2.563541978597641\n",
      "17.6796013712883\n",
      "268.9133608341217\n",
      "0.0\n",
      "12.20294277369976\n",
      "17.947200775146484\n",
      "125.33506554365158\n",
      "0.23785099387168884\n",
      "13.33136485517025\n",
      "780.6789400875568\n",
      "11.730950385332108\n",
      "104.35696370899677\n",
      "68.47733472287655\n",
      "505.4049491882324\n",
      "1105.1386847794056\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1750.1659967303276\n",
      "11950.503212548792\n",
      "1830.258882433176\n",
      "142.01828277111053\n",
      "51.14943131804466\n",
      "1309.6817324012518\n",
      "315.00050354003906\n",
      "16.96616780757904\n",
      "3635.90821069479\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "229.03450395166874\n",
      "866.5378602445126\n",
      "210.8642332404852\n",
      "90.06189227104187\n",
      "1.996146023273468\n",
      "12.42020034790039\n",
      "435.83944910764694\n",
      "38.01227778196335\n",
      "394.4952077716589\n",
      "2692.4940472245216\n",
      "1948.4898858368397\n",
      "806.9795556664467\n",
      "4.159485876560211\n",
      "5.773519992828369\n",
      "162.3611245378852\n",
      "11.751843243837357\n",
      "1.9980499744415283\n",
      "2.8137170672416687\n",
      "92.46156388521194\n",
      "115.72342981398106\n",
      "1134.6790567934513\n",
      "113.62431536614895\n",
      "26884.55097040534\n",
      "4.282869815826416\n",
      "2.732476979494095\n",
      "0.0\n",
      "219.0346258878708\n",
      "223.6563060581684\n",
      "122.30510994791985\n",
      "48.849825114011765\n",
      "7.234164774417877\n",
      "16.817792609333992\n",
      "1197.4079259186983\n",
      "212.87693585455418\n",
      "3413.254840955138\n",
      "629.668710231781\n",
      "265.36383394151926\n",
      "4.541200906038284\n",
      "402.15846014022827\n",
      "7.372740037739277\n",
      "8544.247101590037\n",
      "0.5126410126686096\n",
      "418.0794902741909\n",
      "8547.194951191545\n",
      "2.3011660426855087\n",
      "20.933046504855156\n",
      "266.04217314720154\n",
      "0.0\n",
      "390.2158091068268\n",
      "26059.51519867778\n",
      "898.8024578541517\n",
      "4.261290073394775\n",
      "41.83813760429621\n",
      "0.0\n",
      "2785.604699894786\n",
      "83.0936344563961\n",
      "0.0\n",
      "0.0\n",
      "5.422714918851852\n",
      "0.0\n",
      "7.831073880195618\n",
      "2318.9901445508003\n",
      "0.0\n",
      "317.1429452598095\n",
      "4448.461510762572\n",
      "0.0\n",
      "4.477937072515488\n",
      "201.36934188008308\n",
      "0.0\n",
      "79.72758048772812\n",
      "364.41381604224443\n",
      "79.48035591840744\n",
      "473.62859562039375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 18.014 seconds\n",
      "Cross-validation score: 0.6845188198129375\n",
      "Test score: 0.6470588235294119\n",
      "Best Hyperparameters: {}\n",
      "7849.492887958884\n",
      "23320.546225838363\n",
      "232078.53786106408\n",
      "378.9214857965708\n",
      "169.1990047544241\n",
      "1384.5383361577988\n",
      "10.76405020058155\n",
      "1.2685830295085907\n",
      "0.6954689919948578\n",
      "42.038078151643276\n",
      "6993.758774146438\n",
      "795.0971154868603\n",
      "35.75299954414368\n",
      "0.0\n",
      "36.07670494914055\n",
      "0.0\n",
      "3.521850064396858\n",
      "0.0\n",
      "0.2708350121974945\n",
      "0.0\n",
      "10.350571528077126\n",
      "16.640419125556946\n",
      "258.7017941623926\n",
      "0.27870090305805206\n",
      "48.77349853515625\n",
      "0.0\n",
      "2.9285110533237457\n",
      "0.0\n",
      "0.5017083883285522\n",
      "7.316232420504093\n",
      "74.63779376447201\n",
      "276.9197671711445\n",
      "92.37103708088398\n",
      "195.1220097243786\n",
      "939.1474779844284\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "104.52453534305096\n",
      "15928.431829690933\n",
      "182.43109334260225\n",
      "15.565491527318954\n",
      "104.48385713249445\n",
      "845.9117229878902\n",
      "3.864468038082123\n",
      "2.2553629875183105\n",
      "2046.589763469994\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "530.8847876787186\n",
      "91.21790805459023\n",
      "507.9314827620983\n",
      "18.565069139003754\n",
      "24.918399810791016\n",
      "0.0\n",
      "4931.880496963859\n",
      "798.2418625056744\n",
      "65.87268254160881\n",
      "2346.240741789341\n",
      "890.8751532137394\n",
      "93.9904178828001\n",
      "13.297474935650826\n",
      "87.1844310760498\n",
      "0.0\n",
      "61.617494627833366\n",
      "0.0\n",
      "0.0\n",
      "206.08400344848633\n",
      "1084.1030286028981\n",
      "1133.8637021929026\n",
      "75.19186030328274\n",
      "28228.997842535377\n",
      "0.0\n",
      "15.214485049247742\n",
      "0.0\n",
      "36.612656623125076\n",
      "6.936999022960663\n",
      "113.55611480772495\n",
      "60.85657715797424\n",
      "50.40049982070923\n",
      "14.90010017156601\n",
      "183.46229499578476\n",
      "88.49033134430647\n",
      "22760.979135408998\n",
      "20.563308849930763\n",
      "65.23232167959213\n",
      "0.17580200731754303\n",
      "112.8143921494484\n",
      "1.8067639470100403\n",
      "8986.55653130263\n",
      "0.6695979833602905\n",
      "47.423262380063534\n",
      "6790.32147847116\n",
      "217.05208839476109\n",
      "8.821919918060303\n",
      "371.2021776139736\n",
      "0.0\n",
      "466.16131380945444\n",
      "7279.194016486406\n",
      "318.2030629441142\n",
      "85.95119681954384\n",
      "124.51165828108788\n",
      "0.0\n",
      "37.623912796378136\n",
      "26.5569117218256\n",
      "0.0\n",
      "63.218299865722656\n",
      "0.600037008523941\n",
      "0.0\n",
      "44.22083190083504\n",
      "1828.0553494989872\n",
      "0.0\n",
      "724.4154450297356\n",
      "3302.6346897631884\n",
      "0.0\n",
      "89.86459991335869\n",
      "56.66090048849583\n",
      "0.0\n",
      "613.0628045648336\n",
      "49.02838355302811\n",
      "187.01716774702072\n",
      "442.2444489300251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 17.674 seconds\n",
      "Cross-validation score: 0.6396730465967286\n",
      "Test score: 0.7647058823529411\n",
      "Best Hyperparameters: {}\n",
      "2973.9765182584524\n",
      "5865.7318314909935\n",
      "240384.22211059928\n",
      "795.243518859148\n",
      "3728.0067954584956\n",
      "10.8339102268219\n",
      "4.555308923125267\n",
      "2.255905032157898\n",
      "0.0\n",
      "8.944408878684044\n",
      "2215.3689906597137\n",
      "392.04330241680145\n",
      "40.58694925904274\n",
      "0.0\n",
      "35.1196524053812\n",
      "0.0\n",
      "704.7034591734409\n",
      "0.0\n",
      "291.45123732089996\n",
      "13.338471174240112\n",
      "14.81948509812355\n",
      "14.957987681031227\n",
      "268.9718592315912\n",
      "0.0\n",
      "80.93169784545898\n",
      "0.0\n",
      "1.1082780063152313\n",
      "0.4164170026779175\n",
      "1.2758129835128784\n",
      "329.7782623767853\n",
      "5.802391946315765\n",
      "455.48895312845707\n",
      "1386.6710687428713\n",
      "440.9992128536105\n",
      "1525.2193825691938\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "92.82149969041348\n",
      "11476.279289782047\n",
      "178.61151406168938\n",
      "22.83196896314621\n",
      "225.2126908302307\n",
      "1410.5945746302605\n",
      "19.59037621319294\n",
      "11.763776034116745\n",
      "661.3295210599899\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "850.163166642189\n",
      "2560.571218699217\n",
      "178.6119288727641\n",
      "20.618491664528847\n",
      "0.0\n",
      "0.0\n",
      "13.346306771039963\n",
      "74.39788043498993\n",
      "127.65313871204853\n",
      "4402.226302176714\n",
      "2673.249214120209\n",
      "366.0797525346279\n",
      "23.204892724752426\n",
      "57.66235700249672\n",
      "42.54039238393307\n",
      "10.429549217224121\n",
      "6.633127868175507\n",
      "11.155400276184082\n",
      "0.0\n",
      "254.22251252830029\n",
      "159.28462775051594\n",
      "498.03463776409626\n",
      "24768.27770513296\n",
      "3.339526951313019\n",
      "1200.796096354723\n",
      "2.304069995880127\n",
      "134.01827535033226\n",
      "106.85890857875347\n",
      "1471.728915065527\n",
      "57.41875094175339\n",
      "283.3819722533226\n",
      "76.22701671719551\n",
      "4047.6228466928005\n",
      "337.4803762435913\n",
      "1600.9831726551056\n",
      "170.3527004122734\n",
      "516.0636824071407\n",
      "196.06406527757645\n",
      "145.9618048220873\n",
      "0.14271099865436554\n",
      "1128.1913033127785\n",
      "0.0\n",
      "113.04599177837372\n",
      "10422.62395966053\n",
      "30.720651984214783\n",
      "384.9986648708582\n",
      "2214.8131695985794\n",
      "0.0\n",
      "206.73373879492283\n",
      "27786.568091511726\n",
      "451.1480992436409\n",
      "0.8116809725761414\n",
      "85.82090268284082\n",
      "0.0\n",
      "3724.2740411013365\n",
      "25.944910943508148\n",
      "0.0\n",
      "65.84680505096912\n",
      "644.7297973632812\n",
      "0.0\n",
      "19.534329891204834\n",
      "2953.0475764274597\n",
      "0.0\n",
      "683.8975168019533\n",
      "15442.883286610246\n",
      "0.0\n",
      "97.31950378417969\n",
      "348.85178473591805\n",
      "0.0\n",
      "188.76213635504246\n",
      "21.468197897076607\n",
      "54.394967034459114\n",
      "474.97061428427696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 17.844 seconds\n",
      "Cross-validation score: 0.5928410840175545\n",
      "Test score: 0.7558139534883721\n",
      "Best Hyperparameters: {}\n",
      "5800.857585340738\n",
      "9238.187021553516\n",
      "231651.77839341015\n",
      "936.3296315819025\n",
      "3029.3118290007114\n",
      "867.1396980285645\n",
      "88.57701027393341\n",
      "13.434020280838013\n",
      "27.095771580934525\n",
      "15.558680534362793\n",
      "2504.3992764651775\n",
      "3.673191010951996\n",
      "5.053540229797363\n",
      "0.0\n",
      "184.02698677778244\n",
      "0.0\n",
      "255.4980598539114\n",
      "0.0\n",
      "2.0579869747161865\n",
      "5.896470069885254\n",
      "6.871365994215012\n",
      "12.431290924549103\n",
      "307.23889222741127\n",
      "4.166500091552734\n",
      "299.84273570775986\n",
      "0.0\n",
      "297.2518945634365\n",
      "34.180150389671326\n",
      "0.0\n",
      "56.81205013394356\n",
      "48.88127210736275\n",
      "244.36709094047546\n",
      "308.7352253496647\n",
      "81.5211159735918\n",
      "120.06271056830883\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2107.4373453855515\n",
      "14494.923840142787\n",
      "922.4627189934254\n",
      "179.4684484153986\n",
      "12.500948198139668\n",
      "895.0732183903456\n",
      "483.63955676555634\n",
      "15.162582665681839\n",
      "3983.413219191134\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "620.4189659059048\n",
      "1541.9972968399525\n",
      "226.9802074059844\n",
      "23.012547552585602\n",
      "52.41806733608246\n",
      "0.0\n",
      "293.7319173514843\n",
      "74.23927380144596\n",
      "148.5450648739934\n",
      "1595.2609927803278\n",
      "2156.7553335279226\n",
      "94.96860928833485\n",
      "52.76871404051781\n",
      "0.0\n",
      "287.11609990894794\n",
      "91.27420234680176\n",
      "2.9848198890686035\n",
      "0.0\n",
      "5.585120975971222\n",
      "1083.9141708910465\n",
      "1295.9580816924572\n",
      "32.44742000102997\n",
      "36204.99231693894\n",
      "1.9168130457401276\n",
      "35.81136405467987\n",
      "0.0\n",
      "423.5313261896372\n",
      "245.66896378993988\n",
      "39.372543185949326\n",
      "83.54909613728523\n",
      "3.172095015645027\n",
      "165.5378774702549\n",
      "901.9417825490236\n",
      "1566.5182625055313\n",
      "3100.932990372181\n",
      "83.19116586446762\n",
      "416.9180181622505\n",
      "945.6921806335449\n",
      "260.2811296880245\n",
      "7.313658982515335\n",
      "11063.520311683416\n",
      "2.1862099170684814\n",
      "280.05374878644943\n",
      "7968.433724477887\n",
      "64.40601119399071\n",
      "6.986568935215473\n",
      "75.55785347521305\n",
      "0.0\n",
      "427.8287377655506\n",
      "28122.100018173456\n",
      "313.3514504879713\n",
      "0.0\n",
      "47.12740930914879\n",
      "0.0\n",
      "784.5779044777155\n",
      "197.5235555395484\n",
      "0.0\n",
      "0.0\n",
      "281.5947081744671\n",
      "0.0\n",
      "50.670168459415436\n",
      "2835.970436640084\n",
      "0.0\n",
      "336.6120863482356\n",
      "3276.7000780254602\n",
      "0.0\n",
      "45.24106869101524\n",
      "389.69126565009356\n",
      "0.0\n",
      "115.95863397419453\n",
      "140.92077493667603\n",
      "7.4600649774074554\n",
      "564.631158977747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 17.142 seconds\n",
      "Cross-validation score: 0.6521460393751415\n",
      "Test score: 0.6547619047619049\n",
      "Best Hyperparameters: {}\n",
      "9728.11877144128\n",
      "763.7625909149647\n",
      "231501.88915950805\n",
      "135.68837651610374\n",
      "5538.557370126247\n",
      "671.9739391207695\n",
      "12.781822085380554\n",
      "0.0\n",
      "8.084871977567673\n",
      "0.0\n",
      "7601.056592985988\n",
      "217.06739127635956\n",
      "15.722692549228668\n",
      "0.0\n",
      "5.248457983136177\n",
      "0.0\n",
      "1189.009752213955\n",
      "3.5299201011657715\n",
      "1.1023900508880615\n",
      "12.401214063167572\n",
      "10.631472915410995\n",
      "1.475163996219635\n",
      "693.0161541700363\n",
      "2.9693950414657593\n",
      "108.80129514634609\n",
      "2.663450002670288\n",
      "1038.6910164952278\n",
      "8.132694959640503\n",
      "37.930108070373535\n",
      "311.47323593497276\n",
      "12.093460038304329\n",
      "24.8053620159626\n",
      "259.17743679881096\n",
      "576.1891873925924\n",
      "48.317910715937614\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "353.11752888560295\n",
      "24157.278924897313\n",
      "515.158300369978\n",
      "46.90066985785961\n",
      "696.3268654644489\n",
      "820.4691066741943\n",
      "38.09682980179787\n",
      "101.33230063319206\n",
      "994.6260248422623\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "179.00536526739597\n",
      "443.22400533407927\n",
      "270.657180711627\n",
      "0.9508939832448959\n",
      "5.176330015063286\n",
      "40.123600006103516\n",
      "1790.8443097993731\n",
      "70.6575820595026\n",
      "79.9167668223381\n",
      "1319.4239719957113\n",
      "2531.300569832325\n",
      "428.0107136964798\n",
      "2296.8341807127\n",
      "2.5164899826049805\n",
      "58.61968398094177\n",
      "12.263785973191261\n",
      "4.572951078414917\n",
      "0.0\n",
      "118.67422702908516\n",
      "104.74403174221516\n",
      "4861.2573238015175\n",
      "362.0655554383993\n",
      "30789.565945401788\n",
      "68.9025311768055\n",
      "514.7819776087999\n",
      "0.0\n",
      "0.0\n",
      "421.6457779407501\n",
      "1514.060627400875\n",
      "5.84850686788559\n",
      "68.640560567379\n",
      "1182.6616482287645\n",
      "4656.250855982304\n",
      "357.42117089033127\n",
      "12459.675782769918\n",
      "177.6705378293991\n",
      "380.398731559515\n",
      "3.123349905014038\n",
      "137.17768269777298\n",
      "2.1438399851322174\n",
      "1891.101252913475\n",
      "0.0\n",
      "254.59724242985249\n",
      "7305.053105473518\n",
      "37.41867680847645\n",
      "148.3351840376854\n",
      "1061.6565740257502\n",
      "0.0\n",
      "1202.4662587195635\n",
      "8561.805305972695\n",
      "908.1572762876749\n",
      "3.3307099491357803\n",
      "1.2351469993591309\n",
      "0.0\n",
      "168.19354759156704\n",
      "259.50148355960846\n",
      "0.0\n",
      "231.8846440911293\n",
      "123.149408608675\n",
      "0.0\n",
      "1.55840003490448\n",
      "2513.8088773339987\n",
      "0.0\n",
      "663.4968832656741\n",
      "8682.477855354548\n",
      "0.0\n",
      "15.098150253295898\n",
      "131.2566591501236\n",
      "0.0\n",
      "97.23769806325436\n",
      "84.04463368654251\n",
      "53.45550099015236\n",
      "724.8371021896601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 17.907 seconds\n",
      "Cross-validation score: 0.6724160007905471\n",
      "Test score: 0.5882352941176471\n",
      "Best Hyperparameters: {}\n",
      "290.7738082408905\n",
      "264.09494295716286\n",
      "253567.20570394397\n",
      "652.4697199985385\n",
      "3920.1537416875362\n",
      "33.09628975391388\n",
      "5.327095851302147\n",
      "19.005035862326622\n",
      "6.8656060844659805\n",
      "17.80404394865036\n",
      "2273.1496170163155\n",
      "7.1358218640089035\n",
      "6.991171061992645\n",
      "0.0\n",
      "21.290029764175415\n",
      "0.0\n",
      "625.6137169897556\n",
      "0.0\n",
      "224.5239963531494\n",
      "0.216622993350029\n",
      "4.948156982660294\n",
      "0.9816910326480865\n",
      "493.6916908621788\n",
      "0.0\n",
      "440.377911940217\n",
      "5.785140037536621\n",
      "72.5794405117631\n",
      "0.0\n",
      "2.0167360305786133\n",
      "842.3559204041958\n",
      "9.61269986629486\n",
      "208.3765394538641\n",
      "194.8522961139679\n",
      "323.2363557368517\n",
      "1388.7658199220896\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "129.22140255570412\n",
      "9382.277806803584\n",
      "1551.4776741564274\n",
      "69.37010577321053\n",
      "21.609009981155396\n",
      "1214.905923217535\n",
      "20.467133432626724\n",
      "69.94922791421413\n",
      "835.5608465969563\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "390.1491229683161\n",
      "584.0626858025789\n",
      "382.1066918820143\n",
      "2.9015400409698486\n",
      "5.292979031801224\n",
      "116.71708835661411\n",
      "135.38820159435272\n",
      "155.25223465263844\n",
      "37.784876585006714\n",
      "5639.587515115738\n",
      "2785.3821464031935\n",
      "650.5760501772165\n",
      "334.38164199888706\n",
      "7.203179955482483\n",
      "12.19321408867836\n",
      "99.94817250967026\n",
      "7.967154920101166\n",
      "48.91529846191406\n",
      "23.932164788246155\n",
      "81.79521649330854\n",
      "786.1468815803528\n",
      "547.8481208533049\n",
      "29549.69385293126\n",
      "4.43452013283968\n",
      "817.44140625\n",
      "1.5073890686035156\n",
      "100.95890045166016\n",
      "550.772159665823\n",
      "2213.7509535104036\n",
      "160.206400513649\n",
      "0.0\n",
      "8.506547898054123\n",
      "3977.234218388796\n",
      "193.50972582399845\n",
      "17052.87619267404\n",
      "49.20650005340576\n",
      "427.3373295068741\n",
      "6.763233125209808\n",
      "13.84350198507309\n",
      "26.699278309941292\n",
      "83.97700759768486\n",
      "14.469284892082214\n",
      "81.24486789107323\n",
      "9684.244429327548\n",
      "173.67364951968193\n",
      "178.47914275527\n",
      "134.00925047695637\n",
      "0.0\n",
      "5151.304109573364\n",
      "7263.810146912932\n",
      "738.7826826423407\n",
      "3.6676570773124695\n",
      "42.88496232032776\n",
      "0.0\n",
      "3030.7528230696917\n",
      "85.62048578262329\n",
      "0.0\n",
      "244.9372717142105\n",
      "0.21842999756336212\n",
      "0.0\n",
      "12.70206305384636\n",
      "2177.271732583642\n",
      "0.0\n",
      "416.83495761454105\n",
      "8881.054708376527\n",
      "0.0\n",
      "23.46711279451847\n",
      "210.1996922492981\n",
      "0.0\n",
      "287.2695637345314\n",
      "3070.4303239285946\n",
      "67.28701563179493\n",
      "1839.8591884970665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 16.668 seconds\n",
      "Cross-validation score: 0.6726938094585153\n",
      "Test score: 0.5063291139240507\n",
      "Best Hyperparameters: {}\n",
      "995.8638919889927\n",
      "362.52709808945656\n",
      "269222.8003476709\n",
      "186.53897784650326\n",
      "291.62707959115505\n",
      "0.0\n",
      "18.561469670385122\n",
      "0.34353798627853394\n",
      "0.25164860114455223\n",
      "4.476709868758917\n",
      "1318.930282264948\n",
      "16.59743505716324\n",
      "0.0\n",
      "0.0\n",
      "1621.5962519049644\n",
      "0.0\n",
      "51.266749799251556\n",
      "0.0\n",
      "6.351093173027039\n",
      "13.88934288918972\n",
      "0.8018019795417786\n",
      "0.0\n",
      "75.4852414317429\n",
      "0.0\n",
      "48.367500364780426\n",
      "0.0\n",
      "2.1777522563934326\n",
      "11.549374133348465\n",
      "178.70292649418116\n",
      "29.138326421380043\n",
      "2.4959626272320747\n",
      "310.32545955479145\n",
      "36.72752845287323\n",
      "29.93389756977558\n",
      "49.369203221052885\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "24.625099167227745\n",
      "12984.460433587432\n",
      "599.0115852504969\n",
      "590.7388212680817\n",
      "7.02886925637722\n",
      "569.3739607930183\n",
      "6.342744097113609\n",
      "182.65372652560472\n",
      "29.255273178219795\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "92.72639556229115\n",
      "55.083057668060064\n",
      "323.4953371323645\n",
      "44.73622041940689\n",
      "0.0\n",
      "0.0\n",
      "2318.0787369161844\n",
      "32.20448708534241\n",
      "5.05417001247406\n",
      "1629.7260075323284\n",
      "1141.0976346731186\n",
      "93.78376117348671\n",
      "1292.062007471919\n",
      "0.0\n",
      "3.296819120645523\n",
      "34.90869903564453\n",
      "45.473233103752136\n",
      "512.6387231945992\n",
      "9.830851927399635\n",
      "92.8753227069974\n",
      "199.97698429226875\n",
      "43.112969905138016\n",
      "34373.22426698357\n",
      "70.73939990997314\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "158.98278535157442\n",
      "43.39415991306305\n",
      "49.63652104884386\n",
      "2.8529698848724365\n",
      "1105.0851187705994\n",
      "8703.213580653071\n",
      "8.650376930832863\n",
      "25731.047678142786\n",
      "76.73622016981244\n",
      "2239.024359792471\n",
      "2.0939809679985046\n",
      "343.50173219293356\n",
      "0.7983849942684174\n",
      "28.05915242433548\n",
      "0.0770459994673729\n",
      "0.21546100080013275\n",
      "6163.1814890652895\n",
      "0.5228724032640457\n",
      "1.0819044336676598\n",
      "63.753091774880886\n",
      "0.0\n",
      "787.9026972800493\n",
      "2597.0404453128576\n",
      "463.7328291833401\n",
      "0.0\n",
      "150.2452297359705\n",
      "0.0\n",
      "115.52321692183614\n",
      "11.902387622743845\n",
      "0.0\n",
      "1.0795463249087334\n",
      "0.6853899955749512\n",
      "0.0\n",
      "10.037500381469727\n",
      "1571.5156144201756\n",
      "0.0\n",
      "459.01613826677203\n",
      "3555.5416820831597\n",
      "0.0\n",
      "9.674977004528046\n",
      "964.8949249759316\n",
      "0.0\n",
      "166.06875931471586\n",
      "5.862497992813587\n",
      "16.244136974215508\n",
      "3236.4009425118566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 17.739 seconds\n",
      "Cross-validation score: 0.68995552446098\n",
      "Test score: 0.625\n",
      "Best Hyperparameters: {}\n",
      "6466.707689389586\n",
      "6448.5433270558715\n",
      "260155.8182780519\n",
      "1733.2973283827305\n",
      "1561.9718163013458\n",
      "689.137759655714\n",
      "18.391621589660645\n",
      "3.8680700063705444\n",
      "13.686930179595947\n",
      "25.87350082397461\n",
      "9199.426960080862\n",
      "1.72052301466465\n",
      "23.665067747235298\n",
      "0.0\n",
      "3.1846750676631927\n",
      "0.0\n",
      "239.39275455474854\n",
      "5.620397090911865\n",
      "1309.5931315720081\n",
      "9.148770332336426\n",
      "1.2545010149478912\n",
      "0.18108099699020386\n",
      "274.7044016420841\n",
      "564.1047673225403\n",
      "116.77194841951132\n",
      "142.27519989013672\n",
      "123.88191047310829\n",
      "0.11870700120925903\n",
      "0.0\n",
      "1602.6786649376154\n",
      "25.291952252388\n",
      "376.39801290631294\n",
      "1072.578192859888\n",
      "25.834716148674488\n",
      "158.5962182432413\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "208.7031498849392\n",
      "13973.451681017876\n",
      "1917.0300973206758\n",
      "129.07487973570824\n",
      "359.1376465857029\n",
      "106.33880862593651\n",
      "35.415586322546005\n",
      "253.7920379191637\n",
      "1072.253947660327\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "64.59448440372944\n",
      "480.76848877966404\n",
      "411.07449589669704\n",
      "19.028831273317337\n",
      "4.9849410355091095\n",
      "129.6150999069214\n",
      "373.54701921343803\n",
      "409.10565677285194\n",
      "480.19162410497665\n",
      "3887.066178098321\n",
      "1262.4630972892046\n",
      "96.68261829018593\n",
      "0.8660050183534622\n",
      "170.32848089933395\n",
      "16.050664216279984\n",
      "7.191752031445503\n",
      "3.6022229343652725\n",
      "199.34669098258018\n",
      "230.18879467248917\n",
      "6751.1657504066825\n",
      "635.4456679970026\n",
      "163.09969833493233\n",
      "6546.460219100118\n",
      "2.5910579562187195\n",
      "4.365023910999298\n",
      "0.0\n",
      "304.5656152367592\n",
      "1.197970986366272\n",
      "1286.2679040431976\n",
      "94.60142838954926\n",
      "229.62567967176437\n",
      "369.88491064310074\n",
      "5853.206464454532\n",
      "304.403342589736\n",
      "3369.0034457445145\n",
      "880.7148629426956\n",
      "2521.409739986062\n",
      "1.710510015487671\n",
      "260.061696305871\n",
      "1.19777200371027\n",
      "7655.511127084494\n",
      "3.2363100051879883\n",
      "502.26975260674953\n",
      "7313.095682397485\n",
      "14.016150042414665\n",
      "19.399915859103203\n",
      "669.1592973768711\n",
      "0.0\n",
      "511.09427627921104\n",
      "7226.807530045509\n",
      "445.6967595219612\n",
      "0.8663449883460999\n",
      "132.74395555257797\n",
      "0.0\n",
      "30.520707309246063\n",
      "32.759438164532185\n",
      "0.0\n",
      "217.24553394317627\n",
      "173.14966893196106\n",
      "0.0\n",
      "0.8942359983921051\n",
      "1863.0594458580017\n",
      "0.0\n",
      "1941.6650172024965\n",
      "12297.542606703937\n",
      "0.0\n",
      "2.2499799728393555\n",
      "433.66229696571827\n",
      "0.0\n",
      "249.00841599702835\n",
      "79.16894261538982\n",
      "406.912021830678\n",
      "629.4176207482815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 18.308 seconds\n",
      "Cross-validation score: 0.6292940763528999\n",
      "Test score: 0.7142857142857143\n",
      "Best Hyperparameters: {}\n",
      "3986.960341259837\n",
      "605.7750698328018\n",
      "246407.98561049253\n",
      "815.3436652719975\n",
      "4205.408344551921\n",
      "366.2257665991783\n",
      "19.68023383617401\n",
      "0.3033199906349182\n",
      "58.36735221743584\n",
      "5.472932904958725\n",
      "1145.2486546337605\n",
      "533.6078626215458\n",
      "19.384380042552948\n",
      "0.0\n",
      "26.389060348272324\n",
      "0.0\n",
      "2256.4133464396\n",
      "0.637723982334137\n",
      "4.942048981785774\n",
      "10.866399765014648\n",
      "5.596528947353363\n",
      "15.1982936039567\n",
      "436.3086839914322\n",
      "0.0\n",
      "254.56235295534134\n",
      "0.0\n",
      "15.937394067645073\n",
      "7.501029968261719\n",
      "8.43207898736\n",
      "75.38851265609264\n",
      "3.1846229881048203\n",
      "97.10793468356133\n",
      "110.19784171879292\n",
      "84.7266436740756\n",
      "204.4611862450838\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2355.6339279562235\n",
      "2505.5977599322796\n",
      "1070.4020766019821\n",
      "391.43697591125965\n",
      "39.84373760223389\n",
      "947.3286219388247\n",
      "15.969521075487137\n",
      "6.728290095925331\n",
      "762.2983133047819\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "658.0653745010495\n",
      "231.20939873158932\n",
      "54.64525181055069\n",
      "3.4223000705242157\n",
      "2.7384560108184814\n",
      "155.71680450439453\n",
      "141.3702880293131\n",
      "654.9209420681\n",
      "37.32454803586006\n",
      "3122.3075869828463\n",
      "2822.663833938539\n",
      "1154.8410034179688\n",
      "88.63743960857391\n",
      "46.61690139770508\n",
      "115.51977138221264\n",
      "138.76187294721603\n",
      "2.779449939727783\n",
      "3.87609601020813\n",
      "200.64368653297424\n",
      "586.02017557621\n",
      "694.198385193944\n",
      "72.4771766513586\n",
      "32497.246432825923\n",
      "0.0\n",
      "12.997476786375046\n",
      "0.0\n",
      "61.98266100883484\n",
      "90.64587411284447\n",
      "1451.9284131079912\n",
      "9.679324954748154\n",
      "1.8543400168418884\n",
      "1777.3966413587332\n",
      "5155.181286528707\n",
      "309.23630726337433\n",
      "2834.5140911638737\n",
      "1.19759002327919\n",
      "724.5845305323601\n",
      "60.158933252096176\n",
      "507.56634436547756\n",
      "6.585179805755615\n",
      "16.21869195997715\n",
      "0.0\n",
      "35.628097891807556\n",
      "11290.544434443116\n",
      "21.512539565563202\n",
      "46.987158223986626\n",
      "13046.423450775445\n",
      "0.0\n",
      "870.9358231127262\n",
      "27748.21859744191\n",
      "144.32400651276112\n",
      "0.42465201020240784\n",
      "24.581467986106873\n",
      "0.0\n",
      "1827.082596577704\n",
      "23.89475679397583\n",
      "0.0\n",
      "222.90162447094917\n",
      "2.1489601135253906\n",
      "0.0\n",
      "134.58403852581978\n",
      "2977.4111482948065\n",
      "0.0\n",
      "315.90520049631596\n",
      "3196.378610610962\n",
      "0.0\n",
      "1161.6334758996964\n",
      "335.2034527361393\n",
      "0.0\n",
      "91.02595084160566\n",
      "59.58890828490257\n",
      "7.492703005671501\n",
      "1128.3438756018877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 19.933 seconds\n",
      "Cross-validation score: 0.5990323325771618\n",
      "Test score: 0.7058823529411765\n",
      "Best Hyperparameters: {}\n",
      "2723.7441781908274\n",
      "1997.0981187224388\n",
      "240846.01938150823\n",
      "660.0751802176237\n",
      "4667.97611707449\n",
      "119.63236305117607\n",
      "3.765314966440201\n",
      "0.0\n",
      "9.827849864959717\n",
      "7.811324775218964\n",
      "1981.5542500168085\n",
      "3.1047699451446533\n",
      "7.273750066757202\n",
      "0.0\n",
      "12.091919898986816\n",
      "0.0\n",
      "3061.1974135935307\n",
      "0.0\n",
      "54.95715045928955\n",
      "28.119709610939026\n",
      "15.459605678915977\n",
      "1.3542929887771606\n",
      "60.242566630244255\n",
      "2.6485700607299805\n",
      "824.318623483181\n",
      "0.0\n",
      "31.236615918576717\n",
      "0.5902910232543945\n",
      "2.5474620163440704\n",
      "629.9723878502846\n",
      "4.356787979602814\n",
      "342.32799039781094\n",
      "167.57607707381248\n",
      "565.4498279094696\n",
      "3198.730767726898\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "972.0439769178629\n",
      "2219.5816828906536\n",
      "316.9888079762459\n",
      "49.532949179410934\n",
      "42.121148988604546\n",
      "818.9872137606144\n",
      "291.4986999705434\n",
      "22.384510159492493\n",
      "795.341828122735\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "71.3181364685297\n",
      "97.69515503942966\n",
      "355.0828393250704\n",
      "92.02627162635326\n",
      "11.777706891298294\n",
      "3.2662850320339203\n",
      "318.89171819388866\n",
      "131.24573662877083\n",
      "18.2611403465271\n",
      "1790.1603773236275\n",
      "2650.5237555503845\n",
      "317.1356733441353\n",
      "25.231862783432007\n",
      "49.251489251852036\n",
      "57.48849034309387\n",
      "172.9930575489998\n",
      "138.14510370790958\n",
      "0.0\n",
      "50.353648126125336\n",
      "147.59712825715542\n",
      "3465.895141750574\n",
      "233.07563343644142\n",
      "28220.195421382785\n",
      "4.487145215272903\n",
      "41.75564569234848\n",
      "2.792020082473755\n",
      "20.157225996255875\n",
      "472.0284131169319\n",
      "1171.44481036067\n",
      "21.10679006576538\n",
      "1.004201978445053\n",
      "26369.222962483764\n",
      "2482.111059784889\n",
      "515.7402877509594\n",
      "1044.9156947135925\n",
      "271.8273673057556\n",
      "4946.682451963425\n",
      "48.223310232162476\n",
      "83.7555320262909\n",
      "52.52827890217304\n",
      "915.5080932676792\n",
      "0.0\n",
      "1970.987662538886\n",
      "8129.693638265133\n",
      "1.9254289716482162\n",
      "40.99956451356411\n",
      "3223.367834582925\n",
      "0.0\n",
      "117.10068047046661\n",
      "10279.955955550075\n",
      "636.2353816330433\n",
      "3.6629160046577454\n",
      "96.09727564454079\n",
      "0.0\n",
      "350.13395799696445\n",
      "151.69348248839378\n",
      "0.0\n",
      "24.107800975441933\n",
      "652.6948502361774\n",
      "0.0\n",
      "69.93414837121964\n",
      "2589.272117897868\n",
      "0.0\n",
      "1078.0732181072235\n",
      "12239.927017614245\n",
      "0.0\n",
      "50.25535073876381\n",
      "648.7967930734158\n",
      "0.0\n",
      "142.5221218019724\n",
      "3261.1879792511463\n",
      "26.984078735113144\n",
      "865.2766951620579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 17.994 seconds\n",
      "Cross-validation score: 0.6423705578117341\n",
      "Test score: 0.6024096385542168\n",
      "Best Hyperparameters: {}\n",
      "7179.992543071508\n",
      "36875.86498206854\n",
      "193370.99642893672\n",
      "651.1344505250454\n",
      "308.5513878464699\n",
      "155.82622380554676\n",
      "10.19450467824936\n",
      "1.5247299671173096\n",
      "3.942646026611328\n",
      "8.262437909841537\n",
      "806.9327305704355\n",
      "2186.6623001098633\n",
      "51.322571098804474\n",
      "0.0\n",
      "63.47774004936218\n",
      "0.0\n",
      "1105.7741385698318\n",
      "0.0\n",
      "6.317478120326996\n",
      "24.294690132141113\n",
      "4.262905985116959\n",
      "1.0211910009384155\n",
      "465.2539227902889\n",
      "1031.1513195037842\n",
      "446.7632945328951\n",
      "0.1960110068321228\n",
      "0.6579350233078003\n",
      "4.807008147239685\n",
      "79.71903306245804\n",
      "30.545719504356384\n",
      "10.268955007195473\n",
      "185.96816062927246\n",
      "165.48831106722355\n",
      "378.6664607822895\n",
      "2172.5108749121428\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "212.8104309439659\n",
      "3962.1859543025494\n",
      "595.8967678397894\n",
      "42.881034195423126\n",
      "84.12201949954033\n",
      "91.69645695388317\n",
      "2019.6263518333435\n",
      "36.91380366683006\n",
      "1261.4876589626074\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "449.6745734810829\n",
      "274.88184474408627\n",
      "377.4342928081751\n",
      "5.371846958994865\n",
      "0.0\n",
      "0.7669690251350403\n",
      "1334.6133067905903\n",
      "39.00246948003769\n",
      "150.2976879477501\n",
      "1600.8636053800583\n",
      "5414.239997208118\n",
      "835.4098059237003\n",
      "0.8684850037097931\n",
      "38.85619926452637\n",
      "4.081677079200745\n",
      "86.01771134138107\n",
      "0.0\n",
      "0.0\n",
      "198.5268558859825\n",
      "89.91708533465862\n",
      "7010.457291722298\n",
      "11.399300217628479\n",
      "36514.955552875996\n",
      "630.8189029693604\n",
      "5.219006031751633\n",
      "25.675100326538086\n",
      "68.12206234037876\n",
      "224.6226305961609\n",
      "514.1758885830641\n",
      "15.761513501405716\n",
      "16.876392617821693\n",
      "3827.424610286951\n",
      "8711.177400827408\n",
      "187.5595456957817\n",
      "28172.008326351643\n",
      "5.913132056593895\n",
      "1193.9293072074652\n",
      "93.31963348388672\n",
      "5.792016923427582\n",
      "181.4475113451481\n",
      "2203.7719819247723\n",
      "0.0\n",
      "51.931318178772926\n",
      "6506.614592090249\n",
      "74.19034403562546\n",
      "19.629986256361008\n",
      "1461.75264339149\n",
      "0.0\n",
      "891.4371570944786\n",
      "8472.699973225594\n",
      "254.13137769699097\n",
      "0.0\n",
      "124.08875158429146\n",
      "0.0\n",
      "2015.5260342359543\n",
      "212.35770151019096\n",
      "0.0\n",
      "58.30893786251545\n",
      "112.27605059742928\n",
      "0.0\n",
      "38.127909272909164\n",
      "2218.4838099628687\n",
      "0.0\n",
      "203.21985319256783\n",
      "9708.594725191593\n",
      "0.0\n",
      "0.0\n",
      "482.7552461326122\n",
      "0.0\n",
      "323.50038662552834\n",
      "43.805926740169525\n",
      "16.841385573148727\n",
      "1181.540700852871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 17.885 seconds\n",
      "Cross-validation score: 0.6917637070151302\n",
      "Test score: 0.6395348837209303\n",
      "Best Hyperparameters: {}\n",
      "5713.95674226433\n",
      "3133.4694408476353\n",
      "248181.76645696908\n",
      "4.616946026682854\n",
      "567.7445231303573\n",
      "222.34051448106766\n",
      "11.594776913523674\n",
      "0.0\n",
      "2.1363430619239807\n",
      "2.6026789844036102\n",
      "678.9966306090355\n",
      "1316.3215721845627\n",
      "61.85423490405083\n",
      "0.0\n",
      "1.0692399740219116\n",
      "0.0\n",
      "22.62193337082863\n",
      "0.0\n",
      "5.941150069236755\n",
      "46.53378963470459\n",
      "5.256779909133911\n",
      "5.575314104557037\n",
      "948.4079856276512\n",
      "289.741218149662\n",
      "59.43620252609253\n",
      "0.15587900578975677\n",
      "306.04451209306717\n",
      "13.960901722311974\n",
      "5.1600319147109985\n",
      "20907.592126607895\n",
      "1.8913020193576813\n",
      "905.8489652052522\n",
      "467.66102592647076\n",
      "233.25987847149372\n",
      "658.5193004235625\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "41.09185168147087\n",
      "1744.0880200713873\n",
      "1031.9120168536901\n",
      "126.91499301791191\n",
      "1931.8325265347958\n",
      "663.3246593102813\n",
      "102.94255368411541\n",
      "63.555943205952644\n",
      "372.21808184683323\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "60.98399709165096\n",
      "236.9207830056548\n",
      "572.6731231287122\n",
      "24.00334556400776\n",
      "0.4019530117511749\n",
      "24.52047234773636\n",
      "103.85768160223961\n",
      "322.9578360170126\n",
      "52.648409605026245\n",
      "1186.2770074307919\n",
      "11216.84314841032\n",
      "691.6493791043758\n",
      "49.383664667606354\n",
      "21.698999762535095\n",
      "14.087965041399002\n",
      "25.446128472685814\n",
      "28.498219445347786\n",
      "41.242805540561676\n",
      "157.07538749277592\n",
      "390.8908561989665\n",
      "946.8214523270726\n",
      "228.10390236973763\n",
      "5861.0225348472595\n",
      "22.970809936523438\n",
      "10.801213920116425\n",
      "0.0\n",
      "10.486474171280861\n",
      "71.61427500844002\n",
      "1273.6543831974268\n",
      "23.483219742774963\n",
      "14.818979263305664\n",
      "3063.3261452764273\n",
      "9446.088916510344\n",
      "323.1443942785263\n",
      "4924.223662465811\n",
      "1.3631839752197266\n",
      "1431.9609800428152\n",
      "16.94292676448822\n",
      "3.828426018357277\n",
      "6.002225071191788\n",
      "1669.8431503400207\n",
      "0.4193440079689026\n",
      "468.7211354225874\n",
      "8516.18977470696\n",
      "2.410947948694229\n",
      "8.765905976295471\n",
      "8629.070259779692\n",
      "0.0\n",
      "1124.3251924216747\n",
      "26412.43716289103\n",
      "94.53114347159863\n",
      "77.42630100250244\n",
      "162.96923026442528\n",
      "0.0\n",
      "604.329687088728\n",
      "685.2141800522804\n",
      "0.0\n",
      "674.0876342356205\n",
      "29.702499747276306\n",
      "0.0\n",
      "0.0\n",
      "2145.930932626128\n",
      "0.0\n",
      "35.03287400305271\n",
      "5243.758399218321\n",
      "0.0\n",
      "67.89015101641417\n",
      "7.762045085430145\n",
      "0.0\n",
      "53.125674933195114\n",
      "14.617970645427704\n",
      "52.590228617191315\n",
      "575.1229749321938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 19.352 seconds\n",
      "Cross-validation score: 0.6439775910364146\n",
      "Test score: 0.632183908045977\n",
      "Best Hyperparameters: {}\n",
      "191.4433431327343\n",
      "779.5137974172831\n",
      "265588.2552344054\n",
      "555.5857027620077\n",
      "2228.1786911785603\n",
      "24.229057759046555\n",
      "44.69968068599701\n",
      "14.261270821094513\n",
      "0.0\n",
      "3.3328680247068405\n",
      "1200.6535830497742\n",
      "539.8217641711235\n",
      "14.813854992389679\n",
      "0.0\n",
      "0.7448050081729889\n",
      "0.0\n",
      "145.96732425689697\n",
      "0.8730419874191284\n",
      "0.0\n",
      "0.0\n",
      "49.929907381534576\n",
      "41.40989154577255\n",
      "25.373789735138416\n",
      "34.53770065307617\n",
      "25.354084491729736\n",
      "0.6072270274162292\n",
      "0.0\n",
      "11.637292861938477\n",
      "79.59820201992989\n",
      "219.1112174987793\n",
      "13.36189717054367\n",
      "124.46961294859648\n",
      "81.99526534974575\n",
      "370.92667447030544\n",
      "787.0242674350739\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.39437997341156\n",
      "23534.951027333736\n",
      "50.634501442313194\n",
      "1.2720540165901184\n",
      "17.271074935793877\n",
      "1187.4620273262262\n",
      "84.83252184838057\n",
      "330.01006242632866\n",
      "3382.820452094078\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "372.24238991737366\n",
      "2451.0891337394714\n",
      "502.29489786177874\n",
      "2.3915200233459473\n",
      "3.504727065563202\n",
      "75.5321592092514\n",
      "180.19776000082493\n",
      "53.46987888216972\n",
      "34.42044274508953\n",
      "2056.5921870321035\n",
      "986.616919234395\n",
      "133.40412637591362\n",
      "10.589781820774078\n",
      "10.647700071334839\n",
      "44.45727050304413\n",
      "13.0176682472229\n",
      "24.265328153967857\n",
      "3.3815200328826904\n",
      "0.406156986951828\n",
      "187.12599970400333\n",
      "1828.1694289445877\n",
      "197.1672491133213\n",
      "30445.078467473388\n",
      "0.0\n",
      "860.5104439109564\n",
      "0.0\n",
      "302.5239187479019\n",
      "226.42479038238525\n",
      "496.25439120829105\n",
      "69.65728025138378\n",
      "3.4082159847021103\n",
      "44.90535941720009\n",
      "411.69437973201275\n",
      "737.581164509058\n",
      "2728.7018495947123\n",
      "82.78921489417553\n",
      "466.4326140731573\n",
      "3.0778599977493286\n",
      "177.53507959842682\n",
      "17.532019965350628\n",
      "12.851601056754589\n",
      "0.23681800067424774\n",
      "142.9718414247036\n",
      "8205.04754782468\n",
      "15.599699944257736\n",
      "35.98476868867874\n",
      "66.75130452215672\n",
      "0.31153398752212524\n",
      "314.23447881639004\n",
      "22736.430573940277\n",
      "1506.123521372676\n",
      "16.20975823700428\n",
      "101.50278291106224\n",
      "0.0\n",
      "2782.7671001702547\n",
      "40.6054947078228\n",
      "0.0\n",
      "157.1867082491517\n",
      "197.52798449993134\n",
      "0.0\n",
      "0.7160239815711975\n",
      "2423.96262191236\n",
      "0.0\n",
      "311.62847043573856\n",
      "2878.0821979939938\n",
      "0.0\n",
      "0.8529810309410095\n",
      "363.8852789103985\n",
      "0.0\n",
      "70.54711730033159\n",
      "419.2418419867754\n",
      "44.237360805273056\n",
      "261.1983944028616\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "\n",
    "#Import feature selection stuff\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "\n",
    "# Import the model we are using\n",
    "import lightgbm as lgb\n",
    "\n",
    "smote_lightgbm_performance_normalized_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "\n",
    "    ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized,\n",
    "                                                    labels_normalized,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels_normalized)\n",
    "\n",
    "\n",
    "    LightGBMPipeline = Pipeline(steps = [['smote', SMOTE()],\n",
    "                                    #['under', RandomUnderSampler()],\n",
    "                                ['classifier', lgb.LGBMClassifier(n_jobs=-1, importance_type='gain')]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "# define search space\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    spaceEmpty = dict()\n",
    "    space['classifier__num_leaves'] = [11, 16, 21, 26, 31, 36, 41, 46, 51, 56]\n",
    "    space['classifier__min_data_in_leaf'] =  [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__max_depth'] = [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__learning_rate'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9, 1.0]\n",
    "    space['classifier__max_bin'] = [50, 100, 150, 200, 255, 300, 350, 400, 450, 500]\n",
    "\n",
    "    LightGBMSearch = RandomizedSearchCV(estimator = LightGBMPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring= ftwo_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedLightGBMModel = LightGBMSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedLightGBMModel.best_score_\n",
    "    test_score = optimizedLightGBMModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedLightGBMModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedLightGBMModel.best_estimator_._final_estimator.booster_.feature_importance(importance_type='gain')\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedLightGBMModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    smote_lightgbm_performance_normalized_df = pd.concat([smote_lightgbm_performance_normalized_df, new_performance_df])\n",
    "    \n",
    "\n",
    "smote_lightgbm_performance_normalized_df.to_csv(\"../data/05_model_output/smote_lightgbm_performance_normalized_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pending-impression",
   "metadata": {},
   "source": [
    "## 4.3 Rebalancing Strategy - UNDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-class",
   "metadata": {},
   "source": [
    "### 4.3.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "swiss-venue",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "under_randomforest_normalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized,\n",
    "                                                    labels_normalized,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels_normalized)\n",
    "\n",
    "\n",
    "    pipeline = Pipeline(steps = [#['smote', SMOTE(sampling_strategy = 0.5, n_jobs=2)],\n",
    "                              ['under', RandomUnderSampler()],\n",
    "                                ['classifier', RandomForestClassifier(n_jobs=-1)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    spaceEmpty = dict() \n",
    "\n",
    "    search = RandomizedSearchCV(estimator = pipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring='f1', \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedRFModel = search.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    #print(f\"Elapsed time to compute best fit: \"\n",
    "      #f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedRFModel.best_score_\n",
    "    test_score = optimizedRFModel.score(X_test, y_test)\n",
    "    #print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    #print('Best Hyperparameters: %s' % optimizedRFModel.best_params_)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedRFModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    \n",
    "    under_randomforest_normalized_performance_df = pd.concat([under_randomforest_normalized_performance_df, new_performance_df])\n",
    "    \n",
    "under_randomforest_normalized_performance_df.to_csv(\"../data/05_model_output/under_randomforest_normalized_performance_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-housing",
   "metadata": {},
   "source": [
    "### 4.3.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "existing-reach",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:42:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 0.921 seconds\n",
      "Cross-validation score: 0.03455691585972301\n",
      "Test score: 0.048268029528676884\n",
      "Best Hyperparameters: {}\n",
      "0.010113684\n",
      "0.123468354\n",
      "0.20093855\n",
      "0.0\n",
      "0.050189547\n",
      "0.03453695\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.013386338\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.001593966\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0016631448\n",
      "0.0\n",
      "0.0\n",
      "0.004652655\n",
      "0.008409891\n",
      "0.0020591686\n",
      "0.007193151\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.010577968\n",
      "0.004054774\n",
      "0.012053889\n",
      "0.0014198223\n",
      "0.0\n",
      "0.0\n",
      "0.00091137714\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.010474033\n",
      "0.0\n",
      "0.011965466\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.000819364\n",
      "0.0042776517\n",
      "0.002436117\n",
      "0.0\n",
      "0.0060554747\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.013076326\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.023976296\n",
      "0.0052745827\n",
      "0.0\n",
      "0.037094157\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.015011517\n",
      "0.0009485195\n",
      "0.0\n",
      "0.03605568\n",
      "0.005183847\n",
      "0.056807935\n",
      "0.0\n",
      "0.0\n",
      "0.0128970435\n",
      "0.0\n",
      "0.048128888\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.019051304\n",
      "0.035193123\n",
      "0.0\n",
      "0.0\n",
      "0.0036511896\n",
      "0.0\n",
      "0.02129116\n",
      "0.01931501\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0044164914\n",
      "0.0\n",
      "0.0\n",
      "0.014707712\n",
      "0.0\n",
      "0.0019803047\n",
      "0.026348619\n",
      "0.0\n",
      "0.027387226\n",
      "0.011123979\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0025214972\n",
      "0.033982538\n",
      "0.0013237481\n",
      "   Accuracy  Precision  Recall        F1        F2      F0.5  \\\n",
      "0  0.937704   0.038991     1.0  0.075055  0.168651  0.048268   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.038991  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:42:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1.008 seconds\n",
      "Cross-validation score: 0.031248999381987226\n",
      "Test score: 0.03641329085116068\n",
      "Best Hyperparameters: {}\n",
      "0.018650385\n",
      "0.05636085\n",
      "0.14039704\n",
      "0.0\n",
      "0.026776439\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.019540604\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0053458335\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.010789671\n",
      "0.004347833\n",
      "0.0019012826\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.000786781\n",
      "0.0\n",
      "0.00084152975\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0046170643\n",
      "0.0016732365\n",
      "0.011367303\n",
      "0.0053930334\n",
      "0.0\n",
      "0.0\n",
      "0.0006721798\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0042619784\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.042610426\n",
      "0.008329201\n",
      "0.0\n",
      "0.0\n",
      "0.04858333\n",
      "0.016058115\n",
      "0.014019063\n",
      "0.005707343\n",
      "0.0\n",
      "0.00789113\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.018900715\n",
      "0.008704388\n",
      "0.006837135\n",
      "0.036328364\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0219877\n",
      "0.0\n",
      "0.0\n",
      "0.044945028\n",
      "0.08681081\n",
      "0.06132379\n",
      "0.015908835\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0087699685\n",
      "0.06850738\n",
      "0.0\n",
      "0.0\n",
      "0.00072963536\n",
      "0.0\n",
      "0.0\n",
      "0.014987423\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0016644662\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.008025099\n",
      "0.0\n",
      "0.0009936651\n",
      "0.006996765\n",
      "0.0\n",
      "0.030851807\n",
      "0.09726942\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0010618218\n",
      "0.0\n",
      "0.0014741316\n",
      "   Accuracy  Precision    Recall       F1        F2      F0.5  \\\n",
      "0  0.921201   0.029358  0.941176  0.05694  0.130506  0.036413   \n",
      "\n",
      "   Average Precision  \n",
      "0            0.02778  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:42:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 0.925 seconds\n",
      "Cross-validation score: 0.04106393689765801\n",
      "Test score: 0.03227293683725219\n",
      "Best Hyperparameters: {}\n",
      "0.031783957\n",
      "0.09892721\n",
      "0.12259985\n",
      "0.0\n",
      "0.010102823\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0093682865\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "4.6316192e-05\n",
      "0.0\n",
      "0.0\n",
      "0.04823696\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0077588432\n",
      "0.0\n",
      "0.0016458008\n",
      "0.0\n",
      "0.0\n",
      "0.021821965\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0029983777\n",
      "0.0024545882\n",
      "0.0\n",
      "0.0\n",
      "0.0016200441\n",
      "0.008245991\n",
      "0.0\n",
      "0.0073145134\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.005446623\n",
      "0.005532546\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0010992979\n",
      "0.0\n",
      "0.0\n",
      "0.0042672837\n",
      "0.05541971\n",
      "0.012536426\n",
      "0.0\n",
      "0.0\n",
      "0.004694337\n",
      "0.022813404\n",
      "0.0051061865\n",
      "0.0\n",
      "0.0\n",
      "0.026486658\n",
      "0.006383143\n",
      "0.005979995\n",
      "0.0056407265\n",
      "0.0\n",
      "0.008542726\n",
      "0.0\n",
      "0.0\n",
      "0.034846175\n",
      "0.0064912797\n",
      "0.0\n",
      "0.0038219104\n",
      "0.0026055383\n",
      "0.00092621194\n",
      "0.016744688\n",
      "0.024087062\n",
      "0.011464283\n",
      "0.009931853\n",
      "0.0\n",
      "0.024092909\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.049380686\n",
      "0.055611137\n",
      "0.0\n",
      "0.0\n",
      "0.00580525\n",
      "0.0\n",
      "0.0\n",
      "0.04023685\n",
      "0.0\n",
      "0.0\n",
      "0.0013541976\n",
      "0.0\n",
      "0.0\n",
      "0.0017031217\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0061267354\n",
      "0.0\n",
      "0.013659037\n",
      "0.09740612\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0018414094\n",
      "0.045695007\n",
      "0.0012940341\n",
      "   Accuracy  Precision    Recall       F1        F2      F0.5  \\\n",
      "0  0.921647   0.026022  0.823529  0.05045  0.115512  0.032273   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.021876  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:42:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 0.928 seconds\n",
      "Cross-validation score: 0.03720487237070981\n",
      "Test score: 0.0400427122263748\n",
      "Best Hyperparameters: {}\n",
      "0.040994246\n",
      "0.09192758\n",
      "0.18586272\n",
      "0.0\n",
      "0.027623104\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.024762921\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.009753732\n",
      "0.0\n",
      "0.019247252\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0020693932\n",
      "0.04789312\n",
      "0.0\n",
      "0.0\n",
      "0.014225559\n",
      "0.0016400969\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.027402392\n",
      "0.0\n",
      "0.010082781\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.06704727\n",
      "0.025654834\n",
      "0.016059885\n",
      "0.0008670223\n",
      "0.0\n",
      "0.0020284557\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.005939731\n",
      "0.0\n",
      "0.0\n",
      "0.039091147\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0011556719\n",
      "0.0\n",
      "0.0\n",
      "0.07798153\n",
      "0.0\n",
      "0.0022077118\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00116535\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0019465012\n",
      "0.028933195\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007529366\n",
      "0.028382452\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0070657614\n",
      "0.0\n",
      "0.023314375\n",
      "0.08715011\n",
      "0.0\n",
      "0.0\n",
      "0.043406144\n",
      "0.0\n",
      "0.0\n",
      "0.027503692\n",
      "0.0010248242\n",
      "0.0010600772\n",
      "   Accuracy  Precision    Recall       F1        F2      F0.5  \\\n",
      "0  0.932947   0.032328  0.882353  0.06237  0.140977  0.040043   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.028822  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:42:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 0.909 seconds\n",
      "Cross-validation score: 0.026328359253823975\n",
      "Test score: 0.029531192321889995\n",
      "Best Hyperparameters: {}\n",
      "0.019203419\n",
      "0.07234054\n",
      "0.20607582\n",
      "0.0\n",
      "0.015228464\n",
      "0.036562204\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0015292118\n",
      "0.02398205\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0017667373\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0017966513\n",
      "0.0031572755\n",
      "0.0063939826\n",
      "0.009073237\n",
      "0.0\n",
      "0.030371523\n",
      "0.012665468\n",
      "0.0\n",
      "0.01674854\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00086882577\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.002721401\n",
      "0.054132897\n",
      "0.025573462\n",
      "0.010517832\n",
      "0.007948234\n",
      "0.0\n",
      "0.0\n",
      "0.033301212\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.041690774\n",
      "0.0\n",
      "0.0\n",
      "0.07257521\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.002458609\n",
      "0.0034797932\n",
      "0.0\n",
      "0.0\n",
      "0.0443959\n",
      "0.0\n",
      "0.014818606\n",
      "0.041790936\n",
      "0.01957495\n",
      "0.032493696\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.004344424\n",
      "0.0062993513\n",
      "0.0\n",
      "0.0\n",
      "0.0018547791\n",
      "0.008059873\n",
      "0.0\n",
      "0.0\n",
      "0.0011665995\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0018501737\n",
      "0.0\n",
      "0.043450493\n",
      "0.0338212\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0010644724\n",
      "0.0015070419\n",
      "0.031344175\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.902171   0.023774  0.941176  0.046377  0.107962  0.029531   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.022524  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:42:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 0.939 seconds\n",
      "Cross-validation score: 0.03436524809852567\n",
      "Test score: 0.04370179948586118\n",
      "Best Hyperparameters: {}\n",
      "0.020258859\n",
      "0.140302\n",
      "0.14340952\n",
      "0.0012211746\n",
      "0.047671817\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007168114\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.004918837\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.029189965\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0010124908\n",
      "0.012452071\n",
      "0.0\n",
      "0.0027638022\n",
      "0.0\n",
      "0.006874717\n",
      "0.0052290047\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0011530077\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.040598553\n",
      "0.0\n",
      "0.02541508\n",
      "0.009952903\n",
      "0.024655987\n",
      "0.01742081\n",
      "0.004969689\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.009686288\n",
      "0.0\n",
      "0.0\n",
      "0.009946019\n",
      "0.001457225\n",
      "0.0\n",
      "0.06377785\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.005955403\n",
      "0.0016708224\n",
      "0.0\n",
      "0.0\n",
      "0.009138937\n",
      "0.0856154\n",
      "0.0009602589\n",
      "0.057113536\n",
      "0.0\n",
      "0.018336354\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0013146917\n",
      "0.035420194\n",
      "0.0\n",
      "0.0\n",
      "0.008394696\n",
      "0.0\n",
      "0.01287139\n",
      "0.07731463\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.018579168\n",
      "0.0\n",
      "0.0\n",
      "0.029655917\n",
      "0.0\n",
      "0.0\n",
      "0.0032930584\n",
      "0.0\n",
      "0.0028597359\n",
      "   Accuracy  Precision  Recall        F1        F2      F0.5  \\\n",
      "0  0.930865    0.03527     1.0  0.068136  0.154545  0.043702   \n",
      "\n",
      "   Average Precision  \n",
      "0            0.03527  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:42:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 0.909 seconds\n",
      "Cross-validation score: 0.03241672526076686\n",
      "Test score: 0.02685624012638231\n",
      "Best Hyperparameters: {}\n",
      "0.030448634\n",
      "0.08343362\n",
      "0.22091469\n",
      "0.0\n",
      "0.0\n",
      "0.090013795\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0016271943\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0014312271\n",
      "0.0026931146\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.021343704\n",
      "0.0\n",
      "0.003489177\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.01927754\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.01325452\n",
      "0.012171663\n",
      "0.0751231\n",
      "0.050761256\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0019013152\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.03515096\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.020969972\n",
      "0.0\n",
      "0.006842885\n",
      "0.026010992\n",
      "0.0\n",
      "0.010187449\n",
      "0.0\n",
      "0.0\n",
      "0.023239324\n",
      "0.0\n",
      "0.10190247\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.001092297\n",
      "0.0\n",
      "0.0\n",
      "0.00010761967\n",
      "0.0\n",
      "0.0055563133\n",
      "0.049041234\n",
      "0.013376338\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0009102301\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.051819734\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.01880281\n",
      "0.0\n",
      "0.00710485\n",
      "   Accuracy  Precision  Recall        F1        F2      F0.5  \\\n",
      "0  0.885519   0.021601     1.0  0.042289  0.099415  0.026856   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.021601  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:42:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 0.835 seconds\n",
      "Cross-validation score: 0.034220631657277414\n",
      "Test score: 0.0377945753668297\n",
      "Best Hyperparameters: {}\n",
      "0.054712683\n",
      "0.07510974\n",
      "0.14855482\n",
      "0.0\n",
      "0.019540733\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.039999917\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.014221773\n",
      "0.009586858\n",
      "0.00068255037\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0007910476\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0024256213\n",
      "0.0016429718\n",
      "0.0013545009\n",
      "0.0\n",
      "0.022754543\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00635679\n",
      "0.007076657\n",
      "0.005115173\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.006380835\n",
      "0.028568117\n",
      "0.008153484\n",
      "0.0\n",
      "0.027772633\n",
      "0.004180806\n",
      "0.003985353\n",
      "0.0\n",
      "0.0022357341\n",
      "0.0\n",
      "0.0035470652\n",
      "0.012760085\n",
      "0.0\n",
      "0.0\n",
      "0.06303265\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0034120998\n",
      "0.00030874487\n",
      "0.014423531\n",
      "0.09728251\n",
      "0.0\n",
      "0.0\n",
      "0.009290318\n",
      "0.0\n",
      "0.0072942665\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.041442517\n",
      "0.0\n",
      "0.0\n",
      "0.0672804\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0009221349\n",
      "0.020848403\n",
      "0.02083142\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.022538146\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.040993415\n",
      "0.0019829592\n",
      "0.0\n",
      "0.00014965417\n",
      "0.072344735\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00063451065\n",
      "0.0074770786\n",
      "   Accuracy  Precision  Recall       F1        F2      F0.5  Average Precision\n",
      "0  0.919566   0.030466     1.0  0.05913  0.135783  0.037795           0.030466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:42:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 0.794 seconds\n",
      "Cross-validation score: 0.03257430637336342\n",
      "Test score: 0.0399002493765586\n",
      "Best Hyperparameters: {}\n",
      "0.07458471\n",
      "0.15729734\n",
      "0.12144646\n",
      "0.0\n",
      "0.05687356\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0428156\n",
      "0.037337463\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007929249\n",
      "0.0076444717\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00073951425\n",
      "0.0036854316\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.015494811\n",
      "0.0037656133\n",
      "0.015193104\n",
      "0.0\n",
      "0.0\n",
      "0.024387514\n",
      "0.013765689\n",
      "0.002971627\n",
      "0.0042088125\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00089548336\n",
      "0.0\n",
      "0.035485342\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.036566976\n",
      "0.0039631026\n",
      "0.0\n",
      "0.031996503\n",
      "0.013446283\n",
      "0.01117681\n",
      "0.0\n",
      "0.0013332771\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.039406348\n",
      "0.0\n",
      "0.0\n",
      "0.042863574\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.030765845\n",
      "0.0008820702\n",
      "0.0\n",
      "0.0\n",
      "0.0038960055\n",
      "0.0\n",
      "0.0061646616\n",
      "0.0\n",
      "0.0\n",
      "0.017897388\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.004296072\n",
      "0.0\n",
      "0.0010952316\n",
      "0.0040111043\n",
      "0.0\n",
      "0.0056386045\n",
      "0.0006913554\n",
      "0.0\n",
      "0.01874476\n",
      "0.006555072\n",
      "0.005145597\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.024920067\n",
      "0.001080257\n",
      "0.0\n",
      "0.0\n",
      "0.045183804\n",
      "0.0\n",
      "0.0\n",
      "0.00067156315\n",
      "0.0\n",
      "0.00088184816\n",
      "0.0\n",
      "0.01207566\n",
      "0.0021284407\n",
      "   Accuracy  Precision    Recall        F1        F2    F0.5  \\\n",
      "0  0.928338   0.032193  0.941176  0.062257  0.141593  0.0399   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.030448  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:42:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 0.880 seconds\n",
      "Cross-validation score: 0.036449818126144576\n",
      "Test score: 0.029973772948669913\n",
      "Best Hyperparameters: {}\n",
      "0.006372625\n",
      "0.17845409\n",
      "0.14247668\n",
      "0.0\n",
      "0.029814357\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0029013227\n",
      "0.0\n",
      "0.0005639962\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.01100261\n",
      "0.010600677\n",
      "0.0\n",
      "0.0\n",
      "0.028213074\n",
      "0.0\n",
      "0.0\n",
      "0.010553638\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.004030652\n",
      "0.0005734932\n",
      "0.01715428\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0030323183\n",
      "0.012558359\n",
      "0.019968849\n",
      "0.014440685\n",
      "0.0\n",
      "0.0\n",
      "0.00059363205\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.04063438\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.03873264\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.04266392\n",
      "0.008634854\n",
      "0.00037131\n",
      "0.010972541\n",
      "0.1428155\n",
      "0.0039214655\n",
      "0.0023690911\n",
      "0.030843394\n",
      "0.0\n",
      "0.00038807918\n",
      "0.0\n",
      "0.029320851\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.003963881\n",
      "0.0024361403\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.04097138\n",
      "0.010731207\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0005259831\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.042268325\n",
      "0.0015859723\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00926288\n",
      "0.0\n",
      "0.0\n",
      "0.04011368\n",
      "0.0031671566\n",
      "0.0\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.903657   0.024133  0.941176  0.047059  0.109439  0.029974   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.022862  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:42:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 0.997 seconds\n",
      "Cross-validation score: 0.03635594195740142\n",
      "Test score: 0.047801147227533466\n",
      "Best Hyperparameters: {}\n",
      "0.0058084126\n",
      "0.14062722\n",
      "0.102080286\n",
      "0.0\n",
      "0.045176182\n",
      "0.022570126\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.04579528\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.013578932\n",
      "0.0\n",
      "0.00067588926\n",
      "0.0\n",
      "0.0076223505\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.015192117\n",
      "0.0\n",
      "0.0036568844\n",
      "0.0283127\n",
      "0.016220195\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.028105762\n",
      "0.004403217\n",
      "0.0040599364\n",
      "0.0021792345\n",
      "0.050361067\n",
      "0.028947191\n",
      "0.0009938682\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.01885818\n",
      "0.00782714\n",
      "0.0023491613\n",
      "0.012738954\n",
      "0.010072811\n",
      "0.019820778\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0022645413\n",
      "0.0\n",
      "0.0\n",
      "0.05723359\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.022077877\n",
      "0.009025399\n",
      "0.0\n",
      "0.05242192\n",
      "0.0\n",
      "0.0069090887\n",
      "0.028369518\n",
      "0.049737968\n",
      "0.0020795392\n",
      "0.0\n",
      "0.00079182716\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0016875505\n",
      "0.028253183\n",
      "0.0\n",
      "0.0\n",
      "0.006301622\n",
      "0.0\n",
      "0.0010056163\n",
      "0.0\n",
      "0.024650255\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0012736912\n",
      "0.0\n",
      "0.0\n",
      "0.0055191563\n",
      "0.0\n",
      "0.0\n",
      "0.0038739815\n",
      "0.0\n",
      "0.0018871451\n",
      "0.04752014\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0020811849\n",
      "0.0048217517\n",
      "0.002179545\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.944246    0.03866  0.882353  0.074074  0.164474  0.047801   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.034409  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:42:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 0.868 seconds\n",
      "Cross-validation score: 0.03384177494496314\n",
      "Test score: 0.023419203747072598\n",
      "Best Hyperparameters: {}\n",
      "0.035527762\n",
      "0.009830187\n",
      "0.21579453\n",
      "0.0\n",
      "0.020947907\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.047769457\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.01667473\n",
      "0.011022609\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0020335114\n",
      "0.008130358\n",
      "0.0019794563\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0048449645\n",
      "0.0031791392\n",
      "0.0015596998\n",
      "0.0\n",
      "0.0078011625\n",
      "0.0026177117\n",
      "0.006082931\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00753084\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0364774\n",
      "0.111636706\n",
      "0.012145001\n",
      "0.01495438\n",
      "0.034533225\n",
      "0.0\n",
      "0.0029515328\n",
      "0.0\n",
      "0.0\n",
      "0.038572926\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.014532471\n",
      "0.0018742968\n",
      "0.0\n",
      "0.07172977\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0066701416\n",
      "0.004181377\n",
      "0.0\n",
      "0.004456436\n",
      "0.0983553\n",
      "0.009393004\n",
      "0.034984745\n",
      "0.039658364\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.004111585\n",
      "0.0\n",
      "0.004921539\n",
      "0.013236287\n",
      "0.0\n",
      "0.0\n",
      "0.005862119\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007090754\n",
      "0.0\n",
      "0.0\n",
      "0.0049068485\n",
      "0.011167404\n",
      "0.0\n",
      "0.0\n",
      "0.0026681125\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.005601315\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.891169   0.018843  0.823529  0.036842  0.086313  0.023419   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.015963  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:42:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 0.832 seconds\n",
      "Cross-validation score: 0.03790443969447333\n",
      "Test score: 0.033128253667770946\n",
      "Best Hyperparameters: {}\n",
      "0.0081846295\n",
      "0.023863493\n",
      "0.27671385\n",
      "0.0\n",
      "0.061214913\n",
      "0.060975537\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.054807734\n",
      "0.031076092\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.009886012\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0006759165\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.02077439\n",
      "0.008721921\n",
      "0.00195884\n",
      "0.0\n",
      "0.0\n",
      "0.0147109125\n",
      "0.028340692\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.003851901\n",
      "0.0\n",
      "0.0008958013\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.005014126\n",
      "0.010635877\n",
      "0.03539885\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.057139754\n",
      "0.01299735\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.03292339\n",
      "0.0065180995\n",
      "0.0\n",
      "0.034935493\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.015366417\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.08060863\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0012725192\n",
      "0.026948415\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0037895825\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0007656552\n",
      "0.04919857\n",
      "0.0\n",
      "0.0\n",
      "0.0042035044\n",
      "0.0\n",
      "0.005260829\n",
      "0.009614551\n",
      "0.0\n",
      "0.00075569545\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.923729   0.026718  0.823529  0.051756  0.118243  0.033128   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.022449  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:42:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 0.946 seconds\n",
      "Cross-validation score: 0.03285390334323565\n",
      "Test score: 0.04794134235758602\n",
      "Best Hyperparameters: {}\n",
      "0.010554244\n",
      "0.007951047\n",
      "0.16434196\n",
      "0.034672517\n",
      "0.020973593\n",
      "0.0057739206\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.034008253\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.015230998\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.01004179\n",
      "0.0023944408\n",
      "0.012559038\n",
      "0.0\n",
      "0.0010631117\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.014459949\n",
      "0.024443457\n",
      "0.027264308\n",
      "0.0038987373\n",
      "0.0\n",
      "0.004883415\n",
      "0.0031939368\n",
      "0.0\n",
      "0.0068828193\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0024136307\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.011666941\n",
      "0.044609085\n",
      "0.0\n",
      "0.04844381\n",
      "0.011069432\n",
      "0.0\n",
      "0.0010467432\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.011032993\n",
      "0.0\n",
      "0.0\n",
      "0.037821792\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0042755613\n",
      "0.0045359777\n",
      "0.0\n",
      "0.0\n",
      "0.027783297\n",
      "0.062166687\n",
      "0.0\n",
      "0.0020705725\n",
      "0.06550814\n",
      "0.014541737\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0030147908\n",
      "0.0\n",
      "0.011425226\n",
      "0.015908703\n",
      "0.0\n",
      "0.0010744559\n",
      "0.0016277998\n",
      "0.0\n",
      "0.005371671\n",
      "0.030519621\n",
      "0.0027725718\n",
      "0.0\n",
      "0.00087456644\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0013798795\n",
      "0.000981386\n",
      "0.0\n",
      "0.089800335\n",
      "0.06342487\n",
      "0.0\n",
      "0.001538238\n",
      "0.008033971\n",
      "0.0\n",
      "0.0\n",
      "0.0056376345\n",
      "0.0030363896\n",
      "0.0\n",
      "   Accuracy  Precision  Recall        F1        F2      F0.5  \\\n",
      "0  0.937258   0.038724     1.0  0.074561  0.167653  0.047941   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.038724  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:42:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 0.792 seconds\n",
      "Cross-validation score: 0.043950121070894584\n",
      "Test score: 0.03215434083601286\n",
      "Best Hyperparameters: {}\n",
      "0.020451644\n",
      "0.0014264315\n",
      "0.2695808\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.023140658\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.006649352\n",
      "0.00827652\n",
      "0.0\n",
      "0.0032792569\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.035470184\n",
      "0.010962616\n",
      "0.0\n",
      "0.012360418\n",
      "0.0\n",
      "0.0012049947\n",
      "0.006300903\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0060612913\n",
      "0.0\n",
      "0.0028772077\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.010064371\n",
      "0.0\n",
      "0.0\n",
      "0.015001943\n",
      "0.0007566982\n",
      "0.0\n",
      "0.0\n",
      "0.028995654\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.039832007\n",
      "0.0\n",
      "0.0\n",
      "0.106964104\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.03888043\n",
      "0.0\n",
      "0.0029290144\n",
      "0.07159328\n",
      "0.030423433\n",
      "0.0\n",
      "0.016407704\n",
      "0.0\n",
      "0.028093098\n",
      "0.0016831774\n",
      "0.0\n",
      "0.0076632723\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0011307913\n",
      "0.0\n",
      "0.0066868146\n",
      "0.0\n",
      "0.0048721097\n",
      "0.080086686\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0044413013\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.026454592\n",
      "0.0\n",
      "0.0\n",
      "0.06098534\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0070164306\n",
      "0.0009954028\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0   0.92135   0.025926  0.823529  0.050269  0.115132  0.032154   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.021797  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:42:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 0.837 seconds\n",
      "Cross-validation score: 0.03589223523682572\n",
      "Test score: 0.06056018168054504\n",
      "Best Hyperparameters: {}\n",
      "0.016914278\n",
      "0.040592976\n",
      "0.21021067\n",
      "0.06878554\n",
      "0.01272014\n",
      "0.03440975\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.03926455\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0022733486\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.011929296\n",
      "0.013423145\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00438655\n",
      "0.006451232\n",
      "0.0030926303\n",
      "0.0\n",
      "0.0\n",
      "0.008233376\n",
      "0.0\n",
      "0.0070158346\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007603\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007996104\n",
      "0.004358335\n",
      "0.0\n",
      "0.120924786\n",
      "0.01670627\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.034422707\n",
      "0.0013003679\n",
      "0.0\n",
      "0.053603794\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0054465104\n",
      "0.013050785\n",
      "0.0\n",
      "0.0\n",
      "0.025346616\n",
      "0.0\n",
      "0.024027226\n",
      "0.0\n",
      "0.0\n",
      "0.014296887\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.02735124\n",
      "0.0009640379\n",
      "0.0\n",
      "0.011583225\n",
      "0.0\n",
      "0.0\n",
      "0.056999702\n",
      "0.024115793\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.005407888\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.016035786\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.032120105\n",
      "0.0\n",
      "0.0042967796\n",
      "0.0\n",
      "0.0010120412\n",
      "0.011326697\n",
      "   Accuracy  Precision    Recall        F1        F2     F0.5  \\\n",
      "0  0.953762    0.04908  0.941176  0.093294  0.203046  0.06056   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.046341  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:42:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 0.807 seconds\n",
      "Cross-validation score: 0.031050486239989294\n",
      "Test score: 0.03214744963566223\n",
      "Best Hyperparameters: {}\n",
      "0.004983787\n",
      "0.022754656\n",
      "0.20270292\n",
      "0.0037825964\n",
      "0.016003273\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.034245197\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007947283\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.004131847\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.01693137\n",
      "0.0053597777\n",
      "0.03422813\n",
      "0.019453045\n",
      "0.0\n",
      "0.0\n",
      "0.0018426948\n",
      "0.04994214\n",
      "0.00363024\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0031839106\n",
      "0.0\n",
      "0.0047706463\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0062870714\n",
      "0.04524639\n",
      "0.0227952\n",
      "0.010803505\n",
      "0.0\n",
      "0.009492864\n",
      "0.0010131383\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.01957017\n",
      "0.0\n",
      "0.0\n",
      "0.088916585\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0056473897\n",
      "0.006886964\n",
      "0.0\n",
      "0.0\n",
      "0.032335185\n",
      "0.024886472\n",
      "0.0\n",
      "0.008793592\n",
      "0.07503527\n",
      "0.031583745\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.006841273\n",
      "0.0\n",
      "0.0012478479\n",
      "0.038127463\n",
      "0.0009491922\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0038555535\n",
      "0.03143457\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0017151211\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0008061621\n",
      "0.009581902\n",
      "0.0\n",
      "0.022683473\n",
      "0.014941623\n",
      "0.0\n",
      "0.0\n",
      "0.018016312\n",
      "0.0\n",
      "0.0\n",
      "0.00961838\n",
      "0.0\n",
      "0.014994067\n",
      "   Accuracy  Precision    Recall        F1       F2      F0.5  \\\n",
      "0  0.915849   0.025907  0.882353  0.050336  0.11592  0.032147   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.023156  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:42:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 0.904 seconds\n",
      "Cross-validation score: 0.03703638295582286\n",
      "Test score: 0.03314635390107088\n",
      "Best Hyperparameters: {}\n",
      "0.006693675\n",
      "0.018667236\n",
      "0.24213012\n",
      "0.0\n",
      "0.0167524\n",
      "0.004192552\n",
      "0.012787921\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0096232025\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0036785705\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0038794626\n",
      "0.04898439\n",
      "0.013725669\n",
      "0.016162692\n",
      "0.0\n",
      "0.016216254\n",
      "0.007078935\n",
      "0.0\n",
      "0.026843676\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.010240815\n",
      "0.0074418406\n",
      "0.011166583\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.018081026\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.015236711\n",
      "0.010379002\n",
      "0.0\n",
      "0.03086512\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.021199094\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.017383981\n",
      "0.0\n",
      "0.0\n",
      "0.019414492\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0024718838\n",
      "0.0\n",
      "0.036991477\n",
      "0.049722433\n",
      "0.011151613\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00216629\n",
      "0.022735732\n",
      "0.014520085\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.03362192\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.013649572\n",
      "0.0\n",
      "0.0\n",
      "0.16025473\n",
      "0.0\n",
      "0.0\n",
      "0.014104396\n",
      "0.0\n",
      "0.024914429\n",
      "0.0\n",
      "0.0\n",
      "0.0048700795\n",
      "   Accuracy  Precision    Recall       F1        F2      F0.5  \\\n",
      "0  0.929081   0.026749  0.764706  0.05169  0.117329  0.033146   \n",
      "\n",
      "   Average Precision  \n",
      "0            0.02105  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:43:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 0.829 seconds\n",
      "Cross-validation score: 0.03710910535579037\n",
      "Test score: 0.0513347022587269\n",
      "Best Hyperparameters: {}\n",
      "0.00812819\n",
      "0.08130984\n",
      "0.22919947\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.051891513\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0015125215\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0047431025\n",
      "0.0\n",
      "0.024190528\n",
      "0.0\n",
      "0.0066732345\n",
      "0.0056468174\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0012315863\n",
      "0.009973586\n",
      "0.0018330461\n",
      "0.0\n",
      "0.004860075\n",
      "0.00303453\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0031839793\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0024971145\n",
      "0.0017754892\n",
      "0.011559558\n",
      "0.041738816\n",
      "0.019847753\n",
      "0.0\n",
      "0.0\n",
      "0.008687099\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.016705317\n",
      "0.0\n",
      "0.0\n",
      "0.0065425304\n",
      "0.0\n",
      "0.02202634\n",
      "0.0\n",
      "0.0\n",
      "0.021807186\n",
      "0.018972535\n",
      "0.0\n",
      "0.0\n",
      "0.021848528\n",
      "0.019230574\n",
      "0.03622588\n",
      "0.0\n",
      "0.0\n",
      "0.020769484\n",
      "0.0\n",
      "0.0\n",
      "0.0054858\n",
      "0.0\n",
      "0.0\n",
      "0.023729948\n",
      "0.012712197\n",
      "0.0\n",
      "0.0\n",
      "0.013194274\n",
      "0.0\n",
      "0.0023247595\n",
      "0.025253184\n",
      "0.0\n",
      "0.0\n",
      "0.008442931\n",
      "0.0\n",
      "0.0\n",
      "0.00077630143\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.03293496\n",
      "0.027300252\n",
      "0.0\n",
      "0.0\n",
      "0.08226525\n",
      "0.0\n",
      "0.02023414\n",
      "0.030472236\n",
      "0.0\n",
      "0.004790653\n",
      "0.0015236246\n",
      "0.0\n",
      "0.0009132104\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0   0.94826   0.041551  0.882353  0.079365  0.174825  0.051335   \n",
      "\n",
      "   Average Precision  \n",
      "0            0.03696  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:43:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 0.829 seconds\n",
      "Cross-validation score: 0.03702585670356223\n",
      "Test score: 0.03209536909674461\n",
      "Best Hyperparameters: {}\n",
      "0.019174049\n",
      "0.018286938\n",
      "0.19731353\n",
      "0.0\n",
      "0.06774238\n",
      "0.03451894\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.016429089\n",
      "0.019188603\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.033560447\n",
      "0.0\n",
      "0.014950909\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.004581848\n",
      "0.0010526197\n",
      "0.008290957\n",
      "0.0\n",
      "0.015863098\n",
      "0.0\n",
      "0.005251371\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0056230756\n",
      "0.0\n",
      "0.003406941\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.020194164\n",
      "0.0\n",
      "0.043817777\n",
      "0.0\n",
      "0.0077010733\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.020631101\n",
      "0.0\n",
      "0.0\n",
      "0.040012654\n",
      "0.0\n",
      "0.0\n",
      "0.0116669405\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0015454774\n",
      "0.001005392\n",
      "0.007138011\n",
      "0.0034677319\n",
      "0.025115974\n",
      "0.002056785\n",
      "0.0020224578\n",
      "0.015062216\n",
      "0.07585567\n",
      "0.0\n",
      "0.0024951159\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0008037217\n",
      "0.0019176956\n",
      "0.0\n",
      "0.008049612\n",
      "0.002964056\n",
      "0.0\n",
      "0.0010963269\n",
      "0.02766709\n",
      "0.008166385\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.018645214\n",
      "0.0\n",
      "0.0\n",
      "0.026281282\n",
      "0.0\n",
      "0.014547578\n",
      "0.09097766\n",
      "0.0\n",
      "0.0\n",
      "0.0501614\n",
      "0.0\n",
      "0.0028127914\n",
      "0.0\n",
      "0.000885856\n",
      "0.0\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.921201   0.025878  0.823529  0.050179  0.114943  0.032095   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.021757  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:43:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 0.846 seconds\n",
      "Cross-validation score: 0.037757779465726705\n",
      "Test score: 0.028612303290414882\n",
      "Best Hyperparameters: {}\n",
      "0.039058764\n",
      "0.094920054\n",
      "0.20947118\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.030293243\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0040683444\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0075142826\n",
      "0.002484065\n",
      "0.0\n",
      "0.0\n",
      "0.024450837\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0009361959\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.01546305\n",
      "0.0017954139\n",
      "0.0\n",
      "0.0\n",
      "0.0010682697\n",
      "0.038796384\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.015736016\n",
      "0.0\n",
      "0.16960199\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.005128047\n",
      "0.0\n",
      "0.0\n",
      "0.12674928\n",
      "0.11573134\n",
      "0.0\n",
      "0.0009943105\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.03241425\n",
      "0.0\n",
      "0.0\n",
      "0.0047696745\n",
      "0.0\n",
      "0.0\n",
      "0.001369393\n",
      "0.0\n",
      "0.0\n",
      "0.001811342\n",
      "0.0\n",
      "0.0014700698\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.022653306\n",
      "0.0\n",
      "0.0\n",
      "0.03125095\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.923729   0.023077  0.705882  0.044693  0.102041  0.028612   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.017033  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:43:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 0.920 seconds\n",
      "Cross-validation score: 0.0378420814315365\n",
      "Test score: 0.03522780648191639\n",
      "Best Hyperparameters: {}\n",
      "0.01693299\n",
      "0.09787842\n",
      "0.14767426\n",
      "0.015130424\n",
      "0.02993128\n",
      "0.012230157\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.05481103\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.017671315\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.010610288\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0125564635\n",
      "0.0\n",
      "0.0017061487\n",
      "0.0\n",
      "0.0007542836\n",
      "0.0019185147\n",
      "0.020442476\n",
      "0.0\n",
      "0.0065245116\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0019754944\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0033543305\n",
      "0.0\n",
      "0.008382015\n",
      "0.007399627\n",
      "0.064363144\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.020293754\n",
      "0.0\n",
      "0.0\n",
      "0.008693727\n",
      "0.025698213\n",
      "0.0\n",
      "0.0\n",
      "0.050751813\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0019856733\n",
      "0.09477508\n",
      "0.0051968377\n",
      "0.0\n",
      "0.10936511\n",
      "0.029149693\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.011243315\n",
      "0.0\n",
      "0.001173504\n",
      "0.0\n",
      "0.0051462804\n",
      "0.048459437\n",
      "0.0\n",
      "0.002881404\n",
      "0.0017248163\n",
      "0.0\n",
      "0.002597262\n",
      "0.0011106764\n",
      "0.0\n",
      "0.0\n",
      "0.00079817296\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.02495098\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.002196423\n",
      "0.0\n",
      "0.00784795\n",
      "0.0021064086\n",
      "0.0044590086\n",
      "0.0051472127\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.923431   0.028409  0.882353  0.055046  0.125839  0.035228   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.025364  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:43:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 0.832 seconds\n",
      "Cross-validation score: 0.03314934365535828\n",
      "Test score: 0.02942330325617889\n",
      "Best Hyperparameters: {}\n",
      "0.011920216\n",
      "0.056185484\n",
      "0.12721969\n",
      "0.0\n",
      "0.027159207\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.010961958\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.010927818\n",
      "0.0\n",
      "0.02881404\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0005678039\n",
      "0.0\n",
      "0.0048378534\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0033887068\n",
      "0.028397491\n",
      "0.0\n",
      "0.0034653833\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0033595834\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.04805152\n",
      "0.0\n",
      "0.023164142\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.04637321\n",
      "0.0\n",
      "0.0017276438\n",
      "0.004070244\n",
      "0.00970301\n",
      "0.03050032\n",
      "0.0027205418\n",
      "0.0\n",
      "0.0\n",
      "0.0020987294\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0067990455\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0019077503\n",
      "0.0\n",
      "0.0\n",
      "0.072043896\n",
      "0.04553603\n",
      "0.02283307\n",
      "0.1392074\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00052019535\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.01637666\n",
      "0.06823957\n",
      "0.0\n",
      "0.0\n",
      "0.001005506\n",
      "0.0\n",
      "0.0099794725\n",
      "0.04185818\n",
      "0.0021206173\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0008540501\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.009362388\n",
      "0.0\n",
      "0.024488244\n",
      "0.01734276\n",
      "0.0\n",
      "0.0\n",
      "0.01761735\n",
      "0.0\n",
      "0.0075333416\n",
      "0.0053843306\n",
      "0.0033755077\n",
      "0.0\n",
      "   Accuracy  Precision    Recall        F1       F2      F0.5  \\\n",
      "0   0.90782   0.023697  0.882353  0.046154  0.10699  0.029423   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.021206  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:43:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 0.781 seconds\n",
      "Cross-validation score: 0.02971604049723296\n",
      "Test score: 0.0481637567730283\n",
      "Best Hyperparameters: {}\n",
      "0.017400429\n",
      "0.07083218\n",
      "0.10292871\n",
      "0.0\n",
      "0.016120486\n",
      "0.017361661\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0025290395\n",
      "0.0\n",
      "0.014241966\n",
      "0.0011832116\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0012739889\n",
      "0.005078382\n",
      "0.0022495778\n",
      "0.0\n",
      "0.0\n",
      "0.014229211\n",
      "0.0018566455\n",
      "0.0665495\n",
      "0.0092598265\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0048709013\n",
      "0.0\n",
      "0.0037514989\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.012914444\n",
      "0.024458356\n",
      "0.004404659\n",
      "0.0\n",
      "0.051243786\n",
      "0.020018004\n",
      "0.0\n",
      "0.0\n",
      "0.013692202\n",
      "0.0039287996\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.019350965\n",
      "0.0\n",
      "0.0\n",
      "0.097921915\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00043325435\n",
      "0.037963744\n",
      "0.036215436\n",
      "0.0066579096\n",
      "0.15265502\n",
      "0.0\n",
      "0.017266007\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0024857447\n",
      "0.02451796\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.003348453\n",
      "0.0086029675\n",
      "0.0558331\n",
      "0.0\n",
      "0.0006081983\n",
      "0.0\n",
      "0.0002016212\n",
      "0.0013976505\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.046500254\n",
      "0.0\n",
      "0.0\n",
      "0.0004950276\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0039618565\n",
      "0.0012053378\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.941124   0.038929  0.941176  0.074766  0.167015  0.048164   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.036788  \n",
      "[01:43:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 0.926 seconds\n",
      "Cross-validation score: 0.03714226320685664\n",
      "Test score: 0.03649635036496351\n",
      "Best Hyperparameters: {}\n",
      "0.020762129\n",
      "0.02356633\n",
      "0.21838802\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0048609176\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.035394266\n",
      "0.004488521\n",
      "0.0\n",
      "0.0276125\n",
      "0.0\n",
      "0.043878343\n",
      "0.0\n",
      "0.0\n",
      "0.016894935\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.031479854\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0025745924\n",
      "0.0\n",
      "0.010603979\n",
      "0.014580085\n",
      "0.0\n",
      "0.0\n",
      "0.00090454705\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.12009232\n",
      "0.009211473\n",
      "0.0\n",
      "0.009156857\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0014320206\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007330658\n",
      "0.0062022414\n",
      "0.05043939\n",
      "0.0\n",
      "0.034224745\n",
      "0.0\n",
      "0.042601656\n",
      "0.0\n",
      "0.004544568\n",
      "0.0\n",
      "0.0\n",
      "0.01526761\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.022519633\n",
      "0.0066613993\n",
      "0.061466876\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.01066372\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0029788096\n",
      "0.0\n",
      "0.0020143557\n",
      "0.04209094\n",
      "0.0\n",
      "0.0\n",
      "0.08299966\n",
      "0.0\n",
      "0.0\n",
      "0.0037854514\n",
      "0.0\n",
      "0.00832662\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.935772   0.029478  0.764706  0.056769  0.127701  0.036496   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.023137  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "fhalf_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "\n",
    "under_xgboost_normalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized,\n",
    "                                                    labels_normalized,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels_normalized)\n",
    "\n",
    "\n",
    "    GXBoostPipeline = Pipeline(steps = [#['smote', SMOTE()],\n",
    "                                    ['under', RandomUnderSampler()],\n",
    "                                ['classifier', xgb.XGBClassifier(n_jobs=2)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    space['classifier__learning_rate'] = [0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60]\n",
    "    space['classifier__max_depth'] = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "    space['classifier__min_child_weight'] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    space['classifier__gamma'] = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    space['classifier__colsample_bytree'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    spaceEmpty = dict()\n",
    "\n",
    "    GXBoostSearch = RandomizedSearchCV(estimator = GXBoostPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring=fhalf_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedGXBoostModel = GXBoostSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    \n",
    "    cv_score = optimizedGXBoostModel.best_score_\n",
    "    test_score = optimizedGXBoostModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedGXBoostModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedGXBoostModel.best_estimator_._final_estimator.feature_importances_\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedGXBoostModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    print(new_performance_df)\n",
    "    under_xgboost_normalized_performance_df = pd.concat([under_xgboost_normalized_performance_df, new_performance_df])\n",
    "    \n",
    "\n",
    "under_xgboost_normalized_performance_df.to_csv(\"../data/05_model_output/under_xgboost_normalized_performance_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-beads",
   "metadata": {},
   "source": [
    "### 4.2.3 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bottom-relay",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.603 seconds\n",
      "Cross-validation score: 0.1262628457153605\n",
      "Test score: 0.10101010101010101\n",
      "Best Hyperparameters: {}\n",
      "45.87680268460463\n",
      "27.696697015237987\n",
      "591.4083031718037\n",
      "0.0\n",
      "21.901780073414557\n",
      "0.2655539959669113\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "4.7233099937438965\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.663905993103981\n",
      "1.8708415155415423\n",
      "0.0003689379955176264\n",
      "1.1187649965286255\n",
      "0.0017373723861275892\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.52558608725667\n",
      "3.644360065460205\n",
      "5.281849958002567\n",
      "0.0\n",
      "0.0\n",
      "0.42168377394864365\n",
      "0.32085898518562317\n",
      "0.0\n",
      "0.08760210126638412\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.7935304548882414\n",
      "0.9681735062049484\n",
      "0.46890743280528113\n",
      "0.015413600020110607\n",
      "0.49738629907369614\n",
      "0.5341508910059929\n",
      "0.27674201130867004\n",
      "0.4777210056781769\n",
      "16.97296901792288\n",
      "0.5658980011940002\n",
      "5.83089017868042\n",
      "8.833200675435364\n",
      "0.09616569607169367\n",
      "0.0\n",
      "0.0033250401029363275\n",
      "0.08423029631376266\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "12.86983759339546\n",
      "4.061187716230052\n",
      "0.0\n",
      "69.1249105554889\n",
      "2.684878036379814\n",
      "0.5552669763565063\n",
      "0.0\n",
      "0.0\n",
      "0.00787065812619403\n",
      "28.614816715481084\n",
      "0.0\n",
      "0.0\n",
      "23.372580046358053\n",
      "2.0445240437984467\n",
      "4.114916812628508\n",
      "2.02800989386742\n",
      "0.11496099829673767\n",
      "1.0860067829489708\n",
      "0.0\n",
      "0.0\n",
      "0.555021452717483\n",
      "0.47458401322364807\n",
      "0.0\n",
      "3.905409432198212\n",
      "1.3797099594958127\n",
      "0.012531957788496584\n",
      "0.04588633868843317\n",
      "0.34784680485566355\n",
      "1.5819420516490936\n",
      "1.4372169971466064e-05\n",
      "65.96788710355759\n",
      "1.625349998474121\n",
      "0.0\n",
      "0.0428329655047861\n",
      "0.0\n",
      "0.9135110080242157\n",
      "0.7268859893083572\n",
      "0.0\n",
      "0.0\n",
      "0.08583288916270249\n",
      "0.0\n",
      "0.8792180120944977\n",
      "1.564846619963646\n",
      "0.0\n",
      "2.7130599846714176e-06\n",
      "19.30333571881056\n",
      "0.0\n",
      "0.32733601331710815\n",
      "3.6391997318714857\n",
      "0.0\n",
      "0.0\n",
      "0.4260881810914725\n",
      "1.6034845303794683\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.886 seconds\n",
      "Cross-validation score: 0.13797894200469005\n",
      "Test score: 0.14625228519195613\n",
      "Best Hyperparameters: {}\n",
      "60.2022842541337\n",
      "112.31428849697113\n",
      "327.0820177234709\n",
      "0.0\n",
      "0.0312460009008646\n",
      "8.246598847210407\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "14.516815096139908\n",
      "123.01596142351627\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.2092989981174469\n",
      "0.0\n",
      "1.2241100072860718\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.643896073102951\n",
      "0.0\n",
      "0.0006269959849305451\n",
      "1.2432489693164825\n",
      "1.945099949836731\n",
      "15.307964657433331\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.6653209924697876\n",
      "0.12744900584220886\n",
      "1.602929949760437\n",
      "0.11998199671506882\n",
      "3.228879919668543\n",
      "2.181592047214508\n",
      "0.0\n",
      "0.023764999583363533\n",
      "4.580543011426926\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "9.764178141951561\n",
      "6.2806117832660675\n",
      "1.464537389576435\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "15.356647923588753\n",
      "0.0\n",
      "2.5547723434865475\n",
      "0.8629360049962997\n",
      "7.693733975291252\n",
      "7.120999172329903\n",
      "3.116735391318798\n",
      "0.0\n",
      "0.0\n",
      "0.12606599926948547\n",
      "3.6456914097070694\n",
      "1.4818600416183472\n",
      "0.0\n",
      "22.87423411011696\n",
      "1.8892597034573555\n",
      "0.0\n",
      "3.5777480541655677\n",
      "2.1520059406757355\n",
      "0.23203100264072418\n",
      "0.0\n",
      "0.0\n",
      "0.08306629955768585\n",
      "1.160890020430088\n",
      "0.0\n",
      "0.4122779965400696\n",
      "56.598576225340366\n",
      "4.176660940051079\n",
      "0.011681599542498589\n",
      "3.796374004567042\n",
      "0.0\n",
      "1.0999000072479248\n",
      "0.0\n",
      "4.186127036809921\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.47605401277542114\n",
      "0.9859449863433838\n",
      "0.16757699847221375\n",
      "0.0\n",
      "23.626898869872093\n",
      "0.0\n",
      "0.14295600354671478\n",
      "37.1646461263299\n",
      "3.392201606184244\n",
      "0.0\n",
      "0.00013644799764733762\n",
      "0.0\n",
      "0.4139830023050308\n",
      "2.4744370229309425\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.4694739878177643\n",
      "16.74705182015896\n",
      "0.0\n",
      "0.6991200149059296\n",
      "40.52082974463701\n",
      "0.0\n",
      "0.0\n",
      "2.5795199871063232\n",
      "0.0\n",
      "2.229337066411972\n",
      "2.5921669602394104\n",
      "8.149063125252724\n",
      "1.054569959640503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.579 seconds\n",
      "Cross-validation score: 0.1532572595478155\n",
      "Test score: 0.11661807580174928\n",
      "Best Hyperparameters: {}\n",
      "11.254777240945259\n",
      "37.30117763951421\n",
      "474.95844689202977\n",
      "0.0\n",
      "53.98939214646816\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.06502830237150192\n",
      "4.558024048805237\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.8281020075082779\n",
      "0.0\n",
      "0.17129549756646156\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.16982600092887878\n",
      "0.006112630013376474\n",
      "3.521739959716797\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.2846600115299225\n",
      "0.0\n",
      "0.04737810045480728\n",
      "0.0\n",
      "0.4366375186236837\n",
      "0.13814150169491768\n",
      "5.142588049173355\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.9774802644533338\n",
      "0.0\n",
      "8.932599902153015\n",
      "0.0\n",
      "0.0\n",
      "0.9841510057449341\n",
      "0.03281040117144585\n",
      "0.0\n",
      "9.441980179399252\n",
      "21.939432053346536\n",
      "15.238230994138576\n",
      "75.93606147666833\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.722993016242981\n",
      "0.06376039981842041\n",
      "0.0\n",
      "0.24595530703663826\n",
      "4.78835915774107\n",
      "2.0246299925474887e-07\n",
      "0.0\n",
      "32.23861662298441\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.1918649673461914\n",
      "0.5509830117225647\n",
      "17.111624442966104\n",
      "0.0\n",
      "0.0\n",
      "0.42006244882941246\n",
      "21.104630266461044\n",
      "0.0\n",
      "0.5554167008958757\n",
      "0.1598079949617386\n",
      "17.442548729479313\n",
      "0.0\n",
      "0.7855179905891418\n",
      "0.0\n",
      "0.8166940212249756\n",
      "0.05989360064268112\n",
      "10.867239981889725\n",
      "14.251704595983028\n",
      "0.0\n",
      "0.0\n",
      "6.302648901939392\n",
      "0.0\n",
      "25.846260780468583\n",
      "75.6049005240202\n",
      "3.3325710520148277\n",
      "0.0\n",
      "0.077361099421978\n",
      "0.0\n",
      "0.26622503716498613\n",
      "2.3076939582824707\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.892674967646599\n",
      "16.00969462195644\n",
      "0.0\n",
      "5.664987032192585\n",
      "0.7336233928799629\n",
      "0.0\n",
      "0.3459089994430542\n",
      "1.504717007279396\n",
      "0.0\n",
      "0.5235210061073303\n",
      "0.00342423003166914\n",
      "1.5630630552768707\n",
      "3.296811878681183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.640 seconds\n",
      "Cross-validation score: 0.11738082397079945\n",
      "Test score: 0.08342602892102337\n",
      "Best Hyperparameters: {}\n",
      "138.30616364534944\n",
      "44.32346222969818\n",
      "316.4324968419969\n",
      "0.0\n",
      "10.417821805924177\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "15.314889065921307\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.004554320126771927\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.6153600066900253\n",
      "0.0\n",
      "0.12673569656908512\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.16614654627669267\n",
      "11.60664963722229\n",
      "6.274254906202259e-05\n",
      "0.14840970933437347\n",
      "0.0\n",
      "0.094268798828125\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.6031959196552634\n",
      "10.137463107705116\n",
      "8.423077217354148\n",
      "0.9384703943505883\n",
      "0.0\n",
      "8.192598778754473\n",
      "1.7902726233005524\n",
      "2.5585537776350975\n",
      "0.21834300458431244\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.8933314979076385\n",
      "3.3414096599444747\n",
      "4.906170028523775\n",
      "0.00015025900211185217\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.17618799954652786\n",
      "0.3728373944759369\n",
      "2.3741300106048584\n",
      "0.9893217787321191\n",
      "2.342146941460669\n",
      "0.0\n",
      "0.5548142734915018\n",
      "0.0\n",
      "1.0637090168893337\n",
      "0.0\n",
      "0.0\n",
      "27.78524232842028\n",
      "0.7747748047113419\n",
      "0.0\n",
      "6.839507557451725\n",
      "0.0\n",
      "0.0\n",
      "4.850820118917909e-07\n",
      "0.0\n",
      "0.0\n",
      "0.03534679859876633\n",
      "0.3552743047475815\n",
      "0.0\n",
      "197.23148265480995\n",
      "7.42302840496086\n",
      "0.1113400012254715\n",
      "82.29232718795538\n",
      "0.0\n",
      "0.356810986995697\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.2837700441868947e-07\n",
      "0.006932639982551336\n",
      "15.145384453237057\n",
      "0.6864870190620422\n",
      "0.15428049489855766\n",
      "19.117057489580475\n",
      "0.0\n",
      "0.15494590252637863\n",
      "9.541140945058032\n",
      "0.6972160041332245\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.5552934110164642\n",
      "10.290714056463912\n",
      "0.0\n",
      "0.0\n",
      "0.0016583199612796307\n",
      "0.0\n",
      "0.3071709871292114\n",
      "1.867049977183342\n",
      "0.0\n",
      "1.5986530920490623\n",
      "9.478282891213894\n",
      "0.0\n",
      "0.3268449902534485\n",
      "0.0\n",
      "0.0\n",
      "0.26265853455515753\n",
      "19.80519838631153\n",
      "0.5332785287032493\n",
      "0.007682390045374632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.618 seconds\n",
      "Cross-validation score: 0.1320782728156664\n",
      "Test score: 0.15151515151515152\n",
      "Best Hyperparameters: {}\n",
      "80.14740645499182\n",
      "54.7301139831543\n",
      "336.99412326147285\n",
      "0.0\n",
      "0.15651600062847137\n",
      "58.33514181151986\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.1941089928150177\n",
      "2.6992330625653267\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.026228800415992737\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.16176660358905792\n",
      "0.0005829940200783312\n",
      "0.0\n",
      "0.0\n",
      "0.0016625479911454022\n",
      "0.0\n",
      "3.4181169979274273\n",
      "0.0\n",
      "0.1869650036096573\n",
      "0.2748290002346039\n",
      "0.47091300785541534\n",
      "1.0032099485397339\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0235600471496582\n",
      "0.45727960020303726\n",
      "15.118736699223518\n",
      "0.09796214965172112\n",
      "0.11353100091218948\n",
      "1.896314123792763\n",
      "0.0\n",
      "0.12099500000476837\n",
      "3.582209149375558\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "5.270320844108937\n",
      "0.6860709134489298\n",
      "0.6461892947554588\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "19.641094787046313\n",
      "0.993947493154792\n",
      "25.659269731491804\n",
      "24.32033384476199\n",
      "0.3082420080900192\n",
      "0.5339769087731838\n",
      "0.02011149935424328\n",
      "0.4852920174598694\n",
      "0.0\n",
      "0.1762229949235916\n",
      "0.10673700273036957\n",
      "55.98358379153069\n",
      "0.3704279884696007\n",
      "0.0\n",
      "39.73134169541299\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.12068470323350766\n",
      "17.10873735882342\n",
      "0.0\n",
      "1.3864870071411133\n",
      "113.62585312128067\n",
      "1.158227315172553\n",
      "4.26146399974823\n",
      "0.8846888840198517\n",
      "1.2494039684534073\n",
      "2.792166978120804\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.46076199412345886\n",
      "0.0\n",
      "3.364313006401062\n",
      "109.74218226718949\n",
      "0.0\n",
      "0.0\n",
      "1.3825437128543854\n",
      "0.0\n",
      "0.22456650322055793\n",
      "0.11779977630067151\n",
      "0.0\n",
      "0.0\n",
      "1.270227998495102\n",
      "0.0\n",
      "0.0\n",
      "0.2136629968881607\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.6479560136795044\n",
      "0.15292443536463907\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "4.498768996447325\n",
      "0.26899200677871704\n",
      "0.1450590044260025\n",
      "0.08440328635333572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.607 seconds\n",
      "Cross-validation score: 0.14337295547735124\n",
      "Test score: 0.1002673796791444\n",
      "Best Hyperparameters: {}\n",
      "51.49573880279786\n",
      "12.611666791141033\n",
      "573.0915158121352\n",
      "0.0\n",
      "15.239053528755903\n",
      "0.2895990014076233\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.3638403676450253\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.217629909515381\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.1413400024175644\n",
      "5.6743998527526855\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "4.253435015678406\n",
      "0.9916009902954102\n",
      "1.689974894747138\n",
      "0.0\n",
      "0.0\n",
      "0.44555258098989725\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.45436976896598935\n",
      "25.138550251722336\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "5.3591628251597285\n",
      "4.554119944572449\n",
      "0.05163128930144012\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "12.02219787798822\n",
      "1.0550731047987938\n",
      "2.5543003976345062\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.496769905090332\n",
      "13.321354631334543\n",
      "12.132609543390572\n",
      "16.45319453626871\n",
      "0.1536179929971695\n",
      "0.30344029515981674\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.132471490651369\n",
      "0.0\n",
      "0.0\n",
      "0.00010888394243124822\n",
      "0.0\n",
      "0.0\n",
      "17.57424855977297\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "22.644957475364208\n",
      "0.0\n",
      "0.0\n",
      "55.955788674764335\n",
      "38.32955102622509\n",
      "27.28927217423916\n",
      "1.3655280098319054\n",
      "0.13247405365109444\n",
      "0.0\n",
      "0.0\n",
      "1.215217962861061\n",
      "0.47638990730047226\n",
      "0.0\n",
      "0.0\n",
      "0.2954245936198845\n",
      "6.899653892964125\n",
      "0.0708639994263649\n",
      "5.808260947465897\n",
      "12.188917152583599\n",
      "0.0\n",
      "9.359074743636711\n",
      "1.7534350045025349\n",
      "0.0\n",
      "5.279453173279762\n",
      "1.5743160396814346\n",
      "0.0\n",
      "0.0\n",
      "0.21218599379062653\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.022962862625718\n",
      "6.928789844096173e-07\n",
      "0.0\n",
      "0.03744466998614371\n",
      "5.447410531549394\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.49883690662682056\n",
      "0.0\n",
      "1.9434759616851807\n",
      "15.892083786427975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.575 seconds\n",
      "Cross-validation score: 0.12744137701521424\n",
      "Test score: 0.13260530421216848\n",
      "Best Hyperparameters: {}\n",
      "8.625366307795048\n",
      "50.32768201036379\n",
      "452.17959332771716\n",
      "0.0\n",
      "0.661546990275383\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "27.798785485327244\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0057235402055084705\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.12296800315380096\n",
      "3.8396850526332855\n",
      "0.11304300278425217\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.6529419273138046\n",
      "4.203107509762049\n",
      "1.6964399814605713\n",
      "0.0\n",
      "1.1203257738961838\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "4.7306536212563515\n",
      "6.279356881976128\n",
      "9.249370098114014\n",
      "4.901390224695206\n",
      "0.0\n",
      "22.453616119921207\n",
      "1.2846443794405786\n",
      "39.18758852779865\n",
      "0.5339300110936165\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "4.612348495982587\n",
      "0.2868669927120209\n",
      "2.917920518666506\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.29333698749542236\n",
      "0.5687779784202576\n",
      "5.273839831352234\n",
      "0.0\n",
      "0.0\n",
      "0.27156199514865875\n",
      "1.1355600357055664\n",
      "0.691190592944622\n",
      "2.9726110696792603\n",
      "0.03660010173916817\n",
      "0.0\n",
      "0.0\n",
      "1.4913599491119385\n",
      "0.5239984914660454\n",
      "0.0\n",
      "0.0\n",
      "6.329877868294716\n",
      "0.0\n",
      "0.25547099113464355\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.3170559406280518\n",
      "0.20372100174427032\n",
      "0.0\n",
      "95.08631443977356\n",
      "27.728936086874455\n",
      "0.0\n",
      "1.0103179812431335\n",
      "0.440964013338089\n",
      "0.35802939534187317\n",
      "0.0\n",
      "0.45200198888778687\n",
      "0.3704569935798645\n",
      "0.4653806062415242\n",
      "0.0\n",
      "19.966982811689377\n",
      "66.49453192949295\n",
      "1.8560894560068846\n",
      "0.00965586956590414\n",
      "5.25074713001959\n",
      "0.0\n",
      "1.57539901137352\n",
      "66.52090521124046\n",
      "10.681611642241478\n",
      "0.011111600324511528\n",
      "0.047320169396698475\n",
      "0.0\n",
      "0.0\n",
      "0.4494320665098712\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.385635994374752\n",
      "5.132809123955667\n",
      "0.0\n",
      "0.21247419342398643\n",
      "9.038435533642769\n",
      "0.0\n",
      "1.0220069736242294\n",
      "4.436871987767518\n",
      "0.0\n",
      "0.0\n",
      "0.12792399525642395\n",
      "1.3355160057544708\n",
      "4.38003396242857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.593 seconds\n",
      "Cross-validation score: 0.1590311715124747\n",
      "Test score: 0.16455696202531644\n",
      "Best Hyperparameters: {}\n",
      "29.186997252829315\n",
      "63.06084254011512\n",
      "474.6085260361433\n",
      "0.0\n",
      "1.7970577515661716\n",
      "7.381717771291733\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "20.974228590726852\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.009161969646811485\n",
      "0.00926239974796772\n",
      "0.0\n",
      "0.0\n",
      "0.013597399927675724\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0028435999993234873\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.12538300454616547\n",
      "0.415526308119297\n",
      "0.009543710388243198\n",
      "0.0\n",
      "4.636940509080887\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.23893199861049652\n",
      "0.6458585038781166\n",
      "0.24813849478960037\n",
      "5.080305544659495\n",
      "4.381927132606506\n",
      "15.713113714009523\n",
      "0.16095190902706236\n",
      "1.0267499685287476\n",
      "0.34661581367254257\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.6280160420574248\n",
      "0.0013627000153064728\n",
      "3.5829027965664864\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0014813600573688745\n",
      "14.965959791094065\n",
      "0.0\n",
      "0.0\n",
      "0.01611959934234619\n",
      "9.974269084166735\n",
      "0.4901590049266815\n",
      "0.0\n",
      "0.9451422989368439\n",
      "1.397773797739319\n",
      "0.034819820895791054\n",
      "0.0\n",
      "13.700750153977424\n",
      "1.1608200111368205e-05\n",
      "0.0\n",
      "0.0\n",
      "0.5581540018320084\n",
      "0.18222899734973907\n",
      "1.5092089511454105\n",
      "0.0011047200532630086\n",
      "0.29370999336242676\n",
      "193.6714690476656\n",
      "10.315965756773949\n",
      "0.047990376013331115\n",
      "3.5059632249176502\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.3974519968032837\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "4.627105116844177\n",
      "36.05704487115145\n",
      "0.0\n",
      "0.0\n",
      "9.74789397418499\n",
      "0.0\n",
      "0.0007118909852579236\n",
      "11.317601200193167\n",
      "0.0\n",
      "0.0\n",
      "0.26860539615154266\n",
      "0.0\n",
      "0.18507889658212662\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.3234570026397705\n",
      "0.0\n",
      "7.642438504844904\n",
      "0.0\n",
      "0.0\n",
      "0.16593014891259372\n",
      "35.95099882782597\n",
      "0.0\n",
      "0.06837780028581619\n",
      "4.4041213523596525\n",
      "0.0\n",
      "1.1576022803783417\n",
      "2.3252890113135436\n",
      "0.5262010227888823\n",
      "0.012770500034093857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.698 seconds\n",
      "Cross-validation score: 0.12087320224246309\n",
      "Test score: 0.14571948998178508\n",
      "Best Hyperparameters: {}\n",
      "38.02428161818534\n",
      "54.173230725261874\n",
      "309.3220109678805\n",
      "0.0\n",
      "10.061052992939949\n",
      "0.21631499379873276\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "9.991669923067093\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "15.742861229926348\n",
      "0.342238113284111\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.2089631855487823\n",
      "1.493248999118805\n",
      "0.03228349983692169\n",
      "0.324957013130188\n",
      "0.0\n",
      "0.05721979960799217\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.3139091690573537\n",
      "11.38276782631874\n",
      "0.10001300275325775\n",
      "8.86424994468689\n",
      "0.0\n",
      "1.752704086531594\n",
      "0.6880579963326454\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "26.877137849573046\n",
      "0.36690670996904373\n",
      "0.32155200839042664\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "11.019453957676888\n",
      "0.4697299897670746\n",
      "0.06850890070199966\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.1584479957818985\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "5.811954123200849\n",
      "8.878807157278061\n",
      "0.18528099358081818\n",
      "15.786883369088173\n",
      "0.0\n",
      "0.9804746136069298\n",
      "0.0\n",
      "0.0\n",
      "0.07950740307569504\n",
      "9.615268236317206\n",
      "0.0\n",
      "1.712108999490738\n",
      "213.34408812783659\n",
      "59.18703083026776\n",
      "0.2683199942111969\n",
      "10.155090021900833\n",
      "0.0\n",
      "20.8708306401968\n",
      "0.0\n",
      "0.0\n",
      "0.8440069705247879\n",
      "0.0\n",
      "0.0\n",
      "3.001691058278084\n",
      "18.528164759278297\n",
      "0.015853499993681908\n",
      "1.1962268203496933\n",
      "3.5621614195406437\n",
      "0.0\n",
      "5.622360816540095\n",
      "32.23954642272838\n",
      "20.006040275096893\n",
      "0.0\n",
      "1.2266099452972412\n",
      "0.0\n",
      "0.005582420155405998\n",
      "0.0012163700303062797\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.3117609918117523\n",
      "2.709859718568623\n",
      "0.0\n",
      "8.93421727232635\n",
      "30.68583942949772\n",
      "0.0\n",
      "0.0\n",
      "4.597462147474289\n",
      "0.0\n",
      "1.5699119418859482\n",
      "0.0\n",
      "2.164770007133484\n",
      "8.56729869171977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.485 seconds\n",
      "Cross-validation score: 0.14300743109512312\n",
      "Test score: 0.14893617021276598\n",
      "Best Hyperparameters: {}\n",
      "9.813976442441344\n",
      "55.41325993835926\n",
      "408.3920138720423\n",
      "0.0\n",
      "105.81003464758396\n",
      "2.476112674921751\n",
      "8.827689725876553e-07\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "7.784933984279633\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.6758390069007874\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.1926400065422058\n",
      "20.29915016144514\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.7083895941032097\n",
      "1.8857799842953682\n",
      "0.1437000036239624\n",
      "0.0\n",
      "1.8549759685993195\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.2814571037888527\n",
      "6.407742083072662\n",
      "0.8620719909667969\n",
      "0.03453340008854866\n",
      "0.0\n",
      "0.3235729932785034\n",
      "1.9405814595520496\n",
      "2.1226919889450073\n",
      "4.181334771215916\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.5753863433739639\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.013824470341205597\n",
      "0.0\n",
      "6.562255114868094\n",
      "8.361650109291077\n",
      "115.26996260334272\n",
      "11.188116028904915\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.7985399170756864\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "8.699192222207785\n",
      "16.04915764182806\n",
      "0.0\n",
      "15.15095317363739\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "14.942623720038682\n",
      "0.0\n",
      "2.7956900596618652\n",
      "0.0\n",
      "0.0\n",
      "0.019181511364877224\n",
      "0.0\n",
      "1.3151409924030304\n",
      "0.0\n",
      "3.6306924633681774\n",
      "0.0\n",
      "2.6568256244063377\n",
      "0.22708100080490112\n",
      "0.06524679809808731\n",
      "2.300881588831544\n",
      "2.651097672060132\n",
      "0.0\n",
      "3.7882556992408354\n",
      "65.28043044824153\n",
      "3.9382060170173645\n",
      "0.0\n",
      "5.950107637559995\n",
      "0.0\n",
      "0.0\n",
      "2.5333800315856934\n",
      "0.0\n",
      "0.0\n",
      "1.0149939805269241\n",
      "0.0\n",
      "14.05728006362915\n",
      "0.11413560435175896\n",
      "0.0\n",
      "0.002359170001000166\n",
      "47.867387652397156\n",
      "0.0\n",
      "0.029995199292898178\n",
      "1.1163850128650665\n",
      "0.0\n",
      "1.7000660002231598\n",
      "2.902631998062134\n",
      "2.272615000605583\n",
      "0.5292235000379151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.682 seconds\n",
      "Cross-validation score: 0.14296727719717753\n",
      "Test score: 0.15384615384615385\n",
      "Best Hyperparameters: {}\n",
      "67.59193042293191\n",
      "26.03261810578988\n",
      "413.29025556892157\n",
      "0.0\n",
      "0.10414600372314453\n",
      "27.648979030549526\n",
      "0.12945719808340073\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "8.026148080825806\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.5015589892864227\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.11489400267601013\n",
      "0.0\n",
      "0.07262030243873596\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.24762199819087982\n",
      "14.837538540363312\n",
      "0.47069400548934937\n",
      "0.0\n",
      "0.3507480025291443\n",
      "0.0\n",
      "5.679194942116737\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "16.997290374989007\n",
      "2.2427444644272327\n",
      "6.417404860258102\n",
      "1.2553220242261887\n",
      "12.446478843688965\n",
      "43.94398028496653\n",
      "0.0\n",
      "0.0\n",
      "0.08702679723501205\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.46711599081754684\n",
      "1.6082899570465088\n",
      "2.6283064633607864\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.8130980283021927\n",
      "3.3624789118766785\n",
      "29.025045323753147\n",
      "11.785977143626951\n",
      "8.364498503447976\n",
      "4.67011022567749\n",
      "0.0\n",
      "0.15680700540542603\n",
      "0.0013892799615859985\n",
      "0.0\n",
      "0.0\n",
      "0.000657594995573163\n",
      "6.055026143621944\n",
      "2.208135463297367\n",
      "0.0\n",
      "47.38511257991195\n",
      "0.0\n",
      "0.00016693500219844282\n",
      "0.0\n",
      "0.0\n",
      "1.6670389771461487\n",
      "4.031201274496198\n",
      "0.0\n",
      "1.5734965950250626\n",
      "49.12333032488823\n",
      "2.754471033811569\n",
      "0.09986790269613266\n",
      "10.680516002699733\n",
      "0.908710302785039\n",
      "25.32021254301071\n",
      "0.0\n",
      "5.914093911647797\n",
      "0.9445778299123049\n",
      "0.1270345002412796\n",
      "0.0\n",
      "6.577350780367851\n",
      "5.412472367286682\n",
      "0.0\n",
      "0.0\n",
      "0.008707189932465553\n",
      "0.0\n",
      "2.5347839444875717\n",
      "7.773823019117117\n",
      "6.078430007910356\n",
      "0.1216920018196106\n",
      "1.1221089661121368\n",
      "0.0\n",
      "0.02509159967303276\n",
      "3.3999945744872093\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "40.068792439997196\n",
      "2.7230758741497993\n",
      "0.0\n",
      "0.546095997095108\n",
      "34.6334810256958\n",
      "0.0\n",
      "5.439360029413365e-05\n",
      "10.661225974559784\n",
      "0.0\n",
      "2.506386026740074\n",
      "0.6813059896230698\n",
      "0.0\n",
      "0.3740620017051697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.709 seconds\n",
      "Cross-validation score: 0.12612659240315616\n",
      "Test score: 0.1616161616161616\n",
      "Best Hyperparameters: {}\n",
      "67.75733671337366\n",
      "183.9467814899981\n",
      "213.86831994354725\n",
      "0.0\n",
      "35.414065033968654\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9877541065216064\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.4074159860610962\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.575478308009906\n",
      "0.0\n",
      "1.0066819787025452\n",
      "0.0\n",
      "0.0\n",
      "9.074219997273758e-05\n",
      "0.0\n",
      "5.7845839858055115\n",
      "0.0\n",
      "1.0473423918355707\n",
      "0.886838332996831\n",
      "1.20449498295784\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.4786256700754166\n",
      "0.0\n",
      "8.468196486588567\n",
      "2.6164054173968907\n",
      "7.720797881484032\n",
      "2.404472127556801\n",
      "9.877540774643421\n",
      "3.843839943408966\n",
      "2.201469207249829\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "5.397420018911362\n",
      "0.8446270227432251\n",
      "4.684766054153442\n",
      "3.276029929111246e-06\n",
      "0.0\n",
      "0.0\n",
      "0.5167050063610077\n",
      "0.0\n",
      "1.7591939941048622\n",
      "0.3128570020198822\n",
      "1.0097470059990883\n",
      "0.3552176970988512\n",
      "0.0\n",
      "0.0\n",
      "0.8346909880638123\n",
      "0.07361805019900203\n",
      "0.0\n",
      "0.0\n",
      "1.884663999080658\n",
      "1.22527814517494\n",
      "5.209383159415665\n",
      "0.003481850028038025\n",
      "3.027909994125366\n",
      "0.0\n",
      "0.3759840130805969\n",
      "0.0\n",
      "0.2615130990743637\n",
      "0.0\n",
      "4.191344254897558\n",
      "0.0\n",
      "0.0\n",
      "277.3383124573156\n",
      "0.36658499389886856\n",
      "3.453315231949091\n",
      "0.0\n",
      "0.3646849989891052\n",
      "20.90066546140588\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "5.328661772679936\n",
      "0.0\n",
      "0.0\n",
      "7.433487989008427\n",
      "0.4223818477671557\n",
      "5.918020065109886e-07\n",
      "20.295374166560578\n",
      "0.0\n",
      "9.360802421964763\n",
      "8.037709278401735\n",
      "16.54346990585327\n",
      "0.0\n",
      "2.11058247089386\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.85806015401613e-06\n",
      "0.0\n",
      "3.769830072997138e-05\n",
      "2.4128129297459964\n",
      "0.0\n",
      "7.365161525085568\n",
      "0.20228269696235657\n",
      "0.0\n",
      "0.4990040063858032\n",
      "1.6760610714554787\n",
      "0.0\n",
      "0.7737110257148743\n",
      "4.358320369450219\n",
      "2.0415030419826508\n",
      "18.284615077078342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.667 seconds\n",
      "Cross-validation score: 0.12749409199631226\n",
      "Test score: 0.12345679012345678\n",
      "Best Hyperparameters: {}\n",
      "77.59546052012593\n",
      "29.37426271662116\n",
      "364.61254773316796\n",
      "0.0\n",
      "5.377021744847298\n",
      "0.8946869969367981\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "17.886775568127632\n",
      "0.05253089964389801\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "4.727630606192207\n",
      "0.014183400198817253\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.9352680146694183\n",
      "5.020538218785077\n",
      "0.37913399934768677\n",
      "0.41539400815963745\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9707088023424149\n",
      "0.0\n",
      "0.12637099623680115\n",
      "2.3768087029457092\n",
      "0.0\n",
      "1.6938073746860027\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.4647489786148071\n",
      "15.822689771652222\n",
      "17.973222012504266\n",
      "0.10234219022095203\n",
      "0.077400803565979\n",
      "0.2074439972639084\n",
      "1.7840460808329226\n",
      "0.0\n",
      "7.583410024642944\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5792472955768062\n",
      "1.5915115904062986\n",
      "1.3301396071910858\n",
      "0.0\n",
      "0.3861199915409088\n",
      "0.0\n",
      "0.12304859980940819\n",
      "0.005377789959311485\n",
      "5.468610640207771\n",
      "1.53310988843441\n",
      "31.81009316528798\n",
      "4.423111745039932\n",
      "0.0\n",
      "0.0\n",
      "2.8726693131029606\n",
      "1.4366870783269405\n",
      "0.0\n",
      "0.0\n",
      "2.060001015663147\n",
      "0.10520700365304947\n",
      "0.33289239555597305\n",
      "0.0\n",
      "37.71032051742077\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.01552448674920015\n",
      "6.9899710807949305\n",
      "0.224526796489954\n",
      "0.0\n",
      "0.9986823962535709\n",
      "153.81359991803765\n",
      "3.7956912983208895\n",
      "29.56306579709053\n",
      "21.81946216430515\n",
      "0.4449799954891205\n",
      "0.0625016987323761\n",
      "0.0\n",
      "2.018994987010956\n",
      "1.069347689510323\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "54.45210362225771\n",
      "0.04990360140800476\n",
      "2.2880360186100006\n",
      "0.0\n",
      "0.0\n",
      "9.392863999120891\n",
      "28.500432355329394\n",
      "0.2629860043525696\n",
      "0.0\n",
      "5.593577474355698\n",
      "0.0\n",
      "0.0\n",
      "0.07806570082902908\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.16261989623308182\n",
      "1.2485790103673935\n",
      "0.0\n",
      "0.0\n",
      "22.896097287535667\n",
      "0.0\n",
      "0.0\n",
      "4.17149761877954\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.013739700429141521\n",
      "0.06547550112009048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.686 seconds\n",
      "Cross-validation score: 0.1546108258920199\n",
      "Test score: 0.140597539543058\n",
      "Best Hyperparameters: {}\n",
      "50.50861268397421\n",
      "31.944300496950746\n",
      "462.7942570740124\n",
      "0.0\n",
      "28.721566402586177\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.23555199801921844\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.8936580922454596\n",
      "0.0\n",
      "0.042569998651742935\n",
      "0.0\n",
      "0.0\n",
      "0.0660029846476391\n",
      "0.0\n",
      "2.684308501891792\n",
      "0.0\n",
      "0.6795520037412643\n",
      "0.9580685530090705\n",
      "2.3275360465049744\n",
      "0.006677330005913973\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.03715577069669962\n",
      "5.153563886880875\n",
      "20.369356282055378\n",
      "2.1050400733947754\n",
      "0.07095810025930405\n",
      "51.62554206699133\n",
      "1.1701451428234577\n",
      "0.0\n",
      "0.31962141459916893\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.2599569857120514\n",
      "0.029869599267840385\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.17781400121748447\n",
      "1.2329620197415352\n",
      "0.107984799426049\n",
      "1.1041750013828278\n",
      "64.84125366061926\n",
      "26.299805849790573\n",
      "0.042413339600898325\n",
      "0.0\n",
      "0.0690993785392493\n",
      "0.004733869805932045\n",
      "0.1873006192035973\n",
      "0.0\n",
      "0.0\n",
      "0.8797178044915199\n",
      "0.006964460015296936\n",
      "0.0\n",
      "38.550634041428566\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.21622669883072376\n",
      "37.7619707925478\n",
      "0.0\n",
      "0.0\n",
      "41.524496958591044\n",
      "1.6857499929301412e-07\n",
      "25.717072254334198\n",
      "1.1781626166775823\n",
      "0.0\n",
      "5.2230982929468155\n",
      "0.659305989742279\n",
      "0.0\n",
      "2.235779999056831\n",
      "0.0\n",
      "0.0\n",
      "7.428158983588219\n",
      "22.067081784829497\n",
      "0.1259939968585968\n",
      "0.1387619972229004\n",
      "0.060695968102663755\n",
      "0.0\n",
      "0.9090030273531795\n",
      "19.582215405534953\n",
      "0.0\n",
      "0.0\n",
      "2.248166009783745\n",
      "0.0\n",
      "0.00013116130139678717\n",
      "7.022898726165295\n",
      "0.0\n",
      "0.0\n",
      "1.3731471076607704\n",
      "0.0\n",
      "3.045714020729065\n",
      "0.004052649950608611\n",
      "0.0\n",
      "0.0\n",
      "15.28439998626709\n",
      "0.0\n",
      "0.0\n",
      "8.199975620122245\n",
      "0.0\n",
      "0.0\n",
      "0.9510750100016594\n",
      "0.3098235672368901\n",
      "0.00010272899817209691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.583 seconds\n",
      "Cross-validation score: 0.12333413456521931\n",
      "Test score: 0.21067415730337083\n",
      "Best Hyperparameters: {}\n",
      "106.3895863071084\n",
      "110.83940239623189\n",
      "309.67940112550605\n",
      "0.0\n",
      "25.228037476539612\n",
      "13.499692112207413\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "4.201132565736771\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.15801929868757725\n",
      "0.0\n",
      "0.011147200129926205\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.05330066740862094\n",
      "0.0\n",
      "0.0\n",
      "16.154664158821106\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.4166826009750366\n",
      "0.0\n",
      "0.0\n",
      "1.13332998752594\n",
      "0.21961839497089386\n",
      "0.00025245299912057817\n",
      "0.0\n",
      "14.073380499146879\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.004485673998715356\n",
      "8.718401983380318\n",
      "1.6014660000801086\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0738343349366914\n",
      "0.0\n",
      "8.637010097503662\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0388279184699059\n",
      "0.0\n",
      "3.0668680667877197\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.1475464031100273\n",
      "12.498712748289108\n",
      "8.485550194978714\n",
      "1.9563715942203999\n",
      "1.8516159392893314\n",
      "0.10425999760627747\n",
      "0.19279499351978302\n",
      "0.3178130090236664\n",
      "0.016629600897431374\n",
      "0.006847150041721761\n",
      "0.0\n",
      "2.4226660571002867e-05\n",
      "0.490094393491745\n",
      "0.0\n",
      "1.0555399656295776\n",
      "4.148298889398575\n",
      "3.351130089868093e-06\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.6547379046678543\n",
      "31.88010899722576\n",
      "0.0\n",
      "0.2991720139980316\n",
      "87.40808450058103\n",
      "3.9224063408892107\n",
      "2.4742492958903313\n",
      "0.0\n",
      "13.108669877052307\n",
      "15.69458843767643\n",
      "0.0\n",
      "0.6552670001983643\n",
      "0.0\n",
      "4.491185009479523\n",
      "0.0\n",
      "0.42522020637989044\n",
      "6.688031502068043\n",
      "3.9835439026355743\n",
      "14.040791064500809\n",
      "2.44430248439312\n",
      "0.0\n",
      "0.8089739978313446\n",
      "18.48914604485799\n",
      "1.3821109682321548\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00017611800285521895\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "9.998507805168629\n",
      "1.4521600008010864\n",
      "0.0\n",
      "0.0\n",
      "94.37002810509875\n",
      "0.0\n",
      "1.4031729996204376\n",
      "12.035549986583646\n",
      "0.0\n",
      "5.476780856472033\n",
      "0.0\n",
      "1.1403210014104843\n",
      "4.1737190037965775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.611 seconds\n",
      "Cross-validation score: 0.13332145521576988\n",
      "Test score: 0.14492753623188406\n",
      "Best Hyperparameters: {}\n",
      "37.78326557390392\n",
      "130.09357638287474\n",
      "211.75041602905526\n",
      "0.0\n",
      "55.947435118258\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "10.616308256983757\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00011440909656812437\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.04712120071053505\n",
      "0.7339774891734123\n",
      "0.05694720149040222\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.4322569966316223\n",
      "0.0\n",
      "2.642262026667595\n",
      "0.0\n",
      "0.46418800950050354\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9307680130004883\n",
      "0.0\n",
      "0.1505902532512664\n",
      "2.890803962945938\n",
      "0.0028623400721699\n",
      "0.0390515998005867\n",
      "7.522967868018895\n",
      "0.0\n",
      "5.604805909097195\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "12.833673436194658\n",
      "0.0\n",
      "1.040384978055954\n",
      "0.0\n",
      "0.8677579760551453\n",
      "1.155667006969452\n",
      "0.1974640041589737\n",
      "0.0\n",
      "0.34162420273423777\n",
      "0.09974409639835358\n",
      "67.69354767491495\n",
      "8.597565211355686\n",
      "0.0\n",
      "0.0\n",
      "0.00016051100101321936\n",
      "1.0436500310897827\n",
      "5.0346499979496\n",
      "0.0\n",
      "0.29402899742126465\n",
      "10.798848550650291\n",
      "2.194677025079727\n",
      "0.0\n",
      "3.2911899089813232\n",
      "8.007689757505432e-05\n",
      "0.40766819566488266\n",
      "0.0\n",
      "0.42619600892066956\n",
      "9.545374313369393\n",
      "14.27910516411066\n",
      "0.0\n",
      "0.23733100295066833\n",
      "252.9896492147991\n",
      "0.033061299473047256\n",
      "0.4966610574629158\n",
      "7.276333566755056\n",
      "0.011541400104761124\n",
      "2.350909948348999\n",
      "0.0\n",
      "1.7218309864401817\n",
      "0.0\n",
      "0.2768530026078224\n",
      "0.0\n",
      "15.915261872112751\n",
      "22.588178504258394\n",
      "8.400959927712393e-07\n",
      "2.740189015865326\n",
      "1.0295789026422426\n",
      "0.40623199939727783\n",
      "17.709556633206375\n",
      "30.348190504591912\n",
      "0.2624948024749756\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.6559171676635742\n",
      "0.0\n",
      "0.0\n",
      "0.8484904021024704\n",
      "0.0\n",
      "1.1009049862623215\n",
      "0.4325239956378937\n",
      "0.0\n",
      "0.39621277494916285\n",
      "15.816432386636734\n",
      "0.0\n",
      "0.0\n",
      "10.774899694602937\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.182359572034329\n",
      "0.03566566305835295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.684 seconds\n",
      "Cross-validation score: 0.16655375724340898\n",
      "Test score: 0.15695067264573992\n",
      "Best Hyperparameters: {}\n",
      "105.17476784987139\n",
      "49.09275349415839\n",
      "346.6826409474015\n",
      "0.0\n",
      "0.00014474100316874683\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "25.60406517237425\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.2224929928779602\n",
      "0.0\n",
      "0.0\n",
      "0.2058980017900467\n",
      "0.0\n",
      "8.896959968751617e-08\n",
      "0.0\n",
      "0.0\n",
      "0.018217099830508232\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.12538300454616547\n",
      "0.17336103883280884\n",
      "0.0\n",
      "1.1737617086619139\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.21922789647697982\n",
      "29.234296016395092\n",
      "0.5605644760653377\n",
      "0.8577790185809135\n",
      "0.0\n",
      "0.1790158972144127\n",
      "0.7691495966402577\n",
      "0.0\n",
      "0.08258580043911934\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9697449508657883\n",
      "9.319893348030746\n",
      "0.18068803945789114\n",
      "0.0\n",
      "4.94991002142342e-06\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.2219788804650307\n",
      "0.372994726523757\n",
      "56.93125820579007\n",
      "0.0\n",
      "0.0\n",
      "0.021031100302934647\n",
      "0.49760500621050596\n",
      "0.0\n",
      "1.2552769556641579\n",
      "0.0007437149761244655\n",
      "0.0\n",
      "9.793165501207113\n",
      "1.935787983238697\n",
      "0.0\n",
      "68.89506544027608\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.2351589947938919\n",
      "13.07960560418178\n",
      "0.0\n",
      "2.3156766034662724\n",
      "140.14107099641114\n",
      "6.284078970551491\n",
      "1.753370641526999\n",
      "18.686350233852863\n",
      "0.1087689995765686\n",
      "1.8634995752945542\n",
      "0.0\n",
      "0.11124800145626068\n",
      "0.005721639841794968\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "16.711787547916174\n",
      "0.7036189883947372\n",
      "0.013455200009047985\n",
      "1.4097711904905736\n",
      "0.0\n",
      "0.3847281038761139\n",
      "41.49666863886705\n",
      "5.656532375141978\n",
      "0.667516304180026\n",
      "0.0\n",
      "0.0\n",
      "0.0008567059994675219\n",
      "0.07310368996331817\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.649152100086212\n",
      "2.7346298538614064\n",
      "0.0\n",
      "1.2472149804234505\n",
      "13.166971106082201\n",
      "0.0\n",
      "0.003006119979545474\n",
      "0.0\n",
      "0.0\n",
      "1.2612983475701185\n",
      "12.128646893593555\n",
      "0.0\n",
      "1.624405026435852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.687 seconds\n",
      "Cross-validation score: 0.12974124911937196\n",
      "Test score: 0.1478743068391867\n",
      "Best Hyperparameters: {}\n",
      "2.562988275894895\n",
      "95.69436764506541\n",
      "370.9396662810468\n",
      "0.0\n",
      "4.3049123883247375\n",
      "3.2464499473571777\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "9.851481914520264\n",
      "19.72385197877884\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.22680599987506866\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.08493291982449591\n",
      "9.045098721981049\n",
      "0.704816997051239\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.66243939101696\n",
      "0.3385699987411499\n",
      "1.9215282196637418\n",
      "0.06810689717531204\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.7150870114564896\n",
      "0.0007367110229097307\n",
      "4.443568423084798e-05\n",
      "0.21346500515937805\n",
      "1.4032954540098217\n",
      "12.509071066975594\n",
      "1.9433000087738037\n",
      "0.0\n",
      "17.179923379588217\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "5.0770087242126465\n",
      "0.29240700602531433\n",
      "0.14560050144791603\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.692720045160968e-06\n",
      "0.0\n",
      "9.366915591061115\n",
      "0.0\n",
      "28.895883286371827\n",
      "3.319804001948796\n",
      "0.0\n",
      "0.0\n",
      "7.842491090297699\n",
      "0.6455209851264954\n",
      "0.0\n",
      "0.02761089988052845\n",
      "0.001233931372553343\n",
      "7.808264546096325\n",
      "0.006781109783332795\n",
      "0.0\n",
      "64.48696680925786\n",
      "4.061286972500966e-05\n",
      "0.0\n",
      "0.0\n",
      "0.000571560907701496\n",
      "0.8283540159463882\n",
      "8.381814181804657\n",
      "0.6185750067234039\n",
      "0.8657990097999573\n",
      "31.720474369810574\n",
      "62.4676510989666\n",
      "0.0\n",
      "35.82267553731799\n",
      "0.0\n",
      "0.0\n",
      "0.12315600365400314\n",
      "0.30610498785972595\n",
      "0.03424939885735512\n",
      "0.0\n",
      "0.0\n",
      "1.3603606969118118\n",
      "5.780305052088806\n",
      "0.0\n",
      "2.796459952492114e-08\n",
      "6.808028906583786\n",
      "0.0\n",
      "0.0\n",
      "113.91270863322097\n",
      "4.157311744987965\n",
      "0.0\n",
      "0.8628227785229683\n",
      "0.0\n",
      "4.795470158569515e-05\n",
      "6.223327205167152\n",
      "0.0\n",
      "0.0\n",
      "1.3819099876855034e-05\n",
      "0.0\n",
      "0.25588899105787277\n",
      "5.384744167327881\n",
      "0.0\n",
      "7.982360638678074\n",
      "11.759440328925848\n",
      "0.0\n",
      "0.0\n",
      "1.5179546946010305\n",
      "0.0\n",
      "0.0\n",
      "2.2153985649347305\n",
      "6.7290478609502316\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.570 seconds\n",
      "Cross-validation score: 0.13757159891933518\n",
      "Test score: 0.11527377521613832\n",
      "Best Hyperparameters: {}\n",
      "96.19351218950669\n",
      "41.56638089284678\n",
      "196.33193416599534\n",
      "0.0\n",
      "14.036217708140612\n",
      "15.778956022113562\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.7432639896869659\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.7187840193510056\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.12452799826860428\n",
      "6.084032982587814\n",
      "0.0\n",
      "0.0\n",
      "0.5201259851455688\n",
      "0.1416970044374466\n",
      "2.151504673063755\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.60394916716308\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.473706990480423\n",
      "0.08860480040311813\n",
      "9.524701327303774\n",
      "0.13498200476169586\n",
      "0.0\n",
      "8.606669556594625\n",
      "3.695648677647114\n",
      "0.4271453022956848\n",
      "2.7051896173506975\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "13.67771004140377\n",
      "0.9711340069770813\n",
      "0.5044705960899591\n",
      "0.0\n",
      "0.04432540014386177\n",
      "0.04096069931983948\n",
      "0.15304699540138245\n",
      "0.16135600209236145\n",
      "1.713281411677599\n",
      "30.402675472199917\n",
      "74.08200988546014\n",
      "0.3824336929246783\n",
      "0.005335030145943165\n",
      "0.0\n",
      "0.1990325003862381\n",
      "0.04435350000858307\n",
      "0.0\n",
      "2.1257200241088867\n",
      "0.0004137640062253922\n",
      "2.072476677596569\n",
      "5.662318252027035\n",
      "2.503248915076256\n",
      "29.512197092175484\n",
      "0.056372109800577164\n",
      "2.6247700452804565\n",
      "0.0\n",
      "0.0\n",
      "0.08117530215531588\n",
      "5.795370995998383\n",
      "1.4342390447854996\n",
      "0.0\n",
      "294.53406124189496\n",
      "6.170069849016727\n",
      "1.745519444346428\n",
      "10.460078984498978\n",
      "0.0\n",
      "0.0015554300043731928\n",
      "0.0\n",
      "0.0\n",
      "0.012446699663996696\n",
      "0.0\n",
      "3.605570077896118\n",
      "0.0\n",
      "45.64380758535117\n",
      "0.0\n",
      "3.694404080044478\n",
      "0.07721210271120071\n",
      "0.0\n",
      "0.6217679977416992\n",
      "37.96359099075198\n",
      "0.21574999392032623\n",
      "0.0\n",
      "0.03989030048251152\n",
      "0.0\n",
      "0.014108399860560894\n",
      "0.2717760481465348\n",
      "0.0\n",
      "0.0\n",
      "3.669099241378717\n",
      "0.0\n",
      "4.7398975268006325\n",
      "1.5612784214317799\n",
      "0.0\n",
      "0.598034106194973\n",
      "1.9577750409953296\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.7579200267791748\n",
      "0.327101893723011\n",
      "2.9685391840484954\n",
      "1.4322500228881836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.608 seconds\n",
      "Cross-validation score: 0.14287556934545584\n",
      "Test score: 0.12195121951219513\n",
      "Best Hyperparameters: {}\n",
      "124.07717320710402\n",
      "14.001270676031709\n",
      "465.1629289891571\n",
      "0.0\n",
      "5.066310055553913\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.40131930261850357\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.003936806024285033\n",
      "1.2264370461423368e-06\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "5.388125061988831\n",
      "0.0\n",
      "0.11223360151052475\n",
      "8.791749717888251\n",
      "0.0024518799036741257\n",
      "0.9308063834905624\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.073627807199955\n",
      "7.431128600612283\n",
      "0.7972077067242935\n",
      "0.36074599623680115\n",
      "0.0\n",
      "2.0085766911506653\n",
      "5.2966723665595055\n",
      "1.097080155443308\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.8191232047975063\n",
      "0.0\n",
      "0.006538313233761528\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.793814033135277e-05\n",
      "0.0\n",
      "5.301512196660042\n",
      "20.060856819152832\n",
      "1.726249024271965\n",
      "0.04076340049505234\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.12811900675296783\n",
      "13.18748359405754\n",
      "5.10521683296065\n",
      "0.0\n",
      "20.994652361705278\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0006861460278742015\n",
      "0.0\n",
      "46.208914985880256\n",
      "0.0\n",
      "0.791243708692491\n",
      "153.76233863539656\n",
      "0.020271100103855133\n",
      "9.261389777748263e-06\n",
      "34.745460527465184\n",
      "4.589364364743233\n",
      "3.625079035758972\n",
      "0.0\n",
      "5.780940055847168\n",
      "0.0\n",
      "0.0\n",
      "0.00019653610070236027\n",
      "0.4588666073977947\n",
      "0.9063092973083258\n",
      "0.10006039962172508\n",
      "0.0\n",
      "5.490100323459956\n",
      "0.0\n",
      "0.49387800693511963\n",
      "8.091462565505338\n",
      "0.5385695844888687\n",
      "0.0\n",
      "0.29725530141604395\n",
      "0.0\n",
      "1.0923905327731198\n",
      "4.977424943819642\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.4964860081672668\n",
      "4.064789305041145\n",
      "0.0\n",
      "4.349346679483702\n",
      "6.940465345978737\n",
      "0.0\n",
      "0.0\n",
      "0.7362635917961597\n",
      "0.0\n",
      "1.21420496205684\n",
      "0.0\n",
      "0.6427630111575127\n",
      "1.3805270195007324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.685 seconds\n",
      "Cross-validation score: 0.16445430701803104\n",
      "Test score: 0.16853932584269662\n",
      "Best Hyperparameters: {}\n",
      "109.72465916723013\n",
      "66.26797891035676\n",
      "347.08699195086956\n",
      "0.0\n",
      "36.401642970740795\n",
      "1.7788430079817772\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "4.234655894339085\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.11343361995318446\n",
      "0.0\n",
      "0.17277899384498596\n",
      "0.0\n",
      "0.0\n",
      "2.0656966120004654\n",
      "0.0\n",
      "6.59745741635561\n",
      "0.0033678701147437096\n",
      "4.342380190130825\n",
      "0.0010279488376454538\n",
      "0.08000549953430891\n",
      "0.2841362953186035\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.547120548784733\n",
      "5.6166051030159\n",
      "7.547357390634716\n",
      "0.0\n",
      "5.860238311376975\n",
      "0.01150050014257431\n",
      "0.0\n",
      "0.28812869638204575\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.6317674964666367\n",
      "0.27520819939672947\n",
      "0.8265205684583634\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.4458439946174622\n",
      "1.8965100049972534\n",
      "10.009300142526627\n",
      "21.401755712926388\n",
      "0.0\n",
      "1.2748210430145264\n",
      "0.0\n",
      "0.06454210169613361\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "12.20739314505306\n",
      "2.029118090867996\n",
      "0.0\n",
      "48.53899657540023\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.30932718981057405\n",
      "0.13058491563424468\n",
      "0.0\n",
      "2.3384674340486526\n",
      "61.19899503979832\n",
      "0.002409120090305805\n",
      "18.66250212676823\n",
      "39.41250153630972\n",
      "0.0\n",
      "0.5727819800376892\n",
      "0.0\n",
      "5.42784533649683\n",
      "0.4320313073694706\n",
      "0.9395870268344879\n",
      "0.0\n",
      "0.0\n",
      "15.01774287223816\n",
      "0.0\n",
      "0.0\n",
      "5.1425140500068665\n",
      "0.0\n",
      "0.4683309942483902\n",
      "0.2961850608646728\n",
      "3.464974969625473\n",
      "0.0\n",
      "0.3645290637932703\n",
      "0.0\n",
      "0.257109597325325\n",
      "0.38413700461387634\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.2195249050855637\n",
      "0.14758600294589996\n",
      "0.0\n",
      "5.684944663196802\n",
      "135.3724979860708\n",
      "0.0\n",
      "0.16896000504493713\n",
      "0.7732803979888558\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.619215950369835\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.598 seconds\n",
      "Cross-validation score: 0.13093446276451884\n",
      "Test score: 0.125\n",
      "Best Hyperparameters: {}\n",
      "102.51321867108345\n",
      "3.6256649047136307\n",
      "336.82845663279295\n",
      "0.0\n",
      "22.7692369222641\n",
      "12.01667670160532\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.11817718017846346\n",
      "0.0\n",
      "16.336519718170166\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.3808999061584473\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "6.859063848853111\n",
      "0.30204400420188904\n",
      "0.694132000207901\n",
      "0.44170089811086655\n",
      "0.7449840009212494\n",
      "3.0525556169450283\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "7.657981817610562\n",
      "1.007447987794876\n",
      "8.60608695447445\n",
      "1.2071120142936707\n",
      "2.5921730995178223\n",
      "11.181856772047468\n",
      "6.881891191005707\n",
      "0.0\n",
      "4.687692940235138\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "5.818684503436089\n",
      "0.8243965804576874\n",
      "15.231763921678066\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.7708849906921387\n",
      "5.7033480405807495\n",
      "6.770950924335921\n",
      "3.0568140000104904\n",
      "43.41487139463425\n",
      "3.881462603167165\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "2.5482699871063232\n",
      "0.0\n",
      "0.0\n",
      "24.96964715514332\n",
      "0.0\n",
      "0.0\n",
      "35.56349380966276\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.3057159706950188\n",
      "10.125938713550568\n",
      "0.0\n",
      "0.9663069844245911\n",
      "102.1789688244462\n",
      "12.92541660927236\n",
      "1.9231187840923667\n",
      "18.985080242156982\n",
      "2.5155398845672607\n",
      "1.5803699493408203\n",
      "0.0\n",
      "2.19707989692688\n",
      "1.2446099519729614\n",
      "1.5005069971084595\n",
      "0.0\n",
      "5.681411981582642\n",
      "38.018952685408294\n",
      "9.35785499215126\n",
      "0.0\n",
      "0.09295299649238586\n",
      "0.0\n",
      "0.8983820080757141\n",
      "22.416287766303867\n",
      "1.8038038960658014\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.09348169714212418\n",
      "7.454503299668431\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "3.4483533701859415\n",
      "8.331657551229\n",
      "0.0\n",
      "2.8098083920776844\n",
      "14.864168345928192\n",
      "0.0\n",
      "0.018930800259113312\n",
      "5.6339718624949455\n",
      "0.0\n",
      "0.14787399768829346\n",
      "0.25613299012184143\n",
      "15.109246291220188\n",
      "0.4851109981536865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.679 seconds\n",
      "Cross-validation score: 0.11581321919087065\n",
      "Test score: 0.10506798516687268\n",
      "Best Hyperparameters: {}\n",
      "196.7805026602\n",
      "107.79518648330122\n",
      "173.22136111883447\n",
      "0.0\n",
      "43.4031583853066\n",
      "0.8774430155754089\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.1887500286102295\n",
      "0.3878840059041977\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.6507949829101562\n",
      "0.0\n",
      "0.37404200434684753\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.06453999876976013\n",
      "0.9863535836338997\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.04671729914844036\n",
      "24.236120970221236\n",
      "1.1686732177222439\n",
      "0.02104640007019043\n",
      "0.0\n",
      "2.136355035007\n",
      "0.12258599698543549\n",
      "0.0\n",
      "16.832434222102165\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.15291672959574498\n",
      "0.3986699879169464\n",
      "0.2649877965450287\n",
      "0.0\n",
      "0.0\n",
      "1.4893300533294678\n",
      "1.0758399963378906\n",
      "1.615884229540825\n",
      "18.24934872984886\n",
      "0.0\n",
      "0.9983709305524826\n",
      "0.0\n",
      "1.6230454742908478\n",
      "0.0\n",
      "0.07602609694004059\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "12.025507885031402\n",
      "0.3093259930610657\n",
      "0.0\n",
      "27.612312335520983\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.6302299499511719\n",
      "0.3300776109099388\n",
      "0.0\n",
      "0.0\n",
      "4.779970169067383\n",
      "153.2406440768391\n",
      "24.315092608332634\n",
      "6.910381264984608\n",
      "12.285987932235003\n",
      "0.13680100440979004\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.024691300466656685\n",
      "3.2571269990876317\n",
      "0.0\n",
      "0.25095000863075256\n",
      "14.938824925641256\n",
      "0.0\n",
      "2.217360019683838\n",
      "25.851825205609202\n",
      "0.45883860159665346\n",
      "0.0\n",
      "0.23750600218772888\n",
      "0.0\n",
      "6.218049701303244\n",
      "0.7283499985933304\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.1201800107955933\n",
      "0.0\n",
      "25.569507583975792\n",
      "46.59784156084061\n",
      "0.0\n",
      "0.0\n",
      "14.530936241149902\n",
      "0.0\n",
      "0.0019467800157144666\n",
      "1.1271955308338875\n",
      "0.5147770047187805\n",
      "16.92257669568062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.595 seconds\n",
      "Cross-validation score: 0.11763339937651658\n",
      "Test score: 0.09976525821596244\n",
      "Best Hyperparameters: {}\n",
      "24.979594435542822\n",
      "22.439168095588684\n",
      "384.71174261905253\n",
      "0.0\n",
      "31.776607055217028\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "27.171646274626255\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.1036180257797241\n",
      "0.0\n",
      "0.0\n",
      "0.35282761231064796\n",
      "0.0\n",
      "5.242671690881252\n",
      "0.6882150173187256\n",
      "0.0\n",
      "2.9248104244470596\n",
      "0.0\n",
      "3.8721050024032593\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9468389749526978\n",
      "0.0\n",
      "14.446747153997421\n",
      "0.14911500178277493\n",
      "0.13267700374126434\n",
      "1.1004399955272675\n",
      "1.8701519966125488\n",
      "0.0\n",
      "1.6905950158834457\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.1567299962043762\n",
      "0.6191179752349854\n",
      "3.5183781050145626\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.299112007021904\n",
      "0.9757040292024612\n",
      "0.01091460045427084\n",
      "3.5696948170661926\n",
      "12.840765532106161\n",
      "31.44010016322136\n",
      "2.991987258195877\n",
      "0.2677119970321655\n",
      "1.4410750269889832\n",
      "5.033703178167343\n",
      "0.0\n",
      "0.0\n",
      "6.840891105122864\n",
      "1.2902356907725334\n",
      "6.757889062166214\n",
      "0.0\n",
      "33.68007004261017\n",
      "0.0016880299663171172\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "26.398992516100407\n",
      "0.0\n",
      "0.0\n",
      "164.60324081033468\n",
      "0.5788910090923309\n",
      "7.0106000900268555\n",
      "0.721108216792345\n",
      "0.003286600112915039\n",
      "40.55797988176346\n",
      "0.0\n",
      "1.0833699703216553\n",
      "0.0\n",
      "0.23614199459552765\n",
      "0.0\n",
      "1.2975742518901825\n",
      "3.6121928691864014\n",
      "0.0\n",
      "0.0\n",
      "3.538480967283249\n",
      "0.0\n",
      "1.2446429952979088\n",
      "58.7185416506145\n",
      "17.322130143642426\n",
      "2.5911729633808136\n",
      "0.3019361961632967\n",
      "0.0\n",
      "0.7072260938584805\n",
      "0.02134859934449196\n",
      "0.0\n",
      "0.0\n",
      "0.08379272976890206\n",
      "0.0\n",
      "0.24512931595381815\n",
      "6.544249137863517\n",
      "0.0\n",
      "3.7828794764354825\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "11.064070495776832\n",
      "0.0\n",
      "0.0\n",
      "2.1297996645516832\n",
      "0.0\n",
      "7.495378598570824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 0.575 seconds\n",
      "Cross-validation score: 0.13539468397246746\n",
      "Test score: 0.1103448275862069\n",
      "Best Hyperparameters: {}\n",
      "129.5038578318541\n",
      "101.68767499299065\n",
      "334.06956475976784\n",
      "0.0\n",
      "6.487968280911446\n",
      "84.93026852607727\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.8833156079053879\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.12156900018453598\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.19199900329113007\n",
      "1.5782400453190348e-07\n",
      "0.5466139912605286\n",
      "0.0\n",
      "0.1586415022611618\n",
      "0.0\n",
      "0.5065900087356567\n",
      "0.7558259963989258\n",
      "0.4652668982744217\n",
      "0.0063941597371197645\n",
      "0.0\n",
      "8.298118957318366\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.9642201807857873\n",
      "1.6091449856758118\n",
      "5.84266996383667\n",
      "0.0020952799823135138\n",
      "1.2254879921674728\n",
      "8.599105545617931\n",
      "38.46922513842583\n",
      "0.12923899292945862\n",
      "0.5518519878387451\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.5390816163271666\n",
      "0.0\n",
      "3.8258337676525116\n",
      "0.0\n",
      "0.13441899418830872\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.2454013004899025\n",
      "7.247030998580158\n",
      "7.600531794130802\n",
      "48.90164127899334\n",
      "0.20189900696277618\n",
      "0.0\n",
      "0.561777587980032\n",
      "0.0\n",
      "3.717200893908739\n",
      "0.0\n",
      "0.0010859599569812417\n",
      "5.914460307856643\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.1257023203652352\n",
      "0.47960200905799866\n",
      "0.3858354911208153\n",
      "0.07169299061206402\n",
      "90.8936818028833\n",
      "0.478628296405077\n",
      "13.707119941711426\n",
      "9.741668989547179\n",
      "0.8200899958610535\n",
      "2.490882056697046\n",
      "0.0\n",
      "0.0\n",
      "0.4651066180600196\n",
      "0.19905200600624084\n",
      "0.0\n",
      "2.5296120047569275\n",
      "2.9030333273112774\n",
      "0.0\n",
      "0.8349970132112503\n",
      "1.8957125878238337\n",
      "0.0\n",
      "0.9909057021141052\n",
      "39.71617251634598\n",
      "3.2949161306023598\n",
      "0.17706899344921112\n",
      "0.08177018275999615\n",
      "0.0\n",
      "0.0\n",
      "2.004862966910082\n",
      "0.0\n",
      "0.0\n",
      "0.1687111034989357\n",
      "0.0\n",
      "0.29172519594430923\n",
      "9.574078112957068\n",
      "0.0\n",
      "0.479913208168\n",
      "2.861805430613458\n",
      "0.0\n",
      "0.21238300204277039\n",
      "0.5411549843847752\n",
      "0.0\n",
      "0.04536550119519234\n",
      "1.4588567104567574e-05\n",
      "1.8538508450728841\n",
      "4.996746562421322\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "\n",
    "#Import feature selection stuff\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "\n",
    "# Import the model we are using\n",
    "import lightgbm as lgb\n",
    "\n",
    "under_lightgbm_performance_normalized_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "\n",
    "    ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized,\n",
    "                                                    labels_normalized,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels_normalized)\n",
    "\n",
    "\n",
    "    LightGBMPipeline = Pipeline(steps = [#['smote', SMOTE()],\n",
    "                                    ['under', RandomUnderSampler()],\n",
    "                                ['classifier', lgb.LGBMClassifier(n_jobs=-1, importance_type='gain')]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "# define search space\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    spaceEmpty = dict()\n",
    "    space['classifier__num_leaves'] = [11, 16, 21, 26, 31, 36, 41, 46, 51, 56]\n",
    "    space['classifier__min_data_in_leaf'] =  [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__max_depth'] = [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__learning_rate'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9, 1.0]\n",
    "    space['classifier__max_bin'] = [50, 100, 150, 200, 255, 300, 350, 400, 450, 500]\n",
    "\n",
    "    LightGBMSearch = RandomizedSearchCV(estimator = LightGBMPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring= ftwo_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedLightGBMModel = LightGBMSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedLightGBMModel.best_score_\n",
    "    test_score = optimizedLightGBMModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedLightGBMModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedLightGBMModel.best_estimator_._final_estimator.booster_.feature_importance(importance_type='gain')\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedLightGBMModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    under_lightgbm_performance_normalized_df = pd.concat([under_lightgbm_performance_normalized_df, new_performance_df])\n",
    "    \n",
    "\n",
    "under_lightgbm_performance_normalized_df.to_csv(\"../data/05_model_output/under_lightgbm_performance_normalized_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-evanescence",
   "metadata": {},
   "source": [
    "## 4.4 Rebalancing Strategy - 5050"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selective-punch",
   "metadata": {},
   "source": [
    "### 4.4.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "atomic-gateway",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "fiftyfifty_randomforest_normalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized,\n",
    "                                                    labels_normalized,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels_normalized)\n",
    "\n",
    "\n",
    "    pipeline = Pipeline(steps = [['smote', SMOTE(sampling_strategy = 0.5)],\n",
    "                              ['under', RandomUnderSampler()],\n",
    "                                ['classifier', RandomForestClassifier(n_jobs=-1)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    spaceEmpty = dict() \n",
    "\n",
    "    search = RandomizedSearchCV(estimator = pipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring='f1', \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedRFModel = search.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    #print(f\"Elapsed time to compute best fit: \"\n",
    "      #f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedRFModel.best_score_\n",
    "    test_score = optimizedRFModel.score(X_test, y_test)\n",
    "    #print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    #print('Best Hyperparameters: %s' % optimizedRFModel.best_params_)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedRFModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    \n",
    "    fiftyfifty_randomforest_normalized_performance_df = pd.concat([fiftyfifty_randomforest_normalized_performance_df, new_performance_df])\n",
    "    \n",
    "fiftyfifty_randomforest_normalized_performance_df.to_csv(\"../data/05_model_output/fiftyfifty_randomforest_normalized_performance_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-jacket",
   "metadata": {},
   "source": [
    "### 4.4.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "confused-brand",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:00:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 76.897 seconds\n",
      "Cross-validation score: 0.6291675374307735\n",
      "Test score: 0.5797101449275363\n",
      "Best Hyperparameters: {}\n",
      "0.015303044\n",
      "0.012151187\n",
      "0.2891131\n",
      "0.002303017\n",
      "0.01885558\n",
      "0.00043004125\n",
      "0.000705069\n",
      "0.0\n",
      "0.0003200941\n",
      "0.0\n",
      "0.005451348\n",
      "0.0005822181\n",
      "0.0\n",
      "0.0\n",
      "0.0034037982\n",
      "0.0\n",
      "0.00040007944\n",
      "0.0\n",
      "0.0021616411\n",
      "0.00019101227\n",
      "0.00031065714\n",
      "0.0022620454\n",
      "0.009622223\n",
      "0.0064894063\n",
      "0.0003197715\n",
      "0.0001555845\n",
      "0.008179886\n",
      "0.0013154412\n",
      "0.00033465013\n",
      "0.0066124396\n",
      "0.0001843362\n",
      "0.0021646854\n",
      "0.010958387\n",
      "0.0046745054\n",
      "0.009189691\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.016271986\n",
      "0.010476453\n",
      "0.015831139\n",
      "0.0032263002\n",
      "0.0007454184\n",
      "0.0064514256\n",
      "0.0009642835\n",
      "0.0068265\n",
      "0.001973449\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0021376857\n",
      "0.009411111\n",
      "0.00060177286\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0014087681\n",
      "0.005569022\n",
      "0.00064835744\n",
      "0.016545068\n",
      "0.012551411\n",
      "0.010613537\n",
      "0.0\n",
      "0.00015767684\n",
      "0.00198873\n",
      "7.4199e-05\n",
      "0.00038309942\n",
      "0.0\n",
      "0.00079135207\n",
      "0.0036196623\n",
      "0.001796854\n",
      "0.0044112955\n",
      "0.07723891\n",
      "0.0\n",
      "0.0007493126\n",
      "0.00028464117\n",
      "0.0031153292\n",
      "0.00613324\n",
      "0.00021315536\n",
      "0.00018175314\n",
      "5.7523568e-05\n",
      "0.012047626\n",
      "0.03528199\n",
      "0.0013535488\n",
      "0.03302712\n",
      "0.0049068765\n",
      "0.002319632\n",
      "6.648777e-05\n",
      "0.00048110718\n",
      "0.000319478\n",
      "0.0016960645\n",
      "0.0\n",
      "0.0052959267\n",
      "0.030946458\n",
      "0.0\n",
      "0.00023316077\n",
      "0.02751989\n",
      "0.0\n",
      "0.029780192\n",
      "0.07713269\n",
      "0.010698684\n",
      "0.0\n",
      "0.0011994361\n",
      "0.0\n",
      "0.000574363\n",
      "0.0026138148\n",
      "0.0\n",
      "0.0\n",
      "0.00027380313\n",
      "0.0\n",
      "0.004057635\n",
      "0.042455673\n",
      "0.0\n",
      "0.0010383482\n",
      "0.023998396\n",
      "0.0\n",
      "0.00034493985\n",
      "0.002306402\n",
      "0.0\n",
      "0.0011130956\n",
      "0.008250762\n",
      "0.00048539342\n",
      "0.0005856161\n",
      "   Accuracy  Precision    Recall        F1        F2     F0.5  \\\n",
      "0  0.997919   0.615385  0.470588  0.533333  0.493827  0.57971   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.290931  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:01:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 77.191 seconds\n",
      "Cross-validation score: 0.5828990992114816\n",
      "Test score: 0.5639097744360901\n",
      "Best Hyperparameters: {}\n",
      "0.03291727\n",
      "0.0048477645\n",
      "0.22311349\n",
      "0.002673046\n",
      "0.031858236\n",
      "0.0026941216\n",
      "0.0023768041\n",
      "0.001621543\n",
      "0.0014919678\n",
      "0.0\n",
      "0.009841782\n",
      "0.021988874\n",
      "0.0005439931\n",
      "0.0\n",
      "0.0017112792\n",
      "0.0\n",
      "0.007040169\n",
      "0.0\n",
      "0.0005341136\n",
      "0.011564299\n",
      "4.7311696e-05\n",
      "0.0002991011\n",
      "0.0009973061\n",
      "0.00016786161\n",
      "0.0017019657\n",
      "0.011350952\n",
      "0.0\n",
      "0.00014321506\n",
      "0.0\n",
      "0.0031212084\n",
      "5.4283755e-05\n",
      "0.0070397602\n",
      "0.0012134345\n",
      "0.0019854202\n",
      "0.0002938223\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.006997006\n",
      "0.03135011\n",
      "0.017643211\n",
      "0.002899837\n",
      "0.00017677463\n",
      "0.010378898\n",
      "0.000568873\n",
      "0.0013023544\n",
      "0.0015251026\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.000962329\n",
      "0.0023922655\n",
      "0.00022960053\n",
      "0.00033399535\n",
      "0.0\n",
      "0.002048645\n",
      "0.022085395\n",
      "0.005335993\n",
      "0.001969537\n",
      "0.013703114\n",
      "0.0075950595\n",
      "0.012082638\n",
      "0.0019531159\n",
      "2.7534932e-06\n",
      "0.0005062081\n",
      "0.0013115495\n",
      "0.0002001765\n",
      "0.0\n",
      "0.003981773\n",
      "0.0004883398\n",
      "0.0015879397\n",
      "0.0073344\n",
      "0.11354843\n",
      "0.0007503953\n",
      "0.038435604\n",
      "0.0\n",
      "0.0032000523\n",
      "0.0031553048\n",
      "0.004530011\n",
      "0.0007648815\n",
      "0.00069885113\n",
      "0.017610097\n",
      "0.016538836\n",
      "0.002626945\n",
      "0.036270957\n",
      "0.016811855\n",
      "0.0010584268\n",
      "0.0\n",
      "0.00047280698\n",
      "0.00012343233\n",
      "0.00604146\n",
      "0.0\n",
      "0.0029534944\n",
      "0.022698896\n",
      "0.00022290561\n",
      "0.0013965176\n",
      "0.0011294251\n",
      "0.0\n",
      "0.006911374\n",
      "0.05299682\n",
      "0.005362679\n",
      "8.296617e-05\n",
      "0.00016290646\n",
      "0.0\n",
      "0.007986313\n",
      "0.00043664686\n",
      "0.0\n",
      "0.0010651181\n",
      "0.00044411846\n",
      "0.0\n",
      "0.00028883462\n",
      "0.02494913\n",
      "0.0\n",
      "0.0010853214\n",
      "0.011714821\n",
      "0.0\n",
      "0.005030015\n",
      "0.009339179\n",
      "0.0\n",
      "0.00032152355\n",
      "0.016073888\n",
      "0.012509473\n",
      "0.00801783\n",
      "   Accuracy  Precision    Recall        F1        F2     F0.5  \\\n",
      "0  0.997621   0.517241  0.882353  0.652174  0.773196  0.56391   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.456687  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:02:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 70.937 seconds\n",
      "Cross-validation score: 0.5998925753945391\n",
      "Test score: 0.46391752577319584\n",
      "Best Hyperparameters: {}\n",
      "0.01731945\n",
      "0.060653258\n",
      "0.2156559\n",
      "0.0013746538\n",
      "0.016102305\n",
      "0.0055766683\n",
      "0.0011192871\n",
      "0.0\n",
      "0.0022918282\n",
      "0.00063614745\n",
      "0.011895561\n",
      "0.0010537849\n",
      "0.0\n",
      "0.0\n",
      "0.0015517451\n",
      "0.0\n",
      "0.0015134276\n",
      "0.0\n",
      "0.0112278145\n",
      "0.0\n",
      "0.00033559915\n",
      "0.00028224033\n",
      "0.004514912\n",
      "0.0012443103\n",
      "0.0011086694\n",
      "5.301443e-05\n",
      "0.008454538\n",
      "0.0004214221\n",
      "0.0012326061\n",
      "0.016558679\n",
      "0.00032442884\n",
      "0.00039987155\n",
      "0.0073139924\n",
      "0.0018790098\n",
      "0.008798329\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0014842022\n",
      "0.022219468\n",
      "0.0070897313\n",
      "0.00038706893\n",
      "0.0005597954\n",
      "0.006189189\n",
      "0.00015107376\n",
      "0.000434692\n",
      "0.04145274\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00043379408\n",
      "0.0010662759\n",
      "0.000401961\n",
      "0.0009251212\n",
      "0.0\n",
      "0.00051593414\n",
      "0.037046578\n",
      "0.0\n",
      "0.0022724238\n",
      "0.012383336\n",
      "0.007868201\n",
      "0.003424848\n",
      "0.0018999656\n",
      "0.00074293144\n",
      "0.00016219316\n",
      "0.0004379218\n",
      "0.0001643226\n",
      "0.0017586065\n",
      "0.0016077985\n",
      "0.00048170445\n",
      "0.0023394637\n",
      "0.0117902085\n",
      "0.064881384\n",
      "0.0030919183\n",
      "0.038811054\n",
      "8.337925e-05\n",
      "0.00683989\n",
      "1.755348e-05\n",
      "0.003905705\n",
      "0.0038515786\n",
      "0.00073996803\n",
      "0.007964304\n",
      "0.005932963\n",
      "0.0906696\n",
      "0.008232609\n",
      "0.0011713109\n",
      "0.0007050489\n",
      "0.00015688907\n",
      "0.00066933944\n",
      "0.0\n",
      "0.02141154\n",
      "0.0\n",
      "0.003238478\n",
      "0.02342633\n",
      "3.8663748e-05\n",
      "0.00042278392\n",
      "0.0016919731\n",
      "0.0\n",
      "0.002824361\n",
      "0.03781076\n",
      "0.006192176\n",
      "0.0003393569\n",
      "0.0018472013\n",
      "0.0\n",
      "0.004213291\n",
      "0.00017237643\n",
      "0.0\n",
      "0.007097035\n",
      "0.0011508805\n",
      "0.0\n",
      "0.002210028\n",
      "0.020744938\n",
      "0.0\n",
      "0.0056603686\n",
      "0.021214277\n",
      "0.0\n",
      "0.0\n",
      "0.003480629\n",
      "0.0\n",
      "0.00046646158\n",
      "0.025936464\n",
      "0.00048214334\n",
      "0.0016180483\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997175       0.45  0.529412  0.486486  0.511364  0.463918   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.239425  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:04:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 81.514 seconds\n",
      "Cross-validation score: 0.5755837230154339\n",
      "Test score: 0.6790123456790124\n",
      "Best Hyperparameters: {}\n",
      "0.020217538\n",
      "0.048296\n",
      "0.19651268\n",
      "0.0025330135\n",
      "0.017380197\n",
      "0.008448788\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.023225835\n",
      "0.008584983\n",
      "0.00088014215\n",
      "0.0\n",
      "0.0\n",
      "0.00021498551\n",
      "0.0\n",
      "0.003625367\n",
      "0.00029965385\n",
      "0.049170244\n",
      "0.0\n",
      "0.0008145666\n",
      "0.0005673842\n",
      "0.0042508706\n",
      "0.0013026226\n",
      "0.0006751225\n",
      "0.0\n",
      "0.0016875484\n",
      "0.00013784783\n",
      "0.00027724865\n",
      "0.009329194\n",
      "0.00030391474\n",
      "0.0037900144\n",
      "0.002084357\n",
      "0.00057858333\n",
      "0.0015191388\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.005545745\n",
      "0.055053443\n",
      "0.009778989\n",
      "0.00037311038\n",
      "0.009012577\n",
      "0.007947492\n",
      "0.0030624284\n",
      "0.009516302\n",
      "0.007349381\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00164989\n",
      "0.010269444\n",
      "0.0008921704\n",
      "0.0012049185\n",
      "0.0018397036\n",
      "0.0\n",
      "0.0033108406\n",
      "5.7337597e-06\n",
      "0.00039378862\n",
      "0.013045626\n",
      "0.005505026\n",
      "0.0040326365\n",
      "0.004984094\n",
      "0.0011314118\n",
      "0.0009659347\n",
      "0.006998591\n",
      "0.0031577614\n",
      "0.00034005998\n",
      "0.013869133\n",
      "0.004881041\n",
      "0.0015402545\n",
      "0.0032815277\n",
      "0.08625601\n",
      "0.0010664968\n",
      "0.06191623\n",
      "0.0\n",
      "0.0\n",
      "0.0047151963\n",
      "0.004847183\n",
      "0.002454675\n",
      "0.004946347\n",
      "0.006057218\n",
      "0.011873413\n",
      "0.0036568232\n",
      "0.013833965\n",
      "0.0052183666\n",
      "0.00327005\n",
      "0.00039442244\n",
      "0.0052908775\n",
      "3.885502e-05\n",
      "0.001968553\n",
      "0.0012271453\n",
      "0.008171193\n",
      "0.016109454\n",
      "0.000699442\n",
      "0.01861678\n",
      "0.013408155\n",
      "0.0\n",
      "0.0036619944\n",
      "0.051283002\n",
      "0.0015832653\n",
      "0.0\n",
      "0.0025629299\n",
      "0.0\n",
      "0.013913624\n",
      "0.0033784306\n",
      "0.0\n",
      "0.0021493663\n",
      "0.0008149326\n",
      "0.0\n",
      "0.001037144\n",
      "0.008316631\n",
      "0.0\n",
      "0.004262087\n",
      "0.007254791\n",
      "0.0\n",
      "0.00031732346\n",
      "0.0068842545\n",
      "0.0\n",
      "0.00083849794\n",
      "0.00933475\n",
      "0.0055609406\n",
      "0.0031622774\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998365     0.6875  0.647059  0.666667  0.654762  0.679012   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.445745  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:05:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 76.524 seconds\n",
      "Cross-validation score: 0.5925404503693006\n",
      "Test score: 0.5913978494623656\n",
      "Best Hyperparameters: {}\n",
      "0.02313755\n",
      "0.07189571\n",
      "0.18409628\n",
      "0.00061516464\n",
      "0.026673341\n",
      "0.0073615885\n",
      "0.00026798542\n",
      "8.671695e-05\n",
      "0.00055498217\n",
      "0.00035189078\n",
      "0.009538626\n",
      "0.00058925204\n",
      "0.0\n",
      "0.0\n",
      "0.00060695794\n",
      "0.0\n",
      "0.05332218\n",
      "0.0006413617\n",
      "0.02603336\n",
      "0.0\n",
      "0.00070616225\n",
      "0.000749627\n",
      "0.009573179\n",
      "0.0\n",
      "0.00011269953\n",
      "0.0\n",
      "0.0026433542\n",
      "0.0\n",
      "0.0007201927\n",
      "0.0017143796\n",
      "0.00031279566\n",
      "0.007918766\n",
      "0.0012859488\n",
      "0.0028240671\n",
      "0.0033601357\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007192019\n",
      "0.0069280355\n",
      "0.01046393\n",
      "0.00077605055\n",
      "0.0004629578\n",
      "0.010624901\n",
      "0.00026987016\n",
      "0.0026531827\n",
      "0.0034609707\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0059709544\n",
      "0.00973151\n",
      "0.0012298452\n",
      "0.0016492712\n",
      "0.0019182819\n",
      "0.00027951674\n",
      "0.0055644535\n",
      "0.037299097\n",
      "0.0030067752\n",
      "0.009341108\n",
      "0.017859902\n",
      "0.00501658\n",
      "0.0002933893\n",
      "2.4258443e-06\n",
      "0.00010482232\n",
      "0.0018304238\n",
      "7.3360454e-05\n",
      "0.0\n",
      "0.0024455297\n",
      "0.0011807116\n",
      "0.0027174777\n",
      "0.0036646307\n",
      "0.086221226\n",
      "0.008805658\n",
      "0.06921901\n",
      "1.814043e-06\n",
      "0.004947708\n",
      "0.011724436\n",
      "0.0036911608\n",
      "0.0005525638\n",
      "0.0016282857\n",
      "0.0008829174\n",
      "0.012999499\n",
      "0.0024843682\n",
      "0.012455383\n",
      "0.00067465723\n",
      "0.0026971465\n",
      "0.00417585\n",
      "0.0005495484\n",
      "4.6449113e-05\n",
      "0.005094014\n",
      "0.0004933127\n",
      "0.00036868165\n",
      "0.026511788\n",
      "0.009860636\n",
      "0.00041136917\n",
      "0.0016140337\n",
      "0.0\n",
      "0.0016400869\n",
      "0.069625616\n",
      "0.015991848\n",
      "0.0010771008\n",
      "0.00033938023\n",
      "0.0\n",
      "0.001682218\n",
      "0.00028967203\n",
      "0.0\n",
      "0.001367364\n",
      "0.0010309228\n",
      "0.0\n",
      "0.0\n",
      "0.010632386\n",
      "0.0\n",
      "0.0034050625\n",
      "0.01920866\n",
      "0.0\n",
      "0.0008226877\n",
      "0.0045203445\n",
      "0.0\n",
      "0.00019729318\n",
      "0.0012674966\n",
      "0.00086241734\n",
      "0.006221738\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.578947  0.647059  0.611111  0.632184  0.591398   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.375505  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:06:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 80.316 seconds\n",
      "Cross-validation score: 0.6154303715019898\n",
      "Test score: 0.6493506493506493\n",
      "Best Hyperparameters: {}\n",
      "0.0015204615\n",
      "0.002070643\n",
      "0.2254147\n",
      "0.001735025\n",
      "0.050262693\n",
      "0.001097385\n",
      "0.0004989704\n",
      "0.0011769417\n",
      "0.0010645852\n",
      "0.0006108372\n",
      "0.0121666845\n",
      "0.0042089433\n",
      "0.0015992457\n",
      "0.0\n",
      "0.0002903612\n",
      "0.0\n",
      "0.018313525\n",
      "0.00036048502\n",
      "0.0\n",
      "0.009293882\n",
      "0.00044154082\n",
      "0.0011766889\n",
      "0.007933915\n",
      "0.0024638237\n",
      "0.0002332384\n",
      "0.0\n",
      "0.0\n",
      "0.00051279995\n",
      "0.002076668\n",
      "0.008658324\n",
      "0.00015559945\n",
      "0.0028827996\n",
      "0.00093853753\n",
      "0.016504394\n",
      "0.006153898\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007841974\n",
      "0.02665904\n",
      "0.0068312725\n",
      "0.0008741092\n",
      "0.0016842465\n",
      "0.008648407\n",
      "0.0019005515\n",
      "0.0023732842\n",
      "0.0048235646\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.000638522\n",
      "0.00096652325\n",
      "0.0005432927\n",
      "0.0019982515\n",
      "0.0\n",
      "0.001340125\n",
      "0.024243379\n",
      "0.0041374844\n",
      "0.00051431544\n",
      "0.017821845\n",
      "0.013326764\n",
      "0.0028317426\n",
      "0.0011523546\n",
      "3.0188856e-05\n",
      "0.0016415184\n",
      "0.008382771\n",
      "0.0008220101\n",
      "0.0037331867\n",
      "0.0025760925\n",
      "0.0014042596\n",
      "0.0031110938\n",
      "0.0158297\n",
      "0.10453844\n",
      "0.002763404\n",
      "0.00028956684\n",
      "0.00013986528\n",
      "0.0026835697\n",
      "0.0018395451\n",
      "0.008391488\n",
      "0.002573631\n",
      "5.5226097e-05\n",
      "0.0074220626\n",
      "0.02185163\n",
      "0.0034273986\n",
      "0.07081032\n",
      "0.010700137\n",
      "0.0029416848\n",
      "0.0016550041\n",
      "0.00036064466\n",
      "0.003302696\n",
      "0.0013918671\n",
      "0.0\n",
      "0.00016500338\n",
      "0.024924014\n",
      "0.00069558783\n",
      "0.00029049185\n",
      "0.0034627223\n",
      "0.0\n",
      "0.0056835394\n",
      "0.052731045\n",
      "0.0039709914\n",
      "0.0\n",
      "0.00014413218\n",
      "0.0\n",
      "0.0047446396\n",
      "0.0021604188\n",
      "0.0\n",
      "0.0017269478\n",
      "0.0014708552\n",
      "0.0\n",
      "0.0064554256\n",
      "0.0121143125\n",
      "0.0\n",
      "0.004734475\n",
      "0.022482192\n",
      "0.0\n",
      "0.0002528306\n",
      "0.00055269233\n",
      "0.0\n",
      "0.0008166371\n",
      "0.02509046\n",
      "0.0004880835\n",
      "0.027204808\n",
      "   Accuracy  Precision    Recall     F1       F2      F0.5  Average Precision\n",
      "0  0.998216   0.666667  0.588235  0.625  0.60241  0.649351           0.393198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:07:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 73.851 seconds\n",
      "Cross-validation score: 0.6009620941111166\n",
      "Test score: 0.4273504273504274\n",
      "Best Hyperparameters: {}\n",
      "0.009572202\n",
      "0.027510963\n",
      "0.25003082\n",
      "0.00050363946\n",
      "0.012198027\n",
      "0.0015632556\n",
      "0.0014010732\n",
      "6.3530366e-05\n",
      "0.00047150886\n",
      "0.0\n",
      "0.0043096193\n",
      "0.005026406\n",
      "0.0\n",
      "0.0\n",
      "0.0029523498\n",
      "0.0\n",
      "0.00019587816\n",
      "0.0002634987\n",
      "0.0\n",
      "0.0010479088\n",
      "0.0014252953\n",
      "0.00041135002\n",
      "0.004297981\n",
      "0.028442422\n",
      "2.015454e-05\n",
      "0.0\n",
      "0.0056637344\n",
      "0.00020750305\n",
      "4.149613e-05\n",
      "0.0043624854\n",
      "0.0002669072\n",
      "0.00018082513\n",
      "0.0023296897\n",
      "0.0014806073\n",
      "0.0012401992\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.003035763\n",
      "0.015756935\n",
      "0.0014684096\n",
      "0.00056645955\n",
      "9.0077076e-05\n",
      "0.009154644\n",
      "0.0112115145\n",
      "0.00039041083\n",
      "0.015805967\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00078892236\n",
      "0.00029493074\n",
      "0.0006811767\n",
      "0.003689894\n",
      "0.0013436703\n",
      "0.0\n",
      "0.007676031\n",
      "0.01289262\n",
      "0.0009256215\n",
      "0.01098291\n",
      "0.009030039\n",
      "0.047328293\n",
      "0.0005832756\n",
      "4.6492834e-05\n",
      "0.0076490496\n",
      "0.0\n",
      "0.00015729383\n",
      "0.0\n",
      "0.0006731508\n",
      "0.0004319926\n",
      "0.0010871968\n",
      "0.0072202245\n",
      "0.08443\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0010258268\n",
      "4.2093317e-05\n",
      "0.0005680508\n",
      "0.0014015777\n",
      "0.0\n",
      "0.024202317\n",
      "0.031620346\n",
      "0.00035354935\n",
      "0.10818252\n",
      "0.0010458672\n",
      "0.0048091025\n",
      "0.0006885162\n",
      "0.00043393573\n",
      "0.0\n",
      "0.0009212218\n",
      "0.0\n",
      "0.000681725\n",
      "0.016193887\n",
      "0.0011811075\n",
      "0.0003488769\n",
      "0.0426011\n",
      "0.0\n",
      "0.0019928298\n",
      "0.020498713\n",
      "0.021303141\n",
      "0.0\n",
      "0.0004751591\n",
      "0.0\n",
      "0.0048885457\n",
      "0.0016831541\n",
      "0.0\n",
      "0.0\n",
      "0.00062414847\n",
      "0.0\n",
      "0.01720716\n",
      "0.011252727\n",
      "0.0\n",
      "0.0012865423\n",
      "0.023377117\n",
      "0.0\n",
      "0.0004135131\n",
      "0.004978277\n",
      "0.0\n",
      "0.0068688802\n",
      "0.00036417905\n",
      "0.0016627248\n",
      "0.021947334\n",
      "   Accuracy  Precision    Recall       F1        F2     F0.5  \\\n",
      "0  0.996729        0.4  0.588235  0.47619  0.537634  0.42735   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.236335  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:09:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 75.967 seconds\n",
      "Cross-validation score: 0.6724326420837334\n",
      "Test score: 0.5056179775280899\n",
      "Best Hyperparameters: {}\n",
      "0.002237188\n",
      "0.0018154973\n",
      "0.22287904\n",
      "0.0054351473\n",
      "0.034797348\n",
      "0.016942678\n",
      "0.010361248\n",
      "0.0\n",
      "0.00020000442\n",
      "0.0010334322\n",
      "0.022219844\n",
      "0.010271702\n",
      "0.0\n",
      "0.0\n",
      "0.00084605505\n",
      "0.0\n",
      "0.008422156\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.001045025\n",
      "0.0058092317\n",
      "0.006154767\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0016704783\n",
      "0.0\n",
      "0.013811012\n",
      "0.00028497117\n",
      "0.0062507554\n",
      "0.00072763354\n",
      "0.0018704954\n",
      "0.0012418822\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00068764965\n",
      "0.031602032\n",
      "0.009451743\n",
      "0.00012875115\n",
      "0.006967706\n",
      "0.013495125\n",
      "0.00029146485\n",
      "0.0\n",
      "0.0013011765\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0011559738\n",
      "0.027032923\n",
      "0.00035334387\n",
      "0.0\n",
      "0.00095807033\n",
      "0.0\n",
      "0.021671465\n",
      "0.0013060451\n",
      "0.0011124548\n",
      "0.0068882424\n",
      "0.027619107\n",
      "0.005692229\n",
      "0.05170929\n",
      "2.9954058e-06\n",
      "0.0016354524\n",
      "0.0\n",
      "3.956565e-05\n",
      "0.0\n",
      "0.0\n",
      "0.002018419\n",
      "0.008315313\n",
      "0.0\n",
      "0.09404614\n",
      "0.0\n",
      "0.0054863445\n",
      "0.0\n",
      "0.0\n",
      "0.004768031\n",
      "0.0023439804\n",
      "0.0008326727\n",
      "3.836862e-05\n",
      "0.00077668804\n",
      "0.026653215\n",
      "0.028324684\n",
      "0.102872424\n",
      "0.015751632\n",
      "0.00049504766\n",
      "0.0010645201\n",
      "0.0004869882\n",
      "5.8205973e-05\n",
      "0.00084340724\n",
      "0.0\n",
      "0.0017525026\n",
      "0.019606749\n",
      "0.000265581\n",
      "0.0011844278\n",
      "0.0007892503\n",
      "0.0\n",
      "0.0020780037\n",
      "0.036976248\n",
      "0.0017944338\n",
      "0.0\n",
      "0.011695883\n",
      "0.0\n",
      "0.003596457\n",
      "0.00043978062\n",
      "0.0\n",
      "0.0\n",
      "0.0019184786\n",
      "0.0\n",
      "0.003367653\n",
      "0.014578969\n",
      "0.0\n",
      "0.0013719809\n",
      "0.010482927\n",
      "0.0\n",
      "0.00039977976\n",
      "0.00029691233\n",
      "0.0\n",
      "0.00012050151\n",
      "0.0024433061\n",
      "0.0003000144\n",
      "0.0019336364\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997472        0.5  0.529412  0.514286  0.523256  0.505618   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.265895  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:10:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 84.868 seconds\n",
      "Cross-validation score: 0.5416186767200741\n",
      "Test score: 0.5504587155963303\n",
      "Best Hyperparameters: {}\n",
      "0.0016603324\n",
      "0.06614635\n",
      "0.16997223\n",
      "0.0019122217\n",
      "0.03219873\n",
      "0.019446258\n",
      "0.00014807962\n",
      "0.00047328914\n",
      "0.0004267753\n",
      "0.0006982798\n",
      "0.009537077\n",
      "0.0\n",
      "3.2729768e-05\n",
      "0.0\n",
      "0.0034862969\n",
      "0.0\n",
      "0.013215916\n",
      "0.00034034278\n",
      "0.00027665508\n",
      "0.0\n",
      "0.0002933652\n",
      "0.0012488447\n",
      "0.0015816769\n",
      "0.0061528883\n",
      "0.00012566734\n",
      "0.00193709\n",
      "0.00039996504\n",
      "0.00035551653\n",
      "0.00010278293\n",
      "0.01565323\n",
      "0.00028899405\n",
      "0.0010107585\n",
      "0.0057213674\n",
      "0.0033022242\n",
      "0.0085585965\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.009560548\n",
      "0.02304669\n",
      "0.0054062516\n",
      "0.01165854\n",
      "0.0003538951\n",
      "0.013644416\n",
      "0.002242909\n",
      "0.0028945308\n",
      "0.0069798334\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0014801979\n",
      "0.0028100023\n",
      "0.00050681556\n",
      "0.00042719467\n",
      "0.0\n",
      "0.002827364\n",
      "0.016085641\n",
      "0.008224918\n",
      "0.0010666095\n",
      "0.011860939\n",
      "0.016589664\n",
      "0.0075582615\n",
      "9.597561e-05\n",
      "0.00023120311\n",
      "0.0013412634\n",
      "4.960333e-05\n",
      "0.0031204598\n",
      "0.00022919445\n",
      "0.016033426\n",
      "0.0058594444\n",
      "0.004526321\n",
      "0.00030800467\n",
      "0.102847576\n",
      "0.0\n",
      "0.009406996\n",
      "0.00014257879\n",
      "0.002311039\n",
      "0.010818187\n",
      "0.005257856\n",
      "0.00023070938\n",
      "0.0020596904\n",
      "0.009027431\n",
      "0.031897742\n",
      "0.0066948617\n",
      "0.0415043\n",
      "0.034430884\n",
      "0.0007290734\n",
      "0.0\n",
      "0.00014874058\n",
      "8.8953396e-07\n",
      "0.004370279\n",
      "0.0\n",
      "0.003410302\n",
      "0.021970827\n",
      "0.0\n",
      "0.00032520964\n",
      "0.0135039175\n",
      "0.0\n",
      "0.006102368\n",
      "0.05832184\n",
      "0.003180816\n",
      "0.0\n",
      "0.0011335798\n",
      "0.0\n",
      "0.00090595376\n",
      "0.00041302567\n",
      "0.0\n",
      "0.0028231542\n",
      "0.007925934\n",
      "0.0\n",
      "1.41546925e-05\n",
      "0.008509211\n",
      "0.0\n",
      "0.0027967743\n",
      "0.029141746\n",
      "0.0\n",
      "0.00081848784\n",
      "0.003739211\n",
      "0.0\n",
      "0.010006151\n",
      "0.017453423\n",
      "0.0004670605\n",
      "0.0014334283\n",
      "   Accuracy  Precision    Recall   F1        F2      F0.5  Average Precision\n",
      "0  0.997621   0.521739  0.705882  0.6  0.659341  0.550459            0.36903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:11:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 75.099 seconds\n",
      "Cross-validation score: 0.5503072031537847\n",
      "Test score: 0.6989247311827957\n",
      "Best Hyperparameters: {}\n",
      "0.010259512\n",
      "0.08761982\n",
      "0.1617732\n",
      "0.003341831\n",
      "0.007909393\n",
      "0.0032957196\n",
      "0.003171781\n",
      "0.0\n",
      "0.00077006547\n",
      "0.00080531114\n",
      "0.002597054\n",
      "0.09725063\n",
      "0.0\n",
      "0.0\n",
      "0.00028978664\n",
      "0.0\n",
      "0.0008544955\n",
      "9.023912e-05\n",
      "7.134908e-05\n",
      "0.0\n",
      "0.0\n",
      "1.1995362e-05\n",
      "0.0026899078\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0028426757\n",
      "0.0004486917\n",
      "0.00285734\n",
      "0.0011513083\n",
      "0.000225476\n",
      "0.0043412847\n",
      "9.500647e-05\n",
      "0.0026402194\n",
      "0.008626127\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0023926347\n",
      "0.009276496\n",
      "0.004661477\n",
      "0.0005271946\n",
      "0.0007527018\n",
      "0.004724299\n",
      "0.000100869205\n",
      "0.00044489806\n",
      "0.0036515142\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0006913225\n",
      "0.00086135993\n",
      "0.0009241714\n",
      "0.00015551587\n",
      "0.0\n",
      "0.0\n",
      "0.009566794\n",
      "0.000569408\n",
      "0.00068390026\n",
      "0.0073024957\n",
      "0.01016526\n",
      "0.0016356055\n",
      "0.0001292808\n",
      "0.0002645203\n",
      "0.0052591064\n",
      "0.00059615955\n",
      "0.0047210655\n",
      "0.0\n",
      "0.0010244976\n",
      "0.00036367617\n",
      "0.04237001\n",
      "0.000115207804\n",
      "0.11262799\n",
      "0.0058656815\n",
      "0.04894544\n",
      "0.0\n",
      "0.0007846427\n",
      "0.004929011\n",
      "0.0024358255\n",
      "4.6093213e-05\n",
      "0.00026041328\n",
      "0.13052425\n",
      "0.00506519\n",
      "0.00033413712\n",
      "0.0064717904\n",
      "2.7988162e-05\n",
      "0.0020479506\n",
      "0.000186537\n",
      "0.0009428338\n",
      "0.0\n",
      "0.0021401267\n",
      "0.0\n",
      "4.9248072e-05\n",
      "0.035688777\n",
      "0.0018763308\n",
      "0.0\n",
      "0.013158222\n",
      "0.0\n",
      "0.0024849887\n",
      "0.021434309\n",
      "0.010789597\n",
      "0.0001189575\n",
      "0.00054578116\n",
      "0.0\n",
      "0.0022801848\n",
      "0.001090564\n",
      "0.0\n",
      "0.02858261\n",
      "0.0002073182\n",
      "0.0\n",
      "0.0015088173\n",
      "0.017489843\n",
      "0.0\n",
      "0.00014178279\n",
      "0.011283882\n",
      "0.0\n",
      "3.006162e-05\n",
      "0.003137186\n",
      "0.0\n",
      "0.00021767471\n",
      "0.00026796648\n",
      "0.0006019804\n",
      "0.0034163878\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998513   0.684211  0.764706  0.722222  0.747126  0.698925   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.523815  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:13:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 72.560 seconds\n",
      "Cross-validation score: 0.5935297898385666\n",
      "Test score: 0.7216494845360825\n",
      "Best Hyperparameters: {}\n",
      "0.0022126783\n",
      "0.0031731003\n",
      "0.22379866\n",
      "0.0030227746\n",
      "0.04306084\n",
      "0.00015058866\n",
      "0.009007912\n",
      "0.00057745515\n",
      "0.0003278457\n",
      "0.014257455\n",
      "0.013423407\n",
      "0.0\n",
      "0.00048478413\n",
      "0.0\n",
      "0.00018238547\n",
      "0.0\n",
      "1.4101418e-05\n",
      "0.001924094\n",
      "0.004605662\n",
      "0.022257145\n",
      "0.00013933712\n",
      "0.0008628025\n",
      "0.00188345\n",
      "0.010116259\n",
      "0.002632849\n",
      "0.0\n",
      "0.009891894\n",
      "0.0\n",
      "0.0016390206\n",
      "0.0004501188\n",
      "0.00068274693\n",
      "0.0018075233\n",
      "0.0006689532\n",
      "0.0006849698\n",
      "0.0018887683\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0048966943\n",
      "0.04690411\n",
      "0.0076286523\n",
      "0.00063675205\n",
      "0.0009574858\n",
      "0.0073812976\n",
      "0.0002861362\n",
      "0.0017582845\n",
      "0.015269781\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0020226296\n",
      "0.004133211\n",
      "0.001240473\n",
      "0.006291702\n",
      "0.0\n",
      "0.0\n",
      "0.00860642\n",
      "0.00013531251\n",
      "0.0008872339\n",
      "0.017977672\n",
      "0.0051524797\n",
      "0.010288917\n",
      "0.00054562825\n",
      "3.8107446e-05\n",
      "0.0025822525\n",
      "0.0\n",
      "2.9377223e-05\n",
      "0.0041859807\n",
      "0.0017198198\n",
      "0.0042891344\n",
      "0.0034445024\n",
      "0.0006353582\n",
      "0.092798814\n",
      "0.00430381\n",
      "0.027669901\n",
      "0.00045048204\n",
      "0.0007141943\n",
      "0.006832011\n",
      "0.0072492776\n",
      "0.008731904\n",
      "0.00058336166\n",
      "0.011301057\n",
      "0.030961392\n",
      "0.001718233\n",
      "0.032402564\n",
      "0.02389988\n",
      "0.001923047\n",
      "0.0035997862\n",
      "3.7178157e-05\n",
      "0.0\n",
      "0.00046963737\n",
      "0.0\n",
      "0.0012874652\n",
      "0.0313415\n",
      "0.0\n",
      "0.000476042\n",
      "0.0004762655\n",
      "0.0\n",
      "0.003567082\n",
      "0.062356077\n",
      "0.0015397051\n",
      "0.00082619156\n",
      "0.0031401378\n",
      "0.0\n",
      "0.03324113\n",
      "0.00024933927\n",
      "0.0\n",
      "0.00988686\n",
      "0.0\n",
      "0.0\n",
      "0.002809758\n",
      "0.010441658\n",
      "0.0\n",
      "0.0031551195\n",
      "0.026589708\n",
      "0.0\n",
      "0.003188822\n",
      "0.00076593575\n",
      "0.0\n",
      "0.0013667851\n",
      "0.0061921277\n",
      "0.0011453386\n",
      "0.004555468\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998662        0.7  0.823529  0.756757  0.795455  0.721649   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.576917  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 79.502 seconds\n",
      "Cross-validation score: 0.5438139600419588\n",
      "Test score: 0.5445544554455446\n",
      "Best Hyperparameters: {}\n",
      "0.012003975\n",
      "0.07758087\n",
      "0.14162757\n",
      "0.0022962824\n",
      "0.024608007\n",
      "0.05540096\n",
      "0.0006942403\n",
      "0.0006931269\n",
      "0.00036756223\n",
      "0.001185218\n",
      "0.008579361\n",
      "0.00036357658\n",
      "0.0\n",
      "0.0\n",
      "0.0025425346\n",
      "0.0\n",
      "0.02441805\n",
      "0.0\n",
      "0.058900278\n",
      "0.00013927562\n",
      "0.00033130666\n",
      "0.0011786881\n",
      "0.002510465\n",
      "0.00020823123\n",
      "0.0012421444\n",
      "0.00041236522\n",
      "0.008030395\n",
      "0.00027517352\n",
      "0.00033327896\n",
      "0.008138052\n",
      "0.00020391631\n",
      "0.00014138814\n",
      "0.0034843215\n",
      "0.013546665\n",
      "0.0033819606\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0036801193\n",
      "0.049721792\n",
      "0.0038669973\n",
      "0.0021132205\n",
      "4.3228567e-05\n",
      "0.0032363273\n",
      "0.0050057503\n",
      "0.0005204071\n",
      "0.0043120747\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0020223008\n",
      "0.0004663279\n",
      "0.00083350844\n",
      "0.0011768386\n",
      "0.0\n",
      "0.00082189846\n",
      "0.031048043\n",
      "0.0048075602\n",
      "0.00036467725\n",
      "0.005257846\n",
      "0.009061659\n",
      "0.0057135136\n",
      "0.011936455\n",
      "3.5775884e-05\n",
      "0.00074687466\n",
      "0.0009823036\n",
      "0.0\n",
      "0.0\n",
      "0.001461556\n",
      "0.0041199275\n",
      "0.011609779\n",
      "0.012366992\n",
      "0.08871429\n",
      "0.007407322\n",
      "0.027522804\n",
      "0.0\n",
      "0.0012401921\n",
      "0.0061702253\n",
      "0.0026140052\n",
      "0.0020484608\n",
      "0.0\n",
      "0.010536053\n",
      "0.024127971\n",
      "0.0025445337\n",
      "0.035851527\n",
      "0.0058884677\n",
      "0.00075839635\n",
      "1.2914444e-05\n",
      "0.0019866796\n",
      "0.00027175937\n",
      "0.01322556\n",
      "0.0\n",
      "0.0031749953\n",
      "0.01614723\n",
      "0.0012076127\n",
      "0.0018319738\n",
      "0.0002204688\n",
      "0.0\n",
      "0.0016496177\n",
      "0.027522946\n",
      "0.0032940796\n",
      "0.00046314488\n",
      "0.0012149698\n",
      "0.0\n",
      "0.0033575327\n",
      "0.0017543371\n",
      "0.0\n",
      "0.0015606789\n",
      "0.007068149\n",
      "0.0\n",
      "0.0\n",
      "0.014422424\n",
      "0.0\n",
      "0.007765058\n",
      "0.027824773\n",
      "0.0\n",
      "0.0016675388\n",
      "0.0020766677\n",
      "0.0\n",
      "0.0014401919\n",
      "0.0034984713\n",
      "0.004714247\n",
      "0.0030487813\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997621    0.52381  0.647059  0.578947  0.617978  0.544554   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.339828  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:15:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 76.095 seconds\n",
      "Cross-validation score: 0.6001211361285421\n",
      "Test score: 0.5913978494623656\n",
      "Best Hyperparameters: {}\n",
      "0.01271534\n",
      "0.059696488\n",
      "0.20260826\n",
      "0.0024187637\n",
      "0.014518472\n",
      "0.00057128107\n",
      "0.00025459556\n",
      "0.0007021923\n",
      "0.00048912835\n",
      "0.00053570356\n",
      "0.008312278\n",
      "0.00087710004\n",
      "0.0003592116\n",
      "0.0\n",
      "0.0014263658\n",
      "0.0\n",
      "0.00012867099\n",
      "0.0\n",
      "0.00015856078\n",
      "0.0001249821\n",
      "0.00036790757\n",
      "6.0983322e-05\n",
      "0.007293428\n",
      "0.0010849515\n",
      "0.0\n",
      "0.0\n",
      "0.0013068317\n",
      "0.0\n",
      "0.0010871657\n",
      "0.002057447\n",
      "0.00026718818\n",
      "0.0048394026\n",
      "0.0021377588\n",
      "0.0012006423\n",
      "0.010754737\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0016808765\n",
      "0.007907258\n",
      "0.0013781595\n",
      "0.0008915606\n",
      "0.0010810195\n",
      "0.0051517864\n",
      "0.0005371373\n",
      "0.028473178\n",
      "0.0035612301\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0016201665\n",
      "0.04101281\n",
      "0.00031505217\n",
      "0.0024128433\n",
      "0.0\n",
      "0.009826895\n",
      "0.0027634585\n",
      "0.0051629245\n",
      "0.0014921157\n",
      "0.00394059\n",
      "0.008921797\n",
      "0.0030961365\n",
      "0.00024987658\n",
      "0.0010056038\n",
      "0.0011039706\n",
      "0.0008202708\n",
      "0.003851954\n",
      "0.0004431272\n",
      "0.0001378263\n",
      "0.002989261\n",
      "0.0028464668\n",
      "0.0\n",
      "0.08047522\n",
      "0.0002847619\n",
      "0.0005228064\n",
      "0.0\n",
      "0.00822802\n",
      "0.0040281075\n",
      "0.0058014477\n",
      "0.000106262276\n",
      "0.032045238\n",
      "0.050870694\n",
      "0.06357526\n",
      "0.0011365898\n",
      "0.012446409\n",
      "0.0010105806\n",
      "0.006462037\n",
      "2.7461945e-05\n",
      "0.002115566\n",
      "0.0022936596\n",
      "0.09459476\n",
      "0.0\n",
      "0.008733585\n",
      "0.047798347\n",
      "0.002434829\n",
      "0.00056440185\n",
      "0.002273372\n",
      "0.0\n",
      "0.002330424\n",
      "0.018085591\n",
      "0.008215824\n",
      "0.000416515\n",
      "0.00020237434\n",
      "0.0\n",
      "0.002484565\n",
      "0.002203053\n",
      "0.0\n",
      "0.002211554\n",
      "0.0009333274\n",
      "0.0\n",
      "0.003492411\n",
      "0.022424286\n",
      "0.0\n",
      "0.0027555493\n",
      "0.01902491\n",
      "0.0\n",
      "0.0\n",
      "0.0013833761\n",
      "0.0\n",
      "0.0003369528\n",
      "0.00018853035\n",
      "0.00063605286\n",
      "0.0018140133\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.578947  0.647059  0.611111  0.632184  0.591398   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.375505  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:16:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 73.208 seconds\n",
      "Cross-validation score: 0.6180697861855272\n",
      "Test score: 0.617283950617284\n",
      "Best Hyperparameters: {}\n",
      "0.0021186436\n",
      "0.0051868265\n",
      "0.3217337\n",
      "0.0029012733\n",
      "0.03700033\n",
      "0.0047281897\n",
      "0.0064725317\n",
      "0.0008649174\n",
      "0.0\n",
      "0.0\n",
      "0.005439191\n",
      "0.00015352329\n",
      "0.0\n",
      "0.0\n",
      "0.003990892\n",
      "0.0\n",
      "0.025789078\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00066781335\n",
      "0.0036907853\n",
      "0.0019645381\n",
      "0.00036258908\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00040848795\n",
      "0.0004277252\n",
      "0.0019298263\n",
      "0.0005632981\n",
      "0.0015120709\n",
      "0.0017914169\n",
      "0.002782357\n",
      "0.00732244\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0014599863\n",
      "0.009808656\n",
      "0.0009949575\n",
      "0.003105742\n",
      "0.0014839814\n",
      "0.00080955157\n",
      "0.0012263886\n",
      "0.0031777867\n",
      "0.013028427\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0009571658\n",
      "0.005838793\n",
      "0.00034447826\n",
      "0.0008293964\n",
      "0.0003156524\n",
      "0.0002354401\n",
      "0.0026241788\n",
      "0.0011405207\n",
      "0.0012655864\n",
      "0.014432955\n",
      "0.0150807705\n",
      "0.0034920329\n",
      "0.00030304337\n",
      "0.0028352016\n",
      "0.0057754884\n",
      "0.0023218838\n",
      "0.00014689779\n",
      "0.0\n",
      "0.002305422\n",
      "0.00011855841\n",
      "0.006858527\n",
      "3.880263e-05\n",
      "0.13647251\n",
      "0.0035274252\n",
      "0.0\n",
      "0.0\n",
      "0.0011233065\n",
      "5.6480018e-05\n",
      "0.0004627349\n",
      "0.0035019806\n",
      "0.0\n",
      "0.09330252\n",
      "0.030898413\n",
      "0.00584514\n",
      "0.0015997691\n",
      "0.0031868853\n",
      "0.0037330335\n",
      "1.9679635e-05\n",
      "0.0010426282\n",
      "0.0\n",
      "0.0036728294\n",
      "0.0\n",
      "0.0014630712\n",
      "0.045779385\n",
      "0.0\n",
      "0.00076584815\n",
      "0.0008802916\n",
      "0.0\n",
      "0.007449732\n",
      "0.040202864\n",
      "0.009655881\n",
      "0.0003045866\n",
      "0.001940702\n",
      "0.0\n",
      "0.001729596\n",
      "0.0004369085\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00022795204\n",
      "0.018835392\n",
      "0.0\n",
      "0.00012742743\n",
      "0.0069604306\n",
      "0.0\n",
      "9.1708636e-05\n",
      "0.0010049846\n",
      "0.0\n",
      "0.0010865738\n",
      "0.02975177\n",
      "0.00046490083\n",
      "0.00023587806\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998067      0.625  0.588235  0.606061  0.595238  0.617284   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.368688  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:18:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 71.115 seconds\n",
      "Cross-validation score: 0.6045473244692521\n",
      "Test score: 0.7246376811594203\n",
      "Best Hyperparameters: {}\n",
      "0.0201061\n",
      "0.09006511\n",
      "0.18653275\n",
      "0.00090406946\n",
      "0.027796352\n",
      "0.00028968998\n",
      "0.0\n",
      "0.0010807955\n",
      "6.197773e-05\n",
      "0.0025156764\n",
      "0.004447903\n",
      "0.0017585644\n",
      "0.0\n",
      "0.0\n",
      "0.0033844672\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.001095514\n",
      "0.00015999298\n",
      "0.000632558\n",
      "0.0\n",
      "0.0\n",
      "0.0070769563\n",
      "0.0\n",
      "0.00011310876\n",
      "0.0056459615\n",
      "0.0053319708\n",
      "0.0003567629\n",
      "0.0007211788\n",
      "0.0003376714\n",
      "0.005265153\n",
      "0.0029786178\n",
      "0.0013705549\n",
      "0.0038576848\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0091768\n",
      "0.011422136\n",
      "0.0008435619\n",
      "0.0017465438\n",
      "0.0013444163\n",
      "0.0025068051\n",
      "0.0002918174\n",
      "0.0016053424\n",
      "0.0034471762\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00047270578\n",
      "0.0033877348\n",
      "0.0004235939\n",
      "0.002200841\n",
      "0.0\n",
      "0.0002974764\n",
      "0.0050052153\n",
      "2.4823714e-05\n",
      "0.00048405284\n",
      "0.0042363964\n",
      "0.018327324\n",
      "0.003746841\n",
      "0.0071226247\n",
      "0.0\n",
      "0.0017828064\n",
      "0.0022803328\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00033878436\n",
      "0.0017005143\n",
      "0.0007845992\n",
      "0.12701166\n",
      "0.0\n",
      "0.000807288\n",
      "0.0\n",
      "0.0\n",
      "0.000569874\n",
      "0.0037743787\n",
      "0.00033522534\n",
      "0.0032130936\n",
      "0.09860341\n",
      "0.034557413\n",
      "0.0039939666\n",
      "0.007961219\n",
      "0.0021527023\n",
      "0.0016805426\n",
      "0.0010337769\n",
      "4.58879e-05\n",
      "0.0005885016\n",
      "0.059930164\n",
      "0.0\n",
      "0.007720303\n",
      "0.033793375\n",
      "0.0\n",
      "0.000918888\n",
      "0.00079185213\n",
      "0.0\n",
      "0.0050133737\n",
      "0.02861661\n",
      "0.005437188\n",
      "0.0002763634\n",
      "0.00039780993\n",
      "0.0\n",
      "0.0059582414\n",
      "0.00171092\n",
      "0.0\n",
      "0.024048122\n",
      "8.4229185e-05\n",
      "0.0\n",
      "0.004567626\n",
      "0.024776045\n",
      "0.0\n",
      "0.0023576224\n",
      "0.0152111575\n",
      "0.0\n",
      "8.527327e-05\n",
      "0.0004880417\n",
      "0.0\n",
      "0.00044391077\n",
      "0.02866072\n",
      "0.0011223474\n",
      "0.002372377\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998513   0.769231  0.588235  0.666667  0.617284  0.724638   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.453529  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:19:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 74.009 seconds\n",
      "Cross-validation score: 0.6304716935345338\n",
      "Test score: 0.5963302752293578\n",
      "Best Hyperparameters: {}\n",
      "0.014278718\n",
      "0.017132945\n",
      "0.23936185\n",
      "0.003701551\n",
      "0.039809197\n",
      "0.03153452\n",
      "0.00029720028\n",
      "0.0006336169\n",
      "0.002260851\n",
      "0.0024607563\n",
      "0.009996338\n",
      "0.003002823\n",
      "0.0\n",
      "0.0\n",
      "0.00022233966\n",
      "0.0\n",
      "0.0020548243\n",
      "0.00016028214\n",
      "0.0\n",
      "0.0\n",
      "0.00029542184\n",
      "0.00046683216\n",
      "0.004049914\n",
      "0.0031137804\n",
      "0.0062408266\n",
      "0.00055646687\n",
      "0.019349566\n",
      "0.0001924129\n",
      "0.00027519104\n",
      "0.0076493584\n",
      "0.00023476966\n",
      "0.0029535454\n",
      "0.00018760448\n",
      "0.003956624\n",
      "0.007158655\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0062746066\n",
      "0.007534891\n",
      "0.012132854\n",
      "0.0007853113\n",
      "0.0007868563\n",
      "0.00072181894\n",
      "0.0030266643\n",
      "0.0012141888\n",
      "0.004141342\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00084908516\n",
      "0.002961426\n",
      "0.0008998189\n",
      "3.0513822e-05\n",
      "0.0\n",
      "0.0\n",
      "0.004224354\n",
      "0.000444389\n",
      "0.000502671\n",
      "0.014772495\n",
      "0.030304706\n",
      "0.0010743819\n",
      "0.0005264058\n",
      "0.00025512007\n",
      "0.0021888483\n",
      "0.00054828037\n",
      "0.0001280907\n",
      "0.0012355379\n",
      "0.008633166\n",
      "0.003390112\n",
      "0.010796065\n",
      "0.013394287\n",
      "0.08419926\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.001160878\n",
      "0.00719671\n",
      "0.005281644\n",
      "0.00014455576\n",
      "3.6777466e-05\n",
      "5.9320617e-05\n",
      "0.02378561\n",
      "0.0010124297\n",
      "0.039212722\n",
      "0.03963171\n",
      "0.00040068367\n",
      "0.0\n",
      "0.000116085335\n",
      "0.0\n",
      "0.058380757\n",
      "0.0\n",
      "0.0015431104\n",
      "0.03069299\n",
      "0.0\n",
      "0.0004782611\n",
      "0.009110276\n",
      "0.00010043165\n",
      "0.0034773895\n",
      "0.045601685\n",
      "0.009028003\n",
      "0.0\n",
      "0.0032755595\n",
      "0.0\n",
      "0.0015734097\n",
      "0.0004527459\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0038644306\n",
      "0.012904473\n",
      "0.0\n",
      "0.0025363949\n",
      "0.022948459\n",
      "0.0\n",
      "0.00054725574\n",
      "0.0063027455\n",
      "0.0\n",
      "9.665197e-05\n",
      "0.018537387\n",
      "0.0004583183\n",
      "0.008483789\n",
      "   Accuracy  Precision    Recall    F1        F2     F0.5  Average Precision\n",
      "0  0.997919   0.565217  0.764706  0.65  0.714286  0.59633            0.43282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:20:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 75.168 seconds\n",
      "Cross-validation score: 0.6076217670876567\n",
      "Test score: 0.5376344086021505\n",
      "Best Hyperparameters: {}\n",
      "0.0030352566\n",
      "0.010070903\n",
      "0.2432996\n",
      "0.0012891627\n",
      "0.08662259\n",
      "0.0001496475\n",
      "0.0\n",
      "0.0041805618\n",
      "0.00010269801\n",
      "0.00094821333\n",
      "0.0073870462\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.002284176\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.03238801\n",
      "0.00030593728\n",
      "0.00066947774\n",
      "6.5482805e-06\n",
      "0.0012818516\n",
      "0.009183731\n",
      "3.12095e-05\n",
      "0.0013807839\n",
      "0.0\n",
      "0.000104346385\n",
      "0.0021419744\n",
      "0.0022892565\n",
      "0.0\n",
      "0.0021458766\n",
      "0.0011242686\n",
      "0.00046719034\n",
      "0.0022736946\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0029647825\n",
      "0.031343076\n",
      "0.0054422677\n",
      "0.02770538\n",
      "0.0014600953\n",
      "0.0071571227\n",
      "0.003964562\n",
      "5.87434e-05\n",
      "0.0027849372\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00094722206\n",
      "0.010506115\n",
      "0.00025090072\n",
      "0.0012041028\n",
      "0.0018557621\n",
      "0.0\n",
      "0.008629756\n",
      "0.00023231196\n",
      "0.0009041259\n",
      "0.011431349\n",
      "0.006563974\n",
      "0.00238051\n",
      "0.0030840696\n",
      "0.0007093136\n",
      "0.0031994646\n",
      "0.0006581854\n",
      "0.0\n",
      "0.0\n",
      "0.0003219699\n",
      "0.05963928\n",
      "0.017129064\n",
      "3.1765354e-05\n",
      "0.020174246\n",
      "0.0025718128\n",
      "0.056902613\n",
      "0.0\n",
      "0.002239493\n",
      "0.007889677\n",
      "0.0013862035\n",
      "0.000605461\n",
      "0.00020950758\n",
      "0.008389215\n",
      "0.0077820923\n",
      "0.0058595478\n",
      "0.028842892\n",
      "5.629826e-05\n",
      "0.0008052559\n",
      "0.00017000361\n",
      "0.0005526391\n",
      "9.394186e-06\n",
      "0.0027037812\n",
      "0.0\n",
      "0.015538153\n",
      "0.019476851\n",
      "0.0029555205\n",
      "0.00079553423\n",
      "0.008158303\n",
      "0.00011919481\n",
      "0.002023257\n",
      "0.02535663\n",
      "0.0021440142\n",
      "7.3816176e-05\n",
      "0.0012447451\n",
      "0.0\n",
      "0.0013051537\n",
      "0.001382469\n",
      "0.0\n",
      "0.00518618\n",
      "0.035149086\n",
      "0.0\n",
      "0.019906165\n",
      "0.011562521\n",
      "0.0\n",
      "0.0021214604\n",
      "0.032860268\n",
      "0.0\n",
      "0.01250263\n",
      "0.006389775\n",
      "0.0\n",
      "0.0005680167\n",
      "0.0011521761\n",
      "0.014390736\n",
      "0.002763028\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997621   0.526316  0.588235  0.555556  0.574713  0.537634   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.310638  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:21:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 76.970 seconds\n",
      "Cross-validation score: 0.6712640046644917\n",
      "Test score: 0.6470588235294119\n",
      "Best Hyperparameters: {}\n",
      "0.0040629194\n",
      "0.004344365\n",
      "0.24529107\n",
      "0.00193271\n",
      "0.03765681\n",
      "0.026122471\n",
      "0.0059622694\n",
      "0.0\n",
      "0.0017230099\n",
      "0.0051557855\n",
      "0.010764417\n",
      "0.0021127977\n",
      "0.0019778786\n",
      "0.0\n",
      "0.002784751\n",
      "0.0\n",
      "0.017188337\n",
      "0.00013471556\n",
      "0.0071292925\n",
      "0.002338705\n",
      "0.0007340142\n",
      "0.00053238124\n",
      "0.002315831\n",
      "0.0032438184\n",
      "0.0001095947\n",
      "0.0\n",
      "0.0054024514\n",
      "0.00020802746\n",
      "0.0\n",
      "0.0024147148\n",
      "0.00020576952\n",
      "0.0017311871\n",
      "0.00046290227\n",
      "0.0013167536\n",
      "0.004993242\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0013885909\n",
      "0.009124509\n",
      "0.005912915\n",
      "0.0007158785\n",
      "0.001375153\n",
      "0.0064447057\n",
      "0.028952409\n",
      "0.0012166394\n",
      "0.0020699364\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0005611075\n",
      "0.00028252817\n",
      "0.001262672\n",
      "0.0053820703\n",
      "0.00034105827\n",
      "0.0\n",
      "0.010169614\n",
      "0.0016594826\n",
      "0.015795695\n",
      "0.009188554\n",
      "0.0134944115\n",
      "0.0038988534\n",
      "0.00018007924\n",
      "0.0\n",
      "0.0011316014\n",
      "2.8623155e-05\n",
      "6.0852028e-05\n",
      "0.002234758\n",
      "0.0006143771\n",
      "0.004474551\n",
      "0.0018656371\n",
      "0.0015907906\n",
      "0.10068023\n",
      "0.0\n",
      "0.00031997255\n",
      "0.0\n",
      "0.0\n",
      "0.009097466\n",
      "0.008626361\n",
      "0.0001787022\n",
      "0.0\n",
      "0.0069602947\n",
      "0.016845712\n",
      "0.13871266\n",
      "0.00421904\n",
      "0.0006838312\n",
      "0.0014169909\n",
      "3.141647e-05\n",
      "0.0011639013\n",
      "0.00014585438\n",
      "0.0021784361\n",
      "0.0\n",
      "0.00043215472\n",
      "0.022088323\n",
      "0.00015415269\n",
      "0.0013016692\n",
      "0.00020720955\n",
      "0.0\n",
      "0.007802194\n",
      "0.037744965\n",
      "0.0050571566\n",
      "0.00028147848\n",
      "0.0050085927\n",
      "0.0\n",
      "0.005590721\n",
      "0.00039207278\n",
      "0.0\n",
      "0.0017881565\n",
      "0.00048248708\n",
      "0.0\n",
      "0.0055954424\n",
      "0.015832875\n",
      "0.0\n",
      "0.004659208\n",
      "0.0061806734\n",
      "0.0\n",
      "4.680074e-05\n",
      "0.0076085962\n",
      "0.0\n",
      "0.0003235493\n",
      "0.0386818\n",
      "0.004933447\n",
      "0.004774337\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998216   0.647059  0.647059  0.647059  0.647059  0.647059   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.419577  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:23:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 77.156 seconds\n",
      "Cross-validation score: 0.6664895189082951\n",
      "Test score: 0.6435643564356436\n",
      "Best Hyperparameters: {}\n",
      "0.005217873\n",
      "0.050459377\n",
      "0.19001016\n",
      "0.0028607033\n",
      "0.010204397\n",
      "0.003198689\n",
      "0.00052309287\n",
      "0.00033121026\n",
      "0.0025572127\n",
      "0.00058264035\n",
      "0.014845127\n",
      "0.0036968384\n",
      "0.0\n",
      "0.0\n",
      "0.0016117785\n",
      "0.0\n",
      "0.0029085812\n",
      "2.608302e-05\n",
      "0.09315224\n",
      "0.021885836\n",
      "0.00015636969\n",
      "0.0\n",
      "0.0016192981\n",
      "0.016408566\n",
      "0.0\n",
      "0.0\n",
      "0.0018515603\n",
      "0.0051814117\n",
      "0.0030751938\n",
      "0.0063672517\n",
      "0.0004624521\n",
      "0.0039166734\n",
      "0.0033321418\n",
      "0.00041560363\n",
      "0.0042599905\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0012015974\n",
      "0.029232547\n",
      "0.00622613\n",
      "0.0017171628\n",
      "0.003285561\n",
      "0.016956354\n",
      "0.00037844363\n",
      "0.0019043359\n",
      "0.0051214495\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0005894075\n",
      "0.011562683\n",
      "0.00015112756\n",
      "0.0006919554\n",
      "0.014839642\n",
      "0.0003925859\n",
      "0.003321129\n",
      "0.0017875034\n",
      "0.00033939467\n",
      "0.012717132\n",
      "0.023706723\n",
      "0.004954646\n",
      "0.0001637773\n",
      "0.0013550522\n",
      "0.0003112737\n",
      "0.0075483345\n",
      "0.00034856595\n",
      "0.0070225983\n",
      "0.0018579881\n",
      "0.0016903164\n",
      "0.018474437\n",
      "0.017553432\n",
      "0.084044404\n",
      "0.0008766752\n",
      "0.000592998\n",
      "0.0\n",
      "0.0018297626\n",
      "0.007195005\n",
      "0.008741506\n",
      "0.0023768342\n",
      "0.00016575825\n",
      "0.003964397\n",
      "0.011983129\n",
      "0.005057829\n",
      "0.0033785067\n",
      "0.0109480955\n",
      "0.003370918\n",
      "0.0003653495\n",
      "0.004057624\n",
      "0.0012084144\n",
      "0.0024999194\n",
      "0.0\n",
      "0.004055702\n",
      "0.016271843\n",
      "0.00012615016\n",
      "0.0005945254\n",
      "0.041136466\n",
      "0.0\n",
      "0.0033821762\n",
      "0.06315469\n",
      "0.005317737\n",
      "4.69145e-05\n",
      "0.009721192\n",
      "0.0\n",
      "0.00036458156\n",
      "0.0057785204\n",
      "0.0\n",
      "0.001467689\n",
      "0.00052155176\n",
      "0.0\n",
      "0.0034030282\n",
      "0.009324087\n",
      "0.0\n",
      "0.0019945106\n",
      "0.011276392\n",
      "0.0\n",
      "0.0\n",
      "0.004561974\n",
      "0.0\n",
      "0.009664227\n",
      "0.00017624356\n",
      "0.0006406482\n",
      "0.0058403662\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998216   0.619048  0.764706  0.684211  0.730337  0.643564   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.473984  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:24:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 73.866 seconds\n",
      "Cross-validation score: 0.5712436923587172\n",
      "Test score: 0.5882352941176471\n",
      "Best Hyperparameters: {}\n",
      "0.008404211\n",
      "0.011018361\n",
      "0.29621798\n",
      "0.0030187257\n",
      "0.03890132\n",
      "0.016188303\n",
      "0.00029457678\n",
      "0.0010021189\n",
      "0.0\n",
      "0.012563985\n",
      "0.0093996525\n",
      "0.0\n",
      "0.0002549403\n",
      "0.0\n",
      "0.021263955\n",
      "0.0\n",
      "0.0015620568\n",
      "0.0005221344\n",
      "0.0\n",
      "0.0\n",
      "6.41512e-05\n",
      "0.0041543026\n",
      "0.0045177764\n",
      "0.0016943881\n",
      "2.6186895e-05\n",
      "0.0\n",
      "0.0047741975\n",
      "0.0044098017\n",
      "0.00089971366\n",
      "0.0069741583\n",
      "0.00047943572\n",
      "0.001182203\n",
      "0.00089573074\n",
      "0.0002434846\n",
      "0.008221881\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.011678865\n",
      "0.065442234\n",
      "0.0038696462\n",
      "0.0010128937\n",
      "0.0001359804\n",
      "0.00050231797\n",
      "0.00010747153\n",
      "0.0007424738\n",
      "0.0076806573\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0006234967\n",
      "0.029660847\n",
      "0.0010483856\n",
      "0.0041233627\n",
      "0.0\n",
      "0.00010351916\n",
      "0.0021276425\n",
      "0.00052966236\n",
      "0.00064061943\n",
      "0.0073045027\n",
      "0.0042875214\n",
      "0.0002593022\n",
      "0.0003716096\n",
      "0.0\n",
      "0.0015551588\n",
      "0.0021997588\n",
      "0.0033785298\n",
      "0.0\n",
      "0.0040270286\n",
      "0.0010357819\n",
      "0.01900604\n",
      "0.0066595147\n",
      "0.10786778\n",
      "0.0011268957\n",
      "0.002158058\n",
      "0.0\n",
      "0.004062296\n",
      "0.00067511224\n",
      "0.0002252465\n",
      "0.0\n",
      "0.00045970603\n",
      "0.013306827\n",
      "0.018144168\n",
      "0.008261308\n",
      "0.0062200404\n",
      "0.005983294\n",
      "0.007403361\n",
      "0.00030254677\n",
      "0.0026341898\n",
      "0.0012620923\n",
      "0.0022714194\n",
      "0.0\n",
      "0.0096985465\n",
      "0.025601909\n",
      "0.0009906292\n",
      "0.0\n",
      "0.0013421293\n",
      "6.85045e-05\n",
      "0.006140209\n",
      "0.0641938\n",
      "0.0078646345\n",
      "0.00061496877\n",
      "0.00047578552\n",
      "0.0\n",
      "0.0047786613\n",
      "0.00051233347\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00012007825\n",
      "0.017807648\n",
      "0.0\n",
      "0.0005404161\n",
      "0.026647072\n",
      "0.0\n",
      "0.0017148651\n",
      "0.0047908463\n",
      "0.0\n",
      "0.0009111597\n",
      "0.00040938513\n",
      "0.0029203515\n",
      "0.00022724844\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.588235  0.588235  0.588235  0.588235  0.588235   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.347061  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:25:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 76.443 seconds\n",
      "Cross-validation score: 0.5732325376075189\n",
      "Test score: 0.6741573033707865\n",
      "Best Hyperparameters: {}\n",
      "0.007136783\n",
      "0.036387216\n",
      "0.1833895\n",
      "0.0031521607\n",
      "0.021643534\n",
      "0.00029530682\n",
      "0.0\n",
      "0.00039751417\n",
      "0.0016808802\n",
      "0.00078576076\n",
      "0.009957535\n",
      "0.011851322\n",
      "0.00023275372\n",
      "0.0\n",
      "0.00017718435\n",
      "0.0\n",
      "0.001050402\n",
      "0.0\n",
      "0.00718787\n",
      "0.008641894\n",
      "0.0004852271\n",
      "0.00094732654\n",
      "0.0040162373\n",
      "0.0914372\n",
      "0.0005532378\n",
      "0.00017671076\n",
      "0.0027452118\n",
      "1.9620014e-05\n",
      "0.0007894893\n",
      "0.010449933\n",
      "0.0006025379\n",
      "0.0031876839\n",
      "0.0011120066\n",
      "0.00077807327\n",
      "0.0046475246\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0079350835\n",
      "0.0073777013\n",
      "0.0054700226\n",
      "0.00016548265\n",
      "0.00041581315\n",
      "0.0066328463\n",
      "0.0043366603\n",
      "0.00069208385\n",
      "0.017523937\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0017282555\n",
      "0.0027351235\n",
      "0.0006267444\n",
      "0.0008681521\n",
      "0.0\n",
      "0.0010428188\n",
      "0.0026377128\n",
      "0.004374887\n",
      "0.002394641\n",
      "0.020965876\n",
      "0.024121942\n",
      "0.008162025\n",
      "0.0010960384\n",
      "0.00036722433\n",
      "0.0029677474\n",
      "0.010145193\n",
      "0.0\n",
      "0.0005413031\n",
      "9.5842675e-05\n",
      "0.0006220111\n",
      "0.007102787\n",
      "0.0019139627\n",
      "0.06427269\n",
      "0.00070020143\n",
      "0.023677438\n",
      "0.0\n",
      "0.008324033\n",
      "0.0050693164\n",
      "0.0035652635\n",
      "2.2052052e-05\n",
      "0.0025638894\n",
      "0.011292523\n",
      "0.005315732\n",
      "0.0074564284\n",
      "0.051714614\n",
      "0.020455118\n",
      "0.0006189075\n",
      "0.00013912108\n",
      "0.0006193676\n",
      "0.0015389122\n",
      "0.0010618686\n",
      "0.0\n",
      "0.0027309046\n",
      "0.020297535\n",
      "0.0020841504\n",
      "0.0013672062\n",
      "0.033229597\n",
      "0.0\n",
      "0.0027030995\n",
      "0.028006878\n",
      "0.007854293\n",
      "0.00041329622\n",
      "0.0\n",
      "0.0\n",
      "0.0067038536\n",
      "0.0016235771\n",
      "0.0\n",
      "0.0029827314\n",
      "0.0009778345\n",
      "0.0\n",
      "0.009106429\n",
      "0.010223595\n",
      "0.0\n",
      "0.0033121475\n",
      "0.04341818\n",
      "0.0\n",
      "0.0014541245\n",
      "0.0036009992\n",
      "0.0\n",
      "0.0042009465\n",
      "0.039656907\n",
      "0.0004810083\n",
      "0.0041876626\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998365   0.666667  0.705882  0.685714  0.697674  0.674157   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.471332  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:26:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 70.909 seconds\n",
      "Cross-validation score: 0.6859651761848055\n",
      "Test score: 0.5376344086021505\n",
      "Best Hyperparameters: {}\n",
      "0.025760567\n",
      "0.051292058\n",
      "0.22227283\n",
      "0.004100933\n",
      "0.0030444004\n",
      "0.016149757\n",
      "0.0008471425\n",
      "0.0007766618\n",
      "0.0014279964\n",
      "0.0021356894\n",
      "0.012749274\n",
      "0.019134304\n",
      "0.0\n",
      "0.0\n",
      "0.06986746\n",
      "0.0\n",
      "0.0017068444\n",
      "9.282483e-05\n",
      "0.0058824415\n",
      "0.0\n",
      "0.0\n",
      "0.0002760616\n",
      "0.0065407977\n",
      "0.0017542646\n",
      "0.0052320603\n",
      "0.0\n",
      "0.0016889322\n",
      "0.0007976945\n",
      "0.0\n",
      "0.0015790259\n",
      "0.0002141722\n",
      "0.0028787614\n",
      "0.0024968705\n",
      "0.02670028\n",
      "0.00027806417\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0013432102\n",
      "0.04973367\n",
      "0.0015024036\n",
      "0.0007234935\n",
      "0.0047272155\n",
      "0.008006451\n",
      "0.0009834343\n",
      "0.009543271\n",
      "0.0061562457\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0023711761\n",
      "0.00012230422\n",
      "0.00021708736\n",
      "0.0040944694\n",
      "0.00016582602\n",
      "0.0016454622\n",
      "0.015970271\n",
      "0.023825556\n",
      "0.0014319412\n",
      "0.013101187\n",
      "0.017216992\n",
      "0.007695981\n",
      "8.006462e-05\n",
      "0.0\n",
      "0.00093494717\n",
      "0.000111355555\n",
      "0.0022522158\n",
      "0.0\n",
      "0.001994199\n",
      "0.06722402\n",
      "0.00022409282\n",
      "0.0\n",
      "0.03236111\n",
      "0.0\n",
      "0.0020959806\n",
      "0.0\n",
      "0.0\n",
      "0.009027406\n",
      "0.001036076\n",
      "0.011754071\n",
      "0.00017500967\n",
      "0.011715545\n",
      "0.011332838\n",
      "0.0029573913\n",
      "0.0432025\n",
      "0.00042202885\n",
      "0.0015798694\n",
      "0.0010368502\n",
      "0.0006668067\n",
      "0.0017194699\n",
      "0.02620421\n",
      "0.0\n",
      "0.0013638238\n",
      "0.015342626\n",
      "0.0002513148\n",
      "0.000109624394\n",
      "0.0006854343\n",
      "0.0\n",
      "0.003934569\n",
      "0.029196415\n",
      "0.0045469333\n",
      "0.00011628075\n",
      "0.00036872338\n",
      "0.0\n",
      "0.0006601245\n",
      "0.0007887593\n",
      "0.0\n",
      "0.0016295449\n",
      "0.0032986752\n",
      "0.0\n",
      "0.0\n",
      "0.013739788\n",
      "0.0\n",
      "0.004198061\n",
      "0.011777017\n",
      "0.0\n",
      "0.00031845574\n",
      "0.012076886\n",
      "0.0\n",
      "0.001190156\n",
      "0.00019815484\n",
      "0.0012945916\n",
      "0.0045501767\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997621   0.526316  0.588235  0.555556  0.574713  0.537634   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.310638  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:28:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 76.208 seconds\n",
      "Cross-validation score: 0.6103587120193922\n",
      "Test score: 0.5555555555555556\n",
      "Best Hyperparameters: {}\n",
      "0.024685778\n",
      "0.01961323\n",
      "0.23522587\n",
      "0.0061270585\n",
      "0.007276454\n",
      "0.0013509223\n",
      "0.0010345448\n",
      "0.0\n",
      "0.000106793705\n",
      "0.0\n",
      "0.004226381\n",
      "0.021718055\n",
      "0.00066364167\n",
      "0.0\n",
      "0.006807051\n",
      "0.0\n",
      "0.001130632\n",
      "0.00027843204\n",
      "0.0\n",
      "0.005385157\n",
      "0.00042734866\n",
      "0.0005251665\n",
      "0.010584143\n",
      "0.03519049\n",
      "0.0039640022\n",
      "0.0\n",
      "0.0\n",
      "0.002860298\n",
      "0.0038721913\n",
      "0.0015050548\n",
      "0.0006527509\n",
      "0.0009942411\n",
      "0.0025292612\n",
      "0.0015394419\n",
      "0.0021405546\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0050316937\n",
      "0.0061844555\n",
      "0.0045407177\n",
      "0.0008584611\n",
      "0.00035853923\n",
      "0.0034719408\n",
      "0.010942097\n",
      "0.00020200963\n",
      "0.016465468\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0014437014\n",
      "0.0005611383\n",
      "0.00026469777\n",
      "0.0012541793\n",
      "0.0\n",
      "0.0\n",
      "0.005389547\n",
      "0.0016490079\n",
      "0.00038590853\n",
      "0.012547754\n",
      "0.011277517\n",
      "0.0043957047\n",
      "0.00075345434\n",
      "0.00047672947\n",
      "0.0010420867\n",
      "0.025035193\n",
      "0.0017353208\n",
      "0.0025194248\n",
      "0.011945508\n",
      "0.0012750609\n",
      "0.009551226\n",
      "0.0012360811\n",
      "0.10590598\n",
      "0.0\n",
      "0.00082394376\n",
      "0.0\n",
      "0.0005245831\n",
      "0.01210334\n",
      "0.001540154\n",
      "0.00026541104\n",
      "0.0\n",
      "0.06819623\n",
      "0.0010265918\n",
      "0.0027818894\n",
      "0.00839663\n",
      "0.011723265\n",
      "0.014070517\n",
      "4.467527e-05\n",
      "1.7593075e-05\n",
      "0.00046536862\n",
      "0.02214288\n",
      "0.0\n",
      "0.00114051\n",
      "0.021076707\n",
      "0.003676624\n",
      "0.00010232512\n",
      "0.0017431545\n",
      "0.0\n",
      "0.004080489\n",
      "0.04697702\n",
      "0.014572621\n",
      "0.00011672344\n",
      "0.0009766007\n",
      "0.0\n",
      "0.0036801212\n",
      "0.0023769848\n",
      "0.0\n",
      "0.0036333671\n",
      "0.0\n",
      "0.0\n",
      "0.00017694976\n",
      "0.012607272\n",
      "0.0\n",
      "0.00066400226\n",
      "0.028308975\n",
      "0.0\n",
      "0.00016291343\n",
      "0.010831195\n",
      "0.0\n",
      "0.00046282331\n",
      "0.042574506\n",
      "0.00027831987\n",
      "0.004541179\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0   0.99777     0.5625  0.529412  0.545455  0.535714  0.555556   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.298984  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:29:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 81.015 seconds\n",
      "Cross-validation score: 0.6531091564099816\n",
      "Test score: 0.6451612903225806\n",
      "Best Hyperparameters: {}\n",
      "0.014358179\n",
      "0.005057474\n",
      "0.21696346\n",
      "0.006317914\n",
      "0.042102423\n",
      "0.000852579\n",
      "0.0027389852\n",
      "0.00038916708\n",
      "0.00025739172\n",
      "0.0029726631\n",
      "0.009589322\n",
      "0.0\n",
      "0.000567871\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.01853625\n",
      "0.0\n",
      "0.0\n",
      "0.00030651907\n",
      "0.00048466548\n",
      "0.00072652654\n",
      "0.0011194029\n",
      "0.0050505586\n",
      "0.0018025399\n",
      "0.0\n",
      "0.0\n",
      "0.00021435403\n",
      "0.005081787\n",
      "0.021788534\n",
      "0.0030644597\n",
      "0.002773443\n",
      "0.0030294713\n",
      "0.0049017537\n",
      "0.008418339\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0064621484\n",
      "0.020834507\n",
      "0.002937431\n",
      "0.0021230117\n",
      "2.2481674e-05\n",
      "0.00999051\n",
      "0.000743066\n",
      "0.0021905636\n",
      "0.00934172\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0010478082\n",
      "0.002226241\n",
      "0.0013522446\n",
      "0.00053680193\n",
      "0.0\n",
      "0.0\n",
      "0.0069895666\n",
      "0.040582906\n",
      "0.0016980538\n",
      "0.01902581\n",
      "0.0074058347\n",
      "0.0014940251\n",
      "0.00036745847\n",
      "0.00016802324\n",
      "0.0032184764\n",
      "0.0002787587\n",
      "0.00080203393\n",
      "0.003937557\n",
      "0.0040493924\n",
      "0.0026571443\n",
      "0.0018591335\n",
      "0.0011677286\n",
      "0.11791564\n",
      "0.0006462604\n",
      "0.0010665866\n",
      "0.0\n",
      "0.0015578347\n",
      "0.00051392964\n",
      "0.0056546037\n",
      "2.1062142e-05\n",
      "0.0\n",
      "0.014538547\n",
      "0.0200851\n",
      "0.00093477196\n",
      "0.016039692\n",
      "0.0034044497\n",
      "0.0055938666\n",
      "0.000105346364\n",
      "0.0\n",
      "0.0\n",
      "0.025245432\n",
      "0.00015065877\n",
      "0.005157786\n",
      "0.022747148\n",
      "0.0005069969\n",
      "0.000283899\n",
      "0.005355005\n",
      "0.0\n",
      "0.0050887614\n",
      "0.08586914\n",
      "0.010942883\n",
      "0.0030274398\n",
      "0.0015400752\n",
      "0.0\n",
      "0.014480861\n",
      "0.0036382668\n",
      "0.0\n",
      "0.0015391663\n",
      "0.0021363401\n",
      "0.0\n",
      "0.0025605196\n",
      "0.021238683\n",
      "0.0\n",
      "0.0011245265\n",
      "0.027268067\n",
      "0.0\n",
      "0.0014187419\n",
      "0.0001612036\n",
      "0.0\n",
      "0.00016746996\n",
      "0.02627118\n",
      "0.0040957904\n",
      "0.004929859\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998216   0.631579  0.705882  0.666667  0.689655  0.645161   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.446564  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:30:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 72.502 seconds\n",
      "Cross-validation score: 0.5878680626728298\n",
      "Test score: 0.5294117647058824\n",
      "Best Hyperparameters: {}\n",
      "0.001549965\n",
      "0.0014500745\n",
      "0.25236702\n",
      "0.007653078\n",
      "0.014990551\n",
      "0.0032216015\n",
      "0.006623512\n",
      "0.000351004\n",
      "0.0\n",
      "0.0\n",
      "0.007062249\n",
      "0.0017229313\n",
      "0.0061834888\n",
      "0.0\n",
      "5.8064557e-05\n",
      "0.0\n",
      "0.008009274\n",
      "0.0002324028\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0006441658\n",
      "0.00054976007\n",
      "0.033206373\n",
      "0.00095751765\n",
      "0.0\n",
      "0.0\n",
      "0.0001468915\n",
      "0.0064808936\n",
      "0.0065400326\n",
      "0.00034971358\n",
      "0.0025034002\n",
      "0.004766813\n",
      "0.0018335334\n",
      "0.0066875713\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.005374441\n",
      "0.04293162\n",
      "0.003147417\n",
      "0.0039580655\n",
      "0.00514771\n",
      "0.017310599\n",
      "7.021896e-05\n",
      "0.010101689\n",
      "0.020960452\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00197027\n",
      "0.0026419656\n",
      "0.00054537033\n",
      "0.00042105178\n",
      "0.0013458927\n",
      "0.0073627033\n",
      "0.0037853676\n",
      "0.0480387\n",
      "0.0054212636\n",
      "0.040607847\n",
      "0.010144542\n",
      "0.00994184\n",
      "0.00028553288\n",
      "0.0017209812\n",
      "0.031281725\n",
      "0.0041937805\n",
      "0.0044100676\n",
      "0.0\n",
      "0.00066463335\n",
      "0.002575653\n",
      "0.0025506378\n",
      "0.00026139524\n",
      "0.082429335\n",
      "0.0006102917\n",
      "0.0011713216\n",
      "0.0\n",
      "0.003064204\n",
      "0.0020643983\n",
      "0.0047228336\n",
      "0.0\n",
      "6.785265e-05\n",
      "0.011624227\n",
      "0.0015138746\n",
      "0.0021466564\n",
      "0.010982453\n",
      "0.00089854567\n",
      "0.0017143984\n",
      "0.00035366547\n",
      "0.001838503\n",
      "0.0020332215\n",
      "0.0002813123\n",
      "0.0\n",
      "0.00013850212\n",
      "0.018393587\n",
      "0.00080265274\n",
      "0.00024295234\n",
      "0.0013215379\n",
      "0.0\n",
      "0.0024653624\n",
      "0.05789052\n",
      "0.005138199\n",
      "0.00022535601\n",
      "8.104713e-05\n",
      "0.0\n",
      "0.0020272345\n",
      "0.0018926207\n",
      "0.0\n",
      "0.0015025786\n",
      "0.001009254\n",
      "0.0\n",
      "2.168589e-05\n",
      "0.015228544\n",
      "0.0\n",
      "0.0007784905\n",
      "0.061171163\n",
      "0.0\n",
      "0.00019499929\n",
      "0.0013339769\n",
      "0.0\n",
      "0.0072035617\n",
      "0.0010878888\n",
      "0.0005198949\n",
      "0.026495934\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997621   0.529412  0.529412  0.529412  0.529412  0.529412   \n",
      "\n",
      "   Average Precision  \n",
      "0           0.281466  \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "fhalf_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "\n",
    "fiftyfifty_xgboost_normalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized,\n",
    "                                                    labels_normalized,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels_normalized)\n",
    "\n",
    "\n",
    "    GXBoostPipeline = Pipeline(steps = [['smote', SMOTE(sampling_strategy = 0.5)],\n",
    "                                    ['under', RandomUnderSampler()],\n",
    "                                ['classifier', xgb.XGBClassifier(n_jobs=2)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    space['classifier__learning_rate'] = [0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60]\n",
    "    space['classifier__max_depth'] = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "    space['classifier__min_child_weight'] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    space['classifier__gamma'] = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    space['classifier__colsample_bytree'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    spaceEmpty = dict()\n",
    "\n",
    "    GXBoostSearch = RandomizedSearchCV(estimator = GXBoostPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring=fhalf_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedGXBoostModel = GXBoostSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    \n",
    "    cv_score = optimizedGXBoostModel.best_score_\n",
    "    test_score = optimizedGXBoostModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedGXBoostModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedGXBoostModel.best_estimator_._final_estimator.feature_importances_\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedGXBoostModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    print(new_performance_df)\n",
    "    fiftyfifty_xgboost_normalized_performance_df = pd.concat([fiftyfifty_xgboost_normalized_performance_df, new_performance_df])\n",
    "    \n",
    "\n",
    "fiftyfifty_xgboost_normalized_performance_df.to_csv(\"../data/05_model_output/fiftyfifty_xgboost_normalized_performance_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-bibliography",
   "metadata": {},
   "source": [
    "### 4.4.3 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-salem",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute best fit: 11.831 seconds\n",
      "Cross-validation score: 0.6717039845647655\n",
      "Test score: 0.5681818181818182\n",
      "Best Hyperparameters: {}\n",
      "5396.670615058392\n",
      "1799.7686098180711\n",
      "120045.10319454968\n",
      "134.11846401169896\n",
      "704.9035040140152\n",
      "10.366311930119991\n",
      "0.0\n",
      "10.069184593856335\n",
      "14.650080259889364\n",
      "11.029239892959595\n",
      "2622.099277164787\n",
      "133.50733575224876\n",
      "0.06914160028100014\n",
      "0.0\n",
      "387.67689675092697\n",
      "0.0\n",
      "460.6848460957408\n",
      "0.14550599455833435\n",
      "1.0003018900752068\n",
      "12.164654809981585\n",
      "0.5356176905333996\n",
      "13.354241758584976\n",
      "45.83915804326534\n",
      "21.719510078430176\n",
      "92.94408492743969\n",
      "17.228439807891846\n",
      "0.1174900010228157\n",
      "1.9347860738635063\n",
      "56.44881973415613\n",
      "34.66618651151657\n",
      "13.47803020477295\n",
      "408.2693593092263\n",
      "233.10002787411213\n",
      "331.83079332858324\n",
      "2042.7317341193557\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "426.89832520484924\n",
      "3252.0856094919145\n",
      "974.9881523400545\n",
      "32.51532655581832\n",
      "25.89369957894087\n",
      "591.4629293754697\n",
      "24.376262962818146\n",
      "1.755947008728981\n",
      "286.3863976188004\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "151.7824035063386\n",
      "2228.1085266321898\n",
      "253.7350911051035\n",
      "12.076774392277002\n",
      "0.0\n",
      "5.91786003112793\n",
      "124.40177170932293\n",
      "126.59469223022461\n",
      "22.9437198266387\n",
      "672.3564134575427\n",
      "1403.8233832195401\n",
      "148.69318820163608\n",
      "20.41566177457571\n",
      "15.742259085178375\n",
      "850.6605879738927\n",
      "10.336486905813217\n",
      "0.0\n",
      "248.39140294492245\n",
      "37.12136420607567\n",
      "302.2250205613673\n",
      "181.568949110806\n",
      "0.0\n",
      "14744.209797434509\n",
      "0.2568120062351227\n",
      "0.24342800676822662\n",
      "0.0\n",
      "55.854577049613\n",
      "137.614442974329\n",
      "285.0918906144798\n",
      "116.14142486453056\n",
      "0.8790520131587982\n",
      "9822.977352388203\n",
      "502.94075962901115\n",
      "161.61798568814993\n",
      "175.83940757066011\n",
      "186.81496143341064\n",
      "239.48051822930574\n",
      "9.23970977962017\n",
      "22.352727189660072\n",
      "19.15761584788561\n",
      "1134.1938640661538\n",
      "0.0\n",
      "73.26918030530214\n",
      "9791.629319939762\n",
      "36.32647079229355\n",
      "51.31749015301466\n",
      "184.3698466680944\n",
      "0.0\n",
      "285.0277662873268\n",
      "5516.322465330362\n",
      "326.5635078288615\n",
      "6.466090202331543\n",
      "69.20330955460668\n",
      "0.0\n",
      "390.54769292101264\n",
      "7.8299756571650505\n",
      "0.0\n",
      "22.318559646606445\n",
      "0.11197339743375778\n",
      "0.0\n",
      "176.43503892421722\n",
      "1514.1212924718857\n",
      "0.0\n",
      "229.0796891413629\n",
      "1442.8033886998892\n",
      "0.0\n",
      "0.0\n",
      "32.94594959914684\n",
      "0.0\n",
      "195.0045848749578\n",
      "33.473992981016636\n",
      "1.7972994968295097\n",
      "80.76684131100774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "\n",
    "#Import feature selection stuff\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "\n",
    "# Import the model we are using\n",
    "import lightgbm as lgb\n",
    "\n",
    "fiftyfifty_lightgbm_performance_normalized_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "\n",
    "    ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_normalized,\n",
    "                                                    labels_normalized,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels_normalized)\n",
    "\n",
    "\n",
    "    LightGBMPipeline = Pipeline(steps = [['smote', SMOTE(sampling_strategy = 0.5)],\n",
    "                                    ['under', RandomUnderSampler()],\n",
    "                                ['classifier', lgb.LGBMClassifier(n_jobs=-1, importance_type='gain')]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "# define search space\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    spaceEmpty = dict()\n",
    "    space['classifier__num_leaves'] = [11, 16, 21, 26, 31, 36, 41, 46, 51, 56]\n",
    "    space['classifier__min_data_in_leaf'] =  [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__max_depth'] = [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__learning_rate'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9, 1.0]\n",
    "    space['classifier__max_bin'] = [50, 100, 150, 200, 255, 300, 350, 400, 450, 500]\n",
    "\n",
    "    LightGBMSearch = RandomizedSearchCV(estimator = LightGBMPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring= ftwo_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedLightGBMModel = LightGBMSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedLightGBMModel.best_score_\n",
    "    test_score = optimizedLightGBMModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedLightGBMModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedLightGBMModel.best_estimator_._final_estimator.booster_.feature_importance(importance_type='gain')\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedLightGBMModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    fiftyfifty_lightgbm_performance_normalized_df = pd.concat([fiftyfifty_lightgbm_performance_normalized_df, new_performance_df])\n",
    "    \n",
    "\n",
    "fiftyfifty_lightgbm_performance_normalized_df.to_csv(\"../data/05_model_output/fiftyfifty_lightgbm_performance_normalized_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-republican",
   "metadata": {},
   "source": [
    "# 5. Modeling - Non-Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "wicked-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = processedData_mxShopFeatures\n",
    "labels = processedData_mxShopLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-bunch",
   "metadata": {},
   "source": [
    "## 5.1 Rebalancing Strategy - None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-century",
   "metadata": {},
   "source": [
    "### 5.1.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "none_randomforest_nonnormalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "    pipeline = Pipeline(steps = [#['smote', SMOTE(sampling_strategy = 0.5, n_jobs=2)],\n",
    "                              #['under', RandomUnderSampler()],\n",
    "                                ['classifier', RandomForestClassifier(n_jobs=-1)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    spaceEmpty = dict() \n",
    "\n",
    "    search = RandomizedSearchCV(estimator = pipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring='f1', \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedRFModel = search.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    #print(f\"Elapsed time to compute best fit: \"\n",
    "      #f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedRFModel.best_score_\n",
    "    test_score = optimizedRFModel.score(X_test, y_test)\n",
    "    #print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    #print('Best Hyperparameters: %s' % optimizedRFModel.best_params_)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedRFModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    \n",
    "    none_randomforest_nonnormalized_performance_df = pd.concat([none_randomforest_nonnormalized_performance_df, new_performance_df])\n",
    "    \n",
    "none_randomforest_nonnormalized_performance_df.to_csv(\"../data/05_model_output/none_randomforest_nonnormalized_performance_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-street",
   "metadata": {},
   "source": [
    "### 5.1.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "satellite-husband",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:26:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1398.972 seconds\n",
      "Cross-validation score: 0.8580835171925448\n",
      "Test score: 0.5737704918032787\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 9, 'classifier__max_depth': 12, 'classifier__learning_rate': 0.35, 'classifier__gamma': 0.1, 'classifier__colsample_bytree': 0.8}\n",
      "0.027060336\n",
      "0.02657418\n",
      "0.06091818\n",
      "0.0\n",
      "0.033658937\n",
      "0.011471945\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.025657088\n",
      "0.004869667\n",
      "0.0\n",
      "0.0\n",
      "0.030228166\n",
      "0.0\n",
      "0.03633201\n",
      "0.002460159\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.04055345\n",
      "0.005087352\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0024800962\n",
      "0.009542161\n",
      "0.0009427847\n",
      "0.0\n",
      "0.0020863754\n",
      "0.0054643895\n",
      "0.0\n",
      "0.010119024\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0097494675\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.014767831\n",
      "0.0043677106\n",
      "0.102277234\n",
      "0.096444346\n",
      "0.01572338\n",
      "0.001752062\n",
      "0.0\n",
      "0.004650726\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.001913054\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.010781068\n",
      "0.015439428\n",
      "0.0\n",
      "0.0051251394\n",
      "0.030844178\n",
      "0.017113695\n",
      "0.01313323\n",
      "0.027034467\n",
      "0.0025352498\n",
      "0.0061360346\n",
      "0.0\n",
      "0.0059890784\n",
      "0.0\n",
      "0.0044179265\n",
      "0.0\n",
      "0.0\n",
      "0.01228227\n",
      "0.0\n",
      "0.0\n",
      "0.003436581\n",
      "0.0\n",
      "0.0027875125\n",
      "0.022274178\n",
      "0.008598959\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0030138264\n",
      "0.0\n",
      "0.018223396\n",
      "0.0066534216\n",
      "0.015638577\n",
      "0.021356296\n",
      "0.027896287\n",
      "0.0032570362\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0031662497\n",
      "0.11035073\n",
      "0.01536302\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998811   0.909091  0.588235  0.714286  0.632911  0.819672   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0             0.5358  0.755169    0.819672  \n",
      "   Accuracy  Precision    Recall   F1        F2     F0.5  Average Precision  \\\n",
      "0  0.997919   0.636364  0.411765  0.5  0.443038  0.57377           0.263519   \n",
      "\n",
      "   cv_score  test_score  \n",
      "0  0.858084     0.57377  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:51:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1497.546 seconds\n",
      "Cross-validation score: 0.8469812328858612\n",
      "Test score: 0.655737704918033\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 9, 'classifier__max_depth': 4, 'classifier__learning_rate': 0.25, 'classifier__gamma': 0.7, 'classifier__colsample_bytree': 1.0}\n",
      "0.031246787\n",
      "0.02461585\n",
      "0.05543514\n",
      "0.0\n",
      "0.05777382\n",
      "0.020388754\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.023663945\n",
      "0.0049281716\n",
      "0.0\n",
      "0.0\n",
      "0.02924011\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.03344807\n",
      "0.007264928\n",
      "0.015874542\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.009750613\n",
      "0.0\n",
      "0.0035277444\n",
      "0.0\n",
      "0.0035536145\n",
      "0.0061080065\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.008565672\n",
      "0.0\n",
      "0.0059989695\n",
      "0.0\n",
      "0.010863172\n",
      "0.0\n",
      "0.028088434\n",
      "0.0061305254\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0067714225\n",
      "0.011216676\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.008336717\n",
      "0.04405682\n",
      "0.04864308\n",
      "0.023500841\n",
      "0.0\n",
      "0.0\n",
      "0.0067943432\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.01248832\n",
      "0.0\n",
      "0.0\n",
      "0.021231798\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.011258664\n",
      "0.0155519415\n",
      "0.0\n",
      "0.008903076\n",
      "0.040253565\n",
      "0.014384421\n",
      "0.0\n",
      "0.02949222\n",
      "0.0076476717\n",
      "0.051105417\n",
      "0.0\n",
      "0.0051572807\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.020478863\n",
      "0.01883661\n",
      "0.0\n",
      "0.012891572\n",
      "0.009272952\n",
      "0.0\n",
      "0.008622883\n",
      "0.01371583\n",
      "0.0071404\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.005928131\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.015879866\n",
      "0.03356349\n",
      "0.0\n",
      "0.0\n",
      "0.01664631\n",
      "0.0\n",
      "0.0\n",
      "0.015303607\n",
      "0.0\n",
      "0.007687227\n",
      "0.0\n",
      "0.051837176\n",
      "0.008933995\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall   F1        F2     F0.5  Average Precision  \\\n",
      "0  0.997919   0.636364  0.411765  0.5  0.443038  0.57377           0.263519   \n",
      "\n",
      "   cv_score  test_score  \n",
      "0  0.858084     0.57377  \n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.636364  0.411765  0.500000  0.443038  0.573770   \n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.263519  0.858084    0.573770  \n",
      "0           0.343584  0.846981    0.655738  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:17:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1585.907 seconds\n",
      "Cross-validation score: 0.8323520703383404\n",
      "Test score: 0.8163265306122449\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 10, 'classifier__max_depth': 8, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0.2, 'classifier__colsample_bytree': 0.6}\n",
      "0.03440917\n",
      "0.022945596\n",
      "0.07082729\n",
      "0.0\n",
      "0.023787247\n",
      "0.03016624\n",
      "0.02156841\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.003128863\n",
      "0.019886898\n",
      "0.0\n",
      "0.0\n",
      "0.018219894\n",
      "0.0\n",
      "0.015219429\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.034056567\n",
      "0.011109067\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0067432355\n",
      "0.0\n",
      "0.004874998\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0041693076\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007559601\n",
      "0.007913764\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.005508682\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.01731819\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0071004536\n",
      "0.0095775435\n",
      "0.035266843\n",
      "0.12671457\n",
      "0.052889667\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0068635796\n",
      "0.0\n",
      "0.011170234\n",
      "0.019358454\n",
      "0.0\n",
      "0.0028379175\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007790304\n",
      "0.016254684\n",
      "0.0\n",
      "0.0\n",
      "0.041853666\n",
      "0.022596652\n",
      "0.014705816\n",
      "0.023745086\n",
      "0.009308911\n",
      "0.009564578\n",
      "0.0\n",
      "0.008830543\n",
      "0.0\n",
      "0.004660196\n",
      "0.0\n",
      "0.0015069741\n",
      "0.018728033\n",
      "0.0\n",
      "0.0\n",
      "0.0057728197\n",
      "0.0\n",
      "0.009866571\n",
      "0.0069483058\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.014201475\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0068637314\n",
      "0.0035501276\n",
      "0.005648229\n",
      "0.006468244\n",
      "0.032490015\n",
      "0.022745\n",
      "0.0070792423\n",
      "0.011730252\n",
      "0.006679678\n",
      "0.005905725\n",
      "0.0030785291\n",
      "0.031494025\n",
      "0.008740956\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.343584  0.846981    0.655738  \n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.636364  0.411765  0.500000  0.443038  0.573770   \n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.263519  0.858084    0.573770  \n",
      "0           0.343584  0.846981    0.655738  \n",
      "0           0.471926  0.832352    0.816327  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:44:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1627.470 seconds\n",
      "Cross-validation score: 0.8545512331553521\n",
      "Test score: 0.8490566037735848\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 9, 'classifier__max_depth': 4, 'classifier__learning_rate': 0.4, 'classifier__gamma': 0.8, 'classifier__colsample_bytree': 0.8}\n",
      "0.023422407\n",
      "0.03304791\n",
      "0.090817176\n",
      "0.0\n",
      "0.053193115\n",
      "0.027778776\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.020765804\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.028397415\n",
      "0.0\n",
      "0.045911577\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.041613605\n",
      "0.007819906\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0139705455\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0038726858\n",
      "0.0153662935\n",
      "0.016256718\n",
      "0.0037978108\n",
      "0.0\n",
      "0.0\n",
      "0.009221184\n",
      "0.0\n",
      "0.005030212\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007938508\n",
      "0.0\n",
      "0.013381723\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0044746427\n",
      "0.011828481\n",
      "0.068275854\n",
      "0.04075442\n",
      "0.024449917\n",
      "0.0087375\n",
      "0.0\n",
      "0.008376755\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.014467896\n",
      "0.0\n",
      "0.0\n",
      "0.009740472\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.011718019\n",
      "0.010966483\n",
      "0.0\n",
      "0.0055991095\n",
      "0.048230346\n",
      "0.007908915\n",
      "0.015899265\n",
      "0.01300851\n",
      "0.0091036\n",
      "0.009313932\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.004307201\n",
      "0.0\n",
      "0.0\n",
      "0.0030003039\n",
      "0.0\n",
      "0.010544103\n",
      "0.0061744777\n",
      "0.0\n",
      "0.010371922\n",
      "0.010893673\n",
      "0.011261157\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.006381744\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.011162278\n",
      "0.028608786\n",
      "0.0\n",
      "0.02267982\n",
      "0.031638406\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0055987006\n",
      "0.04337505\n",
      "0.009544912\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall    F1        F2      F0.5  Average Precision  \\\n",
      "0  0.998662        1.0  0.470588  0.64  0.526316  0.816327           0.471926   \n",
      "\n",
      "   cv_score  test_score  \n",
      "0  0.832352    0.816327  \n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.636364  0.411765  0.500000  0.443038  0.573770   \n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998811   1.000000  0.529412  0.692308  0.584416  0.849057   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.263519  0.858084    0.573770  \n",
      "0           0.343584  0.846981    0.655738  \n",
      "0           0.471926  0.832352    0.816327  \n",
      "0           0.530601  0.854551    0.849057  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:11:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1575.189 seconds\n",
      "Cross-validation score: 0.81053289766713\n",
      "Test score: 0.9016393442622951\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 9, 'classifier__max_depth': 2, 'classifier__learning_rate': 0.55, 'classifier__gamma': 0.7, 'classifier__colsample_bytree': 0.9}\n",
      "0.042415038\n",
      "0.017314587\n",
      "0.11133856\n",
      "0.0\n",
      "0.059716824\n",
      "0.0\n",
      "0.01888198\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.021411968\n",
      "0.0\n",
      "0.021610761\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.040782783\n",
      "0.015798692\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.009489368\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.01877317\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.008178784\n",
      "0.016609356\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.020094935\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0067750467\n",
      "0.20170622\n",
      "0.045003857\n",
      "0.0\n",
      "0.00998987\n",
      "0.0\n",
      "0.0064825197\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.01508205\n",
      "0.0\n",
      "0.013966216\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007167047\n",
      "0.008354575\n",
      "0.0\n",
      "0.010448437\n",
      "0.06432578\n",
      "0.0\n",
      "0.0\n",
      "0.034295186\n",
      "0.0043684496\n",
      "0.02147952\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.022150174\n",
      "0.0\n",
      "0.0\n",
      "0.0037598314\n",
      "0.0\n",
      "0.010039915\n",
      "0.0\n",
      "0.009797187\n",
      "0.0\n",
      "0.004933614\n",
      "0.0\n",
      "0.0\n",
      "0.009946545\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.012206992\n",
      "0.0\n",
      "0.0\n",
      "0.0028081352\n",
      "0.03656639\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007062795\n",
      "0.0037502123\n",
      "0.0051168064\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998811        1.0  0.529412  0.692308  0.584416  0.849057   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.530601  0.854551    0.849057  \n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.636364  0.411765  0.500000  0.443038  0.573770   \n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998811   1.000000  0.529412  0.692308  0.584416  0.849057   \n",
      "0  0.999108   1.000000  0.647059  0.785714  0.696203  0.901639   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.263519  0.858084    0.573770  \n",
      "0           0.343584  0.846981    0.655738  \n",
      "0           0.471926  0.832352    0.816327  \n",
      "0           0.530601  0.854551    0.849057  \n",
      "0           0.647951  0.810533    0.901639  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:38:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1628.539 seconds\n",
      "Cross-validation score: 0.7973849988281227\n",
      "Test score: 0.8771929824561404\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 9, 'classifier__max_depth': 16, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0.2, 'classifier__colsample_bytree': 0.8}\n",
      "0.023663705\n",
      "0.02195563\n",
      "0.042025615\n",
      "0.0\n",
      "0.044185955\n",
      "0.013943908\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.041066658\n",
      "0.006101533\n",
      "0.0\n",
      "0.0\n",
      "0.02262935\n",
      "0.0\n",
      "0.024247115\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.005892229\n",
      "0.009274564\n",
      "0.018120099\n",
      "0.0\n",
      "0.016355418\n",
      "0.0\n",
      "0.0\n",
      "0.0066096033\n",
      "0.009189359\n",
      "0.0\n",
      "0.00434883\n",
      "0.006461588\n",
      "0.0\n",
      "0.017226866\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.013299914\n",
      "0.014918481\n",
      "0.0\n",
      "0.0\n",
      "0.0077795265\n",
      "0.0\n",
      "0.0\n",
      "0.010377186\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.013295432\n",
      "0.0\n",
      "0.007601033\n",
      "0.0\n",
      "0.0\n",
      "0.0050971247\n",
      "0.0\n",
      "0.008489592\n",
      "0.007795713\n",
      "0.032840755\n",
      "0.034264315\n",
      "0.058833595\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00586845\n",
      "0.0\n",
      "0.007893474\n",
      "0.0086417\n",
      "0.014052247\n",
      "0.0013769238\n",
      "0.012781253\n",
      "0.0\n",
      "0.0025262416\n",
      "0.0\n",
      "0.0\n",
      "0.0047153467\n",
      "0.017105697\n",
      "0.0\n",
      "0.0075047165\n",
      "0.033761755\n",
      "0.02842155\n",
      "0.027578248\n",
      "0.02796687\n",
      "0.008511244\n",
      "0.013126652\n",
      "0.0\n",
      "0.006625875\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.029145354\n",
      "0.0\n",
      "0.0\n",
      "0.0038885016\n",
      "0.0\n",
      "0.007529403\n",
      "0.015283694\n",
      "0.006191707\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.014126173\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.009912794\n",
      "0.00597518\n",
      "0.013133322\n",
      "0.0025361413\n",
      "0.018437335\n",
      "0.0034411026\n",
      "0.015966143\n",
      "0.0\n",
      "0.0\n",
      "0.01544614\n",
      "0.010875305\n",
      "0.030909043\n",
      "0.020853708\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.999108        1.0  0.647059  0.785714  0.696203  0.901639   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.647951  0.810533    0.901639  \n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.636364  0.411765  0.500000  0.443038  0.573770   \n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998811   1.000000  0.529412  0.692308  0.584416  0.849057   \n",
      "0  0.999108   1.000000  0.647059  0.785714  0.696203  0.901639   \n",
      "0  0.998959   1.000000  0.588235  0.740741  0.641026  0.877193   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.263519  0.858084    0.573770  \n",
      "0           0.343584  0.846981    0.655738  \n",
      "0           0.471926  0.832352    0.816327  \n",
      "0           0.530601  0.854551    0.849057  \n",
      "0           0.647951  0.810533    0.901639  \n",
      "0           0.589276  0.797385    0.877193  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:04:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1585.669 seconds\n",
      "Cross-validation score: 0.8402307193884665\n",
      "Test score: 0.7317073170731707\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 10, 'classifier__max_depth': 18, 'classifier__learning_rate': 0.55, 'classifier__gamma': 0.7, 'classifier__colsample_bytree': 0.2}\n",
      "0.061685972\n",
      "0.017314395\n",
      "0.059070025\n",
      "0.0\n",
      "0.035394896\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.03921107\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.020391827\n",
      "0.0\n",
      "0.019041682\n",
      "0.0\n",
      "0.0061031412\n",
      "0.013225303\n",
      "0.0\n",
      "0.014796904\n",
      "0.0041940026\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0049587404\n",
      "0.0\n",
      "0.0\n",
      "0.014444299\n",
      "0.0\n",
      "0.003933671\n",
      "0.0\n",
      "0.0\n",
      "0.018904597\n",
      "0.0\n",
      "0.008850975\n",
      "0.009723062\n",
      "0.033510942\n",
      "0.0\n",
      "0.0\n",
      "0.008865407\n",
      "0.0050042206\n",
      "0.0042697634\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.021708148\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.012932643\n",
      "0.005970247\n",
      "0.0\n",
      "0.004821477\n",
      "0.046222053\n",
      "0.0\n",
      "0.0\n",
      "0.0031827602\n",
      "0.012540288\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.010929249\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007003825\n",
      "0.014939473\n",
      "0.0\n",
      "0.0\n",
      "0.026239786\n",
      "0.019622933\n",
      "0.009260473\n",
      "0.04839845\n",
      "0.013188019\n",
      "0.00384391\n",
      "0.0\n",
      "0.0047608884\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.022946721\n",
      "0.010148026\n",
      "0.0\n",
      "0.0052269585\n",
      "0.0\n",
      "0.0044716336\n",
      "0.036641613\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0032090247\n",
      "0.024354707\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.009345381\n",
      "0.015678925\n",
      "0.004624296\n",
      "0.057329256\n",
      "0.06322817\n",
      "0.0\n",
      "0.018501732\n",
      "0.0\n",
      "0.0\n",
      "0.04151517\n",
      "0.006404266\n",
      "0.00791457\n",
      "0.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998959        1.0  0.588235  0.740741  0.641026  0.877193   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.589276  0.797385    0.877193  \n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.636364  0.411765  0.500000  0.443038  0.573770   \n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998811   1.000000  0.529412  0.692308  0.584416  0.849057   \n",
      "0  0.999108   1.000000  0.647059  0.785714  0.696203  0.901639   \n",
      "0  0.998959   1.000000  0.588235  0.740741  0.641026  0.877193   \n",
      "0  0.998365   1.000000  0.352941  0.521739  0.405405  0.731707   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.263519  0.858084    0.573770  \n",
      "0           0.343584  0.846981    0.655738  \n",
      "0           0.471926  0.832352    0.816327  \n",
      "0           0.530601  0.854551    0.849057  \n",
      "0           0.647951  0.810533    0.901639  \n",
      "0           0.589276  0.797385    0.877193  \n",
      "0           0.354577  0.840231    0.731707  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:32:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1670.892 seconds\n",
      "Cross-validation score: 0.7911324651431774\n",
      "Test score: 0.7692307692307693\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 4, 'classifier__max_depth': 12, 'classifier__learning_rate': 0.4, 'classifier__gamma': 0.0, 'classifier__colsample_bytree': 0.9}\n",
      "0.014651898\n",
      "0.016049547\n",
      "0.032367405\n",
      "0.010188894\n",
      "0.025099536\n",
      "0.0076975906\n",
      "0.0\n",
      "0.0019914191\n",
      "0.01050671\n",
      "0.0\n",
      "0.05367147\n",
      "0.0074781124\n",
      "0.0\n",
      "0.0\n",
      "0.018533573\n",
      "0.0\n",
      "0.0033997938\n",
      "0.026582694\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.033418704\n",
      "0.005156682\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0149444295\n",
      "0.0\n",
      "0.00214083\n",
      "0.014495571\n",
      "0.009753681\n",
      "0.01149922\n",
      "0.023408057\n",
      "0.00859064\n",
      "0.0018341261\n",
      "0.0\n",
      "0.0\n",
      "0.0019426807\n",
      "0.0067134397\n",
      "0.0038017868\n",
      "0.0050118626\n",
      "0.004472599\n",
      "0.024432227\n",
      "0.0070314216\n",
      "0.018197877\n",
      "0.019282231\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0039344234\n",
      "0.0\n",
      "0.006139644\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007667579\n",
      "0.0\n",
      "0.0060908394\n",
      "0.04325637\n",
      "0.052321352\n",
      "0.067367606\n",
      "0.011061435\n",
      "0.00239858\n",
      "0.0029787817\n",
      "0.0039755823\n",
      "0.0\n",
      "0.0\n",
      "0.007778987\n",
      "0.009077878\n",
      "0.007991638\n",
      "0.0\n",
      "0.010238003\n",
      "0.0\n",
      "0.009137376\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.006115679\n",
      "0.0\n",
      "0.0034914608\n",
      "0.020628849\n",
      "0.028489381\n",
      "0.0\n",
      "0.024683498\n",
      "0.016545387\n",
      "0.009135156\n",
      "0.0\n",
      "0.0\n",
      "0.0012824433\n",
      "0.014266032\n",
      "0.0\n",
      "0.0041544987\n",
      "0.0099904025\n",
      "0.0031399408\n",
      "0.0026856246\n",
      "0.003809251\n",
      "0.0\n",
      "0.009923833\n",
      "0.0076581133\n",
      "0.0030105829\n",
      "0.0\n",
      "0.005434304\n",
      "0.0\n",
      "0.002126292\n",
      "0.013528589\n",
      "0.0\n",
      "0.0\n",
      "0.010322688\n",
      "0.0\n",
      "0.013383228\n",
      "0.024920033\n",
      "0.0030772416\n",
      "0.0029059036\n",
      "0.016586546\n",
      "0.006560804\n",
      "0.0031272005\n",
      "0.00452226\n",
      "0.0\n",
      "0.0058529475\n",
      "0.0033907453\n",
      "0.004605355\n",
      "0.014882879\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998365        1.0  0.352941  0.521739  0.405405  0.731707   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.354577  0.840231    0.731707  \n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.636364  0.411765  0.500000  0.443038  0.573770   \n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998811   1.000000  0.529412  0.692308  0.584416  0.849057   \n",
      "0  0.999108   1.000000  0.647059  0.785714  0.696203  0.901639   \n",
      "0  0.998959   1.000000  0.588235  0.740741  0.641026  0.877193   \n",
      "0  0.998365   1.000000  0.352941  0.521739  0.405405  0.731707   \n",
      "0  0.998662   0.833333  0.588235  0.689655  0.625000  0.769231   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.263519  0.858084    0.573770  \n",
      "0           0.343584  0.846981    0.655738  \n",
      "0           0.471926  0.832352    0.816327  \n",
      "0           0.530601  0.854551    0.849057  \n",
      "0           0.647951  0.810533    0.901639  \n",
      "0           0.589276  0.797385    0.877193  \n",
      "0           0.354577  0.840231    0.731707  \n",
      "0           0.491237  0.791132    0.769231  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:59:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1605.801 seconds\n",
      "Cross-validation score: 0.8276506678883588\n",
      "Test score: 0.7894736842105263\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 7, 'classifier__max_depth': 2, 'classifier__learning_rate': 0.25, 'classifier__gamma': 0.7, 'classifier__colsample_bytree': 0.3}\n",
      "0.03479883\n",
      "0.016235813\n",
      "0.10923325\n",
      "0.0\n",
      "0.03142682\n",
      "0.011070861\n",
      "0.011721479\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.013109973\n",
      "0.007312582\n",
      "0.0\n",
      "0.0\n",
      "0.051585503\n",
      "0.0\n",
      "0.024258161\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.03608265\n",
      "0.0051737074\n",
      "0.0093201\n",
      "0.019617537\n",
      "0.013788378\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.013143515\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0060430253\n",
      "0.0\n",
      "0.038757358\n",
      "0.008249855\n",
      "0.023233302\n",
      "0.0\n",
      "0.0\n",
      "0.003835126\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007889562\n",
      "0.0\n",
      "0.012478467\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0058688545\n",
      "0.0\n",
      "0.0\n",
      "0.07297753\n",
      "0.03029146\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007823972\n",
      "0.005683502\n",
      "0.010563157\n",
      "0.003075074\n",
      "0.008140188\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.004463916\n",
      "0.005920045\n",
      "0.0\n",
      "0.005463874\n",
      "0.041129418\n",
      "0.021824896\n",
      "0.016433593\n",
      "0.005780097\n",
      "0.009502471\n",
      "0.0041888086\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.011344179\n",
      "0.021338442\n",
      "0.0047908877\n",
      "0.0\n",
      "0.0021386654\n",
      "0.0\n",
      "0.009451612\n",
      "0.024948992\n",
      "0.009395536\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0021531018\n",
      "0.012734179\n",
      "0.0032205507\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0057063056\n",
      "0.0023807122\n",
      "0.01647936\n",
      "0.0028136328\n",
      "0.033020653\n",
      "0.030149432\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0031507602\n",
      "0.033063218\n",
      "0.0042231125\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall        F1     F2      F0.5  \\\n",
      "0  0.998662   0.833333  0.588235  0.689655  0.625  0.769231   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.491237  0.791132    0.769231  \n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.636364  0.411765  0.500000  0.443038  0.573770   \n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998811   1.000000  0.529412  0.692308  0.584416  0.849057   \n",
      "0  0.999108   1.000000  0.647059  0.785714  0.696203  0.901639   \n",
      "0  0.998959   1.000000  0.588235  0.740741  0.641026  0.877193   \n",
      "0  0.998365   1.000000  0.352941  0.521739  0.405405  0.731707   \n",
      "0  0.998662   0.833333  0.588235  0.689655  0.625000  0.769231   \n",
      "0  0.998662   0.900000  0.529412  0.666667  0.576923  0.789474   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.263519  0.858084    0.573770  \n",
      "0           0.343584  0.846981    0.655738  \n",
      "0           0.471926  0.832352    0.816327  \n",
      "0           0.530601  0.854551    0.849057  \n",
      "0           0.647951  0.810533    0.901639  \n",
      "0           0.589276  0.797385    0.877193  \n",
      "0           0.354577  0.840231    0.731707  \n",
      "0           0.491237  0.791132    0.769231  \n",
      "0           0.477660  0.827651    0.789474  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:23:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1457.680 seconds\n",
      "Cross-validation score: 0.7963967890741345\n",
      "Test score: 0.8196721311475408\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 10, 'classifier__max_depth': 10, 'classifier__learning_rate': 0.55, 'classifier__gamma': 0.9, 'classifier__colsample_bytree': 0.6}\n",
      "0.03021961\n",
      "0.021977192\n",
      "0.07026057\n",
      "0.0\n",
      "0.029757163\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0140219815\n",
      "0.062335797\n",
      "0.0\n",
      "0.0\n",
      "0.051566023\n",
      "0.0\n",
      "0.046323255\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.04677971\n",
      "0.018396966\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.010831753\n",
      "0.0037822127\n",
      "0.0051650438\n",
      "0.012098678\n",
      "0.0\n",
      "0.006512684\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.006841854\n",
      "0.013939798\n",
      "0.0\n",
      "0.0\n",
      "0.0052278573\n",
      "0.0\n",
      "0.0052791745\n",
      "0.005263227\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.014650741\n",
      "0.004600978\n",
      "0.024749698\n",
      "0.10955219\n",
      "0.0\n",
      "0.0\n",
      "0.007572385\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.01364155\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.005399542\n",
      "0.020683238\n",
      "0.0\n",
      "0.021381218\n",
      "0.07250879\n",
      "0.016965961\n",
      "0.011372958\n",
      "0.0\n",
      "0.0\n",
      "0.021322362\n",
      "0.0\n",
      "0.01964055\n",
      "0.0\n",
      "0.007772356\n",
      "0.0\n",
      "0.0\n",
      "0.040327005\n",
      "0.0\n",
      "0.0\n",
      "0.006138463\n",
      "0.0\n",
      "0.009405193\n",
      "0.006812069\n",
      "0.0\n",
      "0.0\n",
      "0.012932401\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.010072115\n",
      "0.006599665\n",
      "0.0\n",
      "0.02134136\n",
      "0.019980917\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0032029417\n",
      "0.008533725\n",
      "0.016259085\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998662        0.9  0.529412  0.666667  0.576923  0.789474   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0            0.47766  0.827651    0.789474  \n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.636364  0.411765  0.500000  0.443038  0.573770   \n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998811   1.000000  0.529412  0.692308  0.584416  0.849057   \n",
      "0  0.999108   1.000000  0.647059  0.785714  0.696203  0.901639   \n",
      "0  0.998959   1.000000  0.588235  0.740741  0.641026  0.877193   \n",
      "0  0.998365   1.000000  0.352941  0.521739  0.405405  0.731707   \n",
      "0  0.998662   0.833333  0.588235  0.689655  0.625000  0.769231   \n",
      "0  0.998662   0.900000  0.529412  0.666667  0.576923  0.789474   \n",
      "0  0.998811   0.909091  0.588235  0.714286  0.632911  0.819672   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.263519  0.858084    0.573770  \n",
      "0           0.343584  0.846981    0.655738  \n",
      "0           0.471926  0.832352    0.816327  \n",
      "0           0.530601  0.854551    0.849057  \n",
      "0           0.647951  0.810533    0.901639  \n",
      "0           0.589276  0.797385    0.877193  \n",
      "0           0.354577  0.840231    0.731707  \n",
      "0           0.491237  0.791132    0.769231  \n",
      "0           0.477660  0.827651    0.789474  \n",
      "0           0.535800  0.796397    0.819672  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:50:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1638.508 seconds\n",
      "Cross-validation score: 0.8066844882191452\n",
      "Test score: 0.7792207792207791\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 10, 'classifier__max_depth': 10, 'classifier__learning_rate': 0.5, 'classifier__gamma': 0.1, 'classifier__colsample_bytree': 0.8}\n",
      "0.031261735\n",
      "0.03108646\n",
      "0.0599805\n",
      "0.0\n",
      "0.025391875\n",
      "0.050957188\n",
      "0.020008473\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.042697694\n",
      "0.0039195125\n",
      "0.0\n",
      "0.0\n",
      "0.03645991\n",
      "0.0\n",
      "0.03473061\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.05157139\n",
      "0.011440879\n",
      "0.018057711\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0069201584\n",
      "0.0\n",
      "0.012594747\n",
      "0.0\n",
      "0.0033360422\n",
      "0.0\n",
      "0.0\n",
      "0.024917854\n",
      "0.002556083\n",
      "0.008154499\n",
      "0.015056738\n",
      "0.005834713\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0029573985\n",
      "0.0\n",
      "0.0038417429\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0065095234\n",
      "0.024390882\n",
      "0.113401495\n",
      "0.04862199\n",
      "0.0027279328\n",
      "0.0\n",
      "0.0039896592\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.009439437\n",
      "0.0\n",
      "0.0\n",
      "0.009460472\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0067520784\n",
      "0.009982855\n",
      "0.0\n",
      "0.0\n",
      "0.037503093\n",
      "0.016904978\n",
      "0.022190005\n",
      "0.019000662\n",
      "0.00091402075\n",
      "0.0\n",
      "0.0\n",
      "0.011834588\n",
      "0.0\n",
      "0.0019900517\n",
      "0.0\n",
      "0.0\n",
      "0.027273241\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.010414164\n",
      "0.00049306353\n",
      "0.015117095\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.013708756\n",
      "0.0026502495\n",
      "0.0\n",
      "0.00854327\n",
      "0.028660621\n",
      "0.0019241158\n",
      "0.0\n",
      "0.0018085196\n",
      "0.0\n",
      "0.0012285123\n",
      "0.008765624\n",
      "0.023185212\n",
      "0.00687992\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998811   0.909091  0.588235  0.714286  0.632911  0.819672   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0             0.5358  0.796397    0.819672  \n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.636364  0.411765  0.500000  0.443038  0.573770   \n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998811   1.000000  0.529412  0.692308  0.584416  0.849057   \n",
      "0  0.999108   1.000000  0.647059  0.785714  0.696203  0.901639   \n",
      "0  0.998959   1.000000  0.588235  0.740741  0.641026  0.877193   \n",
      "0  0.998365   1.000000  0.352941  0.521739  0.405405  0.731707   \n",
      "0  0.998662   0.833333  0.588235  0.689655  0.625000  0.769231   \n",
      "0  0.998662   0.900000  0.529412  0.666667  0.576923  0.789474   \n",
      "0  0.998811   0.909091  0.588235  0.714286  0.632911  0.819672   \n",
      "0  0.998811   0.800000  0.705882  0.750000  0.722892  0.779221   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.263519  0.858084    0.573770  \n",
      "0           0.343584  0.846981    0.655738  \n",
      "0           0.471926  0.832352    0.816327  \n",
      "0           0.530601  0.854551    0.849057  \n",
      "0           0.647951  0.810533    0.901639  \n",
      "0           0.589276  0.797385    0.877193  \n",
      "0           0.354577  0.840231    0.731707  \n",
      "0           0.491237  0.791132    0.769231  \n",
      "0           0.477660  0.827651    0.789474  \n",
      "0           0.535800  0.796397    0.819672  \n",
      "0           0.565449  0.806684    0.779221  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:16:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1532.185 seconds\n",
      "Cross-validation score: 0.8255699635562335\n",
      "Test score: 0.6666666666666666\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 4, 'classifier__max_depth': 8, 'classifier__learning_rate': 0.55, 'classifier__gamma': 0.5, 'classifier__colsample_bytree': 0.1}\n",
      "0.024543049\n",
      "0.00831028\n",
      "0.038782846\n",
      "0.0\n",
      "0.03681212\n",
      "0.0021150687\n",
      "0.014999829\n",
      "0.0\n",
      "0.015480613\n",
      "0.0\n",
      "0.03372744\n",
      "0.004601714\n",
      "0.0141901905\n",
      "0.0\n",
      "0.0\n",
      "0.013133407\n",
      "0.043022998\n",
      "0.005395967\n",
      "0.012203612\n",
      "0.035463613\n",
      "0.016646953\n",
      "0.028047865\n",
      "0.0119060455\n",
      "0.013960314\n",
      "0.0033841114\n",
      "0.0\n",
      "0.0026119354\n",
      "0.0029578279\n",
      "0.015973585\n",
      "0.007920673\n",
      "0.0\n",
      "0.0049278103\n",
      "0.0\n",
      "0.0\n",
      "0.005104083\n",
      "0.0034743056\n",
      "0.002589165\n",
      "0.0\n",
      "0.0030455473\n",
      "0.034465052\n",
      "0.0\n",
      "0.006661427\n",
      "0.002774527\n",
      "0.002463605\n",
      "0.005790954\n",
      "0.002828993\n",
      "0.01235152\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0078054415\n",
      "0.0\n",
      "0.0050241314\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0064982735\n",
      "0.0049138693\n",
      "0.012271332\n",
      "0.0059918105\n",
      "0.05364388\n",
      "0.009353136\n",
      "0.003948906\n",
      "0.0028419034\n",
      "0.0038621346\n",
      "0.0\n",
      "0.0057247495\n",
      "0.0\n",
      "0.00246396\n",
      "0.005761758\n",
      "0.0\n",
      "0.0\n",
      "0.019640544\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0047512352\n",
      "0.002604829\n",
      "0.0067495145\n",
      "0.002100634\n",
      "0.029990671\n",
      "0.018495701\n",
      "0.0047512664\n",
      "0.013148774\n",
      "0.01721513\n",
      "0.0038406032\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0051214234\n",
      "0.00948247\n",
      "0.005117961\n",
      "0.00619043\n",
      "0.0009321933\n",
      "0.0034636431\n",
      "0.0058410014\n",
      "0.0\n",
      "0.0017867379\n",
      "0.025328724\n",
      "0.0\n",
      "0.0\n",
      "0.008710605\n",
      "0.0073125465\n",
      "0.0066034496\n",
      "0.0064974674\n",
      "0.014832033\n",
      "0.0\n",
      "0.0\n",
      "0.02946925\n",
      "0.007842838\n",
      "0.0053913817\n",
      "0.0048413845\n",
      "0.020441296\n",
      "0.023298565\n",
      "0.0036502064\n",
      "0.0069448077\n",
      "0.009287133\n",
      "0.0\n",
      "0.006316255\n",
      "0.006942513\n",
      "0.0034662907\n",
      "0.018824184\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall    F1        F2      F0.5  Average Precision  \\\n",
      "0  0.998811        0.8  0.705882  0.75  0.722892  0.779221           0.565449   \n",
      "\n",
      "   cv_score  test_score  \n",
      "0  0.806684    0.779221  \n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.636364  0.411765  0.500000  0.443038  0.573770   \n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998811   1.000000  0.529412  0.692308  0.584416  0.849057   \n",
      "0  0.999108   1.000000  0.647059  0.785714  0.696203  0.901639   \n",
      "0  0.998959   1.000000  0.588235  0.740741  0.641026  0.877193   \n",
      "0  0.998365   1.000000  0.352941  0.521739  0.405405  0.731707   \n",
      "0  0.998662   0.833333  0.588235  0.689655  0.625000  0.769231   \n",
      "0  0.998662   0.900000  0.529412  0.666667  0.576923  0.789474   \n",
      "0  0.998811   0.909091  0.588235  0.714286  0.632911  0.819672   \n",
      "0  0.998811   0.800000  0.705882  0.750000  0.722892  0.779221   \n",
      "0  0.998216   0.857143  0.352941  0.500000  0.400000  0.666667   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.263519  0.858084    0.573770  \n",
      "0           0.343584  0.846981    0.655738  \n",
      "0           0.471926  0.832352    0.816327  \n",
      "0           0.530601  0.854551    0.849057  \n",
      "0           0.647951  0.810533    0.901639  \n",
      "0           0.589276  0.797385    0.877193  \n",
      "0           0.354577  0.840231    0.731707  \n",
      "0           0.491237  0.791132    0.769231  \n",
      "0           0.477660  0.827651    0.789474  \n",
      "0           0.535800  0.796397    0.819672  \n",
      "0           0.565449  0.806684    0.779221  \n",
      "0           0.304156  0.825570    0.666667  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:42:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1557.480 seconds\n",
      "Cross-validation score: 0.8370298656339846\n",
      "Test score: 0.7142857142857142\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 10, 'classifier__max_depth': 20, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0.7, 'classifier__colsample_bytree': 0.2}\n",
      "0.022456435\n",
      "0.022872915\n",
      "0.07106755\n",
      "0.0\n",
      "0.017550718\n",
      "0.016993487\n",
      "0.0061123534\n",
      "0.0\n",
      "0.01564303\n",
      "0.0\n",
      "0.019006291\n",
      "0.033139586\n",
      "0.0\n",
      "0.0\n",
      "0.0042608427\n",
      "0.0034895083\n",
      "0.01176273\n",
      "0.010018735\n",
      "0.0\n",
      "0.003501987\n",
      "0.0\n",
      "0.023634983\n",
      "0.0061513656\n",
      "0.0019908375\n",
      "0.04694696\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00561257\n",
      "0.0\n",
      "0.007390417\n",
      "0.007079714\n",
      "0.004921866\n",
      "0.0\n",
      "0.007229518\n",
      "0.0\n",
      "0.0021084894\n",
      "0.015871705\n",
      "0.016011605\n",
      "0.024781806\n",
      "0.027077574\n",
      "0.0\n",
      "0.03243608\n",
      "0.0070359935\n",
      "0.008467675\n",
      "0.0026715396\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0067255935\n",
      "0.0054709534\n",
      "0.0053796843\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.028547885\n",
      "0.0038794724\n",
      "0.0047538206\n",
      "0.011563818\n",
      "0.024760885\n",
      "0.034382526\n",
      "0.0\n",
      "0.0\n",
      "0.0026199364\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0076042293\n",
      "0.0057429974\n",
      "0.0\n",
      "0.006201258\n",
      "0.0\n",
      "0.0\n",
      "0.002392902\n",
      "0.0\n",
      "0.0027700458\n",
      "0.0061450303\n",
      "0.0030163815\n",
      "0.004544581\n",
      "0.017971115\n",
      "0.022023182\n",
      "0.018930273\n",
      "0.010407441\n",
      "0.0069274884\n",
      "0.00789374\n",
      "0.0\n",
      "0.0\n",
      "0.003606053\n",
      "0.006323523\n",
      "0.0\n",
      "0.004750266\n",
      "0.026123011\n",
      "0.009026316\n",
      "0.0\n",
      "0.0034276075\n",
      "0.0\n",
      "0.0041526095\n",
      "0.019301817\n",
      "0.0072159404\n",
      "0.0\n",
      "0.003544141\n",
      "0.0\n",
      "0.0\n",
      "0.003297214\n",
      "0.0025515985\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0045482684\n",
      "0.006430943\n",
      "0.0043166145\n",
      "0.026291376\n",
      "0.038056318\n",
      "0.033792302\n",
      "0.0\n",
      "0.012189552\n",
      "0.0\n",
      "0.0054929755\n",
      "0.009334637\n",
      "0.0046315393\n",
      "0.005643267\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall   F1   F2      F0.5  Average Precision  \\\n",
      "0  0.998216   0.857143  0.352941  0.5  0.4  0.666667           0.304156   \n",
      "\n",
      "   cv_score  test_score  \n",
      "0   0.82557    0.666667  \n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.636364  0.411765  0.500000  0.443038  0.573770   \n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998811   1.000000  0.529412  0.692308  0.584416  0.849057   \n",
      "0  0.999108   1.000000  0.647059  0.785714  0.696203  0.901639   \n",
      "0  0.998959   1.000000  0.588235  0.740741  0.641026  0.877193   \n",
      "0  0.998365   1.000000  0.352941  0.521739  0.405405  0.731707   \n",
      "0  0.998662   0.833333  0.588235  0.689655  0.625000  0.769231   \n",
      "0  0.998662   0.900000  0.529412  0.666667  0.576923  0.789474   \n",
      "0  0.998811   0.909091  0.588235  0.714286  0.632911  0.819672   \n",
      "0  0.998811   0.800000  0.705882  0.750000  0.722892  0.779221   \n",
      "0  0.998216   0.857143  0.352941  0.500000  0.400000  0.666667   \n",
      "0  0.998365   0.875000  0.411765  0.560000  0.460526  0.714286   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.263519  0.858084    0.573770  \n",
      "0           0.343584  0.846981    0.655738  \n",
      "0           0.471926  0.832352    0.816327  \n",
      "0           0.530601  0.854551    0.849057  \n",
      "0           0.647951  0.810533    0.901639  \n",
      "0           0.589276  0.797385    0.877193  \n",
      "0           0.354577  0.840231    0.731707  \n",
      "0           0.491237  0.791132    0.769231  \n",
      "0           0.477660  0.827651    0.789474  \n",
      "0           0.535800  0.796397    0.819672  \n",
      "0           0.565449  0.806684    0.779221  \n",
      "0           0.304156  0.825570    0.666667  \n",
      "0           0.361781  0.837030    0.714286  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:07:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1521.631 seconds\n",
      "Cross-validation score: 0.8524214736623387\n",
      "Test score: 0.8163265306122449\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 8, 'classifier__max_depth': 16, 'classifier__learning_rate': 0.55, 'classifier__gamma': 0.1, 'classifier__colsample_bytree': 0.9}\n",
      "0.021643942\n",
      "0.04155194\n",
      "0.04053874\n",
      "0.0\n",
      "0.04416553\n",
      "0.026722938\n",
      "0.0\n",
      "0.0007264727\n",
      "0.00966886\n",
      "0.0\n",
      "0.0\n",
      "0.005265869\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.030745802\n",
      "0.0056598624\n",
      "0.0\n",
      "0.0055331625\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0013478128\n",
      "0.0042530657\n",
      "0.0\n",
      "0.012562218\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0014250792\n",
      "0.010861232\n",
      "0.023579376\n",
      "0.06546404\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.012278082\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0044278274\n",
      "0.0028117143\n",
      "0.018242821\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007561177\n",
      "0.06006602\n",
      "0.10063314\n",
      "0.05305441\n",
      "0.010637318\n",
      "0.0\n",
      "0.0041645435\n",
      "0.017791336\n",
      "0.0\n",
      "0.0\n",
      "0.002606198\n",
      "0.023892974\n",
      "0.009050708\n",
      "0.0\n",
      "0.0040711584\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.005676488\n",
      "0.018772649\n",
      "0.0\n",
      "0.00644925\n",
      "0.050698258\n",
      "0.0036346724\n",
      "0.010490921\n",
      "0.0\n",
      "0.0070226016\n",
      "0.004804665\n",
      "0.0\n",
      "0.018183894\n",
      "0.0\n",
      "0.0022653146\n",
      "0.0\n",
      "0.00984406\n",
      "0.038116764\n",
      "0.0\n",
      "0.0\n",
      "0.0052597346\n",
      "0.0\n",
      "0.0012920629\n",
      "0.014889221\n",
      "0.0010106396\n",
      "0.0024423762\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0027097466\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.008448582\n",
      "0.0039058155\n",
      "0.0\n",
      "0.0047645196\n",
      "0.019158492\n",
      "0.0\n",
      "0.0\n",
      "0.0020832492\n",
      "0.0\n",
      "0.029951783\n",
      "0.006599927\n",
      "0.031449813\n",
      "0.007069187\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall    F1        F2      F0.5  Average Precision  \\\n",
      "0  0.998365      0.875  0.411765  0.56  0.460526  0.714286           0.361781   \n",
      "\n",
      "   cv_score  test_score  \n",
      "0   0.83703    0.714286  \n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.636364  0.411765  0.500000  0.443038  0.573770   \n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998811   1.000000  0.529412  0.692308  0.584416  0.849057   \n",
      "0  0.999108   1.000000  0.647059  0.785714  0.696203  0.901639   \n",
      "0  0.998959   1.000000  0.588235  0.740741  0.641026  0.877193   \n",
      "0  0.998365   1.000000  0.352941  0.521739  0.405405  0.731707   \n",
      "0  0.998662   0.833333  0.588235  0.689655  0.625000  0.769231   \n",
      "0  0.998662   0.900000  0.529412  0.666667  0.576923  0.789474   \n",
      "0  0.998811   0.909091  0.588235  0.714286  0.632911  0.819672   \n",
      "0  0.998811   0.800000  0.705882  0.750000  0.722892  0.779221   \n",
      "0  0.998216   0.857143  0.352941  0.500000  0.400000  0.666667   \n",
      "0  0.998365   0.875000  0.411765  0.560000  0.460526  0.714286   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.263519  0.858084    0.573770  \n",
      "0           0.343584  0.846981    0.655738  \n",
      "0           0.471926  0.832352    0.816327  \n",
      "0           0.530601  0.854551    0.849057  \n",
      "0           0.647951  0.810533    0.901639  \n",
      "0           0.589276  0.797385    0.877193  \n",
      "0           0.354577  0.840231    0.731707  \n",
      "0           0.491237  0.791132    0.769231  \n",
      "0           0.477660  0.827651    0.789474  \n",
      "0           0.535800  0.796397    0.819672  \n",
      "0           0.565449  0.806684    0.779221  \n",
      "0           0.304156  0.825570    0.666667  \n",
      "0           0.361781  0.837030    0.714286  \n",
      "0           0.471926  0.852421    0.816327  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:31:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1455.131 seconds\n",
      "Cross-validation score: 0.8519444747133533\n",
      "Test score: 0.7777777777777777\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 10, 'classifier__max_depth': 12, 'classifier__learning_rate': 0.25, 'classifier__gamma': 0.6, 'classifier__colsample_bytree': 0.1}\n",
      "0.0362863\n",
      "0.039779216\n",
      "0.062741384\n",
      "0.0\n",
      "0.029504707\n",
      "0.0074693686\n",
      "0.013276365\n",
      "0.0\n",
      "0.018414157\n",
      "0.0\n",
      "0.0\n",
      "0.012189711\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0032284274\n",
      "0.02250143\n",
      "0.005032219\n",
      "0.0\n",
      "0.013647152\n",
      "0.025813185\n",
      "0.027935034\n",
      "0.010861295\n",
      "0.005148955\n",
      "0.003384772\n",
      "0.0070602763\n",
      "0.0\n",
      "0.014023594\n",
      "0.0\n",
      "0.020472387\n",
      "0.0\n",
      "0.0033607364\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.008346337\n",
      "0.0\n",
      "0.0021626092\n",
      "0.00991079\n",
      "0.004862918\n",
      "0.0077928524\n",
      "0.023484303\n",
      "0.0028310865\n",
      "0.0026628915\n",
      "0.0\n",
      "0.0038185627\n",
      "0.007032476\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.002398756\n",
      "0.008181687\n",
      "0.0066620884\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.011716205\n",
      "0.0\n",
      "0.0045880037\n",
      "0.012193406\n",
      "0.051256612\n",
      "0.03200141\n",
      "0.0025362866\n",
      "0.0\n",
      "0.007938579\n",
      "0.0\n",
      "0.0\n",
      "0.003096965\n",
      "0.0\n",
      "0.0058880867\n",
      "0.0\n",
      "0.004112216\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0037270186\n",
      "0.0037736353\n",
      "0.010312715\n",
      "0.0029014852\n",
      "0.027087819\n",
      "0.01138429\n",
      "0.01111516\n",
      "0.048029963\n",
      "0.006277913\n",
      "0.010803473\n",
      "0.0027994814\n",
      "0.0\n",
      "0.0\n",
      "0.0019820875\n",
      "0.0\n",
      "0.0029547147\n",
      "0.02184896\n",
      "0.015224676\n",
      "0.0\n",
      "0.0036719528\n",
      "0.0\n",
      "0.009765545\n",
      "0.013950122\n",
      "0.0030415999\n",
      "0.0043151695\n",
      "0.0024841726\n",
      "0.008822075\n",
      "0.0\n",
      "0.0\n",
      "0.0074075507\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0046090824\n",
      "0.006377199\n",
      "0.016369177\n",
      "0.019993369\n",
      "0.054000538\n",
      "0.034844503\n",
      "0.008472428\n",
      "0.0\n",
      "0.0\n",
      "0.006284803\n",
      "0.0\n",
      "0.004102129\n",
      "0.0036594104\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall    F1        F2      F0.5  Average Precision  \\\n",
      "0  0.998662        1.0  0.470588  0.64  0.526316  0.816327           0.471926   \n",
      "\n",
      "   cv_score  test_score  \n",
      "0  0.852421    0.816327  \n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.636364  0.411765  0.500000  0.443038  0.573770   \n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998811   1.000000  0.529412  0.692308  0.584416  0.849057   \n",
      "0  0.999108   1.000000  0.647059  0.785714  0.696203  0.901639   \n",
      "0  0.998959   1.000000  0.588235  0.740741  0.641026  0.877193   \n",
      "0  0.998365   1.000000  0.352941  0.521739  0.405405  0.731707   \n",
      "0  0.998662   0.833333  0.588235  0.689655  0.625000  0.769231   \n",
      "0  0.998662   0.900000  0.529412  0.666667  0.576923  0.789474   \n",
      "0  0.998811   0.909091  0.588235  0.714286  0.632911  0.819672   \n",
      "0  0.998811   0.800000  0.705882  0.750000  0.722892  0.779221   \n",
      "0  0.998216   0.857143  0.352941  0.500000  0.400000  0.666667   \n",
      "0  0.998365   0.875000  0.411765  0.560000  0.460526  0.714286   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998513   1.000000  0.411765  0.583333  0.466667  0.777778   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.263519  0.858084    0.573770  \n",
      "0           0.343584  0.846981    0.655738  \n",
      "0           0.471926  0.832352    0.816327  \n",
      "0           0.530601  0.854551    0.849057  \n",
      "0           0.647951  0.810533    0.901639  \n",
      "0           0.589276  0.797385    0.877193  \n",
      "0           0.354577  0.840231    0.731707  \n",
      "0           0.491237  0.791132    0.769231  \n",
      "0           0.477660  0.827651    0.789474  \n",
      "0           0.535800  0.796397    0.819672  \n",
      "0           0.565449  0.806684    0.779221  \n",
      "0           0.304156  0.825570    0.666667  \n",
      "0           0.361781  0.837030    0.714286  \n",
      "0           0.471926  0.852421    0.816327  \n",
      "0           0.413251  0.851944    0.777778  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:54:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1375.025 seconds\n",
      "Cross-validation score: 0.8527972448582177\n",
      "Test score: 0.660377358490566\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 6, 'classifier__max_depth': 10, 'classifier__learning_rate': 0.15, 'classifier__gamma': 0.7, 'classifier__colsample_bytree': 0.4}\n",
      "0.029836249\n",
      "0.014501749\n",
      "0.0432135\n",
      "0.0\n",
      "0.015269862\n",
      "0.008428171\n",
      "0.0\n",
      "0.0\n",
      "0.0073453593\n",
      "0.0065262173\n",
      "0.009992246\n",
      "0.011997316\n",
      "0.0\n",
      "0.0\n",
      "0.015691308\n",
      "0.013891175\n",
      "0.028458063\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.030084077\n",
      "0.019105751\n",
      "0.0081232805\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007419197\n",
      "0.006116866\n",
      "0.0038081235\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.012474128\n",
      "0.013121254\n",
      "0.0058882087\n",
      "0.013046848\n",
      "0.064875826\n",
      "0.013057631\n",
      "0.008318499\n",
      "0.007459388\n",
      "0.004345794\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.006126439\n",
      "0.0041454663\n",
      "0.009368843\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.034651984\n",
      "0.025650349\n",
      "0.060548574\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0027552329\n",
      "0.0\n",
      "0.0\n",
      "0.008675352\n",
      "0.012664734\n",
      "0.017448058\n",
      "0.0\n",
      "0.011629012\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.005210222\n",
      "0.018424299\n",
      "0.0068941326\n",
      "0.006541003\n",
      "0.0344616\n",
      "0.01514494\n",
      "0.011138307\n",
      "0.01529672\n",
      "0.011648333\n",
      "0.015846832\n",
      "0.0\n",
      "0.008564543\n",
      "0.0\n",
      "0.004419003\n",
      "0.0\n",
      "0.015728613\n",
      "0.025388822\n",
      "0.007490983\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.012148318\n",
      "0.018400442\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.003928557\n",
      "0.0\n",
      "0.011318666\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.008030643\n",
      "0.020406343\n",
      "0.005684427\n",
      "0.016800705\n",
      "0.018617274\n",
      "0.008082733\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0074696187\n",
      "0.008784801\n",
      "0.042068966\n",
      "0.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998513        1.0  0.411765  0.583333  0.466667  0.777778   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.413251  0.851944    0.777778  \n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.636364  0.411765  0.500000  0.443038  0.573770   \n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998811   1.000000  0.529412  0.692308  0.584416  0.849057   \n",
      "0  0.999108   1.000000  0.647059  0.785714  0.696203  0.901639   \n",
      "0  0.998959   1.000000  0.588235  0.740741  0.641026  0.877193   \n",
      "0  0.998365   1.000000  0.352941  0.521739  0.405405  0.731707   \n",
      "0  0.998662   0.833333  0.588235  0.689655  0.625000  0.769231   \n",
      "0  0.998662   0.900000  0.529412  0.666667  0.576923  0.789474   \n",
      "0  0.998811   0.909091  0.588235  0.714286  0.632911  0.819672   \n",
      "0  0.998811   0.800000  0.705882  0.750000  0.722892  0.779221   \n",
      "0  0.998216   0.857143  0.352941  0.500000  0.400000  0.666667   \n",
      "0  0.998365   0.875000  0.411765  0.560000  0.460526  0.714286   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998513   1.000000  0.411765  0.583333  0.466667  0.777778   \n",
      "0  0.998216   0.777778  0.411765  0.538462  0.454545  0.660377   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.263519  0.858084    0.573770  \n",
      "0           0.343584  0.846981    0.655738  \n",
      "0           0.471926  0.832352    0.816327  \n",
      "0           0.530601  0.854551    0.849057  \n",
      "0           0.647951  0.810533    0.901639  \n",
      "0           0.589276  0.797385    0.877193  \n",
      "0           0.354577  0.840231    0.731707  \n",
      "0           0.491237  0.791132    0.769231  \n",
      "0           0.477660  0.827651    0.789474  \n",
      "0           0.535800  0.796397    0.819672  \n",
      "0           0.565449  0.806684    0.779221  \n",
      "0           0.304156  0.825570    0.666667  \n",
      "0           0.361781  0.837030    0.714286  \n",
      "0           0.471926  0.852421    0.816327  \n",
      "0           0.413251  0.851944    0.777778  \n",
      "0           0.321748  0.852797    0.660377  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:20:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1557.767 seconds\n",
      "Cross-validation score: 0.8655896988848933\n",
      "Test score: 0.7407407407407408\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 10, 'classifier__max_depth': 10, 'classifier__learning_rate': 0.6, 'classifier__gamma': 0.0, 'classifier__colsample_bytree': 0.4}\n",
      "0.049029894\n",
      "0.032901026\n",
      "0.07706269\n",
      "0.0038442763\n",
      "0.034602396\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0102778645\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.035680298\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.033453472\n",
      "0.0028055601\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.009005654\n",
      "0.0\n",
      "0.02044309\n",
      "0.0042203213\n",
      "0.0\n",
      "0.047693625\n",
      "0.0049471357\n",
      "0.0101508\n",
      "0.005326472\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007639247\n",
      "0.0\n",
      "0.003831852\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0027496433\n",
      "0.04262364\n",
      "0.020632584\n",
      "0.14511158\n",
      "0.0\n",
      "0.0\n",
      "0.0034536205\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0013974378\n",
      "0.0\n",
      "0.03093984\n",
      "0.0\n",
      "0.016479203\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0063438937\n",
      "0.007756429\n",
      "0.002429222\n",
      "0.01807963\n",
      "0.032510005\n",
      "0.022675447\n",
      "0.015959397\n",
      "0.0\n",
      "0.002880803\n",
      "0.009316059\n",
      "0.0\n",
      "0.0014441338\n",
      "0.0\n",
      "0.0064435555\n",
      "0.0\n",
      "0.0025857151\n",
      "0.051857967\n",
      "0.0\n",
      "0.0030371288\n",
      "0.009742441\n",
      "0.0\n",
      "0.0064666388\n",
      "0.0021240853\n",
      "0.0063461075\n",
      "0.005557862\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007127715\n",
      "0.0\n",
      "0.0\n",
      "0.0035645266\n",
      "0.0\n",
      "0.005252814\n",
      "0.0065498822\n",
      "0.012717817\n",
      "0.030239379\n",
      "0.0139492685\n",
      "0.0\n",
      "0.02373932\n",
      "0.0073799845\n",
      "0.0\n",
      "0.0\n",
      "0.011992515\n",
      "0.0037308873\n",
      "0.0038961791\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998216   0.777778  0.411765  0.538462  0.454545  0.660377   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.321748  0.852797    0.660377  \n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.636364  0.411765  0.500000  0.443038  0.573770   \n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998811   1.000000  0.529412  0.692308  0.584416  0.849057   \n",
      "0  0.999108   1.000000  0.647059  0.785714  0.696203  0.901639   \n",
      "0  0.998959   1.000000  0.588235  0.740741  0.641026  0.877193   \n",
      "0  0.998365   1.000000  0.352941  0.521739  0.405405  0.731707   \n",
      "0  0.998662   0.833333  0.588235  0.689655  0.625000  0.769231   \n",
      "0  0.998662   0.900000  0.529412  0.666667  0.576923  0.789474   \n",
      "0  0.998811   0.909091  0.588235  0.714286  0.632911  0.819672   \n",
      "0  0.998811   0.800000  0.705882  0.750000  0.722892  0.779221   \n",
      "0  0.998216   0.857143  0.352941  0.500000  0.400000  0.666667   \n",
      "0  0.998365   0.875000  0.411765  0.560000  0.460526  0.714286   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998513   1.000000  0.411765  0.583333  0.466667  0.777778   \n",
      "0  0.998216   0.777778  0.411765  0.538462  0.454545  0.660377   \n",
      "0  0.998662   0.750000  0.705882  0.727273  0.714286  0.740741   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.263519  0.858084    0.573770  \n",
      "0           0.343584  0.846981    0.655738  \n",
      "0           0.471926  0.832352    0.816327  \n",
      "0           0.530601  0.854551    0.849057  \n",
      "0           0.647951  0.810533    0.901639  \n",
      "0           0.589276  0.797385    0.877193  \n",
      "0           0.354577  0.840231    0.731707  \n",
      "0           0.491237  0.791132    0.769231  \n",
      "0           0.477660  0.827651    0.789474  \n",
      "0           0.535800  0.796397    0.819672  \n",
      "0           0.565449  0.806684    0.779221  \n",
      "0           0.304156  0.825570    0.666667  \n",
      "0           0.361781  0.837030    0.714286  \n",
      "0           0.471926  0.852421    0.816327  \n",
      "0           0.413251  0.851944    0.777778  \n",
      "0           0.321748  0.852797    0.660377  \n",
      "0           0.530155  0.865590    0.740741  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:43:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1331.115 seconds\n",
      "Cross-validation score: 0.8408237105993066\n",
      "Test score: 0.7777777777777777\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 3, 'classifier__max_depth': 2, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0.3, 'classifier__colsample_bytree': 0.6}\n",
      "0.030296715\n",
      "0.015574882\n",
      "0.09014362\n",
      "0.010712637\n",
      "0.03877248\n",
      "0.01602085\n",
      "0.017128255\n",
      "0.0\n",
      "0.014282883\n",
      "0.0\n",
      "0.016687956\n",
      "0.018629476\n",
      "0.0\n",
      "0.0\n",
      "0.02337949\n",
      "0.0\n",
      "0.015367319\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.029385015\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.010359352\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.003096814\n",
      "0.0013682799\n",
      "0.0\n",
      "0.009990874\n",
      "0.0\n",
      "0.0\n",
      "0.0033112033\n",
      "0.0\n",
      "0.0\n",
      "0.011008514\n",
      "0.0\n",
      "0.0\n",
      "0.016639512\n",
      "0.020664291\n",
      "0.008163209\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.005109932\n",
      "0.0\n",
      "0.008271528\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.004567231\n",
      "0.0025759456\n",
      "0.008710413\n",
      "0.043916438\n",
      "0.04680552\n",
      "0.022942506\n",
      "0.012809973\n",
      "0.0\n",
      "0.0036316735\n",
      "0.0042577954\n",
      "0.0\n",
      "0.0\n",
      "0.0075774966\n",
      "0.009508162\n",
      "0.006201367\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0031355696\n",
      "0.0068151397\n",
      "0.0\n",
      "0.0\n",
      "0.052708738\n",
      "0.01515592\n",
      "0.0\n",
      "0.037363395\n",
      "0.02274633\n",
      "0.0\n",
      "0.0\n",
      "0.020816036\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.002827131\n",
      "0.014755394\n",
      "0.0034885614\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.01224361\n",
      "0.013658763\n",
      "0.0027829048\n",
      "0.0\n",
      "0.0015689956\n",
      "0.0\n",
      "0.0\n",
      "0.007021979\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007259266\n",
      "0.006123737\n",
      "0.0031409431\n",
      "0.028998481\n",
      "0.03589446\n",
      "0.013386722\n",
      "0.0\n",
      "0.0061014323\n",
      "0.0\n",
      "0.0\n",
      "0.01714698\n",
      "0.04323549\n",
      "0.013754464\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998662       0.75  0.705882  0.727273  0.714286  0.740741   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.530155   0.86559    0.740741  \n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.636364  0.411765  0.500000  0.443038  0.573770   \n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998811   1.000000  0.529412  0.692308  0.584416  0.849057   \n",
      "0  0.999108   1.000000  0.647059  0.785714  0.696203  0.901639   \n",
      "0  0.998959   1.000000  0.588235  0.740741  0.641026  0.877193   \n",
      "0  0.998365   1.000000  0.352941  0.521739  0.405405  0.731707   \n",
      "0  0.998662   0.833333  0.588235  0.689655  0.625000  0.769231   \n",
      "0  0.998662   0.900000  0.529412  0.666667  0.576923  0.789474   \n",
      "0  0.998811   0.909091  0.588235  0.714286  0.632911  0.819672   \n",
      "0  0.998811   0.800000  0.705882  0.750000  0.722892  0.779221   \n",
      "0  0.998216   0.857143  0.352941  0.500000  0.400000  0.666667   \n",
      "0  0.998365   0.875000  0.411765  0.560000  0.460526  0.714286   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998513   1.000000  0.411765  0.583333  0.466667  0.777778   \n",
      "0  0.998216   0.777778  0.411765  0.538462  0.454545  0.660377   \n",
      "0  0.998662   0.750000  0.705882  0.727273  0.714286  0.740741   \n",
      "0  0.998513   1.000000  0.411765  0.583333  0.466667  0.777778   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.263519  0.858084    0.573770  \n",
      "0           0.343584  0.846981    0.655738  \n",
      "0           0.471926  0.832352    0.816327  \n",
      "0           0.530601  0.854551    0.849057  \n",
      "0           0.647951  0.810533    0.901639  \n",
      "0           0.589276  0.797385    0.877193  \n",
      "0           0.354577  0.840231    0.731707  \n",
      "0           0.491237  0.791132    0.769231  \n",
      "0           0.477660  0.827651    0.789474  \n",
      "0           0.535800  0.796397    0.819672  \n",
      "0           0.565449  0.806684    0.779221  \n",
      "0           0.304156  0.825570    0.666667  \n",
      "0           0.361781  0.837030    0.714286  \n",
      "0           0.471926  0.852421    0.816327  \n",
      "0           0.413251  0.851944    0.777778  \n",
      "0           0.321748  0.852797    0.660377  \n",
      "0           0.530155  0.865590    0.740741  \n",
      "0           0.413251  0.840824    0.777778  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:10:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1620.029 seconds\n",
      "Cross-validation score: 0.82769706269005\n",
      "Test score: 0.7058823529411765\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 7, 'classifier__max_depth': 2, 'classifier__learning_rate': 0.5, 'classifier__gamma': 0.1, 'classifier__colsample_bytree': 1.0}\n",
      "0.032322057\n",
      "0.018382782\n",
      "0.05843469\n",
      "0.0\n",
      "0.025330769\n",
      "0.02450468\n",
      "0.0\n",
      "0.0\n",
      "0.045940384\n",
      "0.0\n",
      "0.07628528\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.03212443\n",
      "0.0\n",
      "0.029252537\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.03864527\n",
      "0.0038189522\n",
      "0.005480243\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.011373758\n",
      "0.0046595945\n",
      "0.00468784\n",
      "0.0026619781\n",
      "0.0\n",
      "0.004754598\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0042585516\n",
      "0.013789252\n",
      "0.008975683\n",
      "0.002413596\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0018146057\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0035259377\n",
      "0.0\n",
      "0.006048507\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.003726551\n",
      "0.015733069\n",
      "0.0031865034\n",
      "0.14292333\n",
      "0.0\n",
      "0.03470034\n",
      "0.0\n",
      "0.0\n",
      "0.0043989425\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0032029015\n",
      "0.015637213\n",
      "0.0\n",
      "0.009513105\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0041725496\n",
      "0.0067171585\n",
      "0.0016727813\n",
      "0.010540143\n",
      "0.041652896\n",
      "0.02829771\n",
      "0.0\n",
      "0.0\n",
      "0.0076298374\n",
      "0.0\n",
      "0.0\n",
      "0.005899286\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00239726\n",
      "0.019444719\n",
      "0.0\n",
      "0.0\n",
      "0.0027367026\n",
      "0.0\n",
      "0.008008863\n",
      "0.0015358313\n",
      "0.0071602133\n",
      "0.0034879344\n",
      "0.0027017859\n",
      "0.0\n",
      "0.0024908339\n",
      "0.0009673742\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.009199282\n",
      "0.011133783\n",
      "0.0\n",
      "0.003762085\n",
      "0.032844983\n",
      "0.0\n",
      "0.0018530862\n",
      "0.014063903\n",
      "0.0\n",
      "0.0\n",
      "0.008871691\n",
      "0.06504333\n",
      "0.003205947\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998513        1.0  0.411765  0.583333  0.466667  0.777778   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.413251  0.840824    0.777778  \n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.636364  0.411765  0.500000  0.443038  0.573770   \n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998811   1.000000  0.529412  0.692308  0.584416  0.849057   \n",
      "0  0.999108   1.000000  0.647059  0.785714  0.696203  0.901639   \n",
      "0  0.998959   1.000000  0.588235  0.740741  0.641026  0.877193   \n",
      "0  0.998365   1.000000  0.352941  0.521739  0.405405  0.731707   \n",
      "0  0.998662   0.833333  0.588235  0.689655  0.625000  0.769231   \n",
      "0  0.998662   0.900000  0.529412  0.666667  0.576923  0.789474   \n",
      "0  0.998811   0.909091  0.588235  0.714286  0.632911  0.819672   \n",
      "0  0.998811   0.800000  0.705882  0.750000  0.722892  0.779221   \n",
      "0  0.998216   0.857143  0.352941  0.500000  0.400000  0.666667   \n",
      "0  0.998365   0.875000  0.411765  0.560000  0.460526  0.714286   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998513   1.000000  0.411765  0.583333  0.466667  0.777778   \n",
      "0  0.998216   0.777778  0.411765  0.538462  0.454545  0.660377   \n",
      "0  0.998662   0.750000  0.705882  0.727273  0.714286  0.740741   \n",
      "0  0.998513   1.000000  0.411765  0.583333  0.466667  0.777778   \n",
      "0  0.998513   0.705882  0.705882  0.705882  0.705882  0.705882   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.263519  0.858084    0.573770  \n",
      "0           0.343584  0.846981    0.655738  \n",
      "0           0.471926  0.832352    0.816327  \n",
      "0           0.530601  0.854551    0.849057  \n",
      "0           0.647951  0.810533    0.901639  \n",
      "0           0.589276  0.797385    0.877193  \n",
      "0           0.354577  0.840231    0.731707  \n",
      "0           0.491237  0.791132    0.769231  \n",
      "0           0.477660  0.827651    0.789474  \n",
      "0           0.535800  0.796397    0.819672  \n",
      "0           0.565449  0.806684    0.779221  \n",
      "0           0.304156  0.825570    0.666667  \n",
      "0           0.361781  0.837030    0.714286  \n",
      "0           0.471926  0.852421    0.816327  \n",
      "0           0.413251  0.851944    0.777778  \n",
      "0           0.321748  0.852797    0.660377  \n",
      "0           0.530155  0.865590    0.740741  \n",
      "0           0.413251  0.840824    0.777778  \n",
      "0           0.499013  0.827697    0.705882  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:35:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1514.991 seconds\n",
      "Cross-validation score: 0.8123205590726075\n",
      "Test score: 0.7547169811320755\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 10, 'classifier__max_depth': 10, 'classifier__learning_rate': 0.3, 'classifier__gamma': 0.4, 'classifier__colsample_bytree': 0.3}\n",
      "0.03477623\n",
      "0.0146381\n",
      "0.072828285\n",
      "0.0\n",
      "0.025654485\n",
      "0.05265948\n",
      "0.008024569\n",
      "0.010236505\n",
      "0.0\n",
      "0.0\n",
      "0.018324314\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.01965831\n",
      "0.014055947\n",
      "0.002993202\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.034417037\n",
      "0.0067689638\n",
      "0.011746616\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0026019316\n",
      "0.0\n",
      "0.0\n",
      "0.007955087\n",
      "0.0\n",
      "0.0043490506\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00777432\n",
      "0.030600898\n",
      "0.019166362\n",
      "0.0\n",
      "0.0\n",
      "0.008973131\n",
      "0.0\n",
      "0.0041130357\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0088985115\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.013342607\n",
      "0.0043329094\n",
      "0.005430892\n",
      "0.032681752\n",
      "0.032013718\n",
      "0.04285833\n",
      "0.0079679955\n",
      "0.011401423\n",
      "0.0055398685\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00443522\n",
      "0.008139184\n",
      "0.006912443\n",
      "0.0\n",
      "0.009606989\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.008325484\n",
      "0.022302218\n",
      "0.0013506141\n",
      "0.0033320882\n",
      "0.03902884\n",
      "0.03103534\n",
      "0.024467345\n",
      "0.016321437\n",
      "0.012054745\n",
      "0.004713856\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0023977342\n",
      "0.015399641\n",
      "0.0047995024\n",
      "0.0\n",
      "0.0036962337\n",
      "0.0\n",
      "0.011385038\n",
      "0.030191889\n",
      "0.006753935\n",
      "0.0\n",
      "0.011255335\n",
      "0.0073427777\n",
      "0.0\n",
      "0.0\n",
      "0.008367472\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.004223001\n",
      "0.004782987\n",
      "0.012686306\n",
      "0.024158925\n",
      "0.030871015\n",
      "0.020450408\n",
      "0.0\n",
      "0.0\n",
      "0.014343504\n",
      "0.0\n",
      "0.0047305766\n",
      "0.007414159\n",
      "0.0059399507\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998513   0.705882  0.705882  0.705882  0.705882  0.705882   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.499013  0.827697    0.705882  \n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.636364  0.411765  0.500000  0.443038  0.573770   \n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998811   1.000000  0.529412  0.692308  0.584416  0.849057   \n",
      "0  0.999108   1.000000  0.647059  0.785714  0.696203  0.901639   \n",
      "0  0.998959   1.000000  0.588235  0.740741  0.641026  0.877193   \n",
      "0  0.998365   1.000000  0.352941  0.521739  0.405405  0.731707   \n",
      "0  0.998662   0.833333  0.588235  0.689655  0.625000  0.769231   \n",
      "0  0.998662   0.900000  0.529412  0.666667  0.576923  0.789474   \n",
      "0  0.998811   0.909091  0.588235  0.714286  0.632911  0.819672   \n",
      "0  0.998811   0.800000  0.705882  0.750000  0.722892  0.779221   \n",
      "0  0.998216   0.857143  0.352941  0.500000  0.400000  0.666667   \n",
      "0  0.998365   0.875000  0.411765  0.560000  0.460526  0.714286   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998513   1.000000  0.411765  0.583333  0.466667  0.777778   \n",
      "0  0.998216   0.777778  0.411765  0.538462  0.454545  0.660377   \n",
      "0  0.998662   0.750000  0.705882  0.727273  0.714286  0.740741   \n",
      "0  0.998513   1.000000  0.411765  0.583333  0.466667  0.777778   \n",
      "0  0.998513   0.705882  0.705882  0.705882  0.705882  0.705882   \n",
      "0  0.998513   0.888889  0.470588  0.615385  0.519481  0.754717   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.263519  0.858084    0.573770  \n",
      "0           0.343584  0.846981    0.655738  \n",
      "0           0.471926  0.832352    0.816327  \n",
      "0           0.530601  0.854551    0.849057  \n",
      "0           0.647951  0.810533    0.901639  \n",
      "0           0.589276  0.797385    0.877193  \n",
      "0           0.354577  0.840231    0.731707  \n",
      "0           0.491237  0.791132    0.769231  \n",
      "0           0.477660  0.827651    0.789474  \n",
      "0           0.535800  0.796397    0.819672  \n",
      "0           0.565449  0.806684    0.779221  \n",
      "0           0.304156  0.825570    0.666667  \n",
      "0           0.361781  0.837030    0.714286  \n",
      "0           0.471926  0.852421    0.816327  \n",
      "0           0.413251  0.851944    0.777778  \n",
      "0           0.321748  0.852797    0.660377  \n",
      "0           0.530155  0.865590    0.740741  \n",
      "0           0.413251  0.840824    0.777778  \n",
      "0           0.499013  0.827697    0.705882  \n",
      "0           0.419639  0.812321    0.754717  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:00:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1526.148 seconds\n",
      "Cross-validation score: 0.8034970691352177\n",
      "Test score: 0.7894736842105263\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 1, 'classifier__max_depth': 12, 'classifier__learning_rate': 0.15, 'classifier__gamma': 0.6, 'classifier__colsample_bytree': 0.4}\n",
      "0.017323501\n",
      "0.011286418\n",
      "0.030507386\n",
      "0.0038713363\n",
      "0.012113552\n",
      "0.008912943\n",
      "0.0064142533\n",
      "0.005442061\n",
      "0.0061532524\n",
      "0.006569197\n",
      "0.0075518605\n",
      "0.0064636376\n",
      "0.0\n",
      "0.0\n",
      "0.009162448\n",
      "0.012492706\n",
      "0.0154045485\n",
      "0.004692261\n",
      "0.004147171\n",
      "0.0\n",
      "0.0062378454\n",
      "0.018265462\n",
      "0.0085553955\n",
      "0.009379002\n",
      "0.010582722\n",
      "0.018378722\n",
      "0.0\n",
      "0.0062251533\n",
      "0.0040343455\n",
      "0.008127265\n",
      "0.0\n",
      "0.005933266\n",
      "0.0077891336\n",
      "0.012177072\n",
      "0.0070495713\n",
      "0.006363657\n",
      "0.0025265033\n",
      "0.006039981\n",
      "0.012085311\n",
      "0.010720868\n",
      "0.017034644\n",
      "0.010824145\n",
      "0.0077618994\n",
      "0.009397161\n",
      "0.012699667\n",
      "0.007245022\n",
      "0.0071975146\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00900556\n",
      "0.0083019715\n",
      "0.0052252547\n",
      "0.010892463\n",
      "0.0\n",
      "0.0\n",
      "0.014916417\n",
      "0.0032462855\n",
      "0.009366101\n",
      "0.027556414\n",
      "0.019319016\n",
      "0.049003627\n",
      "0.015210717\n",
      "0.0\n",
      "0.006390525\n",
      "0.013107988\n",
      "0.0075967927\n",
      "0.0\n",
      "0.0062987767\n",
      "0.008004589\n",
      "0.0070414487\n",
      "0.005344413\n",
      "0.006683988\n",
      "0.009854506\n",
      "0.007988894\n",
      "0.0\n",
      "0.0039623864\n",
      "0.008367755\n",
      "0.010004984\n",
      "0.005075378\n",
      "0.0073497235\n",
      "0.016690359\n",
      "0.01970682\n",
      "0.0076870415\n",
      "0.007027126\n",
      "0.015045422\n",
      "0.008251003\n",
      "0.0029342668\n",
      "0.011795482\n",
      "0.00380395\n",
      "0.006024783\n",
      "0.0\n",
      "0.0076293075\n",
      "0.011192364\n",
      "0.0049990797\n",
      "0.010561769\n",
      "0.0052072327\n",
      "0.0\n",
      "0.007241662\n",
      "0.010333114\n",
      "0.009569956\n",
      "0.004935387\n",
      "0.007923883\n",
      "0.0036044111\n",
      "0.011973537\n",
      "0.0080372095\n",
      "0.0079838205\n",
      "0.0\n",
      "0.00202555\n",
      "0.0\n",
      "0.0060218554\n",
      "0.007387185\n",
      "0.008432103\n",
      "0.011675171\n",
      "0.013686246\n",
      "0.010449519\n",
      "0.0049715256\n",
      "0.00532244\n",
      "0.007365316\n",
      "0.0054570483\n",
      "0.0038535697\n",
      "0.012617429\n",
      "0.0043201577\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998513   0.888889  0.470588  0.615385  0.519481  0.754717   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.419639  0.812321    0.754717  \n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.636364  0.411765  0.500000  0.443038  0.573770   \n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998811   1.000000  0.529412  0.692308  0.584416  0.849057   \n",
      "0  0.999108   1.000000  0.647059  0.785714  0.696203  0.901639   \n",
      "0  0.998959   1.000000  0.588235  0.740741  0.641026  0.877193   \n",
      "0  0.998365   1.000000  0.352941  0.521739  0.405405  0.731707   \n",
      "0  0.998662   0.833333  0.588235  0.689655  0.625000  0.769231   \n",
      "0  0.998662   0.900000  0.529412  0.666667  0.576923  0.789474   \n",
      "0  0.998811   0.909091  0.588235  0.714286  0.632911  0.819672   \n",
      "0  0.998811   0.800000  0.705882  0.750000  0.722892  0.779221   \n",
      "0  0.998216   0.857143  0.352941  0.500000  0.400000  0.666667   \n",
      "0  0.998365   0.875000  0.411765  0.560000  0.460526  0.714286   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998513   1.000000  0.411765  0.583333  0.466667  0.777778   \n",
      "0  0.998216   0.777778  0.411765  0.538462  0.454545  0.660377   \n",
      "0  0.998662   0.750000  0.705882  0.727273  0.714286  0.740741   \n",
      "0  0.998513   1.000000  0.411765  0.583333  0.466667  0.777778   \n",
      "0  0.998513   0.705882  0.705882  0.705882  0.705882  0.705882   \n",
      "0  0.998513   0.888889  0.470588  0.615385  0.519481  0.754717   \n",
      "0  0.998662   0.900000  0.529412  0.666667  0.576923  0.789474   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.263519  0.858084    0.573770  \n",
      "0           0.343584  0.846981    0.655738  \n",
      "0           0.471926  0.832352    0.816327  \n",
      "0           0.530601  0.854551    0.849057  \n",
      "0           0.647951  0.810533    0.901639  \n",
      "0           0.589276  0.797385    0.877193  \n",
      "0           0.354577  0.840231    0.731707  \n",
      "0           0.491237  0.791132    0.769231  \n",
      "0           0.477660  0.827651    0.789474  \n",
      "0           0.535800  0.796397    0.819672  \n",
      "0           0.565449  0.806684    0.779221  \n",
      "0           0.304156  0.825570    0.666667  \n",
      "0           0.361781  0.837030    0.714286  \n",
      "0           0.471926  0.852421    0.816327  \n",
      "0           0.413251  0.851944    0.777778  \n",
      "0           0.321748  0.852797    0.660377  \n",
      "0           0.530155  0.865590    0.740741  \n",
      "0           0.413251  0.840824    0.777778  \n",
      "0           0.499013  0.827697    0.705882  \n",
      "0           0.419639  0.812321    0.754717  \n",
      "0           0.477660  0.803497    0.789474  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:25:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1517.312 seconds\n",
      "Cross-validation score: 0.8130625574376958\n",
      "Test score: 0.6923076923076923\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 1, 'classifier__max_depth': 16, 'classifier__learning_rate': 0.3, 'classifier__gamma': 0.8, 'classifier__colsample_bytree': 0.8}\n",
      "0.017222555\n",
      "0.02006795\n",
      "0.024390291\n",
      "0.012172934\n",
      "0.01526878\n",
      "0.010819824\n",
      "0.0083431685\n",
      "0.0\n",
      "0.0065542897\n",
      "0.004889781\n",
      "0.013579792\n",
      "0.0037732706\n",
      "0.0\n",
      "0.0\n",
      "0.01128631\n",
      "0.012570192\n",
      "0.012685544\n",
      "0.0053379377\n",
      "0.0\n",
      "0.0\n",
      "0.011311333\n",
      "0.016390273\n",
      "0.0053150174\n",
      "0.0046773157\n",
      "0.010667261\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0058019455\n",
      "0.0067280973\n",
      "0.008773183\n",
      "0.0\n",
      "0.0\n",
      "0.0066051786\n",
      "0.007379075\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.008646832\n",
      "0.017182644\n",
      "0.011390239\n",
      "0.01855783\n",
      "0.017580345\n",
      "0.0071496386\n",
      "0.018270891\n",
      "0.0\n",
      "0.003899414\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007062233\n",
      "0.0051773386\n",
      "0.011613422\n",
      "0.0\n",
      "0.0\n",
      "0.014103161\n",
      "0.0046404027\n",
      "0.019391984\n",
      "0.009772104\n",
      "0.03120659\n",
      "0.04713799\n",
      "0.0818144\n",
      "0.0050013303\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.008824001\n",
      "0.0\n",
      "0.008191303\n",
      "0.011810686\n",
      "0.019962788\n",
      "0.0\n",
      "0.009271174\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0072979955\n",
      "0.010116241\n",
      "0.0\n",
      "0.010615211\n",
      "0.020475758\n",
      "0.017625375\n",
      "0.009159412\n",
      "0.018559268\n",
      "0.023835674\n",
      "0.013123705\n",
      "0.022063117\n",
      "0.008511033\n",
      "0.006465372\n",
      "0.0062662167\n",
      "0.0\n",
      "0.021195674\n",
      "0.008651235\n",
      "0.004646638\n",
      "0.007379407\n",
      "0.00919311\n",
      "0.0\n",
      "0.005034015\n",
      "0.012681823\n",
      "0.0\n",
      "0.0\n",
      "0.0037443643\n",
      "0.0\n",
      "0.002644785\n",
      "0.008729617\n",
      "0.0\n",
      "0.009712857\n",
      "0.0\n",
      "0.0\n",
      "0.006999789\n",
      "0.003465813\n",
      "0.0068260967\n",
      "0.00062385335\n",
      "0.013993531\n",
      "0.0\n",
      "0.0\n",
      "0.012016655\n",
      "0.0\n",
      "0.01204972\n",
      "0.0\n",
      "0.01602666\n",
      "0.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998662        0.9  0.529412  0.666667  0.576923  0.789474   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0            0.47766  0.803497    0.789474  \n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.636364  0.411765  0.500000  0.443038  0.573770   \n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998811   1.000000  0.529412  0.692308  0.584416  0.849057   \n",
      "0  0.999108   1.000000  0.647059  0.785714  0.696203  0.901639   \n",
      "0  0.998959   1.000000  0.588235  0.740741  0.641026  0.877193   \n",
      "0  0.998365   1.000000  0.352941  0.521739  0.405405  0.731707   \n",
      "0  0.998662   0.833333  0.588235  0.689655  0.625000  0.769231   \n",
      "0  0.998662   0.900000  0.529412  0.666667  0.576923  0.789474   \n",
      "0  0.998811   0.909091  0.588235  0.714286  0.632911  0.819672   \n",
      "0  0.998811   0.800000  0.705882  0.750000  0.722892  0.779221   \n",
      "0  0.998216   0.857143  0.352941  0.500000  0.400000  0.666667   \n",
      "0  0.998365   0.875000  0.411765  0.560000  0.460526  0.714286   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998513   1.000000  0.411765  0.583333  0.466667  0.777778   \n",
      "0  0.998216   0.777778  0.411765  0.538462  0.454545  0.660377   \n",
      "0  0.998662   0.750000  0.705882  0.727273  0.714286  0.740741   \n",
      "0  0.998513   1.000000  0.411765  0.583333  0.466667  0.777778   \n",
      "0  0.998513   0.705882  0.705882  0.705882  0.705882  0.705882   \n",
      "0  0.998513   0.888889  0.470588  0.615385  0.519481  0.754717   \n",
      "0  0.998662   0.900000  0.529412  0.666667  0.576923  0.789474   \n",
      "0  0.998365   0.750000  0.529412  0.620690  0.562500  0.692308   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.263519  0.858084    0.573770  \n",
      "0           0.343584  0.846981    0.655738  \n",
      "0           0.471926  0.832352    0.816327  \n",
      "0           0.530601  0.854551    0.849057  \n",
      "0           0.647951  0.810533    0.901639  \n",
      "0           0.589276  0.797385    0.877193  \n",
      "0           0.354577  0.840231    0.731707  \n",
      "0           0.491237  0.791132    0.769231  \n",
      "0           0.477660  0.827651    0.789474  \n",
      "0           0.535800  0.796397    0.819672  \n",
      "0           0.565449  0.806684    0.779221  \n",
      "0           0.304156  0.825570    0.666667  \n",
      "0           0.361781  0.837030    0.714286  \n",
      "0           0.471926  0.852421    0.816327  \n",
      "0           0.413251  0.851944    0.777778  \n",
      "0           0.321748  0.852797    0.660377  \n",
      "0           0.530155  0.865590    0.740741  \n",
      "0           0.413251  0.840824    0.777778  \n",
      "0           0.499013  0.827697    0.705882  \n",
      "0           0.419639  0.812321    0.754717  \n",
      "0           0.477660  0.803497    0.789474  \n",
      "0           0.398248  0.813063    0.692308  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05:52:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1567.466 seconds\n",
      "Cross-validation score: 0.8400198684763531\n",
      "Test score: 0.7246376811594203\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 1, 'classifier__max_depth': 18, 'classifier__learning_rate': 0.15, 'classifier__gamma': 0.2, 'classifier__colsample_bytree': 0.5}\n",
      "0.017783398\n",
      "0.010445803\n",
      "0.023265544\n",
      "0.0069849156\n",
      "0.013042193\n",
      "0.009539294\n",
      "0.0072332597\n",
      "0.0044642272\n",
      "0.0071337754\n",
      "0.004953865\n",
      "0.010919995\n",
      "0.005994347\n",
      "0.002657501\n",
      "0.0\n",
      "0.00947422\n",
      "0.0\n",
      "0.020102803\n",
      "0.0047182417\n",
      "0.005347487\n",
      "0.0052059675\n",
      "0.009526406\n",
      "0.012553446\n",
      "0.004668325\n",
      "0.003976835\n",
      "0.008236402\n",
      "0.0\n",
      "0.0\n",
      "0.0043390603\n",
      "0.0066785053\n",
      "0.0036627545\n",
      "0.004747202\n",
      "0.01801832\n",
      "0.011034906\n",
      "0.0032005971\n",
      "0.006261696\n",
      "0.004800747\n",
      "0.00469419\n",
      "0.006768458\n",
      "0.013532625\n",
      "0.03761838\n",
      "0.0087037375\n",
      "0.0143677145\n",
      "0.006070503\n",
      "0.009417574\n",
      "0.013436762\n",
      "0.03934586\n",
      "0.0042739236\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0076544173\n",
      "0.0004485746\n",
      "0.0049625686\n",
      "0.0055663814\n",
      "0.0\n",
      "0.0\n",
      "0.00753941\n",
      "0.0048160967\n",
      "0.0036263578\n",
      "0.0301554\n",
      "0.031324908\n",
      "0.03888488\n",
      "0.006316641\n",
      "0.0075205723\n",
      "0.0066313576\n",
      "0.004059015\n",
      "0.0040000156\n",
      "0.0\n",
      "0.004602538\n",
      "0.004450619\n",
      "0.0074921553\n",
      "0.004294001\n",
      "0.010325219\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.012626809\n",
      "0.005115594\n",
      "0.014443863\n",
      "0.009053467\n",
      "0.016285451\n",
      "0.0073732096\n",
      "0.009153972\n",
      "0.010785006\n",
      "0.011835916\n",
      "0.031518452\n",
      "0.012073266\n",
      "0.0071247593\n",
      "0.0\n",
      "0.007049268\n",
      "0.0\n",
      "0.014336291\n",
      "0.010797278\n",
      "0.0\n",
      "0.0054840706\n",
      "0.004140962\n",
      "0.0\n",
      "0.00886516\n",
      "0.007699191\n",
      "0.004002959\n",
      "0.0045920257\n",
      "0.011515489\n",
      "0.0032387285\n",
      "0.0030968257\n",
      "0.0067871492\n",
      "0.0018344466\n",
      "0.0\n",
      "0.00339347\n",
      "0.0\n",
      "0.00718871\n",
      "0.008812887\n",
      "0.014204813\n",
      "0.014458495\n",
      "0.016296895\n",
      "0.012826207\n",
      "0.0018985167\n",
      "0.011214787\n",
      "0.0020779679\n",
      "0.0053625475\n",
      "0.012225156\n",
      "0.020652266\n",
      "0.0046848287\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall       F1      F2      F0.5  \\\n",
      "0  0.998365       0.75  0.529412  0.62069  0.5625  0.692308   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.398248  0.813063    0.692308  \n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.636364  0.411765  0.500000  0.443038  0.573770   \n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998811   1.000000  0.529412  0.692308  0.584416  0.849057   \n",
      "0  0.999108   1.000000  0.647059  0.785714  0.696203  0.901639   \n",
      "0  0.998959   1.000000  0.588235  0.740741  0.641026  0.877193   \n",
      "0  0.998365   1.000000  0.352941  0.521739  0.405405  0.731707   \n",
      "0  0.998662   0.833333  0.588235  0.689655  0.625000  0.769231   \n",
      "0  0.998662   0.900000  0.529412  0.666667  0.576923  0.789474   \n",
      "0  0.998811   0.909091  0.588235  0.714286  0.632911  0.819672   \n",
      "0  0.998811   0.800000  0.705882  0.750000  0.722892  0.779221   \n",
      "0  0.998216   0.857143  0.352941  0.500000  0.400000  0.666667   \n",
      "0  0.998365   0.875000  0.411765  0.560000  0.460526  0.714286   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998513   1.000000  0.411765  0.583333  0.466667  0.777778   \n",
      "0  0.998216   0.777778  0.411765  0.538462  0.454545  0.660377   \n",
      "0  0.998662   0.750000  0.705882  0.727273  0.714286  0.740741   \n",
      "0  0.998513   1.000000  0.411765  0.583333  0.466667  0.777778   \n",
      "0  0.998513   0.705882  0.705882  0.705882  0.705882  0.705882   \n",
      "0  0.998513   0.888889  0.470588  0.615385  0.519481  0.754717   \n",
      "0  0.998662   0.900000  0.529412  0.666667  0.576923  0.789474   \n",
      "0  0.998365   0.750000  0.529412  0.620690  0.562500  0.692308   \n",
      "0  0.998513   0.769231  0.588235  0.666667  0.617284  0.724638   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.263519  0.858084    0.573770  \n",
      "0           0.343584  0.846981    0.655738  \n",
      "0           0.471926  0.832352    0.816327  \n",
      "0           0.530601  0.854551    0.849057  \n",
      "0           0.647951  0.810533    0.901639  \n",
      "0           0.589276  0.797385    0.877193  \n",
      "0           0.354577  0.840231    0.731707  \n",
      "0           0.491237  0.791132    0.769231  \n",
      "0           0.477660  0.827651    0.789474  \n",
      "0           0.535800  0.796397    0.819672  \n",
      "0           0.565449  0.806684    0.779221  \n",
      "0           0.304156  0.825570    0.666667  \n",
      "0           0.361781  0.837030    0.714286  \n",
      "0           0.471926  0.852421    0.816327  \n",
      "0           0.413251  0.851944    0.777778  \n",
      "0           0.321748  0.852797    0.660377  \n",
      "0           0.530155  0.865590    0.740741  \n",
      "0           0.413251  0.840824    0.777778  \n",
      "0           0.499013  0.827697    0.705882  \n",
      "0           0.419639  0.812321    0.754717  \n",
      "0           0.477660  0.803497    0.789474  \n",
      "0           0.398248  0.813063    0.692308  \n",
      "0           0.453529  0.840020    0.724638  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:20:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1681.048 seconds\n",
      "Cross-validation score: 0.8176605875690542\n",
      "Test score: 0.8461538461538461\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 9, 'classifier__max_depth': 8, 'classifier__learning_rate': 0.25, 'classifier__gamma': 0.6, 'classifier__colsample_bytree': 0.2}\n",
      "0.027981607\n",
      "0.019025546\n",
      "0.039914478\n",
      "0.0\n",
      "0.025728663\n",
      "0.012835792\n",
      "0.0021307191\n",
      "0.0\n",
      "0.015966978\n",
      "0.0\n",
      "0.02019319\n",
      "0.016637834\n",
      "0.0\n",
      "0.0\n",
      "0.019855244\n",
      "0.0029060037\n",
      "0.010486606\n",
      "0.0\n",
      "0.0030290885\n",
      "0.008340126\n",
      "0.0\n",
      "0.015449965\n",
      "0.0040073553\n",
      "0.009077386\n",
      "0.018733641\n",
      "0.008455257\n",
      "0.0076214727\n",
      "0.0\n",
      "0.0\n",
      "0.012157812\n",
      "0.0\n",
      "0.0\n",
      "0.003479851\n",
      "0.0\n",
      "0.016277775\n",
      "0.004577668\n",
      "0.0\n",
      "0.0059053013\n",
      "0.012100523\n",
      "0.014764965\n",
      "0.005198684\n",
      "0.016816402\n",
      "0.0\n",
      "0.012541658\n",
      "0.0051368135\n",
      "0.00817843\n",
      "0.004454905\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.011866252\n",
      "0.0075404863\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.021503156\n",
      "0.0026310477\n",
      "0.007552999\n",
      "0.0\n",
      "0.066509865\n",
      "0.035368416\n",
      "0.0020129674\n",
      "0.0\n",
      "0.0030403954\n",
      "0.009506022\n",
      "0.004358728\n",
      "0.0\n",
      "0.0\n",
      "0.01479404\n",
      "0.0\n",
      "0.0\n",
      "0.0068007526\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0027279945\n",
      "0.02772114\n",
      "0.0065485463\n",
      "0.003782225\n",
      "0.027152712\n",
      "0.022709502\n",
      "0.012413525\n",
      "0.013938878\n",
      "0.007937925\n",
      "0.009826821\n",
      "0.0\n",
      "0.0026895883\n",
      "0.0028099262\n",
      "0.0\n",
      "0.0\n",
      "0.006609677\n",
      "0.019695675\n",
      "0.0066456427\n",
      "0.0022506202\n",
      "0.0022656317\n",
      "0.0\n",
      "0.007079809\n",
      "0.020078871\n",
      "0.0053000418\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.009267073\n",
      "0.011227205\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0036793367\n",
      "0.006526923\n",
      "0.002789514\n",
      "0.02138576\n",
      "0.0327895\n",
      "0.034080375\n",
      "0.005991649\n",
      "0.004628058\n",
      "0.0016325659\n",
      "0.005536121\n",
      "0.0066574425\n",
      "0.03612161\n",
      "0.0040492574\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.998513   0.769231  0.588235  0.666667  0.617284  0.724638   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.453529   0.84002    0.724638  \n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.636364  0.411765  0.500000  0.443038  0.573770   \n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998811   1.000000  0.529412  0.692308  0.584416  0.849057   \n",
      "0  0.999108   1.000000  0.647059  0.785714  0.696203  0.901639   \n",
      "0  0.998959   1.000000  0.588235  0.740741  0.641026  0.877193   \n",
      "0  0.998365   1.000000  0.352941  0.521739  0.405405  0.731707   \n",
      "0  0.998662   0.833333  0.588235  0.689655  0.625000  0.769231   \n",
      "0  0.998662   0.900000  0.529412  0.666667  0.576923  0.789474   \n",
      "0  0.998811   0.909091  0.588235  0.714286  0.632911  0.819672   \n",
      "0  0.998811   0.800000  0.705882  0.750000  0.722892  0.779221   \n",
      "0  0.998216   0.857143  0.352941  0.500000  0.400000  0.666667   \n",
      "0  0.998365   0.875000  0.411765  0.560000  0.460526  0.714286   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998513   1.000000  0.411765  0.583333  0.466667  0.777778   \n",
      "0  0.998216   0.777778  0.411765  0.538462  0.454545  0.660377   \n",
      "0  0.998662   0.750000  0.705882  0.727273  0.714286  0.740741   \n",
      "0  0.998513   1.000000  0.411765  0.583333  0.466667  0.777778   \n",
      "0  0.998513   0.705882  0.705882  0.705882  0.705882  0.705882   \n",
      "0  0.998513   0.888889  0.470588  0.615385  0.519481  0.754717   \n",
      "0  0.998662   0.900000  0.529412  0.666667  0.576923  0.789474   \n",
      "0  0.998365   0.750000  0.529412  0.620690  0.562500  0.692308   \n",
      "0  0.998513   0.769231  0.588235  0.666667  0.617284  0.724638   \n",
      "0  0.998959   0.916667  0.647059  0.758621  0.687500  0.846154   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.263519  0.858084    0.573770  \n",
      "0           0.343584  0.846981    0.655738  \n",
      "0           0.471926  0.832352    0.816327  \n",
      "0           0.530601  0.854551    0.849057  \n",
      "0           0.647951  0.810533    0.901639  \n",
      "0           0.589276  0.797385    0.877193  \n",
      "0           0.354577  0.840231    0.731707  \n",
      "0           0.491237  0.791132    0.769231  \n",
      "0           0.477660  0.827651    0.789474  \n",
      "0           0.535800  0.796397    0.819672  \n",
      "0           0.565449  0.806684    0.779221  \n",
      "0           0.304156  0.825570    0.666667  \n",
      "0           0.361781  0.837030    0.714286  \n",
      "0           0.471926  0.852421    0.816327  \n",
      "0           0.413251  0.851944    0.777778  \n",
      "0           0.321748  0.852797    0.660377  \n",
      "0           0.530155  0.865590    0.740741  \n",
      "0           0.413251  0.840824    0.777778  \n",
      "0           0.499013  0.827697    0.705882  \n",
      "0           0.419639  0.812321    0.754717  \n",
      "0           0.477660  0.803497    0.789474  \n",
      "0           0.398248  0.813063    0.692308  \n",
      "0           0.453529  0.840020    0.724638  \n",
      "0           0.594029  0.817661    0.846154  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:45:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Elapsed time to compute best fit: 1490.370 seconds\n",
      "Cross-validation score: 0.8282951177466567\n",
      "Test score: 0.8771929824561404\n",
      "Best Hyperparameters: {'classifier__min_child_weight': 10, 'classifier__max_depth': 20, 'classifier__learning_rate': 0.35, 'classifier__gamma': 0.5, 'classifier__colsample_bytree': 0.3}\n",
      "0.04014066\n",
      "0.02067864\n",
      "0.058260985\n",
      "0.0\n",
      "0.028923104\n",
      "0.0\n",
      "0.011637523\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.03864932\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.040493187\n",
      "0.0\n",
      "0.013114424\n",
      "0.0\n",
      "0.0\n",
      "0.027486484\n",
      "0.0\n",
      "0.043072112\n",
      "0.0054737604\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.006639543\n",
      "0.01238989\n",
      "0.0\n",
      "0.0048587057\n",
      "0.0056446698\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.02143818\n",
      "0.012465622\n",
      "0.006913664\n",
      "0.014057444\n",
      "0.0\n",
      "0.005579692\n",
      "0.008386345\n",
      "0.004165718\n",
      "0.0030776907\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.008532318\n",
      "0.0\n",
      "0.015436978\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.012169782\n",
      "0.0040262644\n",
      "0.056593277\n",
      "0.03615816\n",
      "0.05604669\n",
      "0.0\n",
      "0.0\n",
      "0.002093178\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.017853608\n",
      "0.0060463552\n",
      "0.022801097\n",
      "0.0\n",
      "0.007917485\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.004084143\n",
      "0.012184312\n",
      "0.0\n",
      "0.0024262457\n",
      "0.023723288\n",
      "0.03792321\n",
      "0.02349078\n",
      "0.01664557\n",
      "0.0054342924\n",
      "0.0042169928\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0056782244\n",
      "0.01486049\n",
      "0.0\n",
      "0.0\n",
      "0.002927697\n",
      "0.0\n",
      "0.0109793795\n",
      "0.011951219\n",
      "0.011716138\n",
      "0.0024128216\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.013563459\n",
      "0.020761613\n",
      "0.0\n",
      "0.013486248\n",
      "0.033985734\n",
      "0.0\n",
      "0.005787656\n",
      "0.019553838\n",
      "0.0025915853\n",
      "0.005155358\n",
      "0.0054549356\n",
      "0.0051523075\n",
      "0.0046299202\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   Accuracy  Precision    Recall        F1      F2      F0.5  \\\n",
      "0  0.998959   0.916667  0.647059  0.758621  0.6875  0.846154   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.594029  0.817661    0.846154  \n",
      "   Accuracy  Precision    Recall        F1        F2      F0.5  \\\n",
      "0  0.997919   0.636364  0.411765  0.500000  0.443038  0.573770   \n",
      "0  0.998216   0.727273  0.470588  0.571429  0.506329  0.655738   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998811   1.000000  0.529412  0.692308  0.584416  0.849057   \n",
      "0  0.999108   1.000000  0.647059  0.785714  0.696203  0.901639   \n",
      "0  0.998959   1.000000  0.588235  0.740741  0.641026  0.877193   \n",
      "0  0.998365   1.000000  0.352941  0.521739  0.405405  0.731707   \n",
      "0  0.998662   0.833333  0.588235  0.689655  0.625000  0.769231   \n",
      "0  0.998662   0.900000  0.529412  0.666667  0.576923  0.789474   \n",
      "0  0.998811   0.909091  0.588235  0.714286  0.632911  0.819672   \n",
      "0  0.998811   0.800000  0.705882  0.750000  0.722892  0.779221   \n",
      "0  0.998216   0.857143  0.352941  0.500000  0.400000  0.666667   \n",
      "0  0.998365   0.875000  0.411765  0.560000  0.460526  0.714286   \n",
      "0  0.998662   1.000000  0.470588  0.640000  0.526316  0.816327   \n",
      "0  0.998513   1.000000  0.411765  0.583333  0.466667  0.777778   \n",
      "0  0.998216   0.777778  0.411765  0.538462  0.454545  0.660377   \n",
      "0  0.998662   0.750000  0.705882  0.727273  0.714286  0.740741   \n",
      "0  0.998513   1.000000  0.411765  0.583333  0.466667  0.777778   \n",
      "0  0.998513   0.705882  0.705882  0.705882  0.705882  0.705882   \n",
      "0  0.998513   0.888889  0.470588  0.615385  0.519481  0.754717   \n",
      "0  0.998662   0.900000  0.529412  0.666667  0.576923  0.789474   \n",
      "0  0.998365   0.750000  0.529412  0.620690  0.562500  0.692308   \n",
      "0  0.998513   0.769231  0.588235  0.666667  0.617284  0.724638   \n",
      "0  0.998959   0.916667  0.647059  0.758621  0.687500  0.846154   \n",
      "0  0.998959   1.000000  0.588235  0.740741  0.641026  0.877193   \n",
      "\n",
      "   Average Precision  cv_score  test_score  \n",
      "0           0.263519  0.858084    0.573770  \n",
      "0           0.343584  0.846981    0.655738  \n",
      "0           0.471926  0.832352    0.816327  \n",
      "0           0.530601  0.854551    0.849057  \n",
      "0           0.647951  0.810533    0.901639  \n",
      "0           0.589276  0.797385    0.877193  \n",
      "0           0.354577  0.840231    0.731707  \n",
      "0           0.491237  0.791132    0.769231  \n",
      "0           0.477660  0.827651    0.789474  \n",
      "0           0.535800  0.796397    0.819672  \n",
      "0           0.565449  0.806684    0.779221  \n",
      "0           0.304156  0.825570    0.666667  \n",
      "0           0.361781  0.837030    0.714286  \n",
      "0           0.471926  0.852421    0.816327  \n",
      "0           0.413251  0.851944    0.777778  \n",
      "0           0.321748  0.852797    0.660377  \n",
      "0           0.530155  0.865590    0.740741  \n",
      "0           0.413251  0.840824    0.777778  \n",
      "0           0.499013  0.827697    0.705882  \n",
      "0           0.419639  0.812321    0.754717  \n",
      "0           0.477660  0.803497    0.789474  \n",
      "0           0.398248  0.813063    0.692308  \n",
      "0           0.453529  0.840020    0.724638  \n",
      "0           0.594029  0.817661    0.846154  \n",
      "0           0.589276  0.828295    0.877193  \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "fhalf_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "\n",
    "none_xgboost_nonnormalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': [],\n",
    "        'cv_score': [],\n",
    "        'test_score': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "    GXBoostPipeline = Pipeline(steps = [#['smote', SMOTE()],\n",
    "                                    #['under', RandomUnderSampler()],\n",
    "                                ['classifier', xgb.XGBClassifier(n_jobs=2)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    space['classifier__learning_rate'] = [0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60]\n",
    "    space['classifier__max_depth'] = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "    space['classifier__min_child_weight'] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    space['classifier__gamma'] = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    space['classifier__colsample_bytree'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    spaceEmpty = dict()\n",
    "\n",
    "    GXBoostSearch = RandomizedSearchCV(estimator = GXBoostPipeline, \n",
    "                            param_distributions=space, \n",
    "                            n_iter=100, \n",
    "                            scoring=fhalf_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedGXBoostModel = GXBoostSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    \n",
    "    cv_score = optimizedGXBoostModel.best_score_\n",
    "    test_score = optimizedGXBoostModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedGXBoostModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedGXBoostModel.best_estimator_._final_estimator.feature_importances_\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance = showModelPerformance(trainedModel = optimizedGXBoostModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    print(type(new_performance))\n",
    "    print(new_performance_df)\n",
    "    new_performance_df = pd.DataFrame(new_performance)\n",
    "    \n",
    "    cv_score_array = [cv_score]\n",
    "    test_score_array = [test_score]\n",
    "  \n",
    "    # Using 'Address' as the column name\n",
    "    # and equating it to the list\n",
    "    new_performance_df['cv_score'] = cv_score_array\n",
    "    new_performance_df['test_score'] = test_score_array\n",
    "    \n",
    "    none_xgboost_nonnormalized_performance_df = pd.concat([none_xgboost_nonnormalized_performance_df, new_performance_df])\n",
    "    \n",
    "    print(none_xgboost_nonnormalized_performance_df)\n",
    "\n",
    "none_xgboost_nonnormalized_performance_df.to_csv(\"../data/05_model_output/none_xgboost_nonnormalized_performance_hyperparameter_fhalf_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classical-kitty",
   "metadata": {},
   "source": [
    "### 5.1.3 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-isolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "\n",
    "#Import feature selection stuff\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "\n",
    "# Import the model we are using\n",
    "import lightgbm as lgb\n",
    "\n",
    "none_lightgbm_performance_nonnormalized_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "\n",
    "    ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "    LightGBMPipeline = Pipeline(steps = [#['smote', SMOTE()],\n",
    "                                    #['under', RandomUnderSampler()],\n",
    "                                ['classifier', lgb.LGBMClassifier(n_jobs=-1, importance_type='gain')]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "# define search space\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    spaceEmpty = dict()\n",
    "    space['classifier__num_leaves'] = [11, 16, 21, 26, 31, 36, 41, 46, 51, 56]\n",
    "    space['classifier__min_data_in_leaf'] =  [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__max_depth'] = [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__learning_rate'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9, 1.0]\n",
    "    space['classifier__max_bin'] = [50, 100, 150, 200, 255, 300, 350, 400, 450, 500]\n",
    "\n",
    "    LightGBMSearch = RandomizedSearchCV(estimator = LightGBMPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring= ftwo_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedLightGBMModel = LightGBMSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedLightGBMModel.best_score_\n",
    "    test_score = optimizedLightGBMModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedLightGBMModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedLightGBMModel.best_estimator_._final_estimator.booster_.feature_importance(importance_type='gain')\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedLightGBMModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    none_lightgbm_performance_nonnormalized_df = pd.concat([none_lightgbm_performance_nonnormalized_df, new_performance_df])\n",
    "    \n",
    "\n",
    "none_lightgbm_performance_nonnormalized_df.to_csv(\"../data/05_model_output/none_lightgbm_performance_nonnormalized_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-short",
   "metadata": {},
   "source": [
    "## 5.2 Rebalancing Strategy - SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-madison",
   "metadata": {},
   "source": [
    "### 5.2.1 Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-advocate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "smote_randomforest_nonnormalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "    pipeline = Pipeline(steps = [['smote', SMOTE()],\n",
    "                              #['under', RandomUnderSampler()],\n",
    "                                ['classifier', RandomForestClassifier(n_jobs=-1)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    spaceEmpty = dict() \n",
    "\n",
    "    search = RandomizedSearchCV(estimator = pipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring='f1', \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedRFModel = search.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    #print(f\"Elapsed time to compute best fit: \"\n",
    "      #f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedRFModel.best_score_\n",
    "    test_score = optimizedRFModel.score(X_test, y_test)\n",
    "    #print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    #print('Best Hyperparameters: %s' % optimizedRFModel.best_params_)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedRFModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    \n",
    "    smote_randomforest_nonnormalized_performance_df = pd.concat([smote_randomforest_nonnormalized_performance_df, new_performance_df])\n",
    "    \n",
    "smote_randomforest_nonnormalized_performance_df.to_csv(\"../data/05_model_output/smote_randomforest_nonnormalized_performance_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-custody",
   "metadata": {},
   "source": [
    "### 5.2.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fresh-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "fhalf_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "\n",
    "smote_xgboost_nonnormalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "    GXBoostPipeline = Pipeline(steps = [['smote', SMOTE()],\n",
    "                                    #['under', RandomUnderSampler()],\n",
    "                                ['classifier', xgb.XGBClassifier(n_jobs=2)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    space['classifier__learning_rate'] = [0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60]\n",
    "    space['classifier__max_depth'] = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "    space['classifier__min_child_weight'] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    space['classifier__gamma'] = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    space['classifier__colsample_bytree'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    spaceEmpty = dict()\n",
    "\n",
    "    GXBoostSearch = RandomizedSearchCV(estimator = GXBoostPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring=fhalf_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedGXBoostModel = GXBoostSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    \n",
    "    cv_score = optimizedGXBoostModel.best_score_\n",
    "    test_score = optimizedGXBoostModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedGXBoostModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedGXBoostModel.best_estimator_._final_estimator.feature_importances_\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedGXBoostModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    print(new_performance_df)\n",
    "    smote_xgboost_nonnormalized_performance_df = pd.concat([smote_xgboost_nonnormalized_performance_df, new_performance_df])\n",
    "    \n",
    "\n",
    "smote_xgboost_nonnormalized_performance_df.to_csv(\"../data/05_model_output/smote_xgboost_nonnormalized_performance_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-request",
   "metadata": {},
   "source": [
    "### 5.2.3 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "\n",
    "#Import feature selection stuff\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "\n",
    "# Import the model we are using\n",
    "import lightgbm as lgb\n",
    "\n",
    "smote_lightgbm_performance_nonnormalized_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "\n",
    "    ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "    LightGBMPipeline = Pipeline(steps = [['smote', SMOTE()],\n",
    "                                    #['under', RandomUnderSampler()],\n",
    "                                ['classifier', lgb.LGBMClassifier(n_jobs=-1, importance_type='gain')]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "# define search space\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    spaceEmpty = dict()\n",
    "    space['classifier__num_leaves'] = [11, 16, 21, 26, 31, 36, 41, 46, 51, 56]\n",
    "    space['classifier__min_data_in_leaf'] =  [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__max_depth'] = [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__learning_rate'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9, 1.0]\n",
    "    space['classifier__max_bin'] = [50, 100, 150, 200, 255, 300, 350, 400, 450, 500]\n",
    "\n",
    "    LightGBMSearch = RandomizedSearchCV(estimator = LightGBMPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring= ftwo_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedLightGBMModel = LightGBMSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedLightGBMModel.best_score_\n",
    "    test_score = optimizedLightGBMModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedLightGBMModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedLightGBMModel.best_estimator_._final_estimator.booster_.feature_importance(importance_type='gain')\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedLightGBMModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    smote_lightgbm_performance_nonnormalized_df = pd.concat([smote_lightgbm_performance_nonnormalized_df, new_performance_df])\n",
    "    \n",
    "\n",
    "smote_lightgbm_performance_nonnormalized_df.to_csv(\"../data/05_model_output/smote_lightgbm_performance_nonnormalized_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-short",
   "metadata": {},
   "source": [
    "## 5.3 Rebalancing Strategy - UNDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-allocation",
   "metadata": {},
   "source": [
    "### 5.3.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "under_randomforest_nonnormalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "    pipeline = Pipeline(steps = [#['smote', SMOTE()],\n",
    "                              ['under', RandomUnderSampler()],\n",
    "                                ['classifier', RandomForestClassifier(n_jobs=-1)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    spaceEmpty = dict() \n",
    "\n",
    "    search = RandomizedSearchCV(estimator = pipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring='f1', \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedRFModel = search.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    #print(f\"Elapsed time to compute best fit: \"\n",
    "      #f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedRFModel.best_score_\n",
    "    test_score = optimizedRFModel.score(X_test, y_test)\n",
    "    #print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    #print('Best Hyperparameters: %s' % optimizedRFModel.best_params_)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedRFModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    \n",
    "    under_randomforest_nonnormalized_performance_df = pd.concat([under_randomforest_nonnormalized_performance_df, new_performance_df])\n",
    "    \n",
    "under_randomforest_nonnormalized_performance_df.to_csv(\"../data/05_model_output/under_randomforest_nonnormalized_performance_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-alias",
   "metadata": {},
   "source": [
    "### 5.3.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "fhalf_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "\n",
    "under_xgboost_nonnormalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "    GXBoostPipeline = Pipeline(steps = [#['smote', SMOTE()],\n",
    "                                    ['under', RandomUnderSampler()],\n",
    "                                ['classifier', xgb.XGBClassifier(n_jobs=2)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    space['classifier__learning_rate'] = [0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60]\n",
    "    space['classifier__max_depth'] = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "    space['classifier__min_child_weight'] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    space['classifier__gamma'] = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    space['classifier__colsample_bytree'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    spaceEmpty = dict()\n",
    "\n",
    "    GXBoostSearch = RandomizedSearchCV(estimator = GXBoostPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring=fhalf_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedGXBoostModel = GXBoostSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    \n",
    "    cv_score = optimizedGXBoostModel.best_score_\n",
    "    test_score = optimizedGXBoostModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedGXBoostModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedGXBoostModel.best_estimator_._final_estimator.feature_importances_\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedGXBoostModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    print(new_performance_df)\n",
    "    under_xgboost_nonnormalized_performance_df = pd.concat([under_xgboost_nonnormalized_performance_df, new_performance_df])\n",
    "    \n",
    "\n",
    "under_xgboost_nonnormalized_performance_df.to_csv(\"../data/05_model_output/under_xgboost_nonnormalized_performance_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-vinyl",
   "metadata": {},
   "source": [
    "### 5.3.3 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "\n",
    "#Import feature selection stuff\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "\n",
    "# Import the model we are using\n",
    "import lightgbm as lgb\n",
    "\n",
    "under_lightgbm_performance_nonnormalized_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "\n",
    "    ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "    LightGBMPipeline = Pipeline(steps = [#['smote', SMOTE()],\n",
    "                                    ['under', RandomUnderSampler()],\n",
    "                                ['classifier', lgb.LGBMClassifier(n_jobs=-1, importance_type='gain')]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "# define search space\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    spaceEmpty = dict()\n",
    "    space['classifier__num_leaves'] = [11, 16, 21, 26, 31, 36, 41, 46, 51, 56]\n",
    "    space['classifier__min_data_in_leaf'] =  [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__max_depth'] = [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__learning_rate'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9, 1.0]\n",
    "    space['classifier__max_bin'] = [50, 100, 150, 200, 255, 300, 350, 400, 450, 500]\n",
    "\n",
    "    LightGBMSearch = RandomizedSearchCV(estimator = LightGBMPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring= ftwo_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedLightGBMModel = LightGBMSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedLightGBMModel.best_score_\n",
    "    test_score = optimizedLightGBMModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedLightGBMModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedLightGBMModel.best_estimator_._final_estimator.booster_.feature_importance(importance_type='gain')\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedLightGBMModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    under_lightgbm_performance_nonnormalized_df = pd.concat([under_lightgbm_performance_nonnormalized_df, new_performance_df])\n",
    "    \n",
    "\n",
    "under_lightgbm_performance_nonnormalized_df.to_csv(\"../data/05_model_output/under_lightgbm_performance_nonnormalized_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-spider",
   "metadata": {},
   "source": [
    "## 5.1 Rebalancing Strategy - 5050"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-clerk",
   "metadata": {},
   "source": [
    "### 5.4.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "answering-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "fiftyfifty_randomforest_nonnormalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "    pipeline = Pipeline(steps = [['smote', SMOTE(sampling_strategy = 0.5)],\n",
    "                              ['under', RandomUnderSampler()],\n",
    "                                ['classifier', RandomForestClassifier(n_jobs=-1)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    spaceEmpty = dict() \n",
    "\n",
    "    search = RandomizedSearchCV(estimator = pipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring='f1', \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedRFModel = search.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    #print(f\"Elapsed time to compute best fit: \"\n",
    "      #f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedRFModel.best_score_\n",
    "    test_score = optimizedRFModel.score(X_test, y_test)\n",
    "    #print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    #print('Best Hyperparameters: %s' % optimizedRFModel.best_params_)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedRFModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    \n",
    "    fiftyfifty_randomforest_nonnormalized_performance_df = pd.concat([fiftyfifty_randomforest_nonnormalized_performance_df, new_performance_df])\n",
    "    \n",
    "fiftyfifty_randomforest_nonnormalized_performance_df.to_csv(\"../data/05_model_output/fiftyfifty_randomforest_nonnormalized_performance_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-feedback",
   "metadata": {},
   "source": [
    "### 5.4.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-revision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "fhalf_scorer = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "\n",
    "fiftyfifty_xgboost_nonnormalized_performance_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "    GXBoostPipeline = Pipeline(steps = [['smote', SMOTE(sampling_strategy = 0.5)],\n",
    "                                    ['under', RandomUnderSampler()],\n",
    "                                ['classifier', xgb.XGBClassifier(n_jobs=2)]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    space['classifier__learning_rate'] = [0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60]\n",
    "    space['classifier__max_depth'] = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "    space['classifier__min_child_weight'] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    space['classifier__gamma'] = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    space['classifier__colsample_bytree'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    spaceEmpty = dict()\n",
    "\n",
    "    GXBoostSearch = RandomizedSearchCV(estimator = GXBoostPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring=fhalf_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedGXBoostModel = GXBoostSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    \n",
    "    cv_score = optimizedGXBoostModel.best_score_\n",
    "    test_score = optimizedGXBoostModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedGXBoostModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedGXBoostModel.best_estimator_._final_estimator.feature_importances_\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedGXBoostModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    print(new_performance_df)\n",
    "    fiftyfifty_xgboost_nonnormalized_performance_df = pd.concat([fiftyfifty_xgboost_nonnormalized_performance_df, new_performance_df])\n",
    "    \n",
    "\n",
    "fiftyfifty_xgboost_nonnormalized_performance_df.to_csv(\"../data/05_model_output/fiftyfifty_xgboost_nonnormalized_performance_df.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-drain",
   "metadata": {},
   "source": [
    "### 5.4.3 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-wheel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "\n",
    "#Import feature selection stuff\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "\n",
    "# Import the model we are using\n",
    "import lightgbm as lgb\n",
    "\n",
    "fiftyfifty_lightgbm_performance_nonnormalized_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "\n",
    "    ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "    start_time = time.time()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "    LightGBMPipeline = Pipeline(steps = [['smote', SMOTE(sampling_strategy = 0.5)],\n",
    "                                    ['under', RandomUnderSampler()],\n",
    "                                ['classifier', lgb.LGBMClassifier(n_jobs=-1, importance_type='gain')]])\n",
    "\n",
    "    stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "# define search space\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    spaceEmpty = dict()\n",
    "    space['classifier__num_leaves'] = [11, 16, 21, 26, 31, 36, 41, 46, 51, 56]\n",
    "    space['classifier__min_data_in_leaf'] =  [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__max_depth'] = [-1, 100, 200, 300, 400, 500, 600, 700, 800, 900]\n",
    "    space['classifier__learning_rate'] = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.9, 1.0]\n",
    "    space['classifier__max_bin'] = [50, 100, 150, 200, 255, 300, 350, 400, 450, 500]\n",
    "\n",
    "    LightGBMSearch = RandomizedSearchCV(estimator = LightGBMPipeline, \n",
    "                            param_distributions=spaceEmpty, \n",
    "                            n_iter=100, \n",
    "                            scoring= ftwo_scorer, \n",
    "                            n_jobs=-1, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "    optimizedLightGBMModel = LightGBMSearch.fit(X_train, y_train)\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "    cv_score = optimizedLightGBMModel.best_score_\n",
    "    test_score = optimizedLightGBMModel.score(X_test, y_test)\n",
    "    print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "    print('Best Hyperparameters: %s' % optimizedLightGBMModel.best_params_)\n",
    "    \n",
    "    #feature importance\n",
    "    importances = optimizedLightGBMModel.best_estimator_._final_estimator.booster_.feature_importance(importance_type='gain')\n",
    "    for i,v in enumerate(importances):\n",
    "        print(v)\n",
    "\n",
    "\n",
    "    #Display the model performance    \n",
    "    new_performance_df = showModelPerformance(trainedModel = optimizedLightGBMModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)\n",
    "    fiftyfifty_lightgbm_performance_nonnormalized_df = pd.concat([fiftyfifty_lightgbm_performance_nonnormalized_df, new_performance_df])\n",
    "    \n",
    "\n",
    "fiftyfifty_lightgbm_performance_nonnormalized_df.to_csv(\"../data/05_model_output/fiftyfifty_lightgbm_performance_nonnormalized_df.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-might",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-sharp",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-strategy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-chambers",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-death",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-balance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
