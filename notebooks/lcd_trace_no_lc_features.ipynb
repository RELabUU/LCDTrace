{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "southern-success",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\rande\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#Import Python Libraries\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "#Import Self-written Functions\n",
    "import os\n",
    "import sys\n",
    "src_dir = os.path.join(os.getcwd(), '..', 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from d00_utils.calculateTimeDifference import calculateTimeDifference #Function to calc time difference\n",
    "from d01_data.loadCommits import loadCommits #Function to load SVN data\n",
    "from d02_intermediate.cleanCommitData import cleanCommitData #Function to clean commit data\n",
    "from d02_intermediate.cleanJiraData import cleanJiraData #Function to clean JIRA data\n",
    "\n",
    "from d03_processing.createFittedTF_IDF import createFittedTF_IDF #Function to see if a trace is valid\n",
    "from d03_processing.createCorpusFromDocumentList import createCorpusFromDocumentList #Function to create a corpus\n",
    "from d03_processing.checkValidityTrace import checkValidityTrace #Function to see if a trace is valid\n",
    "from d03_processing.calculateTimeDif import calculateTimeDif #Calculate the time difference between 2 dates in seconds\n",
    "from d03_processing.checkFullnameEqualsEmail import checkFullnameEqualsEmail #Check if fullName is equal to the email\n",
    "from d03_processing.calculateCosineSimilarity import calculateCosineSimilarity #Calculate the cos similarity\n",
    "from d03_processing.calculateDocumentStatistics import *\n",
    "\n",
    "from d03_processing.calculateQueryQuality import *\n",
    "from d03_processing.normalize_data import *\n",
    "\n",
    "from d04_model_evaluation.model_evaluation import *\n",
    "\n",
    "#Display full value of a column\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "#Display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-texas",
   "metadata": {},
   "source": [
    "## 3.1 Load Cartesian and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caring-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Cartersian Product\n",
    "cartesian_df = pd.read_pickle(r'../data/03_processed/cartesian_df.pkl')\n",
    "labels_df = pd.read_pickle(r'../data/03_processed/labels_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-nomination",
   "metadata": {},
   "source": [
    "# 3.2 Recalculate non-LC-specific features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "duplicate-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Document Statistics Features\n",
    "features_document_statistics = pd.read_pickle(r'../data/03_processed/features_document_statistics.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "thrown-coordinate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149853, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cartesian_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "professional-weather",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51415, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_document_statistics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bacterial-paintball",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f5_total_terms_jira</th>\n",
       "      <th>f6_total_terms_svn</th>\n",
       "      <th>f7_unique_terms_jira</th>\n",
       "      <th>f8_unique_terms_svn</th>\n",
       "      <th>f9_overlap_terms_compared_to_jira</th>\n",
       "      <th>f10_overlap_terms_to_svn</th>\n",
       "      <th>f11_overlap_terms_to_union</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      f5_total_terms_jira  f6_total_terms_svn  f7_unique_terms_jira  \\\n",
       "1578                   62                 NaN                    43   \n",
       "1579                   62                 NaN                    43   \n",
       "1580                   62                 NaN                    43   \n",
       "1581                   62                 NaN                    43   \n",
       "1582                   62                 NaN                    43   \n",
       "\n",
       "      f8_unique_terms_svn  f9_overlap_terms_compared_to_jira  \\\n",
       "1578                  NaN                                NaN   \n",
       "1579                  NaN                                NaN   \n",
       "1580                  NaN                                NaN   \n",
       "1581                  NaN                                NaN   \n",
       "1582                  NaN                                NaN   \n",
       "\n",
       "      f10_overlap_terms_to_svn  f11_overlap_terms_to_union  \n",
       "1578                       NaN                         NaN  \n",
       "1579                       NaN                         NaN  \n",
       "1580                       NaN                         NaN  \n",
       "1581                       NaN                         NaN  \n",
       "1582                       NaN                         NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_document_statistics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unnecessary-agriculture",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate total terms JIRA for each trace\n",
    "features_document_statistics[\"f6_total_terms_svn\"] = cartesian_df.apply(lambda x: calculateTotalWordCount(x.Commit_natural_text), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Calculate unique terms JIRA for each trace\n",
    "features_document_statistics[\"f8_unique_terms_svn\"] = cartesian_df.apply(lambda x: calculateUniqueWordCount(x.Commit_natural_text), \n",
    "                                                            axis=1)\n",
    "\n",
    "\n",
    "features_document_statistics[\"f9_overlap_terms_compared_to_jira\"] = cartesian_df.apply(lambda x: calculateOverlapBetweenDocuments(x.Jira_natural_text, x.Commit_natural_text, 'list1'),\n",
    "                                                            axis=1)\n",
    "features_document_statistics[\"f10_overlap_terms_to_svn\"] = cartesian_df.apply(lambda x: calculateOverlapBetweenDocuments(x.Jira_natural_text, x.Commit_natural_text, 'list2'),\n",
    "                                                            axis=1)\n",
    "features_document_statistics[\"f11_overlap_terms_to_union\"] = cartesian_df.apply(lambda x: calculateOverlapBetweenDocuments(x.Jira_natural_text, x.Commit_natural_text, 'union'),\n",
    "                                                            axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "civilian-thompson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f5_total_terms_jira</th>\n",
       "      <th>f6_total_terms_svn</th>\n",
       "      <th>f7_unique_terms_jira</th>\n",
       "      <th>f8_unique_terms_svn</th>\n",
       "      <th>f9_overlap_terms_compared_to_jira</th>\n",
       "      <th>f10_overlap_terms_to_svn</th>\n",
       "      <th>f11_overlap_terms_to_union</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      f5_total_terms_jira  f6_total_terms_svn  f7_unique_terms_jira  \\\n",
       "1578                   62                 NaN                    43   \n",
       "1579                   62                 NaN                    43   \n",
       "1580                   62                 NaN                    43   \n",
       "1581                   62                 NaN                    43   \n",
       "1582                   62                 NaN                    43   \n",
       "\n",
       "      f8_unique_terms_svn  f9_overlap_terms_compared_to_jira  \\\n",
       "1578                  NaN                                NaN   \n",
       "1579                  NaN                                NaN   \n",
       "1580                  NaN                                NaN   \n",
       "1581                  NaN                                NaN   \n",
       "1582                  NaN                                NaN   \n",
       "\n",
       "      f10_overlap_terms_to_svn  f11_overlap_terms_to_union  \n",
       "1578                       NaN                         NaN  \n",
       "1579                       NaN                         NaN  \n",
       "1580                       NaN                         NaN  \n",
       "1581                       NaN                         NaN  \n",
       "1582                       NaN                         NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_document_statistics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "proprietary-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save results in pickle\n",
    "features_document_statistics.to_pickle(path= \"../data/03_processed/features_document_statistics.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-marijuana",
   "metadata": {},
   "source": [
    "## 3.3 Remove LC-specific features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "professional-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Information Retrieval Features\n",
    "features_information_retrieval = pd.read_pickle(r'../data/03_processed/features_information_retrieval.pkl')\n",
    "\n",
    "#Load Query Quality Features\n",
    "features_qq_specificity = pd.read_pickle(r'../data/03_processed/features_qq_specificity.pkl')\n",
    "features_qq_similarity = pd.read_pickle(r'../data/03_processed/features_qq_similarity.pkl')\n",
    "features_qq_termrelatedness = pd.read_pickle(r'../data/03_processed/features_qq_termrelatedness.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "previous-morgan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All features which need to be removed from the final feature set\n",
    "features_to_be_removed_list = [\"f18_ir_unitname_and_summary_unitname_as_query\",\n",
    "                               \"f19_ir_unitname_and_summary_summary_as_query\",\n",
    "                               \"f20_ir_unitname_and_description_unitname_as_query\",\n",
    "                               \"f21_ir_unitname_and_description_description_as_query\",\n",
    "                               \"f22_ir_unitname_and_jira_all_unitname_as_query\",\n",
    "                               \"f23_ir_unitname_and_jira_all_jira_all_as_query\",\n",
    "                               \"f24_ir_svn_all_and_summary_svn_all_as_query\",\n",
    "                               \"f25_ir_svn_all_and_summary_summary_as_query\",\n",
    "                               \"f26_ir_svn_all_and_description_svn_all_as_query\",\n",
    "                               \"f27_ir_svn_all_and_description_description_as_query\",\n",
    "                               \"f28_ir_svn_all_and_jira_all_svn_all_as_query\",\n",
    "                               \"f29_ir_svn_all_and_jira_all_jira_all_as_query\",\n",
    "                               \"f30_avgidf_svn_all_as_query\",\n",
    "                               \"f31_maxidf_svn_all_as_query\",\n",
    "                               \"f32_devidf_svn_all_as_query\",\n",
    "                               \"f36_avgidf_unitname_as_query\",\n",
    "                               \"f37_maxidf_unitname_as_query\",\n",
    "                               \"f38_devidf_unitname_as_query\",\n",
    "                               \"f48_avgictf_svn_all_as_query\",\n",
    "                               \"f49_maxictf_svn_all_as_query\",\n",
    "                               \"f50_devictf_svn_all_as_query\",\n",
    "                               \"f54_avgictf_svn_unitname_as_query\",\n",
    "                               \"f55_maxictf_svn_unitname_as_query\",\n",
    "                               \"f56_devictf_svn_unitname_as_query\",\n",
    "                               \"f66_avgentropy_svn_all_as_query\",\n",
    "                               \"f67_medentropy_svn_all_as_query\",\n",
    "                               \"f68_maxentropy_svn_all_as_query\",    \n",
    "                               \"f69_deventropy_svn_all_as_query\",\n",
    "                               \"f74_avgentropy_svn_unitname_as_query\",    \n",
    "                               \"f75_medentropy_svn_unitname_as_query\",\n",
    "                               \"f76_maxentropy_svn_unitname_as_query\",    \n",
    "                               \"f77_deventropy_svn_unitname_as_query\",\n",
    "                               \"f90_queryscope_svn_all_as_query\",    \n",
    "                               \"f92_queryscope_svn_unitname_as_query\",\n",
    "                               \"f96_scs_svn_all_as_query\",    \n",
    "                               \"f98_scs_svn_unitname_as_query\",\n",
    "                               \"f102_SvnAsQuery_avgSCQ\", \n",
    "                               \"f103_SvnAsQuery_maxSCQ\",\n",
    "                               \"f104_SvnAsQuery_sumSCQ\",\n",
    "                               \"f108_avgscq_svn_unitname_as_query\",\n",
    "                               \"f109_maxscq_svn_unitname_as_query\",\n",
    "                               \"f110_sumscq_svn_unitname_as_query\",\n",
    "                               \"f120_avgpmi_svn_all_as_query\",\n",
    "                               \"f121_maxpmi_svn_all_as_query\",\n",
    "                               \"f124_avgpmi_svn_unitname_as_query\",\n",
    "                               \"f125_maxpmi_svn_unitname_as_query\"                            \n",
    "                              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "protecting-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove LCD-specific features\n",
    "features_information_retrieval = features_information_retrieval[features_information_retrieval.columns.difference(features_to_be_removed_list)]\n",
    "features_qq_specificity = features_qq_specificity[features_qq_specificity.columns.difference(features_to_be_removed_list)]\n",
    "features_qq_similarity = features_qq_similarity[features_qq_similarity.columns.difference(features_to_be_removed_list)]\n",
    "features_qq_termrelatedness = features_qq_termrelatedness[features_qq_termrelatedness.columns.difference(features_to_be_removed_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "special-poland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51415, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_qq_termrelatedness.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "needed-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save results in pickle\n",
    "features_information_retrieval.to_pickle(path= \"../data/03_processed/features_information_retrieval.pkl\")\n",
    "features_qq_specificity.to_pickle(path= \"../data/03_processed/features_qq_specificity.pkl\")\n",
    "features_qq_similarity.to_pickle(path= \"../data/03_processed/features_qq_similarity.pkl\")\n",
    "features_qq_termrelatedness.to_pickle(path= \"../data/03_processed/features_qq_termrelatedness.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-material",
   "metadata": {},
   "source": [
    "## 3.8 Preprocess Data - Load and transform feature families needed for training\n",
    "Load features and create a normalized set of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "behavioral-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Process-Related Features\n",
    "features_process_related = pd.read_pickle(r'../data/03_processed/features_process_related.pkl')\n",
    "\n",
    "#Load IR-Related Features\n",
    "features_information_retrieval = pd.read_pickle(r'../data/03_processed/features_information_retrieval.pkl')\n",
    "\n",
    "#Load Document Statistics Features\n",
    "features_document_statistics = pd.read_pickle(r'../data/03_processed/features_document_statistics.pkl')\n",
    "\n",
    "#Load Query Quality Features\n",
    "features_qq_specificity = pd.read_pickle(r'../data/03_processed/features_qq_specificity.pkl')\n",
    "features_qq_similarity = pd.read_pickle(r'../data/03_processed/features_qq_similarity.pkl')\n",
    "features_qq_termrelatedness = pd.read_pickle(r'../data/03_processed/features_qq_termrelatedness.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "superb-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize Process-Related Features\n",
    "features_process_related_normalized = normalize_data(features_process_related)\n",
    "\n",
    "#Normalize IR-Related Features\n",
    "features_information_retrieval_normalized = normalize_data(features_information_retrieval)\n",
    "\n",
    "#Normalize Document Statistics Features\n",
    "features_document_statistics_normalized = normalize_data(features_document_statistics)\n",
    "\n",
    "#Normalize Query Quality Features\n",
    "features_qq_specificity_normalized = normalize_data(features_qq_specificity)\n",
    "features_qq_similarity_normalized = normalize_data(features_qq_similarity)\n",
    "features_qq_termrelatedness_normalized = normalize_data(features_qq_termrelatedness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-tower",
   "metadata": {},
   "source": [
    "Put all features in a single data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sophisticated-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a single data frame for the non-normalized features\n",
    "features_all_df = pd.concat([features_process_related,\n",
    "                             features_document_statistics,\n",
    "                             features_information_retrieval,\n",
    "                             features_qq_specificity,\n",
    "                             features_qq_similarity,\n",
    "                             features_qq_termrelatedness], axis=1)\n",
    "\n",
    "#Create a single data frame for the normalized features\n",
    "features_all_normalized_df = pd.concat([features_process_related_normalized,\n",
    "                                        features_document_statistics_normalized,\n",
    "                                        features_information_retrieval_normalized,\n",
    "                                        features_qq_specificity_normalized,\n",
    "                                        features_qq_similarity_normalized,\n",
    "                                        features_qq_termrelatedness_normalized], axis=1)\n",
    "\n",
    "#Save into xlsx files\n",
    "features_all_df.to_excel(excel_writer = \"../results/1. Trace Link Feature Data/features_non-normalized.xlsx\", index = False)\n",
    "features_all_normalized_df.to_excel(excel_writer = \"../results/1. Trace Link Feature Data/features_normalized.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "alert-treaty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51415, 85)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-clothing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "romantic-paint",
   "metadata": {},
   "source": [
    "Perform additional preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "forty-disorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the NaN to 0\n",
    "features_all_df = features_all_df.fillna(0)\n",
    "features_all_normalized_df = features_all_normalized_df.fillna(0)\n",
    "\n",
    "#Saving feature names for later use\n",
    "feature_name_df = list(features_all_df.columns)\n",
    "\n",
    "#Transform pandas data frame into numpy arrays\n",
    "features_all_array = np.array(features_all_df)\n",
    "features_all_normalized_array = np.array(features_all_normalized_df)\n",
    "\n",
    "#Load labels\n",
    "labels_df = pd.read_pickle(r'../data/03_processed/labels_df.pkl')\n",
    "labels_array = np.array(labels_df[\"is_valid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-album",
   "metadata": {},
   "source": [
    "# 4.1 Evaluation - Non-normalized\n",
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "defensive-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Python Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "#Method to show the different model evaluation metrics\n",
    "def showModelPerformance(trainedModel, testFeatures, testLabels):\n",
    "    # Use the fitted model to predict the labels of the test set\n",
    "    predictionLabels = trainedModel.predict(testFeatures)\n",
    "    \n",
    "    #Calculate the different metrics for the test vs predicted labels\n",
    "    accuracyValue = accuracy_score(testLabels.astype(bool), predictionLabels)\n",
    "    precisionValue = precision_score(testLabels.astype(bool), predictionLabels, average='binary')\n",
    "    f1Value = f1_score(testLabels.astype(bool), predictionLabels)\n",
    "    f2Value = fbeta_score(testLabels.astype(bool), predictionLabels, beta=2.0)\n",
    "    f05Value = fbeta_score(testLabels.astype(bool), predictionLabels, beta=0.5)\n",
    "    recallValue = recall_score(testLabels.astype(bool), predictionLabels)\n",
    "    averagePrecisionValue = average_precision_score(testLabels.astype(bool), predictionLabels)\n",
    "    \n",
    "    #Create a dataframe to output all evaluation metrics in\n",
    "    performanceData = {'Accuracy':  [accuracyValue],\n",
    "                       'Precision': [precisionValue],\n",
    "                       'Recall': [recallValue],\n",
    "                       'F1': [f1Value],\n",
    "                       'F2': [f2Value],\n",
    "                       'F0.5': [f05Value],\n",
    "                       'Average Precision': [averagePrecisionValue]\n",
    "                      }\n",
    "    performanceDf = pd.DataFrame(performanceData)\n",
    "    return(performanceDf)\n",
    "\n",
    "#Method to define the Pipeline steps based on the given rebalancing strategy and classification algorithm\n",
    "def define_steps(rebalancing_strategy, classification_algorithm):\n",
    "    steps = None\n",
    "    if(rebalancing_strategy == 'none'):\n",
    "        if(classification_algorithm == 'random_forests'):\n",
    "            steps = [['classifier', RandomForestClassifier(n_jobs=-1)]]\n",
    "        elif (classification_algorithm == 'xg_boost'):\n",
    "            steps = [['classifier', xgb.XGBClassifier(n_jobs=-1)]]\n",
    "            return(steps)\n",
    "        elif(classification_algorithm == 'light_gbm'):\n",
    "            steps = [['classifier', lgb.LGBMClassifier(n_jobs=-1, importance_type='gain')]]\n",
    "    elif(rebalancing_strategy == 'over'):\n",
    "        if(classification_algorithm == 'random_forests'):\n",
    "            steps = [['smote', SMOTE()],\n",
    "                    ['classifier', RandomForestClassifier(n_jobs=-1)]]\n",
    "        elif (classification_algorithm == 'xg_boost'):\n",
    "            steps = [['smote', SMOTE()],\n",
    "                    ['classifier', xgb.XGBClassifier(n_jobs=-1)]]\n",
    "        elif(classification_algorithm == 'light_gbm'):\n",
    "            steps = [['smote', SMOTE()],\n",
    "                    ['classifier', lgb.LGBMClassifier(n_jobs=-1, importance_type='gain')]]\n",
    "    elif(rebalancing_strategy == 'under'):\n",
    "        if(classification_algorithm == 'random_forests'):\n",
    "            steps = [['under', RandomUnderSampler()],\n",
    "                    ['classifier', RandomForestClassifier(n_jobs=-1)]]\n",
    "        elif (classification_algorithm == 'xg_boost'):\n",
    "            steps = [['under', RandomUnderSampler()],\n",
    "                    ['classifier', xgb.XGBClassifier(n_jobs=-1)]]\n",
    "        elif(classification_algorithm == 'light_gbm'):\n",
    "            steps = [['under', RandomUnderSampler()],\n",
    "                    ['classifier', lgb.LGBMClassifier(n_jobs=-1, importance_type='gain')]]\n",
    "    elif(rebalancing_strategy == '5050'):\n",
    "        if(classification_algorithm == 'random_forests'):\n",
    "            steps = [['smote', SMOTE(sampling_strategy = 0.5)],\n",
    "                    ['under', RandomUnderSampler()],\n",
    "                    ['classifier', RandomForestClassifier(n_jobs=-1)]]\n",
    "        elif (classification_algorithm == 'xg_boost'):\n",
    "            steps = [['smote', SMOTE(sampling_strategy = 0.5)],\n",
    "                    ['under', RandomUnderSampler()],\n",
    "                    ['classifier', xgb.XGBClassifier(n_jobs=-1)]]\n",
    "        elif(classification_algorithm == 'light_gbm'):\n",
    "            steps = [['smote', SMOTE(sampling_strategy = 0.5)],\n",
    "                    ['under', RandomUnderSampler()],\n",
    "                    ['classifier', lgb.LGBMClassifier(n_jobs=-1, importance_type='gain')]]\n",
    "    return steps\n",
    "\n",
    "#Method to generate the f1, f2, f0.5, accuracy, precision, recall, and average precision\n",
    "def generate_evaluation_metrics(rebalancing_strategy, classification_algorithm, data, labels, is_normalized, n_runs, feature_names):\n",
    "    #Create a dataframe to append to the results of each individual run\n",
    "    evaluation_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "    \n",
    "    #Create a np array to put the importances per feature in\n",
    "    importance_array = np.empty(shape=(n_runs, 85))\n",
    "    \n",
    "    #Perform the described pipeline steps to produce the results for the defined number of runs\n",
    "    for i in range(n_runs):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data,\n",
    "                                                        labels,\n",
    "                                                        test_size=0.2,\n",
    "                                                        stratify=labels)\n",
    "        \n",
    "        #Set the pipeline steps according to the defined rebalancing strategy and classification algorithm\n",
    "        steps = define_steps(rebalancing_strategy, classification_algorithm)\n",
    "        \n",
    "        #Create the pipeline\n",
    "        model_pipeline = Pipeline(steps=steps)\n",
    "        \n",
    "        space_empty = dict()    \n",
    "        \n",
    "        stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)           \n",
    "    \n",
    "        #Create a model\n",
    "        model = RandomizedSearchCV(estimator = model_pipeline, \n",
    "                                param_distributions = space_empty, \n",
    "                                n_iter=1, \n",
    "                                n_jobs=-1, \n",
    "                                cv = stratified_kfold)\n",
    "        \n",
    "        #Fit the model on the training data\n",
    "        fitted_model = model.fit(X_train, y_train)\n",
    "        \n",
    "        #Evaluate the fitted model\n",
    "        fitted_model_evaluation_df = showModelPerformance(trainedModel = fitted_model, \n",
    "                         testFeatures = X_test, \n",
    "                         testLabels = y_test)     \n",
    "        \n",
    "        #Add the evaluation of the current run to the results of the previous runs\n",
    "        evaluation_df = pd.concat([evaluation_df,\n",
    "                                   fitted_model_evaluation_df])\n",
    "        \n",
    "        #Find the feature importances of the fitted model\n",
    "        if(classification_algorithm == \"light_gbm\"):\n",
    "            current_importances = fitted_model.best_estimator_._final_estimator.booster_.feature_importance(importance_type='gain')\n",
    "        else:\n",
    "            current_importances = fitted_model.best_estimator_._final_estimator.feature_importances_\n",
    "        #Add the feature importances of the current fitted model to the results of the previous runs\n",
    "\n",
    "        importance_array[i] = current_importances  \n",
    "    \n",
    "    if is_normalized == True:\n",
    "        dir_string = \"3. Normalised Results\"\n",
    "    else:\n",
    "        dir_string = \"2. Non-Normalised Results\"\n",
    "    \n",
    "    #Set the index as the run number\n",
    "    evaluation_df = evaluation_df.reset_index(drop = True)\n",
    "    evaluation_df.index += 1 \n",
    "    evaluation_df.index.name = \"run\"\n",
    "    \n",
    "    #Output the evaluation data to a csv file\n",
    "    evaluation_df.to_csv(\"../results/\" + dir_string + \"/\" + classification_algorithm + \"/\" + rebalancing_strategy + \"_results.csv\")\n",
    "    \n",
    "    #Transform the importance array to a data frame\n",
    "    importance_df = pd.DataFrame(data=importance_array, \n",
    "                                 columns= feature_names, \n",
    "                                 index=list(range(1, n_runs +1)))\n",
    "    \n",
    "    #Set the index as the run number\n",
    "    importance_df.index.name = \"run\"\n",
    "    \n",
    "    #Output the importance data to a csv file\n",
    "    importance_df.to_csv(\"../results/4. Feature Importance Results/\" + classification_algorithm + \"/\" + rebalancing_strategy + \"_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-digest",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "strategic-monaco",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:05:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:06:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:07:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:08:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:09:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:10:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:11:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:12:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:13:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:14:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:15:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:16:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:17:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:18:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:19:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:20:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:21:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:22:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:23:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:24:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:26:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:27:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rande\\AppData\\Roaming\\Python\\Python39\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "generate_evaluation_metrics(rebalancing_strategy = 'none', \n",
    "                            classification_algorithm = 'xg_boost', \n",
    "                            data = features_all_array, \n",
    "                            labels = labels_array, \n",
    "                            feature_names = feature_name_df,\n",
    "                            is_normalized = False,\n",
    "                            n_runs = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-calculator",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "handmade-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluation_metrics(rebalancing_strategy = '5050', \n",
    "                            classification_algorithm = 'light_gbm', \n",
    "                            data = features_all_array, \n",
    "                            labels = labels_array, \n",
    "                            feature_names = feature_name_df,\n",
    "                            is_normalized = False,\n",
    "                            n_runs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-links",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-vanilla",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
