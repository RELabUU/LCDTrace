{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "southern-success",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#Import Python Libraries\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "#Import Self-written Functions\n",
    "import os\n",
    "import sys\n",
    "src_dir = os.path.join(os.getcwd(), '..', 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from d00_utils.calculateTimeDifference import calculateTimeDifference #Function to calc time difference\n",
    "from d01_data.loadCommits import loadCommits #Function to load SVN data\n",
    "from d02_intermediate.cleanCommitData import cleanCommitData #Function to clean commit data\n",
    "from d02_intermediate.cleanJiraData import cleanJiraData #Function to clean JIRA data\n",
    "\n",
    "from d03_processing.createFittedTF_IDF import createFittedTF_IDF #Function to see if a trace is valid\n",
    "from d03_processing.createCorpusFromDocumentList import createCorpusFromDocumentList #Function to create a corpus\n",
    "from d03_processing.checkValidityTrace import checkValidityTrace #Function to see if a trace is valid\n",
    "from d03_processing.calculateTimeDif import calculateTimeDif #Calculate the time difference between 2 dates in seconds\n",
    "from d03_processing.checkFullnameEqualsEmail import checkFullnameEqualsEmail #Check if fullName is equal to the email\n",
    "from d03_processing.calculateCosineSimilarity import calculateCosineSimilarity #Calculate the cos similarity\n",
    "from d03_processing.calculateDocumentStatistics import *\n",
    "\n",
    "from d03_processing.calculateQueryQuality import *\n",
    "from d03_processing.normalize_data import *\n",
    "\n",
    "from d04_model_evaluation.model_evaluation import *\n",
    "\n",
    "#Display full value of a column\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "#Display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-texas",
   "metadata": {},
   "source": [
    "## 3.1 Load Cartesian and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "caring-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Cartersian Product\n",
    "cartesian_df = pd.read_pickle(r'../data/03_processed/cartesian_df.pkl')\n",
    "labels_df = pd.read_pickle(r'../data/03_processed/labels_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-nomination",
   "metadata": {},
   "source": [
    "# 3.2 Recalculate non-LC-specific features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "duplicate-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Document Statistics Features\n",
    "features_document_statistics = pd.read_pickle(r'../data/03_processed/features_document_statistics.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "thrown-coordinate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21567, 28)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cartesian_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "professional-weather",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21567, 7)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_document_statistics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bacterial-paintball",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f5_total_terms_jira</th>\n",
       "      <th>f6_total_terms_svn</th>\n",
       "      <th>f7_unique_terms_jira</th>\n",
       "      <th>f8_unique_terms_svn</th>\n",
       "      <th>f9_overlap_terms_compared_to_jira</th>\n",
       "      <th>f10_overlap_terms_to_svn</th>\n",
       "      <th>f11_overlap_terms_to_union</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>50</td>\n",
       "      <td>9.0</td>\n",
       "      <td>39</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.128205</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>4.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>50</td>\n",
       "      <td>76.0</td>\n",
       "      <td>39</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17.948718</td>\n",
       "      <td>18.421053</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>50</td>\n",
       "      <td>9.0</td>\n",
       "      <td>39</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.128205</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>4.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>50</td>\n",
       "      <td>9.0</td>\n",
       "      <td>39</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.128205</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>4.545455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f5_total_terms_jira  f6_total_terms_svn  f7_unique_terms_jira  \\\n",
       "425                   50                 9.0                    39   \n",
       "426                   50                76.0                    39   \n",
       "427                   50                 9.0                    39   \n",
       "428                   50                 NaN                    39   \n",
       "429                   50                 9.0                    39   \n",
       "\n",
       "     f8_unique_terms_svn  f9_overlap_terms_compared_to_jira  \\\n",
       "425                  7.0                           5.128205   \n",
       "426                 38.0                          17.948718   \n",
       "427                  7.0                           5.128205   \n",
       "428                  NaN                                NaN   \n",
       "429                  7.0                           5.128205   \n",
       "\n",
       "     f10_overlap_terms_to_svn  f11_overlap_terms_to_union  \n",
       "425                 28.571429                    4.545455  \n",
       "426                 18.421053                   10.000000  \n",
       "427                 28.571429                    4.545455  \n",
       "428                       NaN                         NaN  \n",
       "429                 28.571429                    4.545455  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_document_statistics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "unnecessary-agriculture",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate total terms JIRA for each trace\n",
    "features_document_statistics[\"f6_total_terms_svn\"] = cartesian_df.apply(lambda x: calculateTotalWordCount(x.Logs), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Calculate unique terms JIRA for each trace\n",
    "features_document_statistics[\"f8_unique_terms_svn\"] = cartesian_df.apply(lambda x: calculateUniqueWordCount(x.Logs), \n",
    "                                                            axis=1)\n",
    "\n",
    "\n",
    "features_document_statistics[\"f9_overlap_terms_compared_to_jira\"] = cartesian_df.apply(lambda x: calculateOverlapBetweenDocuments(x.Jira_natural_text, x.Logs, 'list1'),\n",
    "                                                            axis=1)\n",
    "features_document_statistics[\"f10_overlap_terms_to_svn\"] = cartesian_df.apply(lambda x: calculateOverlapBetweenDocuments(x.Jira_natural_text, x.Logs, 'list2'),\n",
    "                                                            axis=1)\n",
    "features_document_statistics[\"f11_overlap_terms_to_union\"] = cartesian_df.apply(lambda x: calculateOverlapBetweenDocuments(x.Jira_natural_text, x.Logs, 'union'),\n",
    "                                                            axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "civilian-thompson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f5_total_terms_jira</th>\n",
       "      <th>f6_total_terms_svn</th>\n",
       "      <th>f7_unique_terms_jira</th>\n",
       "      <th>f8_unique_terms_svn</th>\n",
       "      <th>f9_overlap_terms_compared_to_jira</th>\n",
       "      <th>f10_overlap_terms_to_svn</th>\n",
       "      <th>f11_overlap_terms_to_union</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>5.128205</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>4.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>5.128205</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>4.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>2.564103</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>2.439024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>39</td>\n",
       "      <td>7</td>\n",
       "      <td>5.128205</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>4.545455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f5_total_terms_jira  f6_total_terms_svn  f7_unique_terms_jira  \\\n",
       "425                   50                   9                    39   \n",
       "426                   50                   2                    39   \n",
       "427                   50                   9                    39   \n",
       "428                   50                   3                    39   \n",
       "429                   50                   9                    39   \n",
       "\n",
       "     f8_unique_terms_svn  f9_overlap_terms_compared_to_jira  \\\n",
       "425                    7                           5.128205   \n",
       "426                    2                           0.000000   \n",
       "427                    7                           5.128205   \n",
       "428                    3                           2.564103   \n",
       "429                    7                           5.128205   \n",
       "\n",
       "     f10_overlap_terms_to_svn  f11_overlap_terms_to_union  \n",
       "425                 28.571429                    4.545455  \n",
       "426                  0.000000                    0.000000  \n",
       "427                 28.571429                    4.545455  \n",
       "428                 33.333333                    2.439024  \n",
       "429                 28.571429                    4.545455  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_document_statistics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "proprietary-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save results in pickle\n",
    "features_document_statistics.to_pickle(path= \"../data/03_processed/features_document_statistics.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-marijuana",
   "metadata": {},
   "source": [
    "## 3.3 Remove LC-specific features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "professional-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Information Retrieval Features\n",
    "features_information_retrieval = pd.read_pickle(r'../data/03_processed/features_information_retrieval.pkl')\n",
    "\n",
    "#Load Query Quality Features\n",
    "features_qq_specificity = pd.read_pickle(r'../data/03_processed/features_qq_specificity.pkl')\n",
    "features_qq_similarity = pd.read_pickle(r'../data/03_processed/features_qq_similarity.pkl')\n",
    "features_qq_termrelatedness = pd.read_pickle(r'../data/03_processed/features_qq_termrelatedness.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "previous-morgan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All features which need to be removed from the final feature set\n",
    "features_to_be_removed_list = [\"f18_ir_unitname_and_summary_unitname_as_query\",\n",
    "                               \"f19_ir_unitname_and_summary_summary_as_query\",\n",
    "                               \"f20_ir_unitname_and_description_unitname_as_query\",\n",
    "                               \"f21_ir_unitname_and_description_description_as_query\",\n",
    "                               \"f22_ir_unitname_and_jira_all_unitname_as_query\",\n",
    "                               \"f23_ir_unitname_and_jira_all_jira_all_as_query\",\n",
    "                               \"f24_ir_svn_all_and_summary_svn_all_as_query\",\n",
    "                               \"f25_ir_svn_all_and_summary_summary_as_query\",\n",
    "                               \"f26_ir_svn_all_and_description_svn_all_as_query\",\n",
    "                               \"f27_ir_svn_all_and_description_description_as_query\",\n",
    "                               \"f28_ir_svn_all_and_jira_all_svn_all_as_query\",\n",
    "                               \"f29_ir_svn_all_and_jira_all_jira_all_as_query\",\n",
    "                               \"f30_avgidf_svn_all_as_query\",\n",
    "                               \"f31_maxidf_svn_all_as_query\",\n",
    "                               \"f32_devidf_svn_all_as_query\",\n",
    "                               \"f36_avgidf_unitname_as_query\",\n",
    "                               \"f37_maxidf_unitname_as_query\",\n",
    "                               \"f38_devidf_unitname_as_query\",\n",
    "                               \"f48_avgictf_svn_all_as_query\",\n",
    "                               \"f49_maxictf_svn_all_as_query\",\n",
    "                               \"f50_devictf_svn_all_as_query\",\n",
    "                               \"f54_avgictf_svn_unitname_as_query\",\n",
    "                               \"f55_maxictf_svn_unitname_as_query\",\n",
    "                               \"f56_devictf_svn_unitname_as_query\",\n",
    "                               \"f66_avgentropy_svn_all_as_query\",\n",
    "                               \"f67_medentropy_svn_all_as_query\",\n",
    "                               \"f68_maxentropy_svn_all_as_query\",    \n",
    "                               \"f69_deventropy_svn_all_as_query\",\n",
    "                               \"f74_avgentropy_svn_unitname_as_query\",    \n",
    "                               \"f75_medentropy_svn_unitname_as_query\",\n",
    "                               \"f76_maxentropy_svn_unitname_as_query\",    \n",
    "                               \"f77_deventropy_svn_unitname_as_query\",\n",
    "                               \"f90_queryscope_svn_all_as_query\",    \n",
    "                               \"f92_queryscope_svn_unitname_as_query\",\n",
    "                               \"f96_scs_svn_all_as_query\",    \n",
    "                               \"f98_scs_svn_unitname_as_query\",\n",
    "                               \"f102_SvnAsQuery_avgSCQ\", \n",
    "                               \"f103_SvnAsQuery_maxSCQ\",\n",
    "                               \"f104_SvnAsQuery_sumSCQ\",\n",
    "                               \"f108_avgscq_svn_unitname_as_query\",\n",
    "                               \"f109_maxscq_svn_unitname_as_query\",\n",
    "                               \"f110_sumscq_svn_unitname_as_query\",\n",
    "                               \"f120_avgpmi_svn_all_as_query\",\n",
    "                               \"f121_maxpmi_svn_all_as_query\",\n",
    "                               \"f124_avgpmi_svn_unitname_as_query\",\n",
    "                               \"f125_maxpmi_svn_unitname_as_query\"                            \n",
    "                              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "protecting-healing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove LCD-specific features\n",
    "features_information_retrieval = features_information_retrieval[features_information_retrieval.columns.difference(features_to_be_removed_list)]\n",
    "features_qq_specificity = features_qq_specificity[features_qq_specificity.columns.difference(features_to_be_removed_list)]\n",
    "features_qq_similarity = features_qq_similarity[features_qq_similarity.columns.difference(features_to_be_removed_list)]\n",
    "features_qq_termrelatedness = features_qq_termrelatedness[features_qq_termrelatedness.columns.difference(features_to_be_removed_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "special-poland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21567, 8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_qq_termrelatedness.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "needed-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save results in pickle\n",
    "features_information_retrieval.to_pickle(path= \"../data/03_processed/features_information_retrieval.pkl\")\n",
    "features_qq_specificity.to_pickle(path= \"../data/03_processed/features_qq_specificity.pkl\")\n",
    "features_qq_similarity.to_pickle(path= \"../data/03_processed/features_qq_similarity.pkl\")\n",
    "features_qq_termrelatedness.to_pickle(path= \"../data/03_processed/features_qq_termrelatedness.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-material",
   "metadata": {},
   "source": [
    "## 3.8 Preprocess Data - Load and transform feature families needed for training\n",
    "Load features and create a normalized set of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "behavioral-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Process-Related Features\n",
    "features_process_related = pd.read_pickle(r'../data/03_processed/features_process_related.pkl')\n",
    "\n",
    "#Load IR-Related Features\n",
    "features_information_retrieval = pd.read_pickle(r'../data/03_processed/features_information_retrieval.pkl')\n",
    "\n",
    "#Load Document Statistics Features\n",
    "features_document_statistics = pd.read_pickle(r'../data/03_processed/features_document_statistics.pkl')\n",
    "\n",
    "#Load Query Quality Features\n",
    "features_qq_specificity = pd.read_pickle(r'../data/03_processed/features_qq_specificity.pkl')\n",
    "features_qq_similarity = pd.read_pickle(r'../data/03_processed/features_qq_similarity.pkl')\n",
    "features_qq_termrelatedness = pd.read_pickle(r'../data/03_processed/features_qq_termrelatedness.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "superb-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize Process-Related Features\n",
    "features_process_related_normalized = normalize_data(features_process_related)\n",
    "\n",
    "#Normalize IR-Related Features\n",
    "features_information_retrieval_normalized = normalize_data(features_information_retrieval)\n",
    "\n",
    "#Normalize Document Statistics Features\n",
    "features_document_statistics_normalized = normalize_data(features_document_statistics)\n",
    "\n",
    "#Normalize Query Quality Features\n",
    "features_qq_specificity_normalized = normalize_data(features_qq_specificity)\n",
    "features_qq_similarity_normalized = normalize_data(features_qq_similarity)\n",
    "features_qq_termrelatedness_normalized = normalize_data(features_qq_termrelatedness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-tower",
   "metadata": {},
   "source": [
    "Put all features in a single data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "sophisticated-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a single data frame for the non-normalized features\n",
    "features_all_df = pd.concat([features_process_related,\n",
    "                             features_document_statistics,\n",
    "                             features_information_retrieval,\n",
    "                             features_qq_specificity,\n",
    "                             features_qq_similarity,\n",
    "                             features_qq_termrelatedness], axis=1)\n",
    "\n",
    "#Create a single data frame for the normalized features\n",
    "features_all_normalized_df = pd.concat([features_process_related_normalized,\n",
    "                                        features_document_statistics_normalized,\n",
    "                                        features_information_retrieval_normalized,\n",
    "                                        features_qq_specificity_normalized,\n",
    "                                        features_qq_similarity_normalized,\n",
    "                                        features_qq_termrelatedness_normalized], axis=1)\n",
    "\n",
    "#Save into xlsx files\n",
    "features_all_df.to_excel(excel_writer = \"../results/1. Trace Link Feature Data/features_non-normalized.xlsx\", index = False)\n",
    "features_all_normalized_df.to_excel(excel_writer = \"../results/1. Trace Link Feature Data/features_normalized.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "alert-treaty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21567, 85)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-clothing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "romantic-paint",
   "metadata": {},
   "source": [
    "Perform additional preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "forty-disorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the NaN to 0\n",
    "features_all_df = features_all_df.fillna(0)\n",
    "features_all_normalized_df = features_all_normalized_df.fillna(0)\n",
    "\n",
    "#Saving feature names for later use\n",
    "feature_name_df = list(features_all_df.columns)\n",
    "\n",
    "#Transform pandas data frame into numpy arrays\n",
    "features_all_array = np.array(features_all_df)\n",
    "features_all_normalized_array = np.array(features_all_normalized_df)\n",
    "\n",
    "#Load labels\n",
    "labels_df = pd.read_pickle(r'../data/03_processed/labels_df.pkl')\n",
    "labels_array = np.array(labels_df[\"is_valid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-album",
   "metadata": {},
   "source": [
    "# 4.1 Evaluation - Non-normalized\n",
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "defensive-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Python Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "#Method to show the different model evaluation metrics\n",
    "def showModelPerformance(trainedModel, testFeatures, testLabels):\n",
    "    # Use the fitted model to predict the labels of the test set\n",
    "    predictionLabels = trainedModel.predict(testFeatures)\n",
    "    \n",
    "    #Calculate the different metrics for the test vs predicted labels\n",
    "    accuracyValue = accuracy_score(testLabels.astype(bool), predictionLabels)\n",
    "    precisionValue = precision_score(testLabels.astype(bool), predictionLabels, average='binary')\n",
    "    f1Value = f1_score(testLabels.astype(bool), predictionLabels)\n",
    "    f2Value = fbeta_score(testLabels.astype(bool), predictionLabels, beta=2.0)\n",
    "    f05Value = fbeta_score(testLabels.astype(bool), predictionLabels, beta=0.5)\n",
    "    recallValue = recall_score(testLabels.astype(bool), predictionLabels)\n",
    "    averagePrecisionValue = average_precision_score(testLabels.astype(bool), predictionLabels)\n",
    "    \n",
    "    #Create a dataframe to output all evaluation metrics in\n",
    "    performanceData = {'Accuracy':  [accuracyValue],\n",
    "                       'Precision': [precisionValue],\n",
    "                       'Recall': [recallValue],\n",
    "                       'F1': [f1Value],\n",
    "                       'F2': [f2Value],\n",
    "                       'F0.5': [f05Value],\n",
    "                       'Average Precision': [averagePrecisionValue]\n",
    "                      }\n",
    "    performanceDf = pd.DataFrame(performanceData)\n",
    "    return(performanceDf)\n",
    "\n",
    "#Method to define the Pipeline steps based on the given rebalancing strategy and classification algorithm\n",
    "def define_steps(rebalancing_strategy, classification_algorithm):\n",
    "    steps = None\n",
    "    if(rebalancing_strategy == 'none'):\n",
    "        if(classification_algorithm == 'random_forests'):\n",
    "            steps = [['classifier', RandomForestClassifier(n_jobs=-1)]]\n",
    "        elif (classification_algorithm == 'xg_boost'):\n",
    "            steps = [['classifier', xgb.XGBClassifier(n_jobs=-1)]]\n",
    "            return(steps)\n",
    "        elif(classification_algorithm == 'light_gbm'):\n",
    "            steps = [['classifier', lgb.LGBMClassifier(n_jobs=-1, importance_type='gain')]]\n",
    "    elif(rebalancing_strategy == 'over'):\n",
    "        if(classification_algorithm == 'random_forests'):\n",
    "            steps = [['smote', SMOTE()],\n",
    "                    ['classifier', RandomForestClassifier(n_jobs=-1)]]\n",
    "        elif (classification_algorithm == 'xg_boost'):\n",
    "            steps = [['smote', SMOTE()],\n",
    "                    ['classifier', xgb.XGBClassifier(n_jobs=-1)]]\n",
    "        elif(classification_algorithm == 'light_gbm'):\n",
    "            steps = [['smote', SMOTE()],\n",
    "                    ['classifier', lgb.LGBMClassifier(n_jobs=-1, importance_type='gain')]]\n",
    "    elif(rebalancing_strategy == 'under'):\n",
    "        if(classification_algorithm == 'random_forests'):\n",
    "            steps = [['under', RandomUnderSampler()],\n",
    "                    ['classifier', RandomForestClassifier(n_jobs=-1)]]\n",
    "        elif (classification_algorithm == 'xg_boost'):\n",
    "            steps = [['under', RandomUnderSampler()],\n",
    "                    ['classifier', xgb.XGBClassifier(n_jobs=-1)]]\n",
    "        elif(classification_algorithm == 'light_gbm'):\n",
    "            steps = [['under', RandomUnderSampler()],\n",
    "                    ['classifier', lgb.LGBMClassifier(n_jobs=-1, importance_type='gain')]]\n",
    "    elif(rebalancing_strategy == '5050'):\n",
    "        if(classification_algorithm == 'random_forests'):\n",
    "            steps = [['smote', SMOTE(sampling_strategy = 0.5)],\n",
    "                    ['under', RandomUnderSampler()],\n",
    "                    ['classifier', RandomForestClassifier(n_jobs=-1)]]\n",
    "        elif (classification_algorithm == 'xg_boost'):\n",
    "            steps = [['smote', SMOTE(sampling_strategy = 0.5)],\n",
    "                    ['under', RandomUnderSampler()],\n",
    "                    ['classifier', xgb.XGBClassifier(n_jobs=-1)]]\n",
    "        elif(classification_algorithm == 'light_gbm'):\n",
    "            steps = [['smote', SMOTE(sampling_strategy = 0.5)],\n",
    "                    ['under', RandomUnderSampler()],\n",
    "                    ['classifier', lgb.LGBMClassifier(n_jobs=-1, importance_type='gain')]]\n",
    "    return steps\n",
    "\n",
    "#Method to generate the f1, f2, f0.5, accuracy, precision, recall, and average precision\n",
    "def generate_evaluation_metrics(rebalancing_strategy, classification_algorithm, data, labels, is_normalized, n_runs, feature_names):\n",
    "    #Create a dataframe to append to the results of each individual run\n",
    "    evaluation_df = pd.DataFrame(\n",
    "    {\n",
    "        'Accuracy':  [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1': [],\n",
    "        'F2': [],\n",
    "        'F0.5': [],\n",
    "        'Average Precision': []\n",
    "    })\n",
    "    \n",
    "    #Create a np array to put the importances per feature in\n",
    "    importance_array = np.empty(shape=(n_runs, 85))\n",
    "    \n",
    "    #Perform the described pipeline steps to produce the results for the defined number of runs\n",
    "    for i in range(n_runs):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data,\n",
    "                                                        labels,\n",
    "                                                        test_size=0.2,\n",
    "                                                        stratify=labels)\n",
    "        \n",
    "        #Set the pipeline steps according to the defined rebalancing strategy and classification algorithm\n",
    "        steps = define_steps(rebalancing_strategy, classification_algorithm)\n",
    "        \n",
    "        #Create the pipeline\n",
    "        model_pipeline = Pipeline(steps=steps)\n",
    "        \n",
    "        space_empty = dict()    \n",
    "        \n",
    "        stratified_kfold = StratifiedKFold(n_splits=10,shuffle=True)           \n",
    "    \n",
    "        #Create a model\n",
    "        model = RandomizedSearchCV(estimator = model_pipeline, \n",
    "                                param_distributions = space_empty, \n",
    "                                n_iter=1, \n",
    "                                n_jobs=-1, \n",
    "                                cv = stratified_kfold)\n",
    "        \n",
    "        #Fit the model on the training data\n",
    "        fitted_model = model.fit(X_train, y_train)\n",
    "        \n",
    "        #Evaluate the fitted model\n",
    "        fitted_model_evaluation_df = showModelPerformance(trainedModel = fitted_model, \n",
    "                         testFeatures = X_test, \n",
    "                         testLabels = y_test)     \n",
    "        \n",
    "        #Add the evaluation of the current run to the results of the previous runs\n",
    "        evaluation_df = pd.concat([evaluation_df,\n",
    "                                   fitted_model_evaluation_df])\n",
    "        \n",
    "        #Find the feature importances of the fitted model\n",
    "        if(classification_algorithm == \"light_gbm\"):\n",
    "            current_importances = fitted_model.best_estimator_._final_estimator.booster_.feature_importance(importance_type='gain')\n",
    "        else:\n",
    "            current_importances = fitted_model.best_estimator_._final_estimator.feature_importances_\n",
    "        #Add the feature importances of the current fitted model to the results of the previous runs\n",
    "\n",
    "        importance_array[i] = current_importances  \n",
    "    \n",
    "    if is_normalized == True:\n",
    "        dir_string = \"3. Normalised Results\"\n",
    "    else:\n",
    "        dir_string = \"2. Non-Normalised Results\"\n",
    "    \n",
    "    #Set the index as the run number\n",
    "    evaluation_df = evaluation_df.reset_index(drop = True)\n",
    "    evaluation_df.index += 1 \n",
    "    evaluation_df.index.name = \"run\"\n",
    "    \n",
    "    #Output the evaluation data to a csv file\n",
    "    evaluation_df.to_csv(\"../results/\" + dir_string + \"/\" + classification_algorithm + \"/\" + rebalancing_strategy + \"_results.csv\")\n",
    "    \n",
    "    #Transform the importance array to a data frame\n",
    "    importance_df = pd.DataFrame(data=importance_array, \n",
    "                                 columns= feature_names, \n",
    "                                 index=list(range(1, n_runs +1)))\n",
    "    \n",
    "    #Set the index as the run number\n",
    "    importance_df.index.name = \"run\"\n",
    "    \n",
    "    #Output the importance data to a csv file\n",
    "    importance_df.to_csv(\"../results/4. Feature Importance Results/\" + classification_algorithm + \"/\" + rebalancing_strategy + \"_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-digest",
   "metadata": {},
   "source": [
    "## XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "strategic-monaco",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluation_metrics(rebalancing_strategy = 'none', \n",
    "                            classification_algorithm = 'xg_boost', \n",
    "                            data = features_all_array, \n",
    "                            labels = labels_array, \n",
    "                            feature_names = feature_name_df,\n",
    "                            is_normalized = False,\n",
    "                            n_runs = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-calculator",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "handmade-homework",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluation_metrics(rebalancing_strategy = '5050', \n",
    "                            classification_algorithm = 'light_gbm', \n",
    "                            data = features_all_array, \n",
    "                            labels = labels_array, \n",
    "                            feature_names = feature_name_df,\n",
    "                            is_normalized = False,\n",
    "                            n_runs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-links",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-vanilla",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
