{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "handled-prediction",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rande\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rande\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Import Python Libraries\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "#Import Self-written Functions\n",
    "import os\n",
    "import sys\n",
    "src_dir = os.path.join(os.getcwd(), '..', 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from d00_utils.calculateTimeDifference import calculateTimeDifference #Function to calc time difference\n",
    "from d01_data.loadCommits import loadCommits #Function to load SVN data\n",
    "from d02_intermediate.cleanCommitData import cleanCommitData #Function to clean commit data\n",
    "from d02_intermediate.cleanJiraData import cleanJiraData #Function to clean JIRA data\n",
    "\n",
    "from d03_processing.createFittedTF_IDF import createFittedTF_IDF #Function to see if a trace is valid\n",
    "from d03_processing.createCorpusFromDocumentList import createCorpusFromDocumentList #Function to create a corpus\n",
    "from d03_processing.checkValidityTrace import checkValidityTrace #Function to see if a trace is valid\n",
    "from d03_processing.calculateTimeDif import calculateTimeDif #Calculate the time difference between 2 dates in seconds\n",
    "from d03_processing.checkFullnameEqualsEmail import checkFullnameEqualsEmail #Check if fullName is equal to the email\n",
    "from d03_processing.calculateCosineSimilarity import calculateCosineSimilarity #Calculate the cos similarity\n",
    "from d03_processing.calculateDocumentStatistics import calculateUniqueWordCount\n",
    "from d03_processing.calculateDocumentStatistics import calculateTotalWordCount\n",
    "from d03_processing.calculateDocumentStatistics import calculateOverlapBetweenDocuments\n",
    "\n",
    "from d04_modelling.summariseClassDistribution import summariseClassDistribution #Visualize the class distribution\n",
    "from d04_modelling.showModelPerformance import showModelPerformance # Show several performance measures\n",
    "\n",
    "#Display full value of a column\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "#Display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-sellers",
   "metadata": {},
   "source": [
    "# 1. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "amended-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set dataset\n",
    "\n",
    "datasetDirectory = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "played-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import raw JIRA dataset\n",
    "rawData_JIRA_academy = pd.read_excel('../data/01_raw/JIRA Mendix Academy export_15_05_2021.xlsx')\n",
    "\n",
    "#import\n",
    "rawData_SVN_academy = loadCommits('../data/01_raw/academy-svn-dump.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-utility",
   "metadata": {},
   "source": [
    "# 2. Clean Raw Data\n",
    "## 2.1 Clean Raw Data - SVN Data\n",
    "Clean the raw data of the SVN files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "institutional-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "#nltk for NLP \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.util import ngrams\n",
    "\n",
    "#Function to transform natural text into unigram tokens\n",
    "def preprocessNaturalLanguage(text, porterStemmer, cachedStopWords):\n",
    "    string_text = str(text)\n",
    "    #lowercase the string\n",
    "    lower_case_string = string_text.lower()\n",
    "    \n",
    "    #Remove interpunction\n",
    "    no_interpunction = lower_case_string.translate(str.maketrans('','',string.punctuation))\n",
    "    \n",
    "    #Remove numbers\n",
    "    no_numbers = ''.join([i for i in no_interpunction if not i.isdigit()])\n",
    "    \n",
    "    #tokenize string\n",
    "    tokens = word_tokenize(no_interpunction)\n",
    "    \n",
    "    #remove stopwords\n",
    "    tokens_without_sw = [word for word in tokens if not word in cachedStopWords]\n",
    "    \n",
    "    #Stem the tokens\n",
    "    stemmedToken = list(map(porterStemmer.stem, tokens_without_sw))\n",
    "\n",
    "    return(stemmedToken)\n",
    "\n",
    "#Function to transform natural text into n-gram tokens\n",
    "def preprocessNGrams(text, porterStemmer, cachedStopWords, nGramSize):\n",
    "    string_text = str(text)\n",
    "    \n",
    "    #lowercase the string\n",
    "    lower_case_string = string_text.lower()\n",
    "    \n",
    "    #Remove interpunction\n",
    "    no_interpunction = lower_case_string.translate(str.maketrans('','',string.punctuation))\n",
    "    \n",
    "    #Remove numbers\n",
    "    no_numbers = ''.join([i for i in no_interpunction if not i.isdigit()])\n",
    "    \n",
    "    #tokenize string\n",
    "    tokens = word_tokenize(no_interpunction)\n",
    "    \n",
    "    #Create the ngrams\n",
    "    ngrams = list(nltk.ngrams(tokens, nGramSize))\n",
    "    \n",
    "    #remove all the n-grams containing a stopword\n",
    "    cleanNGrams = [ngram for ngram in ngrams if not any(stop in ngram for stop in cachedStopWords)]\n",
    "    \n",
    "    #Stem the tokens\n",
    "    stemmedNGrams = []\n",
    "    for ngram in cleanNGrams:\n",
    "        stemmed = list(map(porterStemmer.stem, ngram))\n",
    "        stemmedNGrams.append(stemmed)\n",
    "    return(stemmedNGrams)\n",
    "\n",
    "#Function to transform date into a date object\n",
    "def preprocessCommitDate(date_string):\n",
    "    date_time_obj = datetime.strptime(date_string, '%Y-%m-%dT%H:%M:%S.%fZ')  \n",
    "    return(date_time_obj)\n",
    "    \n",
    "#Remove the found Issue key from the log\n",
    "def removeIssueKey(log_message):\n",
    "    issue_keys = re.findall(r\"LRN+.[0-9]+|AFM+.[0-9]+|MA+.[0-9]+|AFI+.[0-9]+|EM+.[0-9]+|OE+.[0-9]+|EM+.[0-9]+\", log_message)\n",
    "    log_message_without_key = log_message\n",
    "    for issue_key in issue_keys:\n",
    "        log_message_without_key = log_message_without_key.replace(issue_key, \"\")\n",
    "    return(log_message_without_key)\n",
    "\n",
    "def unitNamesLambdaFunc(unitName, stemmer):\n",
    "    #Lower case\n",
    "    unitNameLowered = unitName.lower()\n",
    "    \n",
    "    #Remove interpunction\n",
    "    noInterpunction = unitNameLowered.translate(str.maketrans('','',string.punctuation))\n",
    "    \n",
    "    #Remove numbers\n",
    "    noNumbers = ''.join([i for i in noInterpunction if not i.isdigit()])\n",
    "    \n",
    "    stemmendUnitName = stemmer.stem(noInterpunction)\n",
    "    \n",
    "    \n",
    "    return(stemmendUnitName)\n",
    "    \n",
    "\n",
    "def preprocessUnitNames(unitName, porterStemmer, cachedStopWords):\n",
    "    if (isinstance(unitName, str)):\n",
    "        #Split camelCasing\n",
    "        unitNameSplitList = re.sub('([A-Z][a-z]+)', r' \\1', re.sub('([A-Z]+)', r' \\1', unitName)).split()\n",
    "        \n",
    "        porterStemmer = PorterStemmer() #create an object of class PorterStemmer\n",
    "        \n",
    "        #Preprocess each split found.\n",
    "        unitNameLowered = list(map(lambda unitName: unitNamesLambdaFunc(unitName, porterStemmer), \n",
    "                                   unitNameSplitList))\n",
    "        \n",
    "        #Check for stopwords\n",
    "        tokensWithoutSW = [word for word in unitNameLowered if not word in cachedStopWords]\n",
    "\n",
    "        return(tokensWithoutSW)\n",
    "\n",
    "def preprocessNGramsUnitNames(unitName, porterStemmer, cachedStopWords, nGramSize):\n",
    "    if (isinstance(unitName, str)):\n",
    "        #Split camelCasing\n",
    "        unitNameSplitList = re.sub('([A-Z][a-z]+)', r' \\1', re.sub('([A-Z]+)', r' \\1', unitName)).split()\n",
    "        \n",
    "        cleanedUnitNames = []\n",
    "        for unitNameSplit in unitNameSplitList:\n",
    "            #Lower case unit names\n",
    "            lowerCased = unitNameSplit.lower()\n",
    "\n",
    "            #Remove interpunction\n",
    "            removedInterpunction = lowerCased.translate(str.maketrans('','',string.punctuation))\n",
    "            cleanedUnitNames.append(removedInterpunction)\n",
    "            \n",
    "        #Transform to string (needed for tokenizer\n",
    "        unitNameString = ' '.join(cleanedUnitNames)\n",
    "\n",
    "        #Tokenzize words\n",
    "        tokenized = word_tokenize(unitNameString)\n",
    "        \n",
    "        #Create the ngrams\n",
    "        ngrams = list(nltk.ngrams(tokenized, nGramSize))\n",
    "        \n",
    "        porterStemmer = PorterStemmer() #create an object of class PorterStemmer\n",
    "        \n",
    "        #remove all the n-grams containing a stopword\n",
    "        cleanNGrams = [ngram for ngram in ngrams if not any(stop in ngram for stop in cachedStopWords)]\n",
    "    \n",
    "        #Stem the tokens\n",
    "        stemmedNGrams = []\n",
    "        for ngram in cleanNGrams:\n",
    "            stemmed = list(map(porterStemmer.stem, ngram))\n",
    "            stemmedNGrams.append(stemmed)\n",
    "            \n",
    "        return(stemmedNGrams)\n",
    "\n",
    "#Method to clean all columns of the provided data\n",
    "def cleanCommitData(rawCommitData): \n",
    "    #create an object of class PorterStemmer\n",
    "    porterStemmer = PorterStemmer()\n",
    "    \n",
    "    #Find all stopwords\n",
    "    cachedStopWords = stopwords.words(\"english\")\n",
    "    \n",
    "    #Remove all revisions without an issue key in the log message\n",
    "    commit_df = rawCommitData[rawCommitData[\"related_issue_key\"].notna()]\n",
    "\n",
    "    #Execute cleaning methods on dataset\n",
    "    cleaned_commit_logs = commit_df['log'].apply(lambda x: removeIssueKey(x))\n",
    "    processed_commit_logs = cleaned_commit_logs.apply(lambda x: preprocessNaturalLanguage(x, porterStemmer, cachedStopWords))\n",
    "    processed_commit_logs_2grams = cleaned_commit_logs.apply(lambda x: preprocessNGrams(x, porterStemmer, cachedStopWords, 2))\n",
    "    processed_commit_logs_3grams = cleaned_commit_logs.apply(lambda x: preprocessNGrams(x, porterStemmer, cachedStopWords, 3))\n",
    "    processed_date_times = commit_df['date'].apply(lambda x: preprocessCommitDate(x))\n",
    "    processed_unit_names = commit_df['impacted_unit_names'].apply(lambda x: preprocessUnitNames(x, porterStemmer, cachedStopWords))\n",
    "    processed_unit_names_2grams = commit_df['impacted_unit_names'].apply(lambda x: preprocessNGramsUnitNames(x, porterStemmer, cachedStopWords, 2))\n",
    "    processed_unit_names_3grams = commit_df['impacted_unit_names'].apply(lambda x: preprocessNGramsUnitNames(x, porterStemmer, cachedStopWords, 3))\n",
    "    \n",
    "\n",
    "    #Put all data together into a new dataframe\n",
    "    commit_data = {'Revision': commit_df[\"revision\"],\n",
    "               'Email' : commit_df[\"email\"],\n",
    "               'Commit_date': processed_date_times,\n",
    "               \"Issue_key_commit\": commit_df[\"related_issue_key\"],\n",
    "               'Logs': processed_commit_logs, \n",
    "               'Logs_2grams': processed_commit_logs_2grams, \n",
    "               'Logs_3grams': processed_commit_logs_3grams, \n",
    "               'Unit_names': processed_unit_names,\n",
    "               'Unit_names_2grams': processed_unit_names_2grams,\n",
    "               'Unit_names_3grams': processed_unit_names_3grams,\n",
    "               'Commit_natural_text': processed_commit_logs + processed_unit_names,\n",
    "               'Commit_natural_text_2grams': processed_commit_logs_2grams + processed_unit_names_2grams,\n",
    "               'Commit_natural_text_3grams': processed_commit_logs_3grams + processed_unit_names_3grams\n",
    "               }\n",
    "               \n",
    "    commit_processed_df = pd.DataFrame(data=commit_data)\n",
    "\n",
    "    return(commit_processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "continent-knowing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished cleaning after 0 minutes and 17.753044605255127 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "intermediateData_SVN_academy = cleanCommitData(rawData_SVN_academy)\n",
    "\n",
    "#Create a temp XLSX file for all intermediate datasets\n",
    "intermediateData_SVN_academy.to_excel(excel_writer = \"../data/02_intermediate/intermediateData_SVN_academy.xlsx\", index = False)\n",
    "\n",
    "#Create a pickle file for all intermediate datasets\n",
    "intermediateData_SVN_academy.to_pickle(path= \"../data/02_intermediate/intermediateData_SVN_academy.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished cleaning after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "specialized-shame",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\rande\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import string\n",
    "#nltk for NLP \n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag  import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "#Function to clean the comments\n",
    "def clean_comments(comment):\n",
    "    try:\n",
    "        commentDates = re.findall(r\"[0-9]{2} [A-Z][a-z]{2} [0-9]{4} [0-9]{2}:[0-9]{2};[a-zA-Z0-9_]{24};\", comment)\n",
    "        accountIds = re.findall(r\"\\[~accountid:[a-zA-Z0-9]{24}\\]\", comment)\n",
    "               \n",
    "        \n",
    "        cleanedComment = comment.replace(\"nan\",'')\n",
    "        for commentDate in commentDates:\n",
    "            cleanedComment = cleanedComment.replace(commentDate,'')\n",
    "        \n",
    "        for accountId in accountIds: \n",
    "            cleanedComment = cleanedComment.replace(accountId,'')\n",
    "        \n",
    "        return(cleanedComment)\n",
    "    except:\n",
    "        return(\"\")\n",
    "\n",
    "def preprocess(text, porterStemmer, cachedStopwords):\n",
    "    string_text = str(text)\n",
    "    #lowercase the string\n",
    "    lower_case_string = string_text.lower()\n",
    "    \n",
    "    #Remove interpunction\n",
    "    no_interpunction = lower_case_string.translate(str.maketrans('','',string.punctuation))\n",
    "    \n",
    "    #Remove numbers\n",
    "    no_numbers = ''.join([i for i in no_interpunction if not i.isdigit()])\n",
    "    \n",
    "    #tokenize string\n",
    "    tokens = word_tokenize(no_numbers)\n",
    "    \n",
    "    #remove stopwords\n",
    "    tokens_without_sw = [word for word in tokens if not word in cachedStopwords]\n",
    "    \n",
    "    #Stem the tokens\n",
    "    stemmedToken = list(map(porterStemmer.stem, tokens_without_sw))\n",
    "\n",
    "    return(stemmedToken)\n",
    "\n",
    "def preprocessNGrams(text, porterStemmer, cachedStopWords, nGramSize):\n",
    "    string_text = str(text)\n",
    "    \n",
    "    #lowercase the string\n",
    "    lower_case_string = string_text.lower()\n",
    "    \n",
    "    #Remove interpunction\n",
    "    no_interpunction = lower_case_string.translate(str.maketrans('','',string.punctuation))\n",
    "    \n",
    "    #Remove numbers\n",
    "    no_numbers = ''.join([i for i in no_interpunction if not i.isdigit()])\n",
    "    \n",
    "    #tokenize string\n",
    "    tokens = word_tokenize(no_numbers)\n",
    "    \n",
    "    #Create the ngrams\n",
    "    ngrams = list(nltk.ngrams(tokens, nGramSize))\n",
    "    \n",
    "    #remove all the n-grams containing a stopword\n",
    "    cleanNGrams = [ngram for ngram in ngrams if not any(stop in ngram for stop in cachedStopWords)]\n",
    "    \n",
    "    #Stem the tokens\n",
    "    stemmedNGrams = []\n",
    "    for ngram in cleanNGrams:\n",
    "        stemmed = list(map(porterStemmer.stem, ngram))\n",
    "        stemmedNGrams.append(stemmed)\n",
    "    return(stemmedNGrams)\n",
    "\n",
    "#Function to transform date into a date object\n",
    "def preprocess_jira_date(date_string):\n",
    "    if(isinstance(date_string, str)):\n",
    "        try:\n",
    "            date_time_obj = datetime.strptime(date_string, '%d %b %Y %H:%M')\n",
    "        except:\n",
    "            date_time_obj = datetime.strptime(date_string, '%Y-%m-%d %H:%M:%S:%f')\n",
    "        return(date_time_obj)\n",
    "    elif(isinstance(date_string, datetime)): \n",
    "        return(date_string)\n",
    "    else:\n",
    "        return(np.nan)\n",
    "    \n",
    "    \n",
    "def findVerbs(tokenList):\n",
    "    posTags = pos_tag(tokenList)\n",
    "    verbAbrList = ['VBP', 'VBG', 'VBN', 'VBP', 'VBZ', 'RB', 'RBR', 'RBS']\n",
    "    verbList = []\n",
    "    for posTag in posTags:\n",
    "        if posTag[1] in verbAbrList:\n",
    "            verbList.append(posTag[0])\n",
    "    return(verbList)\n",
    "\n",
    "#Preprocess all the features and transform to the format needed for further processing.\n",
    "def preprocessJiraData(cleanDataFrame, preprocessComments, porterStemmer, cachedStopWords, startTime):\n",
    "    if (preprocessComments == True):\n",
    "        nOfSteps = '4'\n",
    "    else:\n",
    "        nOfSteps = '3'\n",
    "\n",
    "    #preprocess Summaries\n",
    "    jira_summaries = cleanDataFrame['Summary'].apply(lambda x: preprocess(x, porterStemmer, cachedStopWords))\n",
    "    jira_summaries_2grams = cleanDataFrame['Summary'].apply(lambda x: preprocessNGrams(x, porterStemmer, cachedStopWords, 2))\n",
    "    jira_summaries_3grams = cleanDataFrame['Summary'].apply(lambda x: preprocessNGrams(x, porterStemmer, cachedStopWords, 3))\n",
    "    \n",
    "    endTimeCleaningSummaries = time.time() - startTime\n",
    "    print(\"1/\" + nOfSteps + \") Finished Cleaning Summaries after \" + str(endTimeCleaningSummaries) + \" sec\")\n",
    "\n",
    "    #preprocess Descriptions\n",
    "    jira_descriptions = cleanDataFrame['Description'].apply(lambda x: preprocess(x, porterStemmer, cachedStopWords))\n",
    "    jira_descriptions_2grams = cleanDataFrame['Description'].apply(lambda x: preprocessNGrams(x, porterStemmer, cachedStopWords, 2))\n",
    "    jira_descriptions_3grams = cleanDataFrame['Description'].apply(lambda x: preprocessNGrams(x, porterStemmer, cachedStopWords, 2))\n",
    "    \n",
    "    endTimeCleaningDescriptions = time.time() - startTime\n",
    "    print(\"2/\" + nOfSteps + \") Finished Cleaning Description after \" + str(endTimeCleaningDescriptions) + \" sec\")\n",
    "\n",
    "    #preprocess Dates\n",
    "    jira_creation = cleanDataFrame['Created'].apply(lambda x: preprocess_jira_date(x))\n",
    "    jira_updated = cleanDataFrame['Updated'].apply(lambda x: preprocess_jira_date(x))\n",
    "    jira_resolved = cleanDataFrame['Resolved'].apply(lambda x: preprocess_jira_date(x))\n",
    "    endTimeCleaningDates = time.time() - startTime\n",
    "    print(\"3/\" + nOfSteps + \") Finished Cleaning Dates after \" + str(endTimeCleaningDates) + \" sec\")\n",
    "\n",
    "    #Comments take too long for a test run.\n",
    "    if (preprocessComments == True):\n",
    "        jira_comments = cleanDataFrame['Comments'].apply(lambda x: preprocess(x, porterStemmer, cachedStopWords))\n",
    "        jira_comments_2grams = cleanDataFrame['Comments'].apply(lambda x: preprocessNGrams(x, porterStemmer, cachedStopWords, 2))\n",
    "        jira_comments_3grams = cleanDataFrame['Comments'].apply(lambda x: preprocessNGrams(x, porterStemmer, cachedStopWords, 2))\n",
    "        endTimeCleaningComments = time.time() - startTime\n",
    "        print(\"4/\" + nOfSteps + \") Finished Cleaning Comments after \" + str(endTimeCleaningComments) + \" sec\")\n",
    "\n",
    "         #create JIRA corpus by merging Summary and Description\n",
    "        jira_data = {'Issue_key_jira': cleanDataFrame['Issue key'], \n",
    "             'Assignee': cleanDataFrame['Assignee'],\n",
    "             'Jira_created_date': jira_creation, \n",
    "             'Jira_updated_date': jira_updated, \n",
    "             'Jira_resolved_date': jira_resolved, \n",
    "             'Summary': jira_summaries, \n",
    "             'Summary_2grams': jira_summaries_2grams,\n",
    "             'Summary_3grams': jira_summaries_3grams, \n",
    "             'Description': jira_descriptions,\n",
    "             'Description_2grams': jira_descriptions_2grams,\n",
    "             'Description_3grams': jira_descriptions_3grams,\n",
    "             'Comments': jira_comments,\n",
    "             'Comments_2grams': jira_comments_2grams,\n",
    "             'Comments_3grams': jira_comments_3grams,\n",
    "             'Jira_natural_text': jira_summaries +  jira_descriptions + jira_comments,\n",
    "             'Jira_natural_text_2grams': jira_summaries_2grams +  jira_descriptions_2grams + jira_comments_2grams,\n",
    "             'Jira_natural_text_3grams': jira_summaries_3grams +  jira_descriptions_3grams + jira_comments_3grams}\n",
    "    else:\n",
    "         #create JIRA corpus by merging Summary and Description\n",
    "        jira_data = {'Issue_key_jira': cleanDataFrame['Issue key'], \n",
    "             'Assignee': cleanDataFrame['Assignee'],\n",
    "             'Jira_created_date': jira_creation, \n",
    "             'Jira_updated_date': jira_updated, \n",
    "             'Jira_resolved_date': jira_resolved, \n",
    "             'Summary': jira_summaries,\n",
    "             'Summary_2grams': jira_summaries_2grams,\n",
    "             'Summary_3grams': jira_summaries_3grams,\n",
    "             'Description': jira_descriptions,\n",
    "             'Description_2grams': jira_descriptions_2grams,\n",
    "             'Description_3grams': jira_descriptions_3grams,\n",
    "             'Jira_natural_text': jira_summaries +  jira_descriptions,\n",
    "             'Jira_natural_text_2grams': jira_summaries_2grams +  jira_descriptions_2grams,\n",
    "             'Jira_natural_text_3grams': jira_summaries_3grams +  jira_descriptions_3grams}\n",
    "\n",
    "    jira_processed_df = pd.DataFrame(data=jira_data)\n",
    "    \n",
    "    #Find verbs\n",
    "    jira_processed_df['verbs'] = jira_processed_df['Jira_natural_text'].apply(lambda x: findVerbs(x))\n",
    "    \n",
    "    return(jira_processed_df)\n",
    "\n",
    "#Input dataframe and num of_comments, and bool to determine if comments need to be cleaned\n",
    "def cleanJiraData(dataFrame, cleanComments, commentAmount):\n",
    "    startTime = time.time()\n",
    "\n",
    "    #create an object of class PorterStemmer\n",
    "    porterStemmer = PorterStemmer()\n",
    "    \n",
    "    #Find all stopwords\n",
    "    cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "    if (cleanComments == True):\n",
    "        #Subset only all comments \n",
    "        loc_first_comment = dataFrame.columns.get_loc('Comment') # Variable storing the col location of the 1st comment\n",
    "    \n",
    "        dataFrame[\"Comments\"] = dataFrame.iloc[:,loc_first_comment:loc_first_comment+commentAmount].apply(\n",
    "            lambda x: \" \".join(x.astype(str)), axis=1)\n",
    "    \n",
    "        #First remove the date and comment string from the comments\n",
    "        dataFrame[\"Comments\"] = dataFrame[\"Comments\"].apply(lambda x: clean_comments(x))\n",
    "\n",
    "        #Subset JIRA ID, Summary, Description, comments\n",
    "        jira_issues_subset = dataFrame[[\"Issue key\", \"Assignee\", \"Summary\", \"Description\", \"Comments\", \"Created\", \"Resolved\", \"Updated\"]]\n",
    "        cleanedAndProcessedJiraData = preprocessJiraData(jira_issues_subset, preprocessComments = True, porterStemmer = porterStemmer, cachedStopWords = cachedStopWords, startTime = startTime)\n",
    "        return(cleanedAndProcessedJiraData)\n",
    "    else: \n",
    "        jira_issues_subset = dataFrame[[\"Issue key\", \"Assignee\", \"Summary\", \"Description\", \"Created\", \"Resolved\", \"Updated\"]]\n",
    "        cleanedAndProcessedJiraData = preprocessJiraData(jira_issues_subset, preprocessComments = False, porterStemmer = porterStemmer, cachedStopWords = cachedStopWords, startTime = startTime)\n",
    "        return(cleanedAndProcessedJiraData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "loaded-zambia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/3) Finished Cleaning Summaries after 0.9706006050109863 sec\n",
      "2/3) Finished Cleaning Description after 9.605996131896973 sec\n",
      "3/3) Finished Cleaning Dates after 9.614043951034546 sec\n"
     ]
    }
   ],
   "source": [
    "#Rename key to Issue key\n",
    "rawData_JIRA_academy = rawData_JIRA_academy.rename({'Key': 'Issue key'}, axis=1)\n",
    "\n",
    "#Clean Data sets\n",
    "intermediateData_JIRA_academy = cleanJiraData(dataFrame = rawData_JIRA_academy, cleanComments = False, commentAmount = 39)\n",
    "\n",
    "#Create a temp XLSX file for all intermediate datasets\n",
    "intermediateData_JIRA_academy.to_excel(excel_writer = \"../data/02_intermediate/intermediateData_JIRA_academy.xlsx\", index = False)\n",
    "\n",
    "#Create a pickle file for all intermediate datasets\n",
    "intermediateData_JIRA_academy.to_pickle(path= \"../data/02_intermediate/intermediateData_JIRA_academy.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-bankruptcy",
   "metadata": {},
   "source": [
    "## 2.4 Clean Raw Data - Create JIRA Corpora\n",
    "Create the corpora for JIRA UNIGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "provincial-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCorpusFromDocumentList(token_column):\n",
    "    token_list = token_column.tolist()\n",
    "    corpus_list = []\n",
    "    \n",
    "    for document in token_list:\n",
    "        #Only join to the string when a list. When it is not a list, then it is np.NaN, thus no changes\n",
    "        if(isinstance(document, list)):\n",
    "            #Transform list to a string for SKLEARN to accept the input.\n",
    "            token_string = ' '.join(document)\n",
    "        \n",
    "            #Add string to the corpus list\n",
    "            corpus_list.append(token_string)\n",
    "    return(corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "confused-corrections",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create JIRA corpus for academy dataset\n",
    "intermediateData_JIRA_academyCorpusSummary = createCorpusFromDocumentList(intermediateData_JIRA_academy.Summary)\n",
    "intermediateData_JIRA_academyCorpusDescription = createCorpusFromDocumentList(intermediateData_JIRA_academy.Description)\n",
    "\n",
    "#Merge all JIRA Corpora into 1 corpus\n",
    "intermediateData_JIRA_academyCorpus = [i+\" \"+j for i,j in zip(intermediateData_JIRA_academyCorpusSummary,\n",
    "                                                                             intermediateData_JIRA_academyCorpusDescription\n",
    "                                                                            )]\n",
    "\n",
    "#Save intermediate pickles\n",
    "with open('../data/02_intermediate/intermediateData_JIRA_academyCorpus.pkl', 'wb') as f:\n",
    "    pickle.dump(intermediateData_JIRA_academyCorpus, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-tanzania",
   "metadata": {},
   "source": [
    "Bigram corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fifth-belarus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCorpusNGrams(tokenColumn):\n",
    "    tokenList = tokenColumn.tolist()\n",
    "    corpusList = []\n",
    "    \n",
    "    #Transform to strings\n",
    "    for document in tokenList:\n",
    "        if(isinstance(document, list)):\n",
    "            for ngram in document:\n",
    "                ngramString = ' '.join(ngram)\n",
    "                corpusList.append(ngramString)         \n",
    "    return(corpusList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "internal-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create JIRA corpus for academy dataset\n",
    "intermediateData_JIRA_academyCorpusSummary_2grams = createCorpusNGrams(intermediateData_JIRA_academy.Summary_2grams)\n",
    "intermediateData_JIRA_academyCorpusDescription_2grams = createCorpusNGrams(intermediateData_JIRA_academy.Description_2grams)\n",
    "\n",
    "#Merge all JIRA Corpora into 1 corpus\n",
    "intermediateData_JIRA_academyCorpus_2gram = [i+\" \"+j for i,j in zip(intermediateData_JIRA_academyCorpusSummary_2grams,\n",
    "                                                                             intermediateData_JIRA_academyCorpusDescription_2grams\n",
    "                                                                             )]\n",
    "\n",
    "\n",
    "#Save intermediate pickles\n",
    "with open('../data/02_intermediate/intermediateData_JIRA_academyCorpus_2gram.pkl', 'wb') as f:\n",
    "    pickle.dump(intermediateData_JIRA_academyCorpus_2gram, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-syntax",
   "metadata": {},
   "source": [
    "## 2.4 Clean Raw Data - Create SVN Corpora\n",
    "Create the corpora for SVN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "tropical-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediateData_SVN_academy = pd.read_pickle(\"../data/02_intermediate/intermediateData_SVN_academy.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "modern-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create corpus for log messages\n",
    "intermediateData_SVNLogs_academyCorpus = createCorpusFromDocumentList(intermediateData_SVN_academy.Logs)\n",
    "\n",
    "#Create corpus for unit names\n",
    "intermediateData_SVNUnitNames_academyCorpus = createCorpusFromDocumentList(intermediateData_SVN_academy.Unit_names)\n",
    "\n",
    "#Create corpus for entire commit (log message + model)\n",
    "intermediateData_SVN_academyCorpus = createCorpusFromDocumentList(intermediateData_SVN_academy.Logs + intermediateData_SVN_academy.Unit_names)\n",
    "intermediateData_SVN_academyCorpusAll = createCorpusFromDocumentList(intermediateData_SVN_academy.Logs + intermediateData_SVN_academy.Unit_names)\n",
    "#Save intermediate pickles\n",
    "with open('../data/02_intermediate/intermediateData_SVNLogs_academyCorpus.pkl', 'wb') as f:\n",
    "    pickle.dump(intermediateData_SVNLogs_academyCorpus, f)\n",
    "\n",
    "with open('../data/02_intermediate/intermediateData_SVNUnitNames_academyCorpus.pkl', 'wb') as f:\n",
    "    pickle.dump(intermediateData_SVNUnitNames_academyCorpus, f)\n",
    "\n",
    "with open('../data/02_intermediate/intermediateData_SVN_academyCorpus.pkl', 'wb') as f:\n",
    "    pickle.dump(intermediateData_SVN_academyCorpus, f)\n",
    "    \n",
    "with open('../data/02_intermediate/intermediateData_SVN_academyCorpusAll.pkl', 'wb') as f:\n",
    "    pickle.dump(intermediateData_SVN_academyCorpusAll, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-tactics",
   "metadata": {},
   "source": [
    "bigram corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "found-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediateData_SVNLogs_academyCorpus_2gram = createCorpusNGrams(intermediateData_SVN_academy.Logs_2grams)\n",
    "intermediateData_SVNUnitNames_academyCorpus_2gram = createCorpusNGrams(intermediateData_SVN_academy.Unit_names_2grams)\n",
    "with open('../data/02_intermediate/intermediateData_SVNLogs_academyCorpus_2gram.pkl', 'wb') as f:\n",
    "    pickle.dump(intermediateData_SVNLogs_academyCorpus_2gram, f)\n",
    "    \n",
    "    \n",
    "with open('../data/02_intermediate/intermediateData_SVNUnitNames_academyCorpus_2gram.pkl', 'wb') as f:\n",
    "    pickle.dump(intermediateData_SVNUnitNames_academyCorpus_2gram, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-collaboration",
   "metadata": {},
   "source": [
    "# 3. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "raising-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this code block when you've restarted the kernel, and want to use previously gained results.\n",
    "intermediateData_JIRA_academy = pd.read_pickle(\"../data/02_intermediate/intermediateData_JIRA_academy.pkl\")\n",
    "\n",
    "intermediateData_SVN_academy = pd.read_pickle(\"../data/02_intermediate/intermediateData_SVN_academy.pkl\")\n",
    "\n",
    "intermediateData_JIRA_academyCorpus = pd.read_pickle(r'../data/02_intermediate/intermediateData_JIRA_academyCorpus.pkl')\n",
    "intermediateData_JIRA_academyCorpus = pd.read_pickle(r'../data/02_intermediate/intermediateData_JIRA_academyCorpus.pkl')\n",
    "#intermediateData_SVN_academyCorpusAll = pd.read_pickle(r'../data/02_intermediate/intermediateData_SVN_academyCorpusAll.pkl')\n",
    "#intermediateData_SVN_academyCorpusModel = pd.read_pickle(r'../data/02_intermediate/intermediateData_SVN_academyCorpusModel.pkl')\n",
    "intermediateData_SVN_academyCorpus = pd.read_pickle(r'../data/02_intermediate/intermediateData_SVN_academyCorpus.pkl')\n",
    "\n",
    "############# Bigrams\n",
    "\n",
    "\n",
    "############# Trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demographic-mouse",
   "metadata": {},
   "source": [
    "## 3.0 Preprocess Data - Create cartesian product JIRA x Commits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "marked-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediateData_SVN_dataProcessing = pd.read_pickle(\"../data/02_intermediate/intermediateData_SVN_dataProcessing.pkl\")\n",
    "\n",
    "#Create cartesian products JIRA x Commits\n",
    "processedData_academyCartesian = intermediateData_JIRA_academy.merge(intermediateData_SVN_academy, how='cross')\n",
    "\n",
    "processedData_academyCartesian = processedData_academyCartesian.drop(processedData_academyCartesian[processedData_academyCartesian.Jira_created_date > processedData_academyCartesian.Commit_date].index)\n",
    "\n",
    "#Create a pickle file for all intermediate datasets\n",
    "processedData_academyCartesian.to_pickle(path= \"../data/03_processed/processedData_academyCartesian.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "declared-military",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue_key_jira</th>\n",
       "      <th>Assignee</th>\n",
       "      <th>Jira_created_date</th>\n",
       "      <th>Jira_updated_date</th>\n",
       "      <th>Jira_resolved_date</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Summary_2grams</th>\n",
       "      <th>Summary_3grams</th>\n",
       "      <th>Description</th>\n",
       "      <th>Description_2grams</th>\n",
       "      <th>Description_3grams</th>\n",
       "      <th>Jira_natural_text</th>\n",
       "      <th>Jira_natural_text_2grams</th>\n",
       "      <th>Jira_natural_text_3grams</th>\n",
       "      <th>verbs</th>\n",
       "      <th>Revision</th>\n",
       "      <th>Email</th>\n",
       "      <th>Commit_date</th>\n",
       "      <th>Issue_key_commit</th>\n",
       "      <th>Logs</th>\n",
       "      <th>Logs_2grams</th>\n",
       "      <th>Logs_3grams</th>\n",
       "      <th>Unit_names</th>\n",
       "      <th>Unit_names_2grams</th>\n",
       "      <th>Unit_names_3grams</th>\n",
       "      <th>Commit_natural_text</th>\n",
       "      <th>Commit_natural_text_2grams</th>\n",
       "      <th>Commit_natural_text_3grams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138947</th>\n",
       "      <td>LRN-1198</td>\n",
       "      <td>Jasmine Vyas</td>\n",
       "      <td>2021-03-29 14:50:08.502</td>\n",
       "      <td>2021-04-16 10:00:43.182</td>\n",
       "      <td>2021-04-16 10:00:43.178</td>\n",
       "      <td>[academi, v]</td>\n",
       "      <td>[[academi, v]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[constant, constantvalueaddit, inform, schedul, event, none, migrat, none, special, action, colorbd, releas, color, colorb, done, color, datalak, data, produc, remov, tabl, schema, ’, reappli, via, way, data, clean, datalak, valid, databas, viewer, tool, product, tabl, longer, data, insid, tabl, colorfff, releas, color, knowledg, api, stori, assign, releas, reassign, user, certif, certif, api, sinc, chang, order, set, associ, certif, metadata, done, admin, panel, →, dashboard, button, action, first, remov, assign, certif, user, appli, colorfff, releas, color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat, intermedi, exam, page, admin, panel, past, text, found, provid, intermedi, document, easier, text, assign, test, environ, intermedi, exam, also, chang, advanc, develop, exam, ...]</td>\n",
       "      <td>[[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]</td>\n",
       "      <td>[[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]</td>\n",
       "      <td>[academi, v, constant, constantvalueaddit, inform, schedul, event, none, migrat, none, special, action, colorbd, releas, color, colorb, done, color, datalak, data, produc, remov, tabl, schema, ’, reappli, via, way, data, clean, datalak, valid, databas, viewer, tool, product, tabl, longer, data, insid, tabl, colorfff, releas, color, knowledg, api, stori, assign, releas, reassign, user, certif, certif, api, sinc, chang, order, set, associ, certif, metadata, done, admin, panel, →, dashboard, button, action, first, remov, assign, certif, user, appli, colorfff, releas, color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat, intermedi, exam, page, admin, panel, past, text, found, provid, intermedi, document, easier, text, assign, test, environ, intermedi, exam, also, chang, advanc, ...]</td>\n",
       "      <td>[[academi, v], [constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], ...]</td>\n",
       "      <td>[[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]</td>\n",
       "      <td>[done, clean, color, releas, set, done, first, remov, user, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, also, advanc, color, go, seen, fix, also, know, object, test, checklist, jira, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set, testedhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, candid, doubl, mainlin, v, stori, v, v, v, send, send, apithon, follow, project, send, approv, april, scope, learn, suggest, lrn, initialis, lrn, object, lrn, correct, prefer, forward, approv, releas, timeslot, pleas, reach, perform, note, make, written, send, also, includ, written, app, migrat, smoke, also, includ, tmlearn, user, set, done, set, releas]</td>\n",
       "      <td>3653</td>\n",
       "      <td>juliana.bustamante@mendix.com</td>\n",
       "      <td>2021-03-29 15:05:59.840013</td>\n",
       "      <td>[LRN-1142]</td>\n",
       "      <td>[merg, releas, academi, v1121, rev, 3652]</td>\n",
       "      <td>[[merg, releas], [releas, academi], [academi, v1121], [v1121, rev], [rev, 3652]]</td>\n",
       "      <td>[[merg, releas, academi], [releas, academi, v1121], [academi, v1121, rev], [v1121, rev, 3652]]</td>\n",
       "      <td>[imag, home, admin, panel, layout, crud]</td>\n",
       "      <td>[[imag, home], [home, admin], [admin, panel], [panel, layout], [layout, crud]]</td>\n",
       "      <td>[[imag, home, admin], [home, admin, panel], [admin, panel, layout], [panel, layout, crud]]</td>\n",
       "      <td>[merg, releas, academi, v1121, rev, 3652, imag, home, admin, panel, layout, crud]</td>\n",
       "      <td>[[merg, releas], [releas, academi], [academi, v1121], [v1121, rev], [rev, 3652], [imag, home], [home, admin], [admin, panel], [panel, layout], [layout, crud]]</td>\n",
       "      <td>[[merg, releas, academi], [releas, academi, v1121], [academi, v1121, rev], [v1121, rev, 3652], [imag, home, admin], [home, admin, panel], [admin, panel, layout], [panel, layout, crud]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138948</th>\n",
       "      <td>LRN-1198</td>\n",
       "      <td>Jasmine Vyas</td>\n",
       "      <td>2021-03-29 14:50:08.502</td>\n",
       "      <td>2021-04-16 10:00:43.182</td>\n",
       "      <td>2021-04-16 10:00:43.178</td>\n",
       "      <td>[academi, v]</td>\n",
       "      <td>[[academi, v]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[constant, constantvalueaddit, inform, schedul, event, none, migrat, none, special, action, colorbd, releas, color, colorb, done, color, datalak, data, produc, remov, tabl, schema, ’, reappli, via, way, data, clean, datalak, valid, databas, viewer, tool, product, tabl, longer, data, insid, tabl, colorfff, releas, color, knowledg, api, stori, assign, releas, reassign, user, certif, certif, api, sinc, chang, order, set, associ, certif, metadata, done, admin, panel, →, dashboard, button, action, first, remov, assign, certif, user, appli, colorfff, releas, color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat, intermedi, exam, page, admin, panel, past, text, found, provid, intermedi, document, easier, text, assign, test, environ, intermedi, exam, also, chang, advanc, develop, exam, ...]</td>\n",
       "      <td>[[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]</td>\n",
       "      <td>[[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]</td>\n",
       "      <td>[academi, v, constant, constantvalueaddit, inform, schedul, event, none, migrat, none, special, action, colorbd, releas, color, colorb, done, color, datalak, data, produc, remov, tabl, schema, ’, reappli, via, way, data, clean, datalak, valid, databas, viewer, tool, product, tabl, longer, data, insid, tabl, colorfff, releas, color, knowledg, api, stori, assign, releas, reassign, user, certif, certif, api, sinc, chang, order, set, associ, certif, metadata, done, admin, panel, →, dashboard, button, action, first, remov, assign, certif, user, appli, colorfff, releas, color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat, intermedi, exam, page, admin, panel, past, text, found, provid, intermedi, document, easier, text, assign, test, environ, intermedi, exam, also, chang, advanc, ...]</td>\n",
       "      <td>[[academi, v], [constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], ...]</td>\n",
       "      <td>[[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]</td>\n",
       "      <td>[done, clean, color, releas, set, done, first, remov, user, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, also, advanc, color, go, seen, fix, also, know, object, test, checklist, jira, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set, testedhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, candid, doubl, mainlin, v, stori, v, v, v, send, send, apithon, follow, project, send, approv, april, scope, learn, suggest, lrn, initialis, lrn, object, lrn, correct, prefer, forward, approv, releas, timeslot, pleas, reach, perform, note, make, written, send, also, includ, written, app, migrat, smoke, also, includ, tmlearn, user, set, done, set, releas]</td>\n",
       "      <td>3655</td>\n",
       "      <td>juliana.bustamante@mendix.com</td>\n",
       "      <td>2021-03-29 15:20:36.864866</td>\n",
       "      <td>[LRN-1142]</td>\n",
       "      <td>[commit, pd, new, version, 26110]</td>\n",
       "      <td>[[commit, pd], [pd, new], [new, version], [version, 26110]]</td>\n",
       "      <td>[[commit, pd, new], [pd, new, version], [new, version, 26110]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[commit, pd, new, version, 26110]</td>\n",
       "      <td>[[commit, pd], [pd, new], [new, version], [version, 26110]]</td>\n",
       "      <td>[[commit, pd, new], [pd, new, version], [new, version, 26110]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138949</th>\n",
       "      <td>LRN-1198</td>\n",
       "      <td>Jasmine Vyas</td>\n",
       "      <td>2021-03-29 14:50:08.502</td>\n",
       "      <td>2021-04-16 10:00:43.182</td>\n",
       "      <td>2021-04-16 10:00:43.178</td>\n",
       "      <td>[academi, v]</td>\n",
       "      <td>[[academi, v]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[constant, constantvalueaddit, inform, schedul, event, none, migrat, none, special, action, colorbd, releas, color, colorb, done, color, datalak, data, produc, remov, tabl, schema, ’, reappli, via, way, data, clean, datalak, valid, databas, viewer, tool, product, tabl, longer, data, insid, tabl, colorfff, releas, color, knowledg, api, stori, assign, releas, reassign, user, certif, certif, api, sinc, chang, order, set, associ, certif, metadata, done, admin, panel, →, dashboard, button, action, first, remov, assign, certif, user, appli, colorfff, releas, color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat, intermedi, exam, page, admin, panel, past, text, found, provid, intermedi, document, easier, text, assign, test, environ, intermedi, exam, also, chang, advanc, develop, exam, ...]</td>\n",
       "      <td>[[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]</td>\n",
       "      <td>[[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]</td>\n",
       "      <td>[academi, v, constant, constantvalueaddit, inform, schedul, event, none, migrat, none, special, action, colorbd, releas, color, colorb, done, color, datalak, data, produc, remov, tabl, schema, ’, reappli, via, way, data, clean, datalak, valid, databas, viewer, tool, product, tabl, longer, data, insid, tabl, colorfff, releas, color, knowledg, api, stori, assign, releas, reassign, user, certif, certif, api, sinc, chang, order, set, associ, certif, metadata, done, admin, panel, →, dashboard, button, action, first, remov, assign, certif, user, appli, colorfff, releas, color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat, intermedi, exam, page, admin, panel, past, text, found, provid, intermedi, document, easier, text, assign, test, environ, intermedi, exam, also, chang, advanc, ...]</td>\n",
       "      <td>[[academi, v], [constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], ...]</td>\n",
       "      <td>[[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]</td>\n",
       "      <td>[done, clean, color, releas, set, done, first, remov, user, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, also, advanc, color, go, seen, fix, also, know, object, test, checklist, jira, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set, testedhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, candid, doubl, mainlin, v, stori, v, v, v, send, send, apithon, follow, project, send, approv, april, scope, learn, suggest, lrn, initialis, lrn, object, lrn, correct, prefer, forward, approv, releas, timeslot, pleas, reach, perform, note, make, written, send, also, includ, written, app, migrat, smoke, also, includ, tmlearn, user, set, done, set, releas]</td>\n",
       "      <td>3656</td>\n",
       "      <td>juliana.bustamante@mendix.com</td>\n",
       "      <td>2021-03-29 15:26:27.310424</td>\n",
       "      <td>[LRN-1142]</td>\n",
       "      <td>[merg, releas, academi, v1121, rev, 3655, minifi, css, miss]</td>\n",
       "      <td>[[merg, releas], [releas, academi], [academi, v1121], [v1121, rev], [rev, 3655], [3655, minifi], [minifi, css]]</td>\n",
       "      <td>[[merg, releas, academi], [releas, academi, v1121], [academi, v1121, rev], [v1121, rev, 3655], [rev, 3655, minifi], [3655, minifi, css]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[merg, releas, academi, v1121, rev, 3655, minifi, css, miss]</td>\n",
       "      <td>[[merg, releas], [releas, academi], [academi, v1121], [v1121, rev], [rev, 3655], [3655, minifi], [minifi, css]]</td>\n",
       "      <td>[[merg, releas, academi], [releas, academi, v1121], [academi, v1121, rev], [v1121, rev, 3655], [rev, 3655, minifi], [3655, minifi, css]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138950</th>\n",
       "      <td>LRN-1198</td>\n",
       "      <td>Jasmine Vyas</td>\n",
       "      <td>2021-03-29 14:50:08.502</td>\n",
       "      <td>2021-04-16 10:00:43.182</td>\n",
       "      <td>2021-04-16 10:00:43.178</td>\n",
       "      <td>[academi, v]</td>\n",
       "      <td>[[academi, v]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[constant, constantvalueaddit, inform, schedul, event, none, migrat, none, special, action, colorbd, releas, color, colorb, done, color, datalak, data, produc, remov, tabl, schema, ’, reappli, via, way, data, clean, datalak, valid, databas, viewer, tool, product, tabl, longer, data, insid, tabl, colorfff, releas, color, knowledg, api, stori, assign, releas, reassign, user, certif, certif, api, sinc, chang, order, set, associ, certif, metadata, done, admin, panel, →, dashboard, button, action, first, remov, assign, certif, user, appli, colorfff, releas, color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat, intermedi, exam, page, admin, panel, past, text, found, provid, intermedi, document, easier, text, assign, test, environ, intermedi, exam, also, chang, advanc, develop, exam, ...]</td>\n",
       "      <td>[[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]</td>\n",
       "      <td>[[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]</td>\n",
       "      <td>[academi, v, constant, constantvalueaddit, inform, schedul, event, none, migrat, none, special, action, colorbd, releas, color, colorb, done, color, datalak, data, produc, remov, tabl, schema, ’, reappli, via, way, data, clean, datalak, valid, databas, viewer, tool, product, tabl, longer, data, insid, tabl, colorfff, releas, color, knowledg, api, stori, assign, releas, reassign, user, certif, certif, api, sinc, chang, order, set, associ, certif, metadata, done, admin, panel, →, dashboard, button, action, first, remov, assign, certif, user, appli, colorfff, releas, color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat, intermedi, exam, page, admin, panel, past, text, found, provid, intermedi, document, easier, text, assign, test, environ, intermedi, exam, also, chang, advanc, ...]</td>\n",
       "      <td>[[academi, v], [constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], ...]</td>\n",
       "      <td>[[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]</td>\n",
       "      <td>[done, clean, color, releas, set, done, first, remov, user, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, also, advanc, color, go, seen, fix, also, know, object, test, checklist, jira, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set, testedhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, candid, doubl, mainlin, v, stori, v, v, v, send, send, apithon, follow, project, send, approv, april, scope, learn, suggest, lrn, initialis, lrn, object, lrn, correct, prefer, forward, approv, releas, timeslot, pleas, reach, perform, note, make, written, send, also, includ, written, app, migrat, smoke, also, includ, tmlearn, user, set, done, set, releas]</td>\n",
       "      <td>3661</td>\n",
       "      <td>reinoud.fonken@mendix.com</td>\n",
       "      <td>2021-03-30 15:54:48.164916</td>\n",
       "      <td>[LRN-1176]</td>\n",
       "      <td>[updat, progress, overview, page, inlcud, creat, chang, date, object]</td>\n",
       "      <td>[[updat, progress], [progress, overview], [overview, page], [page, inlcud], [inlcud, creat], [chang, date]]</td>\n",
       "      <td>[[updat, progress, overview], [progress, overview, page], [overview, page, inlcud], [page, inlcud, creat]]</td>\n",
       "      <td>[admin, user, progress, overview, user, progress, overview]</td>\n",
       "      <td>[[admin, user], [user, progress], [progress, overview], [overview, user], [user, progress], [progress, overview]]</td>\n",
       "      <td>[[admin, user, progress], [user, progress, overview], [progress, overview, user], [overview, user, progress], [user, progress, overview]]</td>\n",
       "      <td>[updat, progress, overview, page, inlcud, creat, chang, date, object, admin, user, progress, overview, user, progress, overview]</td>\n",
       "      <td>[[updat, progress], [progress, overview], [overview, page], [page, inlcud], [inlcud, creat], [chang, date], [admin, user], [user, progress], [progress, overview], [overview, user], [user, progress], [progress, overview]]</td>\n",
       "      <td>[[updat, progress, overview], [progress, overview, page], [overview, page, inlcud], [page, inlcud, creat], [admin, user, progress], [user, progress, overview], [progress, overview, user], [overview, user, progress], [user, progress, overview]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138951</th>\n",
       "      <td>LRN-1198</td>\n",
       "      <td>Jasmine Vyas</td>\n",
       "      <td>2021-03-29 14:50:08.502</td>\n",
       "      <td>2021-04-16 10:00:43.182</td>\n",
       "      <td>2021-04-16 10:00:43.178</td>\n",
       "      <td>[academi, v]</td>\n",
       "      <td>[[academi, v]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[constant, constantvalueaddit, inform, schedul, event, none, migrat, none, special, action, colorbd, releas, color, colorb, done, color, datalak, data, produc, remov, tabl, schema, ’, reappli, via, way, data, clean, datalak, valid, databas, viewer, tool, product, tabl, longer, data, insid, tabl, colorfff, releas, color, knowledg, api, stori, assign, releas, reassign, user, certif, certif, api, sinc, chang, order, set, associ, certif, metadata, done, admin, panel, →, dashboard, button, action, first, remov, assign, certif, user, appli, colorfff, releas, color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat, intermedi, exam, page, admin, panel, past, text, found, provid, intermedi, document, easier, text, assign, test, environ, intermedi, exam, also, chang, advanc, develop, exam, ...]</td>\n",
       "      <td>[[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]</td>\n",
       "      <td>[[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]</td>\n",
       "      <td>[academi, v, constant, constantvalueaddit, inform, schedul, event, none, migrat, none, special, action, colorbd, releas, color, colorb, done, color, datalak, data, produc, remov, tabl, schema, ’, reappli, via, way, data, clean, datalak, valid, databas, viewer, tool, product, tabl, longer, data, insid, tabl, colorfff, releas, color, knowledg, api, stori, assign, releas, reassign, user, certif, certif, api, sinc, chang, order, set, associ, certif, metadata, done, admin, panel, →, dashboard, button, action, first, remov, assign, certif, user, appli, colorfff, releas, color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat, intermedi, exam, page, admin, panel, past, text, found, provid, intermedi, document, easier, text, assign, test, environ, intermedi, exam, also, chang, advanc, ...]</td>\n",
       "      <td>[[academi, v], [constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], ...]</td>\n",
       "      <td>[[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]</td>\n",
       "      <td>[done, clean, color, releas, set, done, first, remov, user, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, also, advanc, color, go, seen, fix, also, know, object, test, checklist, jira, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set, testedhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, candid, doubl, mainlin, v, stori, v, v, v, send, send, apithon, follow, project, send, approv, april, scope, learn, suggest, lrn, initialis, lrn, object, lrn, correct, prefer, forward, approv, releas, timeslot, pleas, reach, perform, note, make, written, send, also, includ, written, app, migrat, smoke, also, includ, tmlearn, user, set, done, set, releas]</td>\n",
       "      <td>3662</td>\n",
       "      <td>nikolaos.vasileiadis@mendix.com</td>\n",
       "      <td>2021-03-31 07:08:06.261677</td>\n",
       "      <td>[LRN-1194]</td>\n",
       "      <td>[creat, branch, line, datalakecursoruniqueidentifierisnotuniqueforprogressent, revis, 3655, branch, line, develop]</td>\n",
       "      <td>[[creat, branch], [branch, line], [line, datalakecursoruniqueidentifierisnotuniqueforprogressent], [revis, 3655], [branch, line], [line, develop]]</td>\n",
       "      <td>[[creat, branch, line], [branch, line, datalakecursoruniqueidentifierisnotuniqueforprogressent], [branch, line, develop]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[creat, branch, line, datalakecursoruniqueidentifierisnotuniqueforprogressent, revis, 3655, branch, line, develop]</td>\n",
       "      <td>[[creat, branch], [branch, line], [line, datalakecursoruniqueidentifierisnotuniqueforprogressent], [revis, 3655], [branch, line], [line, develop]]</td>\n",
       "      <td>[[creat, branch, line], [branch, line, datalakecursoruniqueidentifierisnotuniqueforprogressent], [branch, line, develop]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Issue_key_jira      Assignee       Jira_created_date  \\\n",
       "138947       LRN-1198  Jasmine Vyas 2021-03-29 14:50:08.502   \n",
       "138948       LRN-1198  Jasmine Vyas 2021-03-29 14:50:08.502   \n",
       "138949       LRN-1198  Jasmine Vyas 2021-03-29 14:50:08.502   \n",
       "138950       LRN-1198  Jasmine Vyas 2021-03-29 14:50:08.502   \n",
       "138951       LRN-1198  Jasmine Vyas 2021-03-29 14:50:08.502   \n",
       "\n",
       "             Jira_updated_date      Jira_resolved_date       Summary  \\\n",
       "138947 2021-04-16 10:00:43.182 2021-04-16 10:00:43.178  [academi, v]   \n",
       "138948 2021-04-16 10:00:43.182 2021-04-16 10:00:43.178  [academi, v]   \n",
       "138949 2021-04-16 10:00:43.182 2021-04-16 10:00:43.178  [academi, v]   \n",
       "138950 2021-04-16 10:00:43.182 2021-04-16 10:00:43.178  [academi, v]   \n",
       "138951 2021-04-16 10:00:43.182 2021-04-16 10:00:43.178  [academi, v]   \n",
       "\n",
       "        Summary_2grams Summary_3grams  \\\n",
       "138947  [[academi, v]]             []   \n",
       "138948  [[academi, v]]             []   \n",
       "138949  [[academi, v]]             []   \n",
       "138950  [[academi, v]]             []   \n",
       "138951  [[academi, v]]             []   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Description  \\\n",
       "138947  [constant, constantvalueaddit, inform, schedul, event, none, migrat, none, special, action, colorbd, releas, color, colorb, done, color, datalak, data, produc, remov, tabl, schema, ’, reappli, via, way, data, clean, datalak, valid, databas, viewer, tool, product, tabl, longer, data, insid, tabl, colorfff, releas, color, knowledg, api, stori, assign, releas, reassign, user, certif, certif, api, sinc, chang, order, set, associ, certif, metadata, done, admin, panel, →, dashboard, button, action, first, remov, assign, certif, user, appli, colorfff, releas, color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat, intermedi, exam, page, admin, panel, past, text, found, provid, intermedi, document, easier, text, assign, test, environ, intermedi, exam, also, chang, advanc, develop, exam, ...]   \n",
       "138948  [constant, constantvalueaddit, inform, schedul, event, none, migrat, none, special, action, colorbd, releas, color, colorb, done, color, datalak, data, produc, remov, tabl, schema, ’, reappli, via, way, data, clean, datalak, valid, databas, viewer, tool, product, tabl, longer, data, insid, tabl, colorfff, releas, color, knowledg, api, stori, assign, releas, reassign, user, certif, certif, api, sinc, chang, order, set, associ, certif, metadata, done, admin, panel, →, dashboard, button, action, first, remov, assign, certif, user, appli, colorfff, releas, color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat, intermedi, exam, page, admin, panel, past, text, found, provid, intermedi, document, easier, text, assign, test, environ, intermedi, exam, also, chang, advanc, develop, exam, ...]   \n",
       "138949  [constant, constantvalueaddit, inform, schedul, event, none, migrat, none, special, action, colorbd, releas, color, colorb, done, color, datalak, data, produc, remov, tabl, schema, ’, reappli, via, way, data, clean, datalak, valid, databas, viewer, tool, product, tabl, longer, data, insid, tabl, colorfff, releas, color, knowledg, api, stori, assign, releas, reassign, user, certif, certif, api, sinc, chang, order, set, associ, certif, metadata, done, admin, panel, →, dashboard, button, action, first, remov, assign, certif, user, appli, colorfff, releas, color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat, intermedi, exam, page, admin, panel, past, text, found, provid, intermedi, document, easier, text, assign, test, environ, intermedi, exam, also, chang, advanc, develop, exam, ...]   \n",
       "138950  [constant, constantvalueaddit, inform, schedul, event, none, migrat, none, special, action, colorbd, releas, color, colorb, done, color, datalak, data, produc, remov, tabl, schema, ’, reappli, via, way, data, clean, datalak, valid, databas, viewer, tool, product, tabl, longer, data, insid, tabl, colorfff, releas, color, knowledg, api, stori, assign, releas, reassign, user, certif, certif, api, sinc, chang, order, set, associ, certif, metadata, done, admin, panel, →, dashboard, button, action, first, remov, assign, certif, user, appli, colorfff, releas, color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat, intermedi, exam, page, admin, panel, past, text, found, provid, intermedi, document, easier, text, assign, test, environ, intermedi, exam, also, chang, advanc, develop, exam, ...]   \n",
       "138951  [constant, constantvalueaddit, inform, schedul, event, none, migrat, none, special, action, colorbd, releas, color, colorb, done, color, datalak, data, produc, remov, tabl, schema, ’, reappli, via, way, data, clean, datalak, valid, databas, viewer, tool, product, tabl, longer, data, insid, tabl, colorfff, releas, color, knowledg, api, stori, assign, releas, reassign, user, certif, certif, api, sinc, chang, order, set, associ, certif, metadata, done, admin, panel, →, dashboard, button, action, first, remov, assign, certif, user, appli, colorfff, releas, color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat, intermedi, exam, page, admin, panel, past, text, found, provid, intermedi, document, easier, text, assign, test, environ, intermedi, exam, also, chang, advanc, develop, exam, ...]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Description_2grams  \\\n",
       "138947  [[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]   \n",
       "138948  [[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]   \n",
       "138949  [[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]   \n",
       "138950  [[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]   \n",
       "138951  [[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Description_3grams  \\\n",
       "138947  [[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]   \n",
       "138948  [[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]   \n",
       "138949  [[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]   \n",
       "138950  [[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]   \n",
       "138951  [[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Jira_natural_text  \\\n",
       "138947  [academi, v, constant, constantvalueaddit, inform, schedul, event, none, migrat, none, special, action, colorbd, releas, color, colorb, done, color, datalak, data, produc, remov, tabl, schema, ’, reappli, via, way, data, clean, datalak, valid, databas, viewer, tool, product, tabl, longer, data, insid, tabl, colorfff, releas, color, knowledg, api, stori, assign, releas, reassign, user, certif, certif, api, sinc, chang, order, set, associ, certif, metadata, done, admin, panel, →, dashboard, button, action, first, remov, assign, certif, user, appli, colorfff, releas, color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat, intermedi, exam, page, admin, panel, past, text, found, provid, intermedi, document, easier, text, assign, test, environ, intermedi, exam, also, chang, advanc, ...]   \n",
       "138948  [academi, v, constant, constantvalueaddit, inform, schedul, event, none, migrat, none, special, action, colorbd, releas, color, colorb, done, color, datalak, data, produc, remov, tabl, schema, ’, reappli, via, way, data, clean, datalak, valid, databas, viewer, tool, product, tabl, longer, data, insid, tabl, colorfff, releas, color, knowledg, api, stori, assign, releas, reassign, user, certif, certif, api, sinc, chang, order, set, associ, certif, metadata, done, admin, panel, →, dashboard, button, action, first, remov, assign, certif, user, appli, colorfff, releas, color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat, intermedi, exam, page, admin, panel, past, text, found, provid, intermedi, document, easier, text, assign, test, environ, intermedi, exam, also, chang, advanc, ...]   \n",
       "138949  [academi, v, constant, constantvalueaddit, inform, schedul, event, none, migrat, none, special, action, colorbd, releas, color, colorb, done, color, datalak, data, produc, remov, tabl, schema, ’, reappli, via, way, data, clean, datalak, valid, databas, viewer, tool, product, tabl, longer, data, insid, tabl, colorfff, releas, color, knowledg, api, stori, assign, releas, reassign, user, certif, certif, api, sinc, chang, order, set, associ, certif, metadata, done, admin, panel, →, dashboard, button, action, first, remov, assign, certif, user, appli, colorfff, releas, color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat, intermedi, exam, page, admin, panel, past, text, found, provid, intermedi, document, easier, text, assign, test, environ, intermedi, exam, also, chang, advanc, ...]   \n",
       "138950  [academi, v, constant, constantvalueaddit, inform, schedul, event, none, migrat, none, special, action, colorbd, releas, color, colorb, done, color, datalak, data, produc, remov, tabl, schema, ’, reappli, via, way, data, clean, datalak, valid, databas, viewer, tool, product, tabl, longer, data, insid, tabl, colorfff, releas, color, knowledg, api, stori, assign, releas, reassign, user, certif, certif, api, sinc, chang, order, set, associ, certif, metadata, done, admin, panel, →, dashboard, button, action, first, remov, assign, certif, user, appli, colorfff, releas, color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat, intermedi, exam, page, admin, panel, past, text, found, provid, intermedi, document, easier, text, assign, test, environ, intermedi, exam, also, chang, advanc, ...]   \n",
       "138951  [academi, v, constant, constantvalueaddit, inform, schedul, event, none, migrat, none, special, action, colorbd, releas, color, colorb, done, color, datalak, data, produc, remov, tabl, schema, ’, reappli, via, way, data, clean, datalak, valid, databas, viewer, tool, product, tabl, longer, data, insid, tabl, colorfff, releas, color, knowledg, api, stori, assign, releas, reassign, user, certif, certif, api, sinc, chang, order, set, associ, certif, metadata, done, admin, panel, →, dashboard, button, action, first, remov, assign, certif, user, appli, colorfff, releas, color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat, intermedi, exam, page, admin, panel, past, text, found, provid, intermedi, document, easier, text, assign, test, environ, intermedi, exam, also, chang, advanc, ...]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Jira_natural_text_2grams  \\\n",
       "138947  [[academi, v], [constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], ...]   \n",
       "138948  [[academi, v], [constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], ...]   \n",
       "138949  [[academi, v], [constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], ...]   \n",
       "138950  [[academi, v], [constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], ...]   \n",
       "138951  [[academi, v], [constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], ...]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Jira_natural_text_3grams  \\\n",
       "138947  [[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]   \n",
       "138948  [[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]   \n",
       "138949  [[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]   \n",
       "138950  [[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]   \n",
       "138951  [[constant, constantvalueaddit], [constantvalueaddit, inform], [inform, schedul], [schedul, event], [event, none], [none, migrat], [migrat, none], [special, action], [action, colorbd], [releas, color], [color, colorb], [colorb, done], [done, color], [color, datalak], [datalak, data], [data, produc], [produc, remov], [schema, ’], [datalak, valid], [databas, viewer], [viewer, tool], [product, tabl], [longer, data], [data, insid], [tabl, colorfff], [releas, color], [color, knowledg], [knowledg, api], [api, stori], [releas, reassign], [certif, api], [api, sinc], [admin, panel], [panel, →], [→, dashboard], [first, remov], [assign, certif], [releas, color], [color, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, creat], [intermedi, exam], [exam, page], [admin, panel], [provid, intermedi], [intermedi, document], [test, environ], [intermedi, exam], [exam, also], [also, chang], [advanc, develop], [develop, exam], [exam, classroom], [admin, panel], [section, prerequis], [rapid, develop], [develop, certif], [intermedi, develop], [develop, certif], [certif, colorfff], [releas, color], [color, jasmin], [jasmin, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink], [httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, go], [admin, panel], [duplic, record], [record, tab], [manual, trigger], [fix, duplic], [duplic, record], [record, button], [tab, learn], [learn, path], [path, none], [none, modul], [modul, lectur], [learningpath, version], [version, draft], [draft, modul], [modul, version], [version, lectur], [lectur, version], [version, also], [duplic, lecturevers], [lecturevers, object], [fix, duplic], [duplic, button], [test, plan], [plan, test], [httpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, day], [releas, statusstepsresult], [statusstepsresult, comment], [comment, xcheck], [releas, checklist], [checklist, check], [relat, stori], [jira, releas], [releas, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set], [jira, releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu], [releasehttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, creat], ...]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              verbs  \\\n",
       "138947  [done, clean, color, releas, set, done, first, remov, user, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, also, advanc, color, go, seen, fix, also, know, object, test, checklist, jira, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set, testedhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, candid, doubl, mainlin, v, stori, v, v, v, send, send, apithon, follow, project, send, approv, april, scope, learn, suggest, lrn, initialis, lrn, object, lrn, correct, prefer, forward, approv, releas, timeslot, pleas, reach, perform, note, make, written, send, also, includ, written, app, migrat, smoke, also, includ, tmlearn, user, set, done, set, releas]   \n",
       "138948  [done, clean, color, releas, set, done, first, remov, user, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, also, advanc, color, go, seen, fix, also, know, object, test, checklist, jira, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set, testedhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, candid, doubl, mainlin, v, stori, v, v, v, send, send, apithon, follow, project, send, approv, april, scope, learn, suggest, lrn, initialis, lrn, object, lrn, correct, prefer, forward, approv, releas, timeslot, pleas, reach, perform, note, make, written, send, also, includ, written, app, migrat, smoke, also, includ, tmlearn, user, set, done, set, releas]   \n",
       "138949  [done, clean, color, releas, set, done, first, remov, user, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, also, advanc, color, go, seen, fix, also, know, object, test, checklist, jira, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set, testedhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, candid, doubl, mainlin, v, stori, v, v, v, send, send, apithon, follow, project, send, approv, april, scope, learn, suggest, lrn, initialis, lrn, object, lrn, correct, prefer, forward, approv, releas, timeslot, pleas, reach, perform, note, make, written, send, also, includ, written, app, migrat, smoke, also, includ, tmlearn, user, set, done, set, releas]   \n",
       "138950  [done, clean, color, releas, set, done, first, remov, user, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, also, advanc, color, go, seen, fix, also, know, object, test, checklist, jira, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set, testedhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, candid, doubl, mainlin, v, stori, v, v, v, send, send, apithon, follow, project, send, approv, april, scope, learn, suggest, lrn, initialis, lrn, object, lrn, correct, prefer, forward, approv, releas, timeslot, pleas, reach, perform, note, make, written, send, also, includ, written, app, migrat, smoke, also, includ, tmlearn, user, set, done, set, releas]   \n",
       "138951  [done, clean, color, releas, set, done, first, remov, user, httpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinkhttpsmendixatlassiannetbrowselrnhttpsmendixatlassiannetbrowselrnsmartlinksmartlink, also, advanc, color, go, seen, fix, also, know, object, test, checklist, jira, listhttpsmendixatlassiannetprojectslrnversionstabreleasereportallissueshttpsmendixatlassiannetprojectslrnversionstabreleasereportallissu, set, testedhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvubhttpspaperdropboxcomdocreleasetestplanacademyvbigzjplffhrxibzukzagoqxjvavqlsbfcacvub, candid, doubl, mainlin, v, stori, v, v, v, send, send, apithon, follow, project, send, approv, april, scope, learn, suggest, lrn, initialis, lrn, object, lrn, correct, prefer, forward, approv, releas, timeslot, pleas, reach, perform, note, make, written, send, also, includ, written, app, migrat, smoke, also, includ, tmlearn, user, set, done, set, releas]   \n",
       "\n",
       "       Revision                            Email                Commit_date  \\\n",
       "138947     3653    juliana.bustamante@mendix.com 2021-03-29 15:05:59.840013   \n",
       "138948     3655    juliana.bustamante@mendix.com 2021-03-29 15:20:36.864866   \n",
       "138949     3656    juliana.bustamante@mendix.com 2021-03-29 15:26:27.310424   \n",
       "138950     3661        reinoud.fonken@mendix.com 2021-03-30 15:54:48.164916   \n",
       "138951     3662  nikolaos.vasileiadis@mendix.com 2021-03-31 07:08:06.261677   \n",
       "\n",
       "       Issue_key_commit  \\\n",
       "138947       [LRN-1142]   \n",
       "138948       [LRN-1142]   \n",
       "138949       [LRN-1142]   \n",
       "138950       [LRN-1176]   \n",
       "138951       [LRN-1194]   \n",
       "\n",
       "                                                                                                                      Logs  \\\n",
       "138947                                                                           [merg, releas, academi, v1121, rev, 3652]   \n",
       "138948                                                                                   [commit, pd, new, version, 26110]   \n",
       "138949                                                        [merg, releas, academi, v1121, rev, 3655, minifi, css, miss]   \n",
       "138950                                               [updat, progress, overview, page, inlcud, creat, chang, date, object]   \n",
       "138951  [creat, branch, line, datalakecursoruniqueidentifierisnotuniqueforprogressent, revis, 3655, branch, line, develop]   \n",
       "\n",
       "                                                                                                                                               Logs_2grams  \\\n",
       "138947                                                                    [[merg, releas], [releas, academi], [academi, v1121], [v1121, rev], [rev, 3652]]   \n",
       "138948                                                                                         [[commit, pd], [pd, new], [new, version], [version, 26110]]   \n",
       "138949                                     [[merg, releas], [releas, academi], [academi, v1121], [v1121, rev], [rev, 3655], [3655, minifi], [minifi, css]]   \n",
       "138950                                         [[updat, progress], [progress, overview], [overview, page], [page, inlcud], [inlcud, creat], [chang, date]]   \n",
       "138951  [[creat, branch], [branch, line], [line, datalakecursoruniqueidentifierisnotuniqueforprogressent], [revis, 3655], [branch, line], [line, develop]]   \n",
       "\n",
       "                                                                                                                                     Logs_3grams  \\\n",
       "138947                                            [[merg, releas, academi], [releas, academi, v1121], [academi, v1121, rev], [v1121, rev, 3652]]   \n",
       "138948                                                                            [[commit, pd, new], [pd, new, version], [new, version, 26110]]   \n",
       "138949  [[merg, releas, academi], [releas, academi, v1121], [academi, v1121, rev], [v1121, rev, 3655], [rev, 3655, minifi], [3655, minifi, css]]   \n",
       "138950                                [[updat, progress, overview], [progress, overview, page], [overview, page, inlcud], [page, inlcud, creat]]   \n",
       "138951                 [[creat, branch, line], [branch, line, datalakecursoruniqueidentifierisnotuniqueforprogressent], [branch, line, develop]]   \n",
       "\n",
       "                                                         Unit_names  \\\n",
       "138947                     [imag, home, admin, panel, layout, crud]   \n",
       "138948                                                           []   \n",
       "138949                                                           []   \n",
       "138950  [admin, user, progress, overview, user, progress, overview]   \n",
       "138951                                                           []   \n",
       "\n",
       "                                                                                                        Unit_names_2grams  \\\n",
       "138947                                     [[imag, home], [home, admin], [admin, panel], [panel, layout], [layout, crud]]   \n",
       "138948                                                                                                                 []   \n",
       "138949                                                                                                                 []   \n",
       "138950  [[admin, user], [user, progress], [progress, overview], [overview, user], [user, progress], [progress, overview]]   \n",
       "138951                                                                                                                 []   \n",
       "\n",
       "                                                                                                                                Unit_names_3grams  \\\n",
       "138947                                                 [[imag, home, admin], [home, admin, panel], [admin, panel, layout], [panel, layout, crud]]   \n",
       "138948                                                                                                                                         []   \n",
       "138949                                                                                                                                         []   \n",
       "138950  [[admin, user, progress], [user, progress, overview], [progress, overview, user], [overview, user, progress], [user, progress, overview]]   \n",
       "138951                                                                                                                                         []   \n",
       "\n",
       "                                                                                                                     Commit_natural_text  \\\n",
       "138947                                                 [merg, releas, academi, v1121, rev, 3652, imag, home, admin, panel, layout, crud]   \n",
       "138948                                                                                                 [commit, pd, new, version, 26110]   \n",
       "138949                                                                      [merg, releas, academi, v1121, rev, 3655, minifi, css, miss]   \n",
       "138950  [updat, progress, overview, page, inlcud, creat, chang, date, object, admin, user, progress, overview, user, progress, overview]   \n",
       "138951                [creat, branch, line, datalakecursoruniqueidentifierisnotuniqueforprogressent, revis, 3655, branch, line, develop]   \n",
       "\n",
       "                                                                                                                                                                                                          Commit_natural_text_2grams  \\\n",
       "138947                                                                [[merg, releas], [releas, academi], [academi, v1121], [v1121, rev], [rev, 3652], [imag, home], [home, admin], [admin, panel], [panel, layout], [layout, crud]]   \n",
       "138948                                                                                                                                                                   [[commit, pd], [pd, new], [new, version], [version, 26110]]   \n",
       "138949                                                                                                               [[merg, releas], [releas, academi], [academi, v1121], [v1121, rev], [rev, 3655], [3655, minifi], [minifi, css]]   \n",
       "138950  [[updat, progress], [progress, overview], [overview, page], [page, inlcud], [inlcud, creat], [chang, date], [admin, user], [user, progress], [progress, overview], [overview, user], [user, progress], [progress, overview]]   \n",
       "138951                                                                            [[creat, branch], [branch, line], [line, datalakecursoruniqueidentifierisnotuniqueforprogressent], [revis, 3655], [branch, line], [line, develop]]   \n",
       "\n",
       "                                                                                                                                                                                                                                 Commit_natural_text_3grams  \n",
       "138947                                                             [[merg, releas, academi], [releas, academi, v1121], [academi, v1121, rev], [v1121, rev, 3652], [imag, home, admin], [home, admin, panel], [admin, panel, layout], [panel, layout, crud]]  \n",
       "138948                                                                                                                                                                                       [[commit, pd, new], [pd, new, version], [new, version, 26110]]  \n",
       "138949                                                                                                             [[merg, releas, academi], [releas, academi, v1121], [academi, v1121, rev], [v1121, rev, 3655], [rev, 3655, minifi], [3655, minifi, css]]  \n",
       "138950  [[updat, progress, overview], [progress, overview, page], [overview, page, inlcud], [page, inlcud, creat], [admin, user, progress], [user, progress, overview], [progress, overview, user], [overview, user, progress], [user, progress, overview]]  \n",
       "138951                                                                                                                            [[creat, branch, line], [branch, line, datalakecursoruniqueidentifierisnotuniqueforprogressent], [branch, line, develop]]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processedData_academyCartesian.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-texas",
   "metadata": {},
   "source": [
    "## 3.1 Preprocess Data - Create Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "romance-dubai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating labels for academy\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1375042 entries, 138947 to 3139051\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Non-Null Count    Dtype\n",
      "---  ------    --------------    -----\n",
      " 0   is_valid  1375042 non-null  bool \n",
      "dtypes: bool(1)\n",
      "memory usage: 11.8 MB\n"
     ]
    }
   ],
   "source": [
    "#Create new dataFrames for the time features\n",
    "processedData_academyLabels = pd.DataFrame() \n",
    "\n",
    "\n",
    "#Create a column, which indicates which traces are valid.\n",
    "processedData_academyLabels[\"is_valid\"] = processedData_academyCartesian.apply(lambda x: checkValidityTrace(x.Issue_key_jira, x.Issue_key_commit), axis=1)\n",
    "print(\"Finished creating labels for academy\")\n",
    "\n",
    "#Save intermediate results\n",
    "processedData_academyLabels.to_pickle(path= \"../data/03_processed/processedData_academyLabels.pkl\")\n",
    "\n",
    "processedData_academyLabels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-oakland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "special-november",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_valid    3104\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#processedData_academyLabels[processedData_academyLabels.is_valid == True].count()\n",
    "processedData_academyLabels[processedData_academyLabels.is_valid == True].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-helicopter",
   "metadata": {},
   "source": [
    "## 3.2 Preprocess Data - Create Time-Related Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "emerging-driving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished data Processing\n"
     ]
    }
   ],
   "source": [
    "#Create new dataFrames for the time features\n",
    "processedData_academyFeaturesTime = pd.DataFrame() \n",
    "\n",
    "\n",
    "#Calculate the time features for data Processing Dataset\n",
    "processedData_academyFeaturesTime['Creation_commit_date_dif'] = processedData_academyCartesian.apply(lambda x: calculateTimeDif(x.Jira_created_date, x.Commit_date), axis=1)\n",
    "processedData_academyFeaturesTime['Updated_commit_date_dif'] = processedData_academyCartesian.apply(lambda x: calculateTimeDif(x.Jira_updated_date, x.Commit_date), axis=1)\n",
    "processedData_academyFeaturesTime['Resolved_commit_date_dif'] = processedData_academyCartesian.apply(lambda x: calculateTimeDif(x.Jira_resolved_date, x.Commit_date), axis=1)\n",
    "print(\"Finished data Processing\")\n",
    "\n",
    "#Create a pickle file for all intermediate datasets\n",
    "processedData_academyFeaturesTime.to_pickle(path= \"../data/03_processed/processedData_academyFeaturesTime.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-tribune",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "played-exchange",
   "metadata": {},
   "source": [
    "## 3.3 Preprocess Data - Create Stakeholder-Related Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "thousand-logistics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished academy\n"
     ]
    }
   ],
   "source": [
    "#Create new dataFrames for the Stakeholder features\n",
    "processedData_academyFeaturesStakeholder = pd.DataFrame() \n",
    "\n",
    "processedData_academyFeaturesStakeholder['Assignee_is_commiter'] = processedData_academyCartesian.apply(lambda x: checkFullnameEqualsEmail(x.Assignee, x.Email), axis=1)\n",
    "print(\"Finished academy\")\n",
    "\n",
    "#Create a pickle file for all intermediate datasets\n",
    "processedData_academyFeaturesStakeholder.to_pickle(path= \"../data/03_processed/processedData_academyFeaturesStakeholder.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "related-eclipse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1375042 entries, 138947 to 3139051\n",
      "Data columns (total 1 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   Assignee_is_commiter  381844 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 21.0 MB\n"
     ]
    }
   ],
   "source": [
    "processedData_academyFeaturesStakeholder.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-marijuana",
   "metadata": {},
   "source": [
    "## 3.4 Preprocess Data - Create Cosine Similarity Features\n",
    "### 3.4.1 academy - Cosine Similarity UniGrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "infectious-imagination",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "import pandas as pd\n",
    "\n",
    "def calc_vector_representation(document, cv, fittedTF_IDF):        \n",
    "    #Transform document type to a string\n",
    "    documentString = document\n",
    "    \n",
    "    #Calculate the Term Frequency of the document\n",
    "    inputDocs = [documentString] \n",
    "\n",
    "    # count matrix \n",
    "    count_vector = cv.transform(inputDocs) \n",
    " \n",
    "    #tf-idf scores \n",
    "    tf_idf_vector = fittedTF_IDF.transform(count_vector)\n",
    "\n",
    "    feature_names = cv.get_feature_names() \n",
    " \n",
    "    #get tfidf vector for first document \n",
    "    document_vector=tf_idf_vector[0] \n",
    " \n",
    "    #print the scores \n",
    "    \n",
    "    # place tf-idf values in a pandas data frame \n",
    "    df = pd.DataFrame(document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"]) \n",
    "    df.sort_values(by=[\"tfidf\"],ascending=False)\n",
    "\n",
    "    return(document_vector.T.todense())\n",
    "\n",
    "def calculateCosineSimilarity(document1, document2, cv, fittedTF_IDF):\n",
    "\n",
    "    #If both doc1 and doc2 are lists\n",
    "    if (isinstance(document1, list) & isinstance(document2, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ' '.join(document1)\n",
    "        document2String = ' '.join(document2)\n",
    "\n",
    "    #Only document1 is a list\n",
    "    elif(isinstance(document1, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ' '.join(document1)\n",
    "        document2String = ''\n",
    "\n",
    "    #Only document2 is a list\n",
    "    elif(isinstance(document2, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ''\n",
    "        document2String = ' '.join(document2)\n",
    "        \n",
    "    else:\n",
    "        document1String = ''\n",
    "        document2String = ''\n",
    "\n",
    "    vector1 = calc_vector_representation(document1String, cv, fittedTF_IDF)\n",
    "    vector2 = calc_vector_representation(document2String, cv, fittedTF_IDF)\n",
    "    \n",
    "    #The cosine similarity. Produces NaN if no terms are found in the corpus.\n",
    "    result = 1 - spatial.distance.cosine(vector1, vector2)\n",
    "    \n",
    "    return(result)\n",
    "\n",
    "def calculateCosineSimilarityNGrams(document1, document2, cv, fittedTF_IDF):\n",
    "\n",
    "    #If both doc1 and doc2 are lists\n",
    "    if (isinstance(document1, list) & isinstance(document2, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ' '.join(document1)\n",
    "        document2String = ' '.join(document2)\n",
    "\n",
    "    #Only document1 is a list\n",
    "    elif(isinstance(document1, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ' '.join(document1)\n",
    "        document2String = ''\n",
    "\n",
    "    #Only document2 is a list\n",
    "    elif(isinstance(document2, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ''\n",
    "        document2String = ' '.join(document2)\n",
    "        \n",
    "    else:\n",
    "        document1String = ''\n",
    "        document2String = ''\n",
    "\n",
    "    vector1 = calc_vector_representation(document1String, cv, fittedTF_IDF)\n",
    "    vector2 = calc_vector_representation(document2String, cv, fittedTF_IDF)\n",
    "    \n",
    "    #The cosine similarity. Produces NaN if no terms are found in the corpus.\n",
    "    result = 1 - spatial.distance.cosine(vector1, vector2)\n",
    "    \n",
    "    return(result)\n",
    "\n",
    "\n",
    "def calculateCosineSimilarityWithPOSPruning(document1, document2, cv, fittedTF_IDF, verbList):\n",
    "\n",
    "    #If both doc1 and doc2 are lists\n",
    "    if (isinstance(document1, list) & isinstance(document2, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ' '.join(document1)\n",
    "        document2String = ' '.join(document2)\n",
    "\n",
    "    #Only document1 is a list\n",
    "    elif(isinstance(document1, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ' '.join(document1)\n",
    "        document2String = ''\n",
    "\n",
    "    #Only document2 is a list\n",
    "    elif(isinstance(document2, list)):\n",
    "        #Transform document to string type\n",
    "        document1String = ''\n",
    "        document2String = ' '.join(document2)\n",
    "        \n",
    "    else:\n",
    "        document1String = ''\n",
    "        document2String = ''\n",
    "\n",
    "    vector1 = calc_vector_representation(document1String, cv, fittedTF_IDF)\n",
    "    vector2 = calc_vector_representation(document2String, cv, fittedTF_IDF)\n",
    "    \n",
    "    #The cosine similarity. Produces NaN if no terms are found in the corpus.\n",
    "    result = 1 - spatial.distance.cosine(vector1, vector2)\n",
    "    \n",
    "    verbCounter = 0\n",
    "    if(isinstance(document2, list)):\n",
    "        for token in document2:\n",
    "            if token in verbList:\n",
    "                verbCounter = verbCounter + 1\n",
    "    \n",
    "    if verbCounter > 0:\n",
    "        result = result * (1 + (0.1 * verbCounter))\n",
    "    else:\n",
    "        result = 0\n",
    "    \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "incorporate-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the count vectorizer and tfidf for the corpus\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "######################################################\n",
    "#                       academy              #\n",
    "######################################################\n",
    "\n",
    "################# Unigrams ###############\n",
    "#instantiate CountVectorizer() for SVN\n",
    "processedData_SVN_academyCountVectorizer = CountVectorizer()\n",
    "processedData_SVN_academyCountTF_IDF = createFittedTF_IDF(processedData_SVN_academyCountVectorizer, intermediateData_SVN_academyCorpus)\n",
    "\n",
    "processedData_SVNLogs_academyCountVectorizer = CountVectorizer()\n",
    "processedData_SVNLogs_academyCountTF_IDF = createFittedTF_IDF(processedData_SVNLogs_academyCountVectorizer, intermediateData_SVNLogs_academyCorpus)\n",
    "\n",
    "processedData_SVNUnitNames_academyCountVectorizer = CountVectorizer()\n",
    "processedData_SVNUnitNames_academyCountTF_IDF = createFittedTF_IDF(processedData_SVNUnitNames_academyCountVectorizer, intermediateData_SVNUnitNames_academyCorpus)\n",
    "\n",
    "#instantiate CountVectorizer() for JIRA - unigram\n",
    "processedData_JIRA_academyCountVectorizer = CountVectorizer()\n",
    "processedData_JIRA_academyCountTF_IDF = createFittedTF_IDF(processedData_JIRA_academyCountVectorizer, intermediateData_JIRA_academyCorpus)\n",
    "\n",
    "processedData_JIRASummaries_academyCountVectorizer = CountVectorizer()\n",
    "processedData_JIRASummaries_academyCountTF_IDF = createFittedTF_IDF(processedData_JIRASummaries_academyCountVectorizer, intermediateData_JIRA_academyCorpusSummary)\n",
    "\n",
    "processedData_JIRADescriptions_academyCountVectorizer = CountVectorizer()\n",
    "processedData_JIRADescriptions_academyCountTF_IDF = createFittedTF_IDF(processedData_JIRADescriptions_academyCountVectorizer, intermediateData_JIRA_academyCorpusDescription)\n",
    "\n",
    "#processedData_JIRAComments_academyCountVectorizer = CountVectorizer()\n",
    "#processedData_JIRAComments_academyCountTF_IDF = createFittedTF_IDF(processedData_JIRAComments_academyCountVectorizer, intermediateData_JIRA_academyCorpusComments)\n",
    "\n",
    "\n",
    "################# Bigrams ###############\n",
    "#instantiate CountVectorizer() for SVN - bigrams\n",
    "processedData_SVNLogs_academyCountVectorizer_2gram = CountVectorizer(ngram_range=(2, 2))\n",
    "processedData_SVNLogs_academyCountTF_IDF_2gram = createFittedTF_IDF(processedData_SVNLogs_academyCountVectorizer_2gram, intermediateData_SVNLogs_academyCorpus_2gram)\n",
    "\n",
    "processedData_SVNUnitNames_academyCountVectorizer_2gram = CountVectorizer()\n",
    "processedData_SVNUnitNames_academyCountTF_IDF_2gram = createFittedTF_IDF(processedData_SVNUnitNames_academyCountVectorizer_2gram, intermediateData_SVNUnitNames_academyCorpus_2gram)\n",
    "\n",
    "\n",
    "#instantiate CountVectorizer() for JIRA - biigram\n",
    "processedData_JIRA_academyCountVectorizer_2gram = CountVectorizer(ngram_range=(2, 2))\n",
    "processedData_JIRA_academyCountTF_IDF_2gram = createFittedTF_IDF(processedData_JIRA_academyCountVectorizer_2gram, intermediateData_JIRA_academyCorpus_2gram)\n",
    "\n",
    "processedData_JIRASummaries_academyCountVectorizer_2gram = CountVectorizer(ngram_range=(2, 2))\n",
    "processedData_JIRASummaries_academyCountTF_IDF_2gram = createFittedTF_IDF(processedData_JIRASummaries_academyCountVectorizer_2gram, intermediateData_JIRA_academyCorpusSummary_2grams)\n",
    "\n",
    "processedData_JIRADescriptions_academyCountVectorizer_2gram = CountVectorizer(ngram_range=(2, 2))\n",
    "processedData_JIRADescriptions_academyCountTF_IDF_2gram = createFittedTF_IDF(processedData_JIRADescriptions_academyCountVectorizer_2gram, intermediateData_JIRA_academyCorpusDescription_2grams)\n",
    "\n",
    "#processedData_JIRAComments_academyCountVectorizer_2gram = CountVectorizer(ngram_range=(2, 2))\n",
    "#processedData_JIRAComments_academyCountTF_IDF_2gram = createFittedTF_IDF(processedData_JIRAComments_academyCountVectorizer_2gram, intermediateData_JIRA_academyCorpusComments_2grams)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-audience",
   "metadata": {},
   "source": [
    "#### 3.4.1 [VSM unigram] Similarity between JIRA issue and Commit Log - Jira As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "governmental-replication",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Randell\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\spatial\\distance.py:699: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM Logs Jira as query' after 171 minutes and 4.538911581039429 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmLogsJiraAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmLogsJiraAsQuery[\"vsm_logs_jira_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Logs, processedData_JIRA_academyCountVectorizer, processedData_JIRA_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmLogsJiraAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmLogsJiraAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-september",
   "metadata": {},
   "source": [
    "#### 3.4.2 [VSM unigram] Similarity between JIRA issue and Commit Log - Log As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "suspected-stretch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM Logs Jira as query' after 129 minutes and 54.4845917224884 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmLogsLogAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmLogsLogAsQuery[\"vsm_logs_log_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Logs, processedData_SVNLogs_academyCountVectorizer, processedData_SVNLogs_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmLogsLogAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmLogsLogAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-basic",
   "metadata": {},
   "source": [
    "#### 3.4.3 [VSM unigram] Similarity between JIRA issue and Unit Names - JIRA As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "broadband-commodity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM Logs Jira as query' after 162 minutes and 42.55891966819763 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmUnitNamesJiraAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmUnitNamesJiraAsQuery[\"vsm_unit_names_jira_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Unit_names, processedData_JIRA_academyCountVectorizer, processedData_JIRA_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmUnitNamesJiraAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmUnitNamesJiraAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-drink",
   "metadata": {},
   "source": [
    "#### 3.4.1 [VSM unigram] Similarity between JIRA Summary and Commit Log - Jira As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "limiting-classics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM Logs Jira as query' after 82 minutes and 24.53457760810852 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmSummaryLogsSummaryAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmSummaryLogsSummaryAsQuery[\"vsm_summary_logs_summary_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Summary, x.Logs, processedData_JIRASummaries_academyCountVectorizer, processedData_JIRASummaries_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmSummaryLogsSummaryAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmSummaryLogsSummaryAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-victor",
   "metadata": {},
   "source": [
    "#### 3.4.1 [VSM unigram] Similarity between JIRA Summary and Commit Log - Log As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "polar-lying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM Logs Jira as query' after 127 minutes and 20.38952612876892 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmSummaryLogsLogsAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmSummaryLogsLogsAsQuery[\"vsm_summary_logs_logs_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Summary, x.Logs, processedData_SVNLogs_academyCountVectorizer, processedData_SVNLogs_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmSummaryLogsLogsAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmSummaryLogsLogsAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-receiver",
   "metadata": {},
   "source": [
    "#### 3.4.1 [VSM unigram] Similarity between JIRA Summary and UnitNames - Summary As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "small-request",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM Logs Jira as query' after 600 minutes and 4.616283893585205 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmSummaryUnitNamesSummaryAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmSummaryUnitNamesSummaryAsQuery[\"vsm_summary_unitNames_summary_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Summary, x.Unit_names, processedData_JIRASummaries_academyCountVectorizer, processedData_JIRASummaries_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmSummaryUnitNamesSummaryAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmSummaryUnitNamesSummaryAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-guinea",
   "metadata": {},
   "source": [
    "#### 3.4.1 [VSM unigram] Similarity between JIRA Summary and UnitNames - UnitNames As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "convinced-terminology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM Logs Jira as query' after 81 minutes and 34.31193780899048 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmSummaryUnitNamesUnitNamesAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmSummaryUnitNamesUnitNamesAsQuery[\"vsm_summary_unitNames_unitNames_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Summary, x.Unit_names, processedData_SVNUnitNames_academyCountVectorizer, processedData_SVNUnitNames_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmSummaryUnitNamesSummaryAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmSummaryUnitNamesUnitNamesAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-greek",
   "metadata": {},
   "source": [
    "#### 3.4.3 [VSM unigram - verb pruning] Similarity between JIRA issue and Unit Names - JIRA As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "rural-cholesterol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM Logs Jira as query and verb pruning' after 163 minutes and 27.66766881942749 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmVerbPruningUnitNamesJiraAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmVerbPruningUnitNamesJiraAsQuery[\"vsm_verb_pruning_unit_names_jira_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarityWithPOSPruning(x.Jira_natural_text, x.Unit_names, processedData_JIRA_academyCountVectorizer, processedData_JIRA_academyCountTF_IDF, x.verbs), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmVerbPruningUnitNamesJiraAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmVerbPruningUnitNamesJiraAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query and verb pruning' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-jungle",
   "metadata": {},
   "source": [
    "#### 3.4.4 [VSM unigram] Similarity between JIRA issue and Unit Names  - Unit Names As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "plastic-northern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 81 minutes and 58.37825131416321 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmUnitNamesUnitNamesAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmUnitNamesUnitNamesAsQuery[\"vsm_unit_names_log_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Unit_names, processedData_SVNUnitNames_academyCountVectorizer, processedData_SVNUnitNames_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmUnitNamesUnitNamesAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmUnitNamesUnitNamesAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-hearts",
   "metadata": {},
   "source": [
    "#### 3.4.5 [VSM unigram] Similarity between JIRA description and commit log - Description as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "durable-afghanistan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 161 minutes and 51.17785954475403 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmDescriptionDescriptionAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmDescriptionDescriptionAsQuery[\"vsm_description_description_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Description, x.Logs, processedData_JIRADescriptions_academyCountVectorizer, processedData_JIRADescriptions_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmDescriptionDescriptionAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmDescriptionDescriptionAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-trash",
   "metadata": {},
   "source": [
    "#### 3.4.5 [VSM unigram Silarity between JIRA description and commit log - Log as descrintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "exciting-colony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 81 minutes and 36.3745481967926 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmDescriptionLogsAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmDescriptionLogsAsQuery[\"vsm_description_log_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Description, x.Unit_names, processedData_SVNUnitNames_academyCountVectorizer, processedData_SVNUnitNames_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmDescriptionLogsAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmDescriptionLogsAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-landing",
   "metadata": {},
   "source": [
    "#### 3.4.5 [VSM unigram Silarity between JIRA Comment and unitnames - Comment as query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-beginning",
   "metadata": {},
   "source": [
    "#### 3.4.5 [VSM unigram Silarity between JIRA Comment and unitnames - Comment as query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-accused",
   "metadata": {},
   "source": [
    "#### 3.4.5 [VSM unigram Silarity between JIRA Comment and commit log - Comment as description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-medicaid",
   "metadata": {},
   "source": [
    "#### 3.4.5 [VSM unigram Silarity between JIRA description and commit log - Log as description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-romantic",
   "metadata": {},
   "source": [
    "#### [VSM bigram] Similarity between JIRA comments and Commit Logs - Logs as query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-festival",
   "metadata": {},
   "source": [
    "#### 3.4.5 [VSM bigram] Silarity between JIRA Comment and commit log - Comment as query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-fairy",
   "metadata": {},
   "source": [
    "#### [VSM Unigram] Similarity between Unit Names and Description - Unit Names as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "violent-pound",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 81 minutes and 50.44815397262573 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmUnitNamesDescriptionUnitNamesAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmUnitNamesDescriptionUnitNamesAsQuery[\"vsm_unitnames_description_unitnames_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Description, x.Unit_names, processedData_SVNUnitNames_academyCountVectorizer, processedData_SVNUnitNames_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmUnitNamesDescriptionUnitNamesAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmUnitNamesDescriptionUnitNamesAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civil-patio",
   "metadata": {},
   "source": [
    "#### [VSM Unigram] Similarity between Unit Names and Description - Description as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "psychological-ghost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 752 minutes and 27.15877938270569 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmUnitNamesDescriptionDescriptionAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmUnitNamesDescriptionDescriptionAsQuery[\"vsm_unitnames_description_description_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Description, x.Unit_names, processedData_JIRADescriptions_academyCountVectorizer, processedData_JIRADescriptions_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmUnitNamesDescriptionDescriptionAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmUnitNamesDescriptionDescriptionAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-schedule",
   "metadata": {},
   "source": [
    "#### [VSM Unigram] Similarity between Unit Names and Comments - Unit Names as query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-council",
   "metadata": {},
   "source": [
    "#### [VSM Unigram] Similarity between Unit Names and Comments - Comments as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ideal-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [VSM Unigram] Similarity between SVN (entirely) and JIRA (entirely)- JIRA as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "happy-charger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 163 minutes and 44.769426107406616 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmSvnJiraJiraAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmSvnJiraJiraAsQuery[\"vsm_svn_jira_jira_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Commit_natural_text, processedData_JIRA_academyCountVectorizer, processedData_JIRA_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmSvnJiraJiraAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmSvnJiraJiraAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "listed-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [VSM Unigram] Similarity between SVN (entirely) and JIRA (entirely) - SVN as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "deluxe-allergy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 133 minutes and 49.20695185661316 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmSvnJiraSvnAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmSvnJiraSvnAsQuery[\"vsm_svn_jira_svn_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Commit_natural_text, processedData_SVN_academyCountVectorizer, processedData_SVN_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmSvnJiraSvnAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmSvnJiraSvnAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "hindu-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [VSM Unigram] Similarity between SVN (entirely) and Summary - SVN as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "documentary-amazon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 131 minutes and 49.182390451431274 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmSvnSummarySvnAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmSvnSummarySvnAsQuery[\"vsm_svn_summary_svn_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Commit_natural_text, x.Summary, processedData_SVN_academyCountVectorizer, processedData_SVN_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmSvnSummarySvnAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmSvnSummarySvnAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "incorporated-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [VSM Unigram] Similarity between SVN (entirely) and Summary - Summary as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "religious-fruit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 83 minutes and 56.17693471908569 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmSvnSummarySummaryAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmSvnSummarySummaryAsQuery[\"vsm_svn_summary_summary_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Commit_natural_text, x.Summary, processedData_JIRASummaries_academyCountVectorizer, processedData_JIRASummaries_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmSvnSummarySummaryAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmSvnSummarySummaryAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "disabled-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [VSM Unigram] Similarity between SVN (entirely) and Description - SVN as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "located-blond",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 132 minutes and 2.7590341567993164 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmSvnDescriptionSvnAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmSvnDescriptionSvnAsQuery[\"vsm_svn_description_svn_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Commit_natural_text, x.Description, processedData_SVN_academyCountVectorizer, processedData_SVN_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmSvnDescriptionSvnAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmSvnDescriptionSvnAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "floppy-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [VSM Unigram] Similarity between SVN (entirely) and Description - Description as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "departmental-prediction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating 'VSM UnitNames Unit Names as query' after 161 minutes and 10.981512308120728 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmSvnDescriptionDescriptionAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmSvnDescriptionDescriptionAsQuery[\"vsm_svn_description_description_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Commit_natural_text, x.Description, processedData_JIRADescriptions_academyCountVectorizer, processedData_JIRADescriptions_academyCountTF_IDF), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmSvnDescriptionDescriptionAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmSvnDescriptionDescriptionAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "valuable-intersection",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [VSM Unigram] Similarity between SVN (entirely) and Comments - SVN as query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cubic-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### [VSM Unigram] Similarity between SVN (entirely) and Comments - Comments as query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-absorption",
   "metadata": {},
   "source": [
    "#### 3.4.3 [VSM unigram - verb pruning] Similarity between JIRA issue and Unit Names and verb pruning - Unit Names As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery[\"vsm_verb_pruning_unit_names_log_as_query\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarityWithPOSPruning(x.Jira_natural_text, x.Unit_names, processedData_SVNUnitNames_academyCountVectorizer, processedData_SVNUnitNames_academyCountTF_IDF, x.verbs), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-freeze",
   "metadata": {},
   "source": [
    "#### 3.4.5 [VSM bigram] Similarity between JIRA issue and Commit Log - Jira As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmLogsJiraAsQuery_2gram = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmLogsJiraAsQuery_2gram[\"vsm_logs_jira_as_query_2gram\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Logs, processedData_JIRA_academyCountVectorizer_2gram, processedData_JIRA_academyCountTF_IDF_2gram), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmLogsJiraAsQuery_2gram.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmLogsJiraAsQuery_2gram.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-northeast",
   "metadata": {},
   "source": [
    "#### 3.4.6 [VSM bigram] Similarity between JIRA issue and Commit Log - Logs As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmLogsLogAsQuery_2gram = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmLogsLogAsQuery_2gram[\"vsm_logs_log_as_query_2gram\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Logs, processedData_SVNLogs_academyCountVectorizer_2gram, processedData_SVNLogs_academyCountTF_IDF_2gram), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmLogsLogAsQuery_2gram.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmLogsLogAsQuery_2gram.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-indie",
   "metadata": {},
   "source": [
    "#### 3.4.6 [VSM bigram] Similarity between JIRA issue and Unit Names - Jira As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmUnitNamesJiraAsQuery_2gram = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmUnitNamesJiraAsQuery_2gram[\"vsm_unit_names_jira_as_query_2gram\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Unit_names, processedData_JIRA_academyCountVectorizer_2gram, processedData_JIRA_academyCountTF_IDF_2gram), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmUnitNamesJiraAsQuery_2gram.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmUnitNamesJiraAsQuery_2gram.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-sixth",
   "metadata": {},
   "source": [
    "#### 3.4.6 [VSM bigram] Similarity between JIRA issue and Unit Names - UnitNames As Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_2gram = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_2gram[\"vsm_unit_names_log_as_query_2gram\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Jira_natural_text, x.Unit_names, processedData_SVNUnitNames_academyCountVectorizer_2gram, processedData_SVNUnitNames_academyCountTF_IDF_2gram), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_2gram.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_2gram.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-sector",
   "metadata": {},
   "source": [
    "#### [VSM bigram] Similarity between Logs and Description - Logs as Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmDescriptionLogsAsQuery_2gram = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmDescriptionLogsAsQuery_2gram[\"vsm_description_log_as_query_2gram\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Description, x.Unit_names, processedData_SVNUnitNames_academyCountVectorizer_2gram, processedData_SVNUnitNames_academyCountTF_IDF_2gram), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmDescriptionLogsAsQuery_2gram.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmDescriptionLogsAsQuery_2gram.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM UnitNames Unit Names as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-prince",
   "metadata": {},
   "source": [
    "#### [VSM bigram] Similarity between Logs and Description - Description as Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmDescriptionDescriptionAsQuery_2gram = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmDescriptionDescriptionAsQuery_2gram[\"vsm_description_description_as_query_2gram\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarity(x.Description, x.Logs, processedData_JIRADescriptions_academyCountVectorizer_2gram, processedData_JIRADescriptions_academyCountTF_IDF_2gram), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmDescriptionDescriptionAsQuery_2gram.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmDescriptionDescriptionAsQuery_2gram.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Bigrams' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-simon",
   "metadata": {},
   "source": [
    "#### [VSM bigram] Similarity between Logs and Summary - Logs as Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-throat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "continent-african",
   "metadata": {},
   "source": [
    "#### [VSM bigram] Similarity between Logs and Summary - Summary as Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_academy_features_VsmSummaryLogsSummaryAsQuery_2gram = pd.DataFrame() \n",
    "\n",
    "#Calculate cosine similarity for each trace\n",
    "processedData_academy_features_VsmSummaryLogsSummaryAsQuery_2gram[\"vsm_summary_logs_summary_as_query_2gram\"] = processedData_academyCartesian.apply(lambda x: calculateCosineSimilarityNGrams(x.Summary, x.Logs, processedData_JIRASummaries_academyCountVectorizer_2gram, processedData_JIRASummaries_academyCountTF_IDF_2gram), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_academy_features_VsmSummaryLogsSummaryAsQuery_2gram.to_pickle(path= \"../data/03_processed/processedData_academy_features_VsmSummaryLogsSummaryAsQuery_2gram.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating 'VSM Logs Jira as query' after \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-separation",
   "metadata": {},
   "source": [
    "## 3.6 Document Statistics\n",
    "\n",
    "### academy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "armed-warren",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating document statistics in 4 minutes and 42.6787588596344 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRA_academyFeaturesUniqueWordCount = pd.DataFrame() \n",
    "processedData_SVN_academyFeaturesUniqueWordCount = pd.DataFrame() \n",
    "processedData_JIRA_academyFeaturesTotalWordCount = pd.DataFrame() \n",
    "processedData_SVN_academyFeaturesTotalWordCount = pd.DataFrame()\n",
    "\n",
    "processedData_JIRA_academyFeaturesOverlapPercentage = pd.DataFrame()\n",
    "processedData_SVN_academyFeaturesOverlapPercentage = pd.DataFrame()\n",
    "processedData_UNION_academyFeaturesOverlapPercentage = pd.DataFrame()\n",
    "\n",
    "#Calculate unique terms JIRA for each trace\n",
    "processedData_JIRA_academyFeaturesUniqueWordCount[\"unique_term_count_jira\"] = processedData_academyCartesian.apply(lambda x: calculateUniqueWordCount(x.Jira_natural_text), \n",
    "                                                            axis=1)\n",
    "#Calculate unique terms JIRA for each trace\n",
    "processedData_SVN_academyFeaturesUniqueWordCount[\"unique_term_count_svn\"] = processedData_academyCartesian.apply(lambda x: calculateUniqueWordCount(x.Commit_natural_text), \n",
    "                                                            axis=1)\n",
    "\n",
    "#Calculate total terms JIRA for each trace\n",
    "processedData_JIRA_academyFeaturesTotalWordCount[\"total_term_count_jira\"] = processedData_academyCartesian.apply(lambda x: calculateTotalWordCount(x.Jira_natural_text), \n",
    "                                                            axis=1)\n",
    "#Calculate total terms JIRA for each trace\n",
    "processedData_SVN_academyFeaturesTotalWordCount[\"total_term_count_svn\"] = processedData_academyCartesian.apply(lambda x: calculateTotalWordCount(x.Commit_natural_text), \n",
    "                                                            axis=1)\n",
    "\n",
    "processedData_JIRA_academyFeaturesOverlapPercentage[\"overlap_percentage_compared_to_jira\"] = processedData_academyCartesian.apply(lambda x: calculateOverlapBetweenDocuments(x.Jira_natural_text, x.Commit_natural_text, 'list1'),\n",
    "                                                            axis=1)\n",
    "processedData_SVN_academyFeaturesOverlapPercentage[\"overlap_percentage_compared_to_svn\"] = processedData_academyCartesian.apply(lambda x: calculateOverlapBetweenDocuments(x.Jira_natural_text, x.Commit_natural_text, 'list2'),\n",
    "                                                            axis=1)\n",
    "processedData_UNION_academyFeaturesOverlapPercentage[\"overlap_percentage_compared_to_union\"] = processedData_academyCartesian.apply(lambda x: calculateOverlapBetweenDocuments(x.Jira_natural_text, x.Commit_natural_text, 'union'),\n",
    "                                                            axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRA_academyFeaturesUniqueWordCount.to_pickle(path= \"../data/03_processed/processedData_JIRA_academyFeaturesUniqueWordCount.pkl\")\n",
    "processedData_SVN_academyFeaturesUniqueWordCount.to_pickle(path= \"../data/03_processed/processedData_SVN_academyFeaturesUniqueWordCount.pkl\")\n",
    "processedData_JIRA_academyFeaturesTotalWordCount.to_pickle(path= \"../data/03_processed/processedData_JIRA_academyFeaturesTotalWordCount.pkl\")\n",
    "processedData_SVN_academyFeaturesTotalWordCount.to_pickle(path= \"../data/03_processed/processedData_SVN_academyFeaturesTotalWordCount.pkl\")\n",
    "\n",
    "processedData_JIRA_academyFeaturesOverlapPercentage.to_pickle(path= \"../data/03_processed/processedData_JIRA_academyFeaturesOverlapPercentage.pkl\")\n",
    "processedData_SVN_academyFeaturesOverlapPercentage.to_pickle(path= \"../data/03_processed/processedData_SVN_academyFeaturesOverlapPercentage.pkl\")\n",
    "processedData_UNION_academyFeaturesOverlapPercentage.to_pickle(path= \"../data/03_processed/processedData_UNION_academyFeaturesOverlapPercentage.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating document statistics in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-pressing",
   "metadata": {},
   "source": [
    "## 3.7 Query Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dirty-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the count vectorizer and tfidf for the corpus\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from statistics import mean, median, mode, stdev, variance\n",
    "from math import log, sqrt\n",
    "import itertools\n",
    "\n",
    "#Function calculating the IDFs of all query terms. Returns a list containing all IDFs\n",
    "def calcIDFList(document, cv, tfidf_transformer):\n",
    "    idfScoreList=[]\n",
    "    if isinstance(document, list):\n",
    "        termCount = len(document)\n",
    "        for term in document:\n",
    "            try:\n",
    "                indexOfWord = cv.get_feature_names().index(term)\n",
    "                idfScore = tfidf_transformer.idf_[indexOfWord]\n",
    "                idfScoreList.append(idfScore)\n",
    "            except:\n",
    "                idfScoreList.append(0)\n",
    "    else:\n",
    "        termCount = 0\n",
    "    return(idfScoreList)\n",
    "\n",
    "\n",
    "def calcAvgIDF(IDFList):\n",
    "    termCount = len(IDFList)\n",
    "    if(termCount != 0):\n",
    "        avgIdf = sum(IDFList) / termCount\n",
    "    else:\n",
    "        avgIdf = 0\n",
    "    return(avgIdf)\n",
    "\n",
    "def calcMaxIDF(IDFList): \n",
    "    termCount = len(IDFList)\n",
    "    if(termCount != 0):\n",
    "        maxIdf = np.amax(IDFList)\n",
    "    else: \n",
    "        maxIdf = 0\n",
    "    return(maxIdf)\n",
    "\n",
    "def calcDevIDF(IDFList):\n",
    "    termCount = len(IDFList)\n",
    "    if(termCount > 1):\n",
    "        stdevIdf = stdev(IDFList)\n",
    "    else: \n",
    "        stdevIdf = 0\n",
    "    return(stdevIdf)\n",
    "\n",
    "#Function calculating the ICTF of all query terms. Returns a list containing all IDFs\n",
    "def calcICTFList(document, cv, documentCount):\n",
    "    ICTFList = []\n",
    "        #For all terms in query, find how often they occur in the Corpus\n",
    "    if isinstance(document, list):\n",
    "        for term in document:\n",
    "            try:\n",
    "            #Find out how often the term occurs in the corpus\n",
    "                termFrequency = (cv.vocabulary_[term])\n",
    "                \n",
    "                #Compute the log\n",
    "                ictF = log(documentCount/termFrequency)\n",
    "            except:\n",
    "                ictF = 0\n",
    "            \n",
    "            ICTFList.append(ictF)\n",
    "    return(ICTFList)\n",
    "\n",
    "def calcAvgICTF(ICTFList, documentCount):\n",
    "    avgICTF = sum(ICTFList) / documentCount\n",
    "    return(avgICTF)\n",
    "\n",
    "\n",
    "def calcMaxICTF(ICTFList): \n",
    "    termCount = len(ICTFList)\n",
    "    if(termCount != 0):\n",
    "        maxICTF = np.amax(ICTFList)\n",
    "    else: \n",
    "        maxICTF = 0\n",
    "    return(maxICTF)\n",
    "\n",
    "def calcDevICTF(ICTFList):\n",
    "    termCount = len(ICTFList)\n",
    "    if(termCount > 1):\n",
    "        stdevICTF = stdev(ICTFList)\n",
    "    else: \n",
    "        stdevICTF = 0\n",
    "    return(stdevICTF)\n",
    "\n",
    "\n",
    "def calcEntropyList(query, cv, documentCount, docCollection):\n",
    "    #entropy(t) = ∑ (d∈Dt)  ( tf(t,d) / tf(t, D) ) * log |D|(tf(t,d) / tf(t, D) )\n",
    "        \n",
    "    entropyValueList = []\n",
    "    #for each term in the query, calculate the entropy of the query\n",
    "    if isinstance(query, list):\n",
    "        for queryTerm in query:\n",
    "            #For each d ∈ D\n",
    "            \n",
    "            partialEntropyList = []\n",
    "            \n",
    "            for d in docCollection:\n",
    "                #Check if queryTerm occurs in D (i.e/ d∈Dt)\n",
    "                if (isinstance(d, list)):\n",
    "                    if queryTerm in d:\n",
    "                        try:\n",
    "                            #Calculate the frequency of the term occurs in the document (i.e tf(t,d))\n",
    "                            queryTermFrequencyInDocument = d.count(queryTerm)\n",
    "                            \n",
    "                            #calculate the frequency the term occurs in the query corpus (i.e tf(t,D))\n",
    "                            queryTermFrequencyInCorpus = (cv.vocabulary_[queryTerm])\n",
    "                             \n",
    "                            # This part of the calculation tf(t,d) / tf(t, D)  * log |D|(tf(t,d) / tf(t, D))\n",
    "                            partialEntropy1stHalf = queryTermFrequencyInDocument / queryTermFrequencyInCorpus\n",
    "                            partialEntropy2ndHalf = log((queryTermFrequencyInDocument / queryTermFrequencyInCorpus), documentCount)\n",
    "                            partialEntropy = partialEntropy1stHalf\n",
    "                            partialEntropyList.append(partialEntropy)\n",
    "                        except:\n",
    "                            partialEntropyList.append(0) #If term not found entropy is 0\n",
    "            #this part of the calculation ∑ (d∈Dt)\n",
    "            entropyValueOfQueryTerm = sum(partialEntropyList)\n",
    "            entropyValueList.append(entropyValueOfQueryTerm)\n",
    "    \n",
    "    return(entropyValueList)\n",
    "\n",
    "\n",
    "def calcAvgEntropy(entropyValueList):\n",
    "    termCount = len(entropyValueList)\n",
    "    if(termCount != 0):\n",
    "        #Calculate the average of all the entropies\n",
    "        avgEntropy = sum(entropyValueList) / len(entropyValueList)\n",
    "    else:\n",
    "        avgEntropy = 0\n",
    "    return(avgEntropy)\n",
    "\n",
    "    \n",
    "def calcMedEntropy(entropyValueList):\n",
    "    termCount = len(entropyValueList)\n",
    "    if(termCount != 0):\n",
    "        #Calculate the average of all the entropies\n",
    "        medEntropy = median(entropyValueList)\n",
    "    else:\n",
    "        medEntropy = 0\n",
    "    return(medEntropy)\n",
    "    \n",
    "def calcMaxEntropy(entropyValueList):\n",
    "    termCount = len(entropyValueList)\n",
    "    if(termCount != 0):\n",
    "        maxEntropy = np.amax(entropyValueList)\n",
    "    else: \n",
    "        maxEntropy = 0\n",
    "    return(maxEntropy)\n",
    "    \n",
    "def calcDevEntropy(entropyValueList):\n",
    "    termCount = len(entropyValueList)\n",
    "    if(termCount > 1):\n",
    "        #Calculate the average of all the entropies\n",
    "        devEntropy = stdev(entropyValueList)\n",
    "    else:\n",
    "        devEntropy = 0\n",
    "    return(devEntropy)\n",
    "\n",
    "#The percentage of documents in the collection containing at least one of the query terms\n",
    "def calcQueryScope(query, docCollection): \n",
    "    counter = 0\n",
    "    if isinstance(query, list):\n",
    "        for document in docCollection:\n",
    "            #check if query occurs in term. \n",
    "            if(isinstance(document, list)):\n",
    "                for queryTerm in query:\n",
    "                    if queryTerm in document:\n",
    "                        counter = counter + 1\n",
    "                        break\n",
    "    queryScope = counter / len(docCollection)\n",
    "    return(queryScope)\n",
    "\n",
    "#The Kullback-Leiber divergence of the query language model from the collection language model\n",
    "def calcSCS(query, cv, docCount):\n",
    "    divergenceList = []\n",
    "    if isinstance(query, list):\n",
    "        for queryTerm in query:\n",
    "            try:\n",
    "                #frequency of term in query - tf(q, Q)/|Q|\n",
    "                pqQ = query.count(queryTerm) / len(query)\n",
    "                \n",
    "                #frequency of term in documentlist - tf(q, D)/|D|\n",
    "                pqD = cv.vocabulary_[queryTerm]\n",
    "                \n",
    "                divergence = pqQ * log(pqQ / pqD)\n",
    "                divergenceList.append(divergence)\n",
    "            except:\n",
    "                continue\n",
    "    SCS = sum(divergenceList)\n",
    "    return(SCS)\n",
    "\n",
    "#The average of the collection-query similarity (SCQ) over all query terms\n",
    "def calcSCQList(query, docCollection, cv, fittedTF_IDF, documentCount):\n",
    "    SCQList = []\n",
    "    if isinstance(query, list):\n",
    "        documentString = ' '.join(query)\n",
    "        \n",
    "        #Calculate the Term Frequency of the document\n",
    "        inputDocs = [documentString] \n",
    "        \n",
    "        # count matrix \n",
    "        count_vector = cv.transform(inputDocs) \n",
    " \n",
    "        #tf-idf scores \n",
    "        tf_idf_vector = fittedTF_IDF.transform(count_vector)\n",
    "        \n",
    "        feature_names = cv.get_feature_names() \n",
    "        # place tf-idf values in a pandas data frame \n",
    "        df = pd.DataFrame(tf_idf_vector.T.todense(), \n",
    "                          index=feature_names, columns=[\"tfidf\"])\n",
    "    \n",
    "        \n",
    "        #Find the tfidf of the term\n",
    "        for queryTerm in query:    \n",
    "            try:\n",
    "                tfidf = df[\"tfidf\"][queryTerm]\n",
    "                SCQ = (1 + log(tfidf))\n",
    "                SCQList.append(SCQ)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "    avgSCQ = sum(SCQList) / documentCount\n",
    "    return(SCQList)\n",
    "\n",
    "#The average of the collection-query similarity (SCQ) over all query terms\n",
    "def calcAvgSCQ(SCQList, documentCount):\n",
    "    avgSCQ = sum(SCQList) / documentCount\n",
    "    return(avgSCQ)\n",
    "    \n",
    "#The average of the collection-query similarity (SCQ) over all query terms\n",
    "def calcMaxSCQ(SCQList):\n",
    "    termCount = len(SCQList)\n",
    "    if(termCount != 0):\n",
    "        maxSCQ = np.amax(SCQList)\n",
    "    else:\n",
    "        maxSCQ = np.NaN\n",
    "    return(maxSCQ)\n",
    "\n",
    "#The average of the collection-query similarity (SCQ) over all query terms\n",
    "def calcSumSCQ(SCQList):\n",
    "    sumSCQ = sum(SCQList)\n",
    "    return(sumSCQ)\n",
    "\n",
    "def createTermPairs(cv):\n",
    "    terms = list(cv.vocabulary_.keys())\n",
    "    #Create all possible pair combinations from the terms in the query \n",
    "    pairCombinationList = list(itertools.combinations(terms, 2))\n",
    "    return(pairCombinationList)\n",
    "\n",
    "#Method to find out how often a term occurs in a document\n",
    "def findTermFrequencies(cv, docCollection):\n",
    "    terms = list(cv.vocabulary_.keys())\n",
    "    termFrequencies = {}\n",
    "    for term in terms:\n",
    "        termCounter = 0\n",
    "        for document in docCollection:\n",
    "            if isinstance(document, list):\n",
    "                if term in document: \n",
    "                    termCounter = termCounter + 1\n",
    "        termFrequencies[term] = termCounter\n",
    "    return(termFrequencies)\n",
    "\n",
    "#Method to find out how often both terms occur in a document. \n",
    "def findTermPairFrequencies(termPairs, docCollection):\n",
    "    termPairFrequencies = {}\n",
    "    for termPair in termPairs:\n",
    "        termPairCount = 0\n",
    "        for document in docCollection:\n",
    "            if (isinstance(document, list)):\n",
    "                if all(i in document for i in termPair):\n",
    "                    termPairCount = termPairCount + 1\n",
    "        termPairFrequencies[termPair] = termPairCount\n",
    "    return(termPairFrequencies)   \n",
    "\n",
    "def calcPMIList(query, termFrequencies, termPairFrequencies, docCollection):\n",
    "    if isinstance(query, list):\n",
    "    #Find the frequencies of the individual terms and the pairs\n",
    "        pairCombinationList = list(itertools.combinations(query, 2))\n",
    "        termOccurances = []\n",
    "        for pair in pairCombinationList:\n",
    "            try:\n",
    "                q1Freq = termFrequencies[pair[0]]\n",
    "            except:\n",
    "                q1Freq = 0\n",
    "            try:\n",
    "                q2Freq = termFrequencies[pair[1]]\n",
    "            except:\n",
    "                q2Freq = 0\n",
    "            try:\n",
    "                q1q2Freq = termPairFrequencies[pair]\n",
    "            except:\n",
    "                q1q2Freq = 0\n",
    "                    \n",
    "            termOccurances.append({'q1Freq': q1Freq, \n",
    "                                   'q2Freq': q2Freq, \n",
    "                                   'q1q2Freq': q1q2Freq})\n",
    "    \n",
    "        docCount = len(docCollection)\n",
    "        pmiList = []\n",
    "        for term in termOccurances:\n",
    "            pq1 = term['q1Freq'] / docCount\n",
    "            pq2 = term['q2Freq'] / docCount\n",
    "            pq1q2 = term['q1q2Freq'] / docCount\n",
    "\n",
    "            try:\n",
    "                pmi = log(pq1q2 /(pq1 * pq2))\n",
    "            except:\n",
    "                pmi = np.nan\n",
    "            pmiList.append(pmi)\n",
    "        return(pmiList)\n",
    "    else:\n",
    "        return(np.nan)\n",
    "\n",
    "def calcAvgPMI(pmiList):\n",
    "    if(isinstance(pmiList, list)):\n",
    "        pairCount = len(pmiList)\n",
    "        if(pairCount != 0):\n",
    "            #Calculate the average of all the entropies\n",
    "            avgPMI= np.nansum(pmiList) / pairCount\n",
    "        else:\n",
    "            avgPMI = 0\n",
    "        return(avgPMI)\n",
    "    return(np.nan)\n",
    "\n",
    "def calcMaxPMI(pmiList): \n",
    "    if(isinstance(pmiList, list)):\n",
    "        pairCount = len(pmiList)\n",
    "        if(pairCount != 0):\n",
    "            maxPMI = np.nanmax(pmiList)\n",
    "        else: \n",
    "            maxPMI = np.nan\n",
    "        return(maxPMI)\n",
    "    return(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "pharmaceutical-mexican",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read datasets from disk\n",
    "processedData_academyCartesian = pd.read_pickle(r\"../data/03_processed/processedData_academyCartesian.pkl\")\n",
    "\n",
    "#instantiate CountVectorizer() for SVN\n",
    "processedData_SVN_academyCountVectorizer = CountVectorizer()\n",
    "processedData_SVN_academyTF_IDF = createFittedTF_IDF(processedData_SVN_academyCountVectorizer, intermediateData_SVN_academyCorpusAll)\n",
    "\n",
    "#instantiate CountVectorizer() for JIRA\n",
    "processedData_JIRA_academyCountVectorizer = CountVectorizer()\n",
    "processedData_JIRA_academyTF_IDF = createFittedTF_IDF(processedData_JIRA_academyCountVectorizer, intermediateData_JIRA_academyCorpus)\n",
    "\n",
    "#Determine document counts\n",
    "intermediateData_JIRA_academy_documentCount = len(intermediateData_JIRA_academy.index)\n",
    "intermediateData_SVN_academy_documentCount = len(intermediateData_SVN_academy.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-stage",
   "metadata": {},
   "source": [
    "#### IDF Scores (SVN as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "opened-identity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 564 minutes and 58.45542812347412 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVN_academyFeaturesIDF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVN_academyFeaturesIDF[\"SvnAsQuery_IDF\"] = processedData_academyCartesian.apply(lambda x: calcIDFList(x.Commit_natural_text, \n",
    "                                                                                                                processedData_SVN_academyCountVectorizer, \n",
    "                                                                                                                processedData_SVN_academyTF_IDF),axis=1)\n",
    "\n",
    "processedData_SVN_academyFeaturesIDF[\"SvnAsQuery_avgIDF\"] = processedData_SVN_academyFeaturesIDF.apply(lambda x: calcAvgIDF(x.SvnAsQuery_IDF), axis=1)\n",
    "processedData_SVN_academyFeaturesIDF[\"SvnAsQuery_maxIDF\"] = processedData_SVN_academyFeaturesIDF.apply(lambda x: calcMaxIDF(x.SvnAsQuery_IDF), axis=1)\n",
    "processedData_SVN_academyFeaturesIDF[\"SvnAsQuery_devIDF\"] = processedData_SVN_academyFeaturesIDF.apply(lambda x: calcDevIDF(x.SvnAsQuery_IDF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVN_academyFeaturesIDF.to_pickle(path= \"../data/03_processed/processedData_SVN_academyFeaturesIDF.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-moment",
   "metadata": {},
   "source": [
    "#### IDF Scores (SVNLogs as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "statistical-warehouse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 641 minutes and 43.974735260009766 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNLogs_academyFeaturesIDF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNLogs_academyFeaturesIDF[\"SvnLogsAsQuery_IDF\"] = processedData_academyCartesian.apply(lambda x: calcIDFList(x.Logs, \n",
    "                                                                                                                processedData_SVNLogs_academyCountVectorizer, \n",
    "                                                                                                                processedData_SVNLogs_academyCountTF_IDF),axis=1)\n",
    "\n",
    "processedData_SVNLogs_academyFeaturesIDF[\"SvnLogsAsQuery_avgIDF\"] = processedData_SVNLogs_academyFeaturesIDF.apply(lambda x: calcAvgIDF(x.SvnLogsAsQuery_IDF), axis=1)\n",
    "processedData_SVNLogs_academyFeaturesIDF[\"SvnLogsAsQuery_maxIDF\"] = processedData_SVNLogs_academyFeaturesIDF.apply(lambda x: calcMaxIDF(x.SvnLogsAsQuery_IDF), axis=1)\n",
    "processedData_SVNLogs_academyFeaturesIDF[\"SvnLogsAsQuery_devIDF\"] = processedData_SVNLogs_academyFeaturesIDF.apply(lambda x: calcDevIDF(x.SvnLogsAsQuery_IDF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNLogs_academyFeaturesIDF.to_pickle(path= \"../data/03_processed/processedData_SVNLogs_academyFeaturesIDF.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-sampling",
   "metadata": {},
   "source": [
    "#### IDF Scores (SVNUnitNames as Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "polish-peeing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 171 minutes and 52.18505048751831 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNUnitNames_academyFeaturesIDF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNUnitNames_academyFeaturesIDF[\"SvnUnitNamesAsQuery_IDF\"] = processedData_academyCartesian.apply(lambda x: calcIDFList(x.Logs, \n",
    "                                                                                                                processedData_SVNLogs_academyCountVectorizer, \n",
    "                                                                                                                processedData_SVNLogs_academyCountTF_IDF),axis=1)\n",
    "\n",
    "processedData_SVNUnitNames_academyFeaturesIDF[\"SvnUnitNamesAsQuery_avgIDF\"] = processedData_SVNUnitNames_academyFeaturesIDF.apply(lambda x: calcAvgIDF(x.SvnUnitNamesAsQuery_IDF), axis=1)\n",
    "processedData_SVNUnitNames_academyFeaturesIDF[\"SvnUnitNamesAsQuery_maxIDF\"] = processedData_SVNUnitNames_academyFeaturesIDF.apply(lambda x: calcMaxIDF(x.SvnUnitNamesAsQuery_IDF), axis=1)\n",
    "processedData_SVNUnitNames_academyFeaturesIDF[\"SvnUnitNamesAsQuery_devIDF\"] = processedData_SVNUnitNames_academyFeaturesIDF.apply(lambda x: calcDevIDF(x.SvnUnitNamesAsQuery_IDF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNUnitNames_academyFeaturesIDF.to_pickle(path= \"../data/03_processed/processedData_SVNUnitNames_academyFeaturesIDF.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-arena",
   "metadata": {},
   "source": [
    "##### IDF Scores (JIRA as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "explicit-egypt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 1467 minutes and 37.279967069625854 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRA_academyFeaturesIDF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRA_academyFeaturesIDF[\"JiraAsQuery_IDF\"] = processedData_academyCartesian.apply(lambda x: calcIDFList(x.Jira_natural_text, \n",
    "                                                                                                                processedData_JIRA_academyCountVectorizer, \n",
    "                                                                                                                processedData_JIRA_academyTF_IDF),axis=1)\n",
    "\n",
    "processedData_JIRA_academyFeaturesIDF[\"JiraAsQuery_avgIDF\"] = processedData_JIRA_academyFeaturesIDF.apply(lambda x: calcAvgIDF(x.JiraAsQuery_IDF), axis=1)\n",
    "processedData_JIRA_academyFeaturesIDF[\"JiraAsQuery_maxIDF\"] = processedData_JIRA_academyFeaturesIDF.apply(lambda x: calcMaxIDF(x.JiraAsQuery_IDF), axis=1)\n",
    "processedData_JIRA_academyFeaturesIDF[\"JiraAsQuery_devIDF\"] = processedData_JIRA_academyFeaturesIDF.apply(lambda x: calcDevIDF(x.JiraAsQuery_IDF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRA_academyFeaturesIDF.to_pickle(path= \"../data/03_processed/processedData_JIRA_academyFeaturesIDF.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-gothic",
   "metadata": {},
   "source": [
    "##### IDF Scores (JIRA Summaries as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "underlying-cleaner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 54 minutes and 36.29969000816345 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRASummaries_academyFeaturesIDF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRASummaries_academyFeaturesIDF[\"JiraSummariesAsQuery_IDF\"] = processedData_academyCartesian.apply(lambda x: calcIDFList(x.Summary, \n",
    "                                                                                                                processedData_JIRASummaries_academyCountVectorizer, \n",
    "                                                                                                                processedData_JIRASummaries_academyCountTF_IDF),axis=1)\n",
    "\n",
    "processedData_JIRASummaries_academyFeaturesIDF[\"JiraSummariesAsQuery_avgIDF\"] = processedData_JIRASummaries_academyFeaturesIDF.apply(lambda x: calcAvgIDF(x.JiraSummariesAsQuery_IDF), axis=1)\n",
    "processedData_JIRASummaries_academyFeaturesIDF[\"JiraSummariesAsQuery_maxIDF\"] = processedData_JIRASummaries_academyFeaturesIDF.apply(lambda x: calcMaxIDF(x.JiraSummariesAsQuery_IDF), axis=1)\n",
    "processedData_JIRASummaries_academyFeaturesIDF[\"JiraSummariesAsQuery_devIDF\"] = processedData_JIRASummaries_academyFeaturesIDF.apply(lambda x: calcDevIDF(x.JiraSummariesAsQuery_IDF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRASummaries_academyFeaturesIDF.to_pickle(path= \"../data/03_processed/processedData_JIRASummaries_academyFeaturesIDF.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-specialist",
   "metadata": {},
   "source": [
    "##### IDF Scores (JIRA Descriptions as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "seeing-worker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 1308 minutes and 4.831335544586182 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRADescriptions_academyFeaturesIDF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRADescriptions_academyFeaturesIDF[\"JiraDescriptionsAsQuery_IDF\"] = processedData_academyCartesian.apply(lambda x: calcIDFList(x.Description, \n",
    "                                                                                                                processedData_JIRADescriptions_academyCountVectorizer, \n",
    "                                                                                                                processedData_JIRADescriptions_academyCountTF_IDF),axis=1)\n",
    "\n",
    "processedData_JIRADescriptions_academyFeaturesIDF[\"JiraDescriptionsAsQuery_avgIDF\"] = processedData_JIRADescriptions_academyFeaturesIDF.apply(lambda x: calcAvgIDF(x.JiraDescriptionsAsQuery_IDF), axis=1)\n",
    "processedData_JIRADescriptions_academyFeaturesIDF[\"JiraDescriptionsAsQuery_maxIDF\"] = processedData_JIRADescriptions_academyFeaturesIDF.apply(lambda x: calcMaxIDF(x.JiraDescriptionsAsQuery_IDF), axis=1)\n",
    "processedData_JIRADescriptions_academyFeaturesIDF[\"JiraDescriptionsAsQuery_devIDF\"] = processedData_JIRADescriptions_academyFeaturesIDF.apply(lambda x: calcDevIDF(x.JiraDescriptionsAsQuery_IDF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRADescriptions_academyFeaturesIDF.to_pickle(path= \"../data/03_processed/processedData_JIRADescriptions_academyFeaturesIDF.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-chile",
   "metadata": {},
   "source": [
    "##### IDF Scores (JIRA Comments as Query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-ensemble",
   "metadata": {},
   "source": [
    "#### ICTF Scores (SVN as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "homeless-trash",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 492 minutes and 6.659823179244995 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVN_academyFeaturesICTF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVN_academyFeaturesICTF[\"SvnAsQuery_ICTF\"] = processedData_academyCartesian.apply(lambda x: calcIDFList(x.Commit_natural_text, \n",
    "                                                                                                                processedData_SVN_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_academy_documentCount),axis=1)\n",
    "\n",
    "processedData_SVN_academyFeaturesICTF[\"SvnAsQuery_avgICTF\"] = processedData_SVN_academyFeaturesICTF.apply(lambda x: calcAvgICTF(x.SvnAsQuery_ICTF, intermediateData_SVN_academy_documentCount), axis=1)\n",
    "processedData_SVN_academyFeaturesICTF[\"SvnAsQuery_maxICTF\"] = processedData_SVN_academyFeaturesICTF.apply(lambda x: calcMaxICTF(x.SvnAsQuery_ICTF), axis=1)\n",
    "processedData_SVN_academyFeaturesICTF[\"SvnAsQuery_devICTF\"] = processedData_SVN_academyFeaturesICTF.apply(lambda x: calcDevICTF(x.SvnAsQuery_ICTF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVN_academyFeaturesICTF.to_pickle(path= \"../data/03_processed/processedData_SVN_academyFeaturesICTF.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-anthropology",
   "metadata": {},
   "source": [
    "#### ICTF Scores (SVNLogs as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "sought-arena",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 4 minutes and 32.035311698913574 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNLogs_academyFeaturesICTF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNLogs_academyFeaturesICTF[\"SvnLogsAsQuery_ICTF\"] = processedData_academyCartesian.apply(lambda x: calcICTFList(x.Logs, \n",
    "                                                                                                                processedData_SVNLogs_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_academy_documentCount),axis=1)\n",
    "##\n",
    "processedData_SVNLogs_academyFeaturesICTF[\"SvnLogsAsQuery_avgICTF\"] = processedData_SVNLogs_academyFeaturesICTF.apply(lambda x: calcAvgICTF(x.SvnLogsAsQuery_ICTF, intermediateData_SVN_academy_documentCount), axis=1)\n",
    "processedData_SVNLogs_academyFeaturesICTF[\"SvnLogsAsQuery_maxICTF\"] = processedData_SVNLogs_academyFeaturesICTF.apply(lambda x: calcMaxICTF(x.SvnLogsAsQuery_ICTF), axis=1)\n",
    "processedData_SVNLogs_academyFeaturesICTF[\"SvnLogsAsQuery_devICTF\"] = processedData_SVNLogs_academyFeaturesICTF.apply(lambda x: calcDevICTF(x.SvnLogsAsQuery_ICTF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNLogs_academyFeaturesICTF.to_pickle(path= \"../data/03_processed/processedData_SVNLogs_academyFeaturesICTF.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-bikini",
   "metadata": {},
   "source": [
    "#### ICTF Scores (SVNUnitNames as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "drawn-maryland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 4 minutes and 36.520785331726074 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNUnitNames_academyFeaturesICTF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNUnitNames_academyFeaturesICTF[\"SvnUnitNamesAsQuery_ICTF\"] = processedData_academyCartesian.apply(lambda x: calcICTFList(x.Unit_names, \n",
    "                                                                                                                processedData_SVNUnitNames_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_academy_documentCount),axis=1)\n",
    "##\n",
    "processedData_SVNUnitNames_academyFeaturesICTF[\"SvnUnitNamesAsQuery_avgICTF\"] = processedData_SVNUnitNames_academyFeaturesICTF.apply(lambda x: calcAvgICTF(x.SvnUnitNamesAsQuery_ICTF, intermediateData_SVN_academy_documentCount), axis=1)\n",
    "processedData_SVNUnitNames_academyFeaturesICTF[\"SvnUnitNamesAsQuery_maxICTF\"] = processedData_SVNUnitNames_academyFeaturesICTF.apply(lambda x: calcMaxICTF(x.SvnUnitNamesAsQuery_ICTF), axis=1)\n",
    "processedData_SVNUnitNames_academyFeaturesICTF[\"SvnUnitNamesAsQuery_devICTF\"] = processedData_SVNUnitNames_academyFeaturesICTF.apply(lambda x: calcDevICTF(x.SvnUnitNamesAsQuery_ICTF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNUnitNames_academyFeaturesICTF.to_pickle(path= \"../data/03_processed/processedData_SVNUnitNames_academyFeaturesICTF.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-japan",
   "metadata": {},
   "source": [
    "#### ICTF Scores (JIRA as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "separate-morris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 7 minutes and 22.17179036140442 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRA_academyFeaturesICTF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRA_academyFeaturesICTF[\"JiraAsQuery_ICTF\"] = processedData_academyCartesian.apply(lambda x: calcICTFList(x.Jira_natural_text, \n",
    "                                                                                                                processedData_JIRA_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_academy_documentCount),axis=1)\n",
    "##\n",
    "processedData_JIRA_academyFeaturesICTF[\"JiraAsQuery_avgICTF\"] = processedData_JIRA_academyFeaturesICTF.apply(lambda x: calcAvgICTF(x.JiraAsQuery_ICTF, intermediateData_JIRA_academy_documentCount), axis=1)\n",
    "processedData_JIRA_academyFeaturesICTF[\"JiraAsQuery_maxICTF\"] = processedData_JIRA_academyFeaturesICTF.apply(lambda x: calcMaxICTF(x.JiraAsQuery_ICTF), axis=1)\n",
    "processedData_JIRA_academyFeaturesICTF[\"JiraAsQuery_devICTF\"] = processedData_JIRA_academyFeaturesICTF.apply(lambda x: calcDevICTF(x.JiraAsQuery_ICTF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRA_academyFeaturesICTF.to_pickle(path= \"../data/03_processed/processedData_JIRA_academyFeaturesICTF.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-freeware",
   "metadata": {},
   "source": [
    "#### ICTF Scores (JIRA Summaries as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "chemical-spank",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 5 minutes and 58.17293381690979 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRASummaries_academyFeaturesICTF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRASummaries_academyFeaturesICTF[\"JiraSummariesAsQuery_ICTF\"] = processedData_academyCartesian.apply(lambda x: calcICTFList(x.Summary, \n",
    "                                                                                                                processedData_JIRASummaries_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_academy_documentCount),axis=1)\n",
    "##\n",
    "processedData_JIRASummaries_academyFeaturesICTF[\"JiraSummariesAsQuery_avgICTF\"] = processedData_JIRASummaries_academyFeaturesICTF.apply(lambda x: calcAvgICTF(x.JiraSummariesAsQuery_ICTF, intermediateData_JIRA_academy_documentCount), axis=1)\n",
    "processedData_JIRASummaries_academyFeaturesICTF[\"JiraSummariesAsQuery_maxICTF\"] = processedData_JIRASummaries_academyFeaturesICTF.apply(lambda x: calcMaxICTF(x.JiraSummariesAsQuery_ICTF), axis=1)\n",
    "processedData_JIRASummaries_academyFeaturesICTF[\"JiraSummariesAsQuery_devICTF\"] = processedData_JIRASummaries_academyFeaturesICTF.apply(lambda x: calcDevICTF(x.JiraSummariesAsQuery_ICTF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRASummaries_academyFeaturesICTF.to_pickle(path= \"../data/03_processed/processedData_JIRASummaries_academyFeaturesICTF.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-offset",
   "metadata": {},
   "source": [
    "#### ICTF Scores (JIRA Descriptions as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "contained-infrastructure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 9 minutes and 30.50741147994995 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRADescriptions_academyFeaturesICTF = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRADescriptions_academyFeaturesICTF[\"JiraDescriptionsAsQuery_ICTF\"] = processedData_academyCartesian.apply(lambda x: calcICTFList(x.Description, \n",
    "                                                                                                                processedData_JIRADescriptions_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_academy_documentCount),axis=1)\n",
    "##\n",
    "processedData_JIRADescriptions_academyFeaturesICTF[\"JiraDescriptionsAsQuery_avgICTF\"] = processedData_JIRADescriptions_academyFeaturesICTF.apply(lambda x: calcAvgICTF(x.JiraDescriptionsAsQuery_ICTF, intermediateData_JIRA_academy_documentCount), axis=1)\n",
    "processedData_JIRADescriptions_academyFeaturesICTF[\"JiraDescriptionsAsQuery_maxICTF\"] = processedData_JIRADescriptions_academyFeaturesICTF.apply(lambda x: calcMaxICTF(x.JiraDescriptionsAsQuery_ICTF), axis=1)\n",
    "processedData_JIRADescriptions_academyFeaturesICTF[\"JiraDescriptionsAsQuery_devICTF\"] = processedData_JIRADescriptions_academyFeaturesICTF.apply(lambda x: calcDevICTF(x.JiraDescriptionsAsQuery_ICTF), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRADescriptions_academyFeaturesICTF.to_pickle(path= \"../data/03_processed/processedData_JIRADescriptions_academyFeaturesICTF.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-ontario",
   "metadata": {},
   "source": [
    "#### ICTF Scores (JIRA Comments as query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-sheffield",
   "metadata": {},
   "source": [
    "#### Entropy (SVN as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "threaded-wonder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 1189 minutes and 7.033888339996338 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVN_academyFeaturesEntropy = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVN_academyFeaturesEntropy[\"SvnAsQuery_Entropy\"] = processedData_academyCartesian.apply(lambda x: calcEntropyList(x.Commit_natural_text, \n",
    "                                                                                                                processedData_SVN_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_academy_documentCount,\n",
    "                                                                                                                intermediateData_SVN_academy.Commit_natural_text),axis=1)\n",
    "\n",
    "processedData_SVN_academyFeaturesEntropy[\"SvnAsQuery_avgEntropy\"] = processedData_SVN_academyFeaturesEntropy.apply(lambda x: calcAvgEntropy(x.SvnAsQuery_Entropy), axis=1)\n",
    "processedData_SVN_academyFeaturesEntropy[\"SvnAsQuery_medEntropy\"] = processedData_SVN_academyFeaturesEntropy.apply(lambda x: calcMedEntropy(x.SvnAsQuery_Entropy), axis=1)\n",
    "processedData_SVN_academyFeaturesEntropy[\"SvnAsQuery_maxEntropy\"] = processedData_SVN_academyFeaturesEntropy.apply(lambda x: calcMaxEntropy(x.SvnAsQuery_Entropy), axis=1)\n",
    "processedData_SVN_academyFeaturesEntropy[\"SvnAsQuery_devEntropy\"] = processedData_SVN_academyFeaturesEntropy.apply(lambda x: calcDevEntropy(x.SvnAsQuery_Entropy), axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVN_academyFeaturesEntropy.to_pickle(path= \"../data/03_processed/processedData_SVN_academyFeaturesEntropy.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-iraqi",
   "metadata": {},
   "source": [
    "#### Entropy (SVNLogs as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "tight-engineer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 114 minutes and 24.40122079849243 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNLogs_academyFeaturesEntropy = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNLogs_academyFeaturesEntropy[\"SvnLogsAsQuery_Entropy\"] = processedData_academyCartesian.apply(lambda x: calcEntropyList(x.Logs, \n",
    "                                                                                                                processedData_SVNLogs_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_academy_documentCount,\n",
    "                                                                                                                intermediateData_SVN_academy.Logs),axis=1)\n",
    "##\n",
    "processedData_SVNLogs_academyFeaturesEntropy[\"SvnLogsAsQuery_avgEntropy\"] = processedData_SVNLogs_academyFeaturesEntropy.apply(lambda x: calcAvgEntropy(x.SvnLogsAsQuery_Entropy), axis=1)\n",
    "processedData_SVNLogs_academyFeaturesEntropy[\"SvnLogsAsQuery_medEntropy\"] = processedData_SVNLogs_academyFeaturesEntropy.apply(lambda x: calcMedEntropy(x.SvnLogsAsQuery_Entropy), axis=1)\n",
    "processedData_SVNLogs_academyFeaturesEntropy[\"SvnLogsAsQuery_maxEntropy\"] = processedData_SVNLogs_academyFeaturesEntropy.apply(lambda x: calcMaxEntropy(x.SvnLogsAsQuery_Entropy), axis=1)\n",
    "processedData_SVNLogs_academyFeaturesEntropy[\"SvnLogsAsQuery_devEntropy\"] = processedData_SVNLogs_academyFeaturesEntropy.apply(lambda x: calcDevEntropy(x.SvnLogsAsQuery_Entropy), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNLogs_academyFeaturesEntropy.to_pickle(path= \"../data/03_processed/processedData_SVNLogs_academyFeaturesEntropy.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-recorder",
   "metadata": {},
   "source": [
    "#### Entropy (SVNUnitNames as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dirty-roberts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 777 minutes and 27.65002202987671 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNUnitNames_academyFeaturesEntropy = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNUnitNames_academyFeaturesEntropy[\"SvnUnitNamesAsQuery_Entropy\"] = processedData_academyCartesian.apply(lambda x: calcEntropyList(x.Unit_names, \n",
    "                                                                                                                processedData_SVNUnitNames_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_academy_documentCount,\n",
    "                                                                                                                intermediateData_SVN_academy.Unit_names),axis=1)\n",
    "##\n",
    "processedData_SVNUnitNames_academyFeaturesEntropy[\"SvnUnitNamesAsQuery_avgEntropy\"] = processedData_SVNUnitNames_academyFeaturesEntropy.apply(lambda x: calcAvgEntropy(x.SvnUnitNamesAsQuery_Entropy), axis=1)\n",
    "processedData_SVNUnitNames_academyFeaturesEntropy[\"SvnUnitNamesAsQuery_medEntropy\"] = processedData_SVNUnitNames_academyFeaturesEntropy.apply(lambda x: calcMedEntropy(x.SvnUnitNamesAsQuery_Entropy), axis=1)\n",
    "processedData_SVNUnitNames_academyFeaturesEntropy[\"SvnUnitNamesAsQuery_maxEntropy\"] = processedData_SVNUnitNames_academyFeaturesEntropy.apply(lambda x: calcMaxEntropy(x.SvnUnitNamesAsQuery_Entropy), axis=1)\n",
    "processedData_SVNUnitNames_academyFeaturesEntropy[\"SvnUnitNamesAsQuery_devEntropy\"] = processedData_SVNUnitNames_academyFeaturesEntropy.apply(lambda x: calcDevEntropy(x.SvnUnitNamesAsQuery_Entropy), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNUnitNames_academyFeaturesEntropy.to_pickle(path= \"../data/03_processed/processedData_SVNUnitNames_academyFeaturesEntropy.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-kingston",
   "metadata": {},
   "source": [
    "#### Entropy (JIRA as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "featured-belle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 1508 minutes and 28.569744348526 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRA_academyFeaturesEntropy = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRA_academyFeaturesEntropy[\"JiraAsQuery_Entropy\"] = processedData_academyCartesian.apply(lambda x: calcEntropyList(x.Jira_natural_text, \n",
    "                                                                                                                processedData_JIRA_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_academy_documentCount,\n",
    "                                                                                                                intermediateData_JIRA_academy.Jira_natural_text),axis=1)\n",
    "##\n",
    "processedData_JIRA_academyFeaturesEntropy[\"JiraAsQuery_avgEntropy\"] = processedData_JIRA_academyFeaturesEntropy.apply(lambda x: calcAvgEntropy(x.JiraAsQuery_Entropy), axis=1)\n",
    "processedData_JIRA_academyFeaturesEntropy[\"JiraAsQuery_medEntropy\"] = processedData_JIRA_academyFeaturesEntropy.apply(lambda x: calcMedEntropy(x.JiraAsQuery_Entropy), axis=1)\n",
    "processedData_JIRA_academyFeaturesEntropy[\"JiraAsQuery_maxEntropy\"] = processedData_JIRA_academyFeaturesEntropy.apply(lambda x: calcMaxEntropy(x.JiraAsQuery_Entropy), axis=1)\n",
    "processedData_JIRA_academyFeaturesEntropy[\"JiraAsQuery_devEntropy\"] = processedData_JIRA_academyFeaturesEntropy.apply(lambda x: calcDevEntropy(x.JiraAsQuery_Entropy), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRA_academyFeaturesEntropy.to_pickle(path= \"../data/03_processed/processedData_JIRA_academyFeaturesEntropy.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-technical",
   "metadata": {},
   "source": [
    "#### Entropy (JIRA Summaries as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "apart-romania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 42 minutes and 17.65159320831299 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRASummaries_academyFeaturesEntropy = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRASummaries_academyFeaturesEntropy[\"JiraSummariesAsQuery_Entropy\"] = processedData_academyCartesian.apply(lambda x: calcEntropyList(x.Summary, \n",
    "                                                                                                                processedData_JIRASummaries_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_academy_documentCount,\n",
    "                                                                                                                intermediateData_JIRA_academy.Summary),axis=1)\n",
    "##\n",
    "processedData_JIRASummaries_academyFeaturesEntropy[\"JiraSummariesAsQuery_avgEntropy\"] = processedData_JIRASummaries_academyFeaturesEntropy.apply(lambda x: calcAvgEntropy(x.JiraSummariesAsQuery_Entropy), axis=1)\n",
    "processedData_JIRASummaries_academyFeaturesEntropy[\"JiraSummariesAsQuery_medEntropy\"] = processedData_JIRASummaries_academyFeaturesEntropy.apply(lambda x: calcMedEntropy(x.JiraSummariesAsQuery_Entropy), axis=1)\n",
    "processedData_JIRASummaries_academyFeaturesEntropy[\"JiraSummariesAsQuery_maxEntropy\"] = processedData_JIRASummaries_academyFeaturesEntropy.apply(lambda x: calcMaxEntropy(x.JiraSummariesAsQuery_Entropy), axis=1)\n",
    "processedData_JIRASummaries_academyFeaturesEntropy[\"JiraSummariesAsQuery_devEntropy\"] = processedData_JIRASummaries_academyFeaturesEntropy.apply(lambda x: calcDevEntropy(x.JiraSummariesAsQuery_Entropy), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRASummaries_academyFeaturesEntropy.to_pickle(path= \"../data/03_processed/processedData_JIRASummaries_academyFeaturesEntropy.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-wallace",
   "metadata": {},
   "source": [
    "#### Entropy (JIRA Descriptions as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "continuing-loading",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 1120 minutes and 58.01217865943909 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRADescriptions_academyFeaturesEntropy = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRADescriptions_academyFeaturesEntropy[\"JiraDescriptionsAsQuery_Entropy\"] = processedData_academyCartesian.apply(lambda x: calcEntropyList(x.Description, \n",
    "                                                                                                                processedData_JIRADescriptions_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_academy_documentCount,\n",
    "                                                                                                                intermediateData_JIRA_academy.Description),axis=1)\n",
    "##\n",
    "processedData_JIRADescriptions_academyFeaturesEntropy[\"JiraDescriptionsAsQuery_avgEntropy\"] = processedData_JIRADescriptions_academyFeaturesEntropy.apply(lambda x: calcAvgEntropy(x.JiraDescriptionsAsQuery_Entropy), axis=1)\n",
    "processedData_JIRADescriptions_academyFeaturesEntropy[\"JiraDescriptionsAsQuery_medEntropy\"] = processedData_JIRADescriptions_academyFeaturesEntropy.apply(lambda x: calcMedEntropy(x.JiraDescriptionsAsQuery_Entropy), axis=1)\n",
    "processedData_JIRADescriptions_academyFeaturesEntropy[\"JiraDescriptionsAsQuery_maxEntropy\"] = processedData_JIRADescriptions_academyFeaturesEntropy.apply(lambda x: calcMaxEntropy(x.JiraDescriptionsAsQuery_Entropy), axis=1)\n",
    "processedData_JIRADescriptions_academyFeaturesEntropy[\"JiraDescriptionsAsQuery_devEntropy\"] = processedData_JIRADescriptions_academyFeaturesEntropy.apply(lambda x: calcDevEntropy(x.JiraDescriptionsAsQuery_Entropy), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRADescriptions_academyFeaturesEntropy.to_pickle(path= \"../data/03_processed/processedData_JIRADescriptions_academyFeaturesEntropy.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-affiliation",
   "metadata": {},
   "source": [
    "#### Entropy (JIRA Comments as query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-kazakhstan",
   "metadata": {},
   "source": [
    "##### Query Scope (SVN as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "integrated-parallel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 187 minutes and 26.664949655532837 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVN_academyFeaturesQueryScope = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVN_academyFeaturesQueryScope[\"SvnAsQuery_QueryScope\"] = processedData_academyCartesian.apply(lambda x: calcQueryScope(x.Commit_natural_text, \n",
    "                                                                                                                intermediateData_SVN_academy.Commit_natural_text),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVN_academyFeaturesQueryScope.to_pickle(path= \"../data/03_processed/processedData_SVN_academyFeaturesQueryScope.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-madrid",
   "metadata": {},
   "source": [
    "##### Query Scope (SVNLogs as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "macro-geology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 61 minutes and 16.10218596458435 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNLogs_academyFeaturesQueryScope = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNLogs_academyFeaturesQueryScope[\"SvnLogsAsQuery_QueryScope\"] = processedData_academyCartesian.apply(lambda x: calcQueryScope(x.Logs, \n",
    "                                                                                                                intermediateData_SVN_academy.Logs),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNLogs_academyFeaturesQueryScope.to_pickle(path= \"../data/03_processed/processedData_SVNLogs_academyFeaturesQueryScope.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-brooks",
   "metadata": {},
   "source": [
    "##### Query Scope (SVNUnitNames as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "turned-invasion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 70 minutes and 30.740331888198853 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNUnitNames_academyFeaturesQueryScope = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNUnitNames_academyFeaturesQueryScope[\"SvnUnitNamesAsQuery_QueryScope\"] = processedData_academyCartesian.apply(lambda x: calcQueryScope(x.Unit_names, \n",
    "                                                                                                                intermediateData_SVN_academy.Unit_names),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNUnitNames_academyFeaturesQueryScope.to_pickle(path= \"../data/03_processed/processedData_SVNUnitNames_academyFeaturesQueryScope.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-cocktail",
   "metadata": {},
   "source": [
    "##### Query Scope (JIRA as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "soviet-keyboard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 194 minutes and 45.88301682472229 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRA_academyFeaturesQueryScope = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRA_academyFeaturesQueryScope[\"JiraAsQuery_QueryScope\"] = processedData_academyCartesian.apply(lambda x: calcQueryScope(x.Jira_natural_text, \n",
    "                                                                                                                intermediateData_JIRA_academy.Jira_natural_text),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRA_academyFeaturesQueryScope.to_pickle(path= \"../data/03_processed/processedData_JIRA_academyFeaturesQueryScope.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-mumbai",
   "metadata": {},
   "source": [
    "##### Query Scope (JIRA Summaries as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "coordinated-paint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 22 minutes and 12.595993280410767 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRASummaries_academyFeaturesQueryScope = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRASummaries_academyFeaturesQueryScope[\"JiraSummariesAsQuery_QueryScope\"] = processedData_academyCartesian.apply(lambda x: calcQueryScope(x.Summary, \n",
    "                                                                                                                intermediateData_JIRA_academy.Summary),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRASummaries_academyFeaturesQueryScope.to_pickle(path= \"../data/03_processed/processedData_JIRASummaries_academyFeaturesQueryScope.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-hopkins",
   "metadata": {},
   "source": [
    "##### Query Scope (JIRA Descriptions as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "awful-trunk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 144 minutes and 1.815511703491211 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRADescriptions_academyFeaturesQueryScope = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRADescriptions_academyFeaturesQueryScope[\"JiraDescriptionsAsQuery_QueryScope\"] = processedData_academyCartesian.apply(lambda x: calcQueryScope(x.Description, \n",
    "                                                                                                                intermediateData_JIRA_academy.Description),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRADescriptions_academyFeaturesQueryScope.to_pickle(path= \"../data/03_processed/processedData_JIRADescriptions_academyFeaturesQueryScope.pkl\")\n",
    "\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-israel",
   "metadata": {},
   "source": [
    "##### Query Scope (JIRA Comments as query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-yorkshire",
   "metadata": {},
   "source": [
    "#### Kullback-Leiber divergence (SVN as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "saving-marks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 3 minutes and 25.807637929916382 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVN_academyFeaturesSCS = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVN_academyFeaturesSCS[\"SvnAsQuery_SCS\"] = processedData_academyCartesian.apply(lambda x: calcSCS(x.Commit_natural_text, \n",
    "                                                                                                                processedData_SVN_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_academy_documentCount),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVN_academyFeaturesSCS.to_pickle(path= \"../data/03_processed/processedData_SVN_academyFeaturesSCS.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-paint",
   "metadata": {},
   "source": [
    "#### Kullback-Leiber divergence (SVNLogs as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "substantial-helmet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 8 minutes and 30.95951771736145 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNLogs_academyFeaturesSCS = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNLogs_academyFeaturesSCS[\"SvnLogsAsQuery_SCS\"] = processedData_academyCartesian.apply(lambda x: calcSCS(x.Logs, \n",
    "                                                                                                                processedData_SVNLogs_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_academy_documentCount),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNLogs_academyFeaturesSCS.to_pickle(path= \"../data/03_processed/processedData_SVNLogs_academyFeaturesSCS.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-calendar",
   "metadata": {},
   "source": [
    "#### Kullback-Leiber divergence (SVNUnitNames as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "breathing-collective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 10 minutes and 17.531525373458862 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNUnitNames_academyFeaturesSCS = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNUnitNames_academyFeaturesSCS[\"SvnUnitNamesAsQuery_SCS\"] = processedData_academyCartesian.apply(lambda x: calcSCS(x.Unit_names, \n",
    "                                                                                                                processedData_SVNUnitNames_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_SVN_academy_documentCount),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNUnitNames_academyFeaturesSCS.to_pickle(path= \"../data/03_processed/processedData_SVNUnitNames_academyFeaturesSCS.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-cargo",
   "metadata": {},
   "source": [
    "#### Kullback-Leiber divergence (JIRA as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "pursuant-reduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 10 minutes and 6.178834915161133 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRA_academyFeaturesSCS = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRA_academyFeaturesSCS[\"JiraAsQuery_SCS\"] = processedData_academyCartesian.apply(lambda x: calcSCS(x.Jira_natural_text, \n",
    "                                                                                                                processedData_JIRA_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_academy_documentCount),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRA_academyFeaturesSCS.to_pickle(path= \"../data/03_processed/processedData_JIRA_academyFeaturesSCS.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-keeping",
   "metadata": {},
   "source": [
    "#### Kullback-Leiber divergence (JIRA Summaries as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "beginning-miniature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 15 minutes and 37.54629707336426 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRASummaries_academyFeaturesSCS = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRASummaries_academyFeaturesSCS[\"JiraSummariesAsQuery_SCS\"] = processedData_academyCartesian.apply(lambda x: calcSCS(x.Summary, \n",
    "                                                                                                                processedData_JIRASummaries_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_academy_documentCount),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRASummaries_academyFeaturesSCS.to_pickle(path= \"../data/03_processed/processedData_JIRASummaries_academyFeaturesSCS.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "quarterly-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Kullback-Leiber divergence (JIRA Description as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "waiting-adventure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 3 minutes and 1.9384474754333496 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRADescriptions_academyFeaturesSCS = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRADescriptions_academyFeaturesSCS[\"JiraDescriptionsAsQuery_SCS\"] = processedData_academyCartesian.apply(lambda x: calcSCS(x.Description, \n",
    "                                                                                                                processedData_JIRADescriptions_academyCountVectorizer, \n",
    "                                                                                                                intermediateData_JIRA_academy_documentCount),axis=1)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRADescriptions_academyFeaturesSCS.to_pickle(path= \"../data/03_processed/processedData_JIRADescriptions_academyFeaturesSCS.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dated-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Kullback-Leiber divergence (JIRA Comments as query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-execution",
   "metadata": {},
   "source": [
    "#### SCQ (SVN as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "latin-toilet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 56 minutes and 37.50871682167053 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVN_academyFeaturesSCQ = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVN_academyFeaturesSCQ[\"SvnAsQuery_SCQ\"] = processedData_academyCartesian.apply(lambda x: calcSCQList(x.Commit_natural_text, intermediateData_SVN_academy.Commit_natural_text,\n",
    "                                                                                                                                         processedData_SVN_academyCountVectorizer,\n",
    "                                                                                                                                         processedData_SVN_academyCountTF_IDF,\n",
    "                                                                                                                                         intermediateData_SVN_academy_documentCount),axis=1)\n",
    "\n",
    "processedData_SVN_academyFeaturesSCQ[\"SvnAsQuery_avgSCQ\"] = processedData_SVN_academyFeaturesSCQ.apply(lambda x: calcAvgSCQ(x.SvnAsQuery_SCQ, intermediateData_SVN_academy_documentCount), axis=1)\n",
    "processedData_SVN_academyFeaturesSCQ[\"SvnAsQuery_maxSCQ\"] = processedData_SVN_academyFeaturesSCQ.apply(lambda x: calcMaxSCQ(x.SvnAsQuery_SCQ), axis=1)\n",
    "processedData_SVN_academyFeaturesSCQ[\"SvnAsQuery_sumSCQ\"] = processedData_SVN_academyFeaturesSCQ.apply(lambda x: calcSumSCQ(x.SvnAsQuery_SCQ), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVN_academyFeaturesSCQ.to_pickle(path= \"../data/03_processed/processedData_SVN_academyFeaturesSCQ.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-technical",
   "metadata": {},
   "source": [
    "#### SCQ (SVNLogs as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "together-cattle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 54 minutes and 40.32813572883606 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNLogs_academyFeaturesSCQ = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNLogs_academyFeaturesSCQ[\"SvnLogsAsQuery_SCQ\"] = processedData_academyCartesian.apply(lambda x: calcSCQList(x.Logs, intermediateData_SVN_academy.Logs,\n",
    "                                                                                                                                         processedData_SVNLogs_academyCountVectorizer,\n",
    "                                                                                                                                         processedData_SVNLogs_academyCountTF_IDF,\n",
    "                                                                                                                                         intermediateData_SVN_academy_documentCount),axis=1)\n",
    "\n",
    "processedData_SVNLogs_academyFeaturesSCQ[\"SvnLogsAsQuery_avgSCQ\"] = processedData_SVNLogs_academyFeaturesSCQ.apply(lambda x: calcAvgSCQ(x.SvnLogsAsQuery_SCQ, intermediateData_SVN_academy_documentCount), axis=1)\n",
    "processedData_SVNLogs_academyFeaturesSCQ[\"SvnLogsAsQuery_maxSCQ\"] = processedData_SVNLogs_academyFeaturesSCQ.apply(lambda x: calcMaxSCQ(x.SvnLogsAsQuery_SCQ), axis=1)\n",
    "processedData_SVNLogs_academyFeaturesSCQ[\"SvnLogsAsQuery_sumSCQ\"] = processedData_SVNLogs_academyFeaturesSCQ.apply(lambda x: calcSumSCQ(x.SvnLogsAsQuery_SCQ), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNLogs_academyFeaturesSCQ.to_pickle(path= \"../data/03_processed/processedData_SVNLogs_academyFeaturesSCQ.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-guess",
   "metadata": {},
   "source": [
    "#### SCQ (SVNUnitNames as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "celtic-better",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 30 minutes and 19.3006112575531 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNUnitNames_academyFeaturesSCQ = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNUnitNames_academyFeaturesSCQ[\"SvnUnitNamesAsQuery_SCQ\"] = processedData_academyCartesian.apply(lambda x: calcSCQList(x.Unit_names, intermediateData_SVN_academy.Unit_names,\n",
    "                                                                                                                                         processedData_SVNUnitNames_academyCountVectorizer,\n",
    "                                                                                                                                         processedData_SVNUnitNames_academyCountTF_IDF,\n",
    "                                                                                                                                         intermediateData_SVN_academy_documentCount),axis=1)\n",
    "\n",
    "processedData_SVNUnitNames_academyFeaturesSCQ[\"SvnUnitNamesAsQuery_avgSCQ\"] = processedData_SVNUnitNames_academyFeaturesSCQ.apply(lambda x: calcAvgSCQ(x.SvnUnitNamesAsQuery_SCQ, intermediateData_SVN_academy_documentCount), axis=1)\n",
    "processedData_SVNUnitNames_academyFeaturesSCQ[\"SvnUnitNamesAsQuery_maxSCQ\"] = processedData_SVNUnitNames_academyFeaturesSCQ.apply(lambda x: calcMaxSCQ(x.SvnUnitNamesAsQuery_SCQ), axis=1)\n",
    "processedData_SVNUnitNames_academyFeaturesSCQ[\"SvnUnitNamesAsQuery_sumSCQ\"] = processedData_SVNUnitNames_academyFeaturesSCQ.apply(lambda x: calcSumSCQ(x.SvnUnitNamesAsQuery_SCQ), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNUnitNames_academyFeaturesSCQ.to_pickle(path= \"../data/03_processed/processedData_SVNUnitNames_academyFeaturesSCQ.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-laundry",
   "metadata": {},
   "source": [
    "#### SCQ (JIRA as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "partial-police",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 71 minutes and 33.48032069206238 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRA_academyFeaturesSCQ = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRA_academyFeaturesSCQ[\"JiraAsQuery_SCQ\"] = processedData_academyCartesian.apply(lambda x: calcSCQList(x.Jira_natural_text, intermediateData_JIRA_academy.Jira_natural_text,\n",
    "                                                                                                                                         processedData_JIRA_academyCountVectorizer,\n",
    "                                                                                                                                         processedData_JIRA_academyTF_IDF,\n",
    "                                                                                                                                         intermediateData_JIRA_academy_documentCount),axis=1)\n",
    "\n",
    "processedData_JIRA_academyFeaturesSCQ[\"JiraAsQuery_avgSCQ\"] = processedData_JIRA_academyFeaturesSCQ.apply(lambda x: calcAvgSCQ(x.JiraAsQuery_SCQ, intermediateData_JIRA_academy_documentCount), axis=1)\n",
    "processedData_JIRA_academyFeaturesSCQ[\"JiraAsQuery_maxSCQ\"] = processedData_JIRA_academyFeaturesSCQ.apply(lambda x: calcMaxSCQ(x.JiraAsQuery_SCQ), axis=1)\n",
    "processedData_JIRA_academyFeaturesSCQ[\"JiraAsQuery_sumSCQ\"] = processedData_JIRA_academyFeaturesSCQ.apply(lambda x: calcSumSCQ(x.JiraAsQuery_SCQ), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRA_academyFeaturesSCQ.to_pickle(path= \"../data/03_processed/processedData_JIRA_academyFeaturesSCQ.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-updating",
   "metadata": {},
   "source": [
    "#### SCQ (JIRA Summaries as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "norwegian-alfred",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 31 minutes and 43.625542402267456 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRASummaries_academyFeaturesSCQ = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRASummaries_academyFeaturesSCQ[\"JiraSummariesAsQuery_SCQ\"] = processedData_academyCartesian.apply(lambda x: calcSCQList(x.Summary, intermediateData_JIRA_academy.Summary,\n",
    "                                                                                                                                         processedData_JIRASummaries_academyCountVectorizer,\n",
    "                                                                                                                                         processedData_JIRASummaries_academyCountTF_IDF,\n",
    "                                                                                                                                         intermediateData_JIRA_academy_documentCount),axis=1)\n",
    "\n",
    "processedData_JIRASummaries_academyFeaturesSCQ[\"JiraSummariesAsQuery_avgSCQ\"] = processedData_JIRASummaries_academyFeaturesSCQ.apply(lambda x: calcAvgSCQ(x.JiraSummariesAsQuery_SCQ, intermediateData_JIRA_academy_documentCount), axis=1)\n",
    "processedData_JIRASummaries_academyFeaturesSCQ[\"JiraSummariesAsQuery_maxSCQ\"] = processedData_JIRASummaries_academyFeaturesSCQ.apply(lambda x: calcMaxSCQ(x.JiraSummariesAsQuery_SCQ), axis=1)\n",
    "processedData_JIRASummaries_academyFeaturesSCQ[\"JiraSummariesAsQuery_sumSCQ\"] = processedData_JIRASummaries_academyFeaturesSCQ.apply(lambda x: calcSumSCQ(x.JiraSummariesAsQuery_SCQ), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRASummaries_academyFeaturesSCQ.to_pickle(path= \"../data/03_processed/processedData_JIRASummaries_academyFeaturesSCQ.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-spirit",
   "metadata": {},
   "source": [
    "#### SCQ (JIRA Descriptions as Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "affected-thanks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 66 minutes and 59.77572679519653 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRADescriptions_academyFeaturesSCQ = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRADescriptions_academyFeaturesSCQ[\"JiraDescriptionsAsQuery_SCQ\"] = processedData_academyCartesian.apply(lambda x: calcSCQList(x.Description, intermediateData_JIRA_academy.Description,\n",
    "                                                                                                                                         processedData_JIRADescriptions_academyCountVectorizer,\n",
    "                                                                                                                                         processedData_JIRADescriptions_academyCountTF_IDF,\n",
    "                                                                                                                                         intermediateData_JIRA_academy_documentCount),axis=1)\n",
    "\n",
    "processedData_JIRADescriptions_academyFeaturesSCQ[\"JiraDescriptionsAsQuery_avgSCQ\"] = processedData_JIRADescriptions_academyFeaturesSCQ.apply(lambda x: calcAvgSCQ(x.JiraDescriptionsAsQuery_SCQ, intermediateData_JIRA_academy_documentCount), axis=1)\n",
    "processedData_JIRADescriptions_academyFeaturesSCQ[\"JiraDescriptionsAsQuery_maxSCQ\"] = processedData_JIRADescriptions_academyFeaturesSCQ.apply(lambda x: calcMaxSCQ(x.JiraDescriptionsAsQuery_SCQ), axis=1)\n",
    "processedData_JIRADescriptions_academyFeaturesSCQ[\"JiraDescriptionsAsQuery_sumSCQ\"] = processedData_JIRADescriptions_academyFeaturesSCQ.apply(lambda x: calcSumSCQ(x.JiraDescriptionsAsQuery_SCQ), axis=1)\n",
    "\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRADescriptions_academyFeaturesSCQ.to_pickle(path= \"../data/03_processed/processedData_JIRADescriptions_academyFeaturesSCQ.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-walker",
   "metadata": {},
   "source": [
    "#### SCQ (JIRA Comments as Query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-owner",
   "metadata": {},
   "source": [
    "#### PMI (SVN as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create pairs and find frequencies\n",
    "termPairs = createTermPairs(processedData_SVN_academyCountVectorizer)\n",
    "termFrequencies = findTermFrequencies(processedData_SVN_academyCountVectorizer, intermediateData_SVN_academy.Commit_natural_text)\n",
    "termPairFrequencies = findTermPairFrequencies(termPairs, intermediateData_SVN_academy.Commit_natural_text)\n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVN_academyFeaturesPMI = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVN_academyFeaturesPMI[\"SvnAsQuery_PMI\"] = processedData_academyCartesian.apply(lambda x: calcPMIList(x.Commit_natural_text, \n",
    "                                                                                                                                  termFrequencies, \n",
    "                                                                                                                                  termPairFrequencies, \n",
    "                                                                                                                                  intermediateData_SVN_academy.Commit_natural_text),axis=1)\n",
    "\n",
    "processedData_SVN_academyFeaturesPMI[\"SvnAsQuery_avgPMI\"] = processedData_SVN_academyFeaturesPMI.apply(lambda x: calcAvgPMI(x.SvnAsQuery_PMI), axis=1)\n",
    "processedData_SVN_academyFeaturesPMI[\"SvnAsQuery_maxPMI\"] = processedData_SVN_academyFeaturesPMI.apply(lambda x: calcMaxPMI(x.SvnAsQuery_PMI), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "processedData_SVN_academyFeaturesPMI.drop('SvnAsQuery_PMI', axis = 1, inplace=True)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVN_academyFeaturesPMI.to_pickle(path= \"../data/03_processed/processedData_SVN_academyFeaturesPMI.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-hotel",
   "metadata": {},
   "source": [
    "#### PMI (SVNLogs as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "verified-analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-48edd07688a2>:332: RuntimeWarning: All-NaN axis encountered\n",
      "  maxPMI = np.nanmax(pmiList)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished creating query quality features in 151 minutes and 33.896199226379395 seconds\n"
     ]
    }
   ],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create pairs and find frequencies\n",
    "termPairs = createTermPairs(processedData_SVNLogs_academyCountVectorizer)\n",
    "termFrequencies = findTermFrequencies(processedData_SVNLogs_academyCountVectorizer, intermediateData_SVN_academy.Logs)\n",
    "termPairFrequencies = findTermPairFrequencies(termPairs, intermediateData_SVN_academy.Logs)\n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNLogs_academyFeaturesPMI = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNLogs_academyFeaturesPMI[\"SvnLogsAsQuery_PMI\"] = processedData_academyCartesian.apply(lambda x: calcPMIList(x.Logs, \n",
    "                                                                                                                                  termFrequencies, \n",
    "                                                                                                                                  termPairFrequencies, \n",
    "                                                                                                                                  intermediateData_SVN_academy.Logs),axis=1)\n",
    "\n",
    "processedData_SVNLogs_academyFeaturesPMI[\"SvnLogsAsQuery_avgPMI\"] = processedData_SVNLogs_academyFeaturesPMI.apply(lambda x: calcAvgPMI(x.SvnLogsAsQuery_PMI), axis=1)\n",
    "processedData_SVNLogs_academyFeaturesPMI[\"SvnLogsAsQuery_maxPMI\"] = processedData_SVNLogs_academyFeaturesPMI.apply(lambda x: calcMaxPMI(x.SvnLogsAsQuery_PMI), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "processedData_SVNLogs_academyFeaturesPMI.drop('SvnLogsAsQuery_PMI', axis = 1, inplace=True)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNLogs_academyFeaturesPMI.to_pickle(path= \"../data/03_processed/processedData_SVNLogs_academyFeaturesPMI.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-efficiency",
   "metadata": {},
   "source": [
    "#### PMI (SVNUnitNames as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-feeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create pairs and find frequencies\n",
    "termPairs = createTermPairs(processedData_SVNUnitNames_academyCountVectorizer)\n",
    "termFrequencies = findTermFrequencies(processedData_SVNUnitNames_academyCountVectorizer, intermediateData_SVN_academy.Unit_names)\n",
    "termPairFrequencies = findTermPairFrequencies(termPairs, intermediateData_SVN_academy.Unit_names)\n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_SVNUnitNames_academyFeaturesPMI = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_SVNUnitNames_academyFeaturesPMI[\"SvnUnitNamesAsQuery_PMI\"] = processedData_academyCartesian.apply(lambda x: calcPMIList(x.Unit_names, \n",
    "                                                                                                                                  termFrequencies, \n",
    "                                                                                                                                  termPairFrequencies, \n",
    "                                                                                                                                  intermediateData_SVN_academy.Unit_names),axis=1)\n",
    "\n",
    "processedData_SVNUnitNames_academyFeaturesPMI[\"SvnUnitNamesAsQuery_avgPMI\"] = processedData_SVNUnitNames_academyFeaturesPMI.apply(lambda x: calcAvgPMI(x.SvnUnitNamesAsQuery_PMI), axis=1)\n",
    "processedData_SVNUnitNames_academyFeaturesPMI[\"SvnUnitNamesAsQuery_maxPMI\"] = processedData_SVNUnitNames_academyFeaturesPMI.apply(lambda x: calcMaxPMI(x.SvnUnitNamesAsQuery_PMI), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "processedData_SVNUnitNames_academyFeaturesPMI.drop('SvnUnitNamesAsQuery_PMI', axis = 1, inplace=True)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_SVNUnitNames_academyFeaturesPMI.to_pickle(path= \"../data/03_processed/processedData_SVNUnitNames_academyFeaturesPMI.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-stomach",
   "metadata": {},
   "source": [
    "#### PMI (JIRA as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create pairs and find frequencies\n",
    "termPairs = createTermPairs(processedData_JIRA_academyCountVectorizer)\n",
    "termFrequencies = findTermFrequencies(processedData_JIRA_academyCountVectorizer, intermediateData_JIRA_academy.Jira_natural_text)\n",
    "termPairFrequencies = findTermPairFrequencies(termPairs, intermediateData_JIRA_academy.Jira_natural_text)\n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRA_academyFeaturesPMI = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRA_academyFeaturesPMI[\"JiraAsQuery_PMI\"] = processedData_academyCartesian.apply(lambda x: calcPMIList(x.Jira_natural_text, \n",
    "                                                                                                                                  termFrequencies, \n",
    "                                                                                                                                  termPairFrequencies, \n",
    "                                                                                                                                  intermediateData_JIRA_academy.Jira_natural_text),axis=1)\n",
    "\n",
    "processedData_JIRA_academyFeaturesPMI[\"JiraAsQuery_avgPMI\"] = processedData_JIRA_academyFeaturesPMI.apply(lambda x: calcAvgPMI(x.JiraAsQuery_PMI), axis=1)\n",
    "processedData_JIRA_academyFeaturesPMI[\"JiraAsQuery_maxPMI\"] = processedData_JIRA_academyFeaturesPMI.apply(lambda x: calcMaxPMI(x.JiraAsQuery_PMI), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "processedData_JIRA_academyFeaturesPMI.drop('JiraAsQuery_PMI', axis = 1, inplace=True)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRA_academyFeaturesPMI.to_pickle(path= \"../data/03_processed/processedData_JIRA_academyFeaturesPMI.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-youth",
   "metadata": {},
   "source": [
    "#### PMI (JIRA Summaries as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create pairs and find frequencies\n",
    "termPairs = createTermPairs(processedData_JIRASummaries_academyCountVectorizer)\n",
    "termFrequencies = findTermFrequencies(processedData_JIRASummaries_academyCountVectorizer, intermediateData_JIRA_academy.Summary)\n",
    "termPairFrequencies = findTermPairFrequencies(termPairs, intermediateData_JIRA_academy.Summary)\n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRASummaries_academyFeaturesPMI = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRASummaries_academyFeaturesPMI[\"JiraSummariesAsQuery_PMI\"] = processedData_academyCartesian.apply(lambda x: calcPMIList(x.Summary, \n",
    "                                                                                                                                  termFrequencies, \n",
    "                                                                                                                                  termPairFrequencies, \n",
    "                                                                                                                                  intermediateData_JIRA_academy.Summary),axis=1)\n",
    "\n",
    "processedData_JIRASummaries_academyFeaturesPMI[\"JiraSummariesAsQuery_avgPMI\"] = processedData_JIRASummaries_academyFeaturesPMI.apply(lambda x: calcAvgPMI(x.JiraSummariesAsQuery_PMI), axis=1)\n",
    "processedData_JIRASummaries_academyFeaturesPMI[\"JiraSummariesAsQuery_maxPMI\"] = processedData_JIRASummaries_academyFeaturesPMI.apply(lambda x: calcMaxPMI(x.JiraSummariesAsQuery_PMI), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "processedData_JIRASummaries_academyFeaturesPMI.drop('JiraSummariesAsQuery_PMI', axis = 1, inplace=True)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRASummaries_academyFeaturesPMI.to_pickle(path= \"../data/03_processed/processedData_JIRASummaries_academyFeaturesPMI.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-award",
   "metadata": {},
   "source": [
    "#### PMI (JIRA Descriptions as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start timer\n",
    "startTime = time.time() \n",
    "\n",
    "#Create pairs and find frequencies\n",
    "termPairs = createTermPairs(processedData_JIRADescriptions_academyCountVectorizer)\n",
    "termFrequencies = findTermFrequencies(processedData_JIRADescriptions_academyCountVectorizer, intermediateData_JIRA_academy.Description)\n",
    "termPairFrequencies = findTermPairFrequencies(termPairs, intermediateData_JIRA_academy.Description)\n",
    "\n",
    "#Create new dataFrame\n",
    "processedData_JIRADescriptions_academyFeaturesPMI = pd.DataFrame()\n",
    "\n",
    "#Calculate IDF stats for each svn\n",
    "processedData_JIRADescriptions_academyFeaturesPMI[\"JiraDescriptionsAsQuery_PMI\"] = processedData_academyCartesian.apply(lambda x: calcPMIList(x.Description, \n",
    "                                                                                                                                  termFrequencies, \n",
    "                                                                                                                                  termPairFrequencies, \n",
    "                                                                                                                                  intermediateData_JIRA_academy.Description),axis=1)\n",
    "\n",
    "processedData_JIRADescriptions_academyFeaturesPMI[\"JiraDescriptionsAsQuery_avgPMI\"] = processedData_JIRADescriptions_academyFeaturesPMI.apply(lambda x: calcAvgPMI(x.JiraDescriptionsAsQuery_PMI), axis=1)\n",
    "processedData_JIRADescriptions_academyFeaturesPMI[\"JiraDescriptionsAsQuery_maxPMI\"] = processedData_JIRADescriptions_academyFeaturesPMI.apply(lambda x: calcMaxPMI(x.JiraDescriptionsAsQuery_PMI), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "processedData_JIRADescriptions_academyFeaturesPMI.drop('JiraDescriptionsAsQuery_PMI', axis = 1, inplace=True)\n",
    "\n",
    "#Save results in pickle\n",
    "processedData_JIRADescriptions_academyFeaturesPMI.to_pickle(path= \"../data/03_processed/processedData_JIRADescriptions_academyFeaturesPMI.pkl\")\n",
    "\n",
    "endTime = time.time()\n",
    "timeDifference = calculateTimeDifference(startTime=startTime, endTime=endTime)\n",
    "print(\"Finished creating query quality features in \" + timeDifference)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-convert",
   "metadata": {},
   "source": [
    "#### PMI (JIRA Comments as query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-blocking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def normalizeData(dataFrame):\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    names = dataFrame.columns\n",
    "    d = scaler.fit_transform(dataFrame)\n",
    "    scaledDataFrame = pd.DataFrame(d, columns=names)\n",
    "    return(scaledDataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-fifteen",
   "metadata": {},
   "source": [
    "# Normalize all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-dominican",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "################################## Loading #################################\n",
    "#Load Process-Related Features\n",
    "processedData_academyFeaturesTime = pd.read_pickle(r'../data/03_processed/processedData_academyFeaturesTime.pkl')\n",
    "processedData_academyFeaturesStakeholder = pd.read_pickle(r'../data/03_processed/processedData_academyFeaturesStakeholder.pkl')\n",
    "\n",
    "#Load IR-Related Features - unigram\n",
    "processedData_academy_features_VsmLogsJiraAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmLogsJiraAsQuery.pkl')\n",
    "processedData_academy_features_VsmLogsLogAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmLogsLogAsQuery.pkl')\n",
    "processedData_academy_features_VsmUnitNamesJiraAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmUnitNamesJiraAsQuery.pkl')\n",
    "processedData_academy_features_VsmUnitNamesUnitNamesAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmUnitNamesUnitNamesAsQuery.pkl')\n",
    "\n",
    "#processedData_academy_features_VsmUnitNamesCommentsCommentsAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmUnitNamesCommentsCommentsAsQuery.pkl')\n",
    "#processedData_academy_features_VsmUnitNamesCommentsUnitNamesAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmUnitNamesCommentsUnitNamesAsQuery.pkl')\n",
    "processedData_academy_features_VsmUnitNamesDescriptionDescriptionAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmUnitNamesDescriptionDescriptionAsQuery.pkl')\n",
    "processedData_academy_features_VsmUnitNamesDescriptionUnitNamesAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmUnitNamesDescriptionUnitNamesAsQuery.pkl')\n",
    "\n",
    "processedData_academy_features_VsmVerbPruningUnitNamesJiraAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmVerbPruningUnitNamesJiraAsQuery.pkl')\n",
    "processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery.pkl')\n",
    "processedData_academy_features_VsmSummaryLogsSummaryAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSummaryLogsSummaryAsQuery.pkl')\n",
    "processedData_academy_features_VsmSummaryLogsLogsAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSummaryLogsLogsAsQuery.pkl')\n",
    "processedData_academy_features_VsmSummaryUnitNamesSummaryAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSummaryUnitNamesSummaryAsQuery.pkl')\n",
    "processedData_academy_features_VsmSummaryUnitNamesUnitNamesAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSummaryUnitNamesUnitNamesAsQuery.pkl')\n",
    "processedData_academy_features_VsmDescriptionDescriptionAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmDescriptionDescriptionAsQuery.pkl')\n",
    "processedData_academy_features_VsmDescriptionLogsAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmDescriptionLogsAsQuery.pkl')\n",
    "#processedData_academy_features_VsmCommentsCommentsAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmCommentsCommentsAsQuery.pkl')\n",
    "#processedData_academy_features_VsmCommentsLogsAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmCommentsLogsAsQuery.pkl')\n",
    "\n",
    "processedData_academy_features_VsmSvnJiraJiraAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSvnJiraJiraAsQuery.pkl')\n",
    "processedData_academy_features_VsmSvnJiraSvnAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSvnJiraSvnAsQuery.pkl')\n",
    "processedData_academy_features_VsmSvnSummarySvnAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSvnSummarySvnAsQuery.pkl')\n",
    "processedData_academy_features_VsmSvnSummarySummaryAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSvnSummarySummaryAsQuery.pkl')\n",
    "processedData_academy_features_VsmSvnDescriptionSvnAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSvnDescriptionSvnAsQuery.pkl')\n",
    "processedData_academy_features_VsmSvnDescriptionDescriptionAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSvnDescriptionDescriptionAsQuery.pkl')\n",
    "#processedData_academy_features_VsmSvnCommentsSvnAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSvnCommentsSvnAsQuery.pkl')\n",
    "#processedData_academy_features_VsmSvnCommentsCommentsAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSvnCommentsCommentsAsQuery.pkl')\n",
    "\n",
    "\n",
    "#Load IR-Related Features - bigram\n",
    "processedData_academy_features_VsmLogsJiraAsQuery_2gram = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmLogsJiraAsQuery_2gram.pkl')\n",
    "processedData_academy_features_VsmLogsLogAsQuery_2gram = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmLogsLogAsQuery_2gram.pkl')\n",
    "processedData_academy_features_VsmUnitNamesJiraAsQuery_2gram = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmUnitNamesJiraAsQuery_2gram.pkl')\n",
    "processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_2gram = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_2gram.pkl')\n",
    "#processedData_academy_features_VsmCommentsLogsAsQuery_2gram = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmCommentsLogsAsQuery_2gram.pkl')\n",
    "#processedData_academy_features_VsmCommentsCommentsAsQuery_2gram = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmCommentsCommentsAsQuery_2gram.pkl')\n",
    "\n",
    "\n",
    "#Load Document Statistics Features\n",
    "processedData_JIRA_academyFeaturesUniqueWordCount = pd.read_pickle(r\"../data/03_processed/processedData_JIRA_academyFeaturesUniqueWordCount.pkl\")\n",
    "processedData_SVN_academyFeaturesUniqueWordCount = pd.read_pickle(r\"../data/03_processed/processedData_SVN_academyFeaturesUniqueWordCount.pkl\")\n",
    "processedData_JIRA_academyFeaturesTotalWordCount = pd.read_pickle(r\"../data/03_processed/processedData_JIRA_academyFeaturesTotalWordCount.pkl\")\n",
    "processedData_SVN_academyFeaturesTotalWordCount = pd.read_pickle(r\"../data/03_processed/processedData_SVN_academyFeaturesTotalWordCount.pkl\")\n",
    "processedData_JIRA_academyFeaturesOverlapPercentage = pd.read_pickle(r\"../data/03_processed/processedData_JIRA_academyFeaturesOverlapPercentage.pkl\")\n",
    "processedData_SVN_academyFeaturesOverlapPercentage = pd.read_pickle(r\"../data/03_processed/processedData_SVN_academyFeaturesOverlapPercentage.pkl\")\n",
    "processedData_UNION_academyFeaturesOverlapPercentage = pd.read_pickle(r\"../data/03_processed/processedData_UNION_academyFeaturesOverlapPercentage.pkl\")\n",
    "\n",
    "#Load Query Quality Features\n",
    "#processedData_academyFeaturesQueryQuality = pd.read_pickle(r'../data/03_processed/processedData_academyFeaturesQueryQuality.pkl')\n",
    "processedData_SVN_academyFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_SVN_academyFeaturesIDF.pkl')\n",
    "processedData_SVNLogs_academyFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_academyFeaturesIDF.pkl')\n",
    "processedData_SVNUnitNames_academyFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_academyFeaturesIDF.pkl')\n",
    "processedData_JIRA_academyFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_JIRA_academyFeaturesIDF.pkl')\n",
    "processedData_JIRASummaries_academyFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_academyFeaturesIDF.pkl')\n",
    "processedData_JIRADescriptions_academyFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_academyFeaturesIDF.pkl')\n",
    "#processedData_JIRAComments_academyFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_academyFeaturesIDF.pkl')\n",
    "\n",
    "\n",
    "processedData_SVN_academyFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_SVN_academyFeaturesICTF.pkl')\n",
    "processedData_SVNLogs_academyFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_academyFeaturesICTF.pkl')\n",
    "processedData_SVNUnitNames_academyFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_academyFeaturesICTF.pkl')\n",
    "processedData_JIRA_academyFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_JIRA_academyFeaturesICTF.pkl')\n",
    "processedData_JIRASummaries_academyFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_academyFeaturesICTF.pkl')\n",
    "processedData_JIRADescriptions_academyFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_academyFeaturesICTF.pkl')\n",
    "#processedData_JIRAComments_academyFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_academyFeaturesICTF.pkl')\n",
    "\n",
    "\n",
    "processedData_SVN_academyFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_SVN_academyFeaturesEntropy.pkl')\n",
    "processedData_SVNLogs_academyFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_academyFeaturesEntropy.pkl')\n",
    "processedData_SVNUnitNames_academyFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_academyFeaturesEntropy.pkl')\n",
    "processedData_JIRA_academyFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_JIRA_academyFeaturesEntropy.pkl')\n",
    "processedData_JIRASummaries_academyFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_academyFeaturesEntropy.pkl')\n",
    "processedData_JIRADescriptions_academyFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_academyFeaturesEntropy.pkl')\n",
    "#processedData_JIRAComments_academyFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_academyFeaturesEntropy.pkl')\n",
    "\n",
    "\n",
    "processedData_SVN_academyFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_SVN_academyFeaturesQueryScope.pkl')\n",
    "processedData_SVNLogs_academyFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_academyFeaturesQueryScope.pkl')\n",
    "processedData_SVNUnitNames_academyFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_academyFeaturesQueryScope.pkl')\n",
    "processedData_JIRA_academyFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_JIRA_academyFeaturesQueryScope.pkl')\n",
    "processedData_JIRASummaries_academyFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_academyFeaturesQueryScope.pkl')\n",
    "processedData_JIRADescriptions_academyFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_academyFeaturesQueryScope.pkl')\n",
    "#processedData_JIRAComments_academyFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_academyFeaturesQueryScope.pkl')\n",
    "\n",
    "\n",
    "processedData_SVN_academyFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_SVN_academyFeaturesSCS.pkl')\n",
    "processedData_SVNLogs_academyFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_academyFeaturesSCS.pkl')\n",
    "processedData_SVNUnitNames_academyFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_academyFeaturesSCS.pkl')\n",
    "processedData_JIRA_academyFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_JIRA_academyFeaturesSCS.pkl')\n",
    "processedData_JIRASummaries_academyFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_academyFeaturesSCS.pkl')\n",
    "processedData_JIRADescriptions_academyFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_academyFeaturesSCS.pkl')\n",
    "#processedData_JIRAComments_academyFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_academyFeaturesSCS.pkl')\n",
    "\n",
    "\n",
    "processedData_SVN_academyFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_SVN_academyFeaturesSCQ.pkl')\n",
    "processedData_SVNLogs_academyFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_academyFeaturesSCQ.pkl')\n",
    "processedData_SVNUnitNames_academyFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_academyFeaturesSCQ.pkl')\n",
    "processedData_JIRA_academyFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_JIRA_academyFeaturesSCQ.pkl')\n",
    "processedData_JIRASummaries_academyFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_academyFeaturesSCQ.pkl')\n",
    "processedData_JIRADescriptions_academyFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_academyFeaturesSCQ.pkl')\n",
    "#processedData_JIRAComments_academyFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_academyFeaturesSCQ.pkl')\n",
    "\n",
    "\n",
    "processedData_SVN_academyFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_SVN_academyFeaturesPMI.pkl')\n",
    "processedData_SVNLogs_academyFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_academyFeaturesPMI.pkl')\n",
    "processedData_SVNUnitNames_academyFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_academyFeaturesPMI.pkl')\n",
    "processedData_JIRA_academyFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_JIRA_academyFeaturesPMI.pkl')\n",
    "processedData_JIRASummaries_academyFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_academyFeaturesPMI.pkl')\n",
    "processedData_JIRADescriptions_academyFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_academyFeaturesPMI.pkl')\n",
    "#processedData_JIRAComments_academyFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_academyFeaturesPMI.pkl')\n",
    "\n",
    "\n",
    "################################## Drop query array for normalization ###############################################\n",
    "\n",
    "\n",
    "processedData_SVN_academyFeaturesIDF.drop('SvnAsQuery_IDF', axis = 1, inplace=True)\n",
    "processedData_SVNLogs_academyFeaturesIDF.drop('SvnLogsAsQuery_IDF', axis = 1, inplace=True)\n",
    "processedData_SVNUnitNames_academyFeaturesIDF.drop('SvnUnitNamesAsQuery_IDF', axis = 1, inplace=True)\n",
    "processedData_JIRA_academyFeaturesIDF.drop('JiraAsQuery_IDF', axis = 1, inplace=True)\n",
    "processedData_JIRASummaries_academyFeaturesIDF.drop('JiraSummariesAsQuery_IDF', axis = 1, inplace=True)\n",
    "processedData_JIRADescriptions_academyFeaturesIDF.drop('JiraDescriptionsAsQuery_IDF', axis = 1, inplace=True)\n",
    "#processedData_JIRAComments_academyFeaturesIDF.drop('JiraCommentsAsQuery_IDF', axis = 1, inplace=True)\n",
    "\n",
    "processedData_SVN_academyFeaturesICTF.drop('SvnAsQuery_ICTF', axis = 1, inplace=True)\n",
    "processedData_SVNLogs_academyFeaturesICTF.drop('SvnLogsAsQuery_ICTF', axis = 1, inplace=True)\n",
    "processedData_SVNUnitNames_academyFeaturesICTF.drop('SvnUnitNamesAsQuery_ICTF', axis = 1, inplace=True)\n",
    "processedData_JIRA_academyFeaturesICTF.drop('JiraAsQuery_ICTF', axis = 1, inplace=True)\n",
    "processedData_JIRASummaries_academyFeaturesICTF.drop('JiraSummariesAsQuery_ICTF', axis = 1, inplace=True)\n",
    "processedData_JIRADescriptions_academyFeaturesICTF.drop('JiraDescriptionsAsQuery_ICTF', axis = 1, inplace=True)\n",
    "#processedData_JIRAComments_academyFeaturesICTF.drop('JiraCommentsAsQuery_ICTF', axis = 1, inplace=True)\n",
    "\n",
    "processedData_SVN_academyFeaturesEntropy.drop('SvnAsQuery_Entropy', axis = 1, inplace=True)\n",
    "processedData_SVNLogs_academyFeaturesEntropy.drop('SvnLogsAsQuery_Entropy', axis = 1, inplace=True)\n",
    "processedData_SVNUnitNames_academyFeaturesEntropy.drop('SvnUnitNamesAsQuery_Entropy', axis = 1, inplace=True)\n",
    "processedData_JIRA_academyFeaturesEntropy.drop('JiraAsQuery_Entropy', axis = 1, inplace=True)\n",
    "processedData_JIRASummaries_academyFeaturesEntropy.drop('JiraSummariesAsQuery_Entropy', axis = 1, inplace=True)\n",
    "processedData_JIRADescriptions_academyFeaturesEntropy.drop('JiraDescriptionsAsQuery_Entropy', axis = 1, inplace=True)\n",
    "#processedData_JIRAComments_academyFeaturesEntropy.drop('JiraCommentsAsQuery_Entropy', axis = 1, inplace=True)\n",
    "\n",
    "processedData_SVN_academyFeaturesSCQ.drop('SvnAsQuery_SCQ', axis = 1, inplace=True)\n",
    "processedData_SVNLogs_academyFeaturesSCQ.drop('SvnLogsAsQuery_SCQ', axis = 1, inplace=True)\n",
    "processedData_SVNUnitNames_academyFeaturesSCQ.drop('SvnUnitNamesAsQuery_SCQ', axis = 1, inplace=True)\n",
    "processedData_JIRA_academyFeaturesSCQ.drop('JiraAsQuery_SCQ', axis = 1, inplace=True)\n",
    "processedData_JIRASummaries_academyFeaturesSCQ.drop('JiraSummariesAsQuery_SCQ', axis = 1, inplace=True)\n",
    "processedData_JIRADescriptions_academyFeaturesSCQ.drop('JiraDescriptionsAsQuery_SCQ', axis = 1, inplace=True)\n",
    "#processedData_JIRAComments_academyFeaturesSCQ.drop('JiraCommentsAsQuery_SCQ', axis = 1, inplace=True)\n",
    "\n",
    "################################## Normalizing ################################################\n",
    "\n",
    "processedData_academyFeaturesTime_normalized = normalizeData(processedData_academyFeaturesTime)\n",
    "processedData_academyFeaturesStakeholder_normalized = normalizeData(processedData_academyFeaturesStakeholder)\n",
    "\n",
    "#Load IR-Related Features - unigram\n",
    "processedData_academy_features_VsmLogsJiraAsQuery_normalized = normalizeData(processedData_academy_features_VsmLogsJiraAsQuery)\n",
    "processedData_academy_features_VsmLogsLogAsQuery_normalized = normalizeData(processedData_academy_features_VsmLogsLogAsQuery)\n",
    "processedData_academy_features_VsmUnitNamesJiraAsQuery_normalized = normalizeData(processedData_academy_features_VsmUnitNamesJiraAsQuery)\n",
    "processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_normalized = normalizeData(processedData_academy_features_VsmUnitNamesUnitNamesAsQuery)\n",
    "#processedData_academy_features_VsmUnitNamesCommentsCommentsAsQuery_normalized = normalizeData(processedData_academy_features_VsmUnitNamesCommentsCommentsAsQuery)\n",
    "#processedData_academy_features_VsmUnitNamesCommentsUnitNamesAsQuery_normalized = normalizeData(processedData_academy_features_VsmUnitNamesCommentsUnitNamesAsQuery)\n",
    "processedData_academy_features_VsmUnitNamesDescriptionDescriptionAsQuery_normalized = normalizeData(processedData_academy_features_VsmUnitNamesDescriptionDescriptionAsQuery)\n",
    "processedData_academy_features_VsmUnitNamesDescriptionUnitNamesAsQuery_normalized = normalizeData(processedData_academy_features_VsmUnitNamesDescriptionUnitNamesAsQuery)\n",
    "\n",
    "processedData_academy_features_VsmVerbPruningUnitNamesJiraAsQuery_normalized = normalizeData(processedData_academy_features_VsmVerbPruningUnitNamesJiraAsQuery)\n",
    "processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery_normalized = normalizeData(processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery)\n",
    "processedData_academy_features_VsmSummaryLogsSummaryAsQuery_normalized = normalizeData(processedData_academy_features_VsmSummaryLogsSummaryAsQuery)\n",
    "processedData_academy_features_VsmSummaryLogsLogsAsQuery_normalized = normalizeData(processedData_academy_features_VsmSummaryLogsLogsAsQuery)\n",
    "processedData_academy_features_VsmSummaryUnitNamesSummaryAsQuery_normalized = normalizeData(processedData_academy_features_VsmSummaryUnitNamesSummaryAsQuery)\n",
    "processedData_academy_features_VsmSummaryUnitNamesUnitNamesAsQuery_normalized = normalizeData(processedData_academy_features_VsmSummaryUnitNamesUnitNamesAsQuery)\n",
    "processedData_academy_features_VsmDescriptionDescriptionAsQuery_normalized = normalizeData(processedData_academy_features_VsmDescriptionDescriptionAsQuery)\n",
    "processedData_academy_features_VsmDescriptionLogsAsQuery_normalized = normalizeData(processedData_academy_features_VsmDescriptionLogsAsQuery)\n",
    "#processedData_academy_features_VsmCommentsCommentsAsQuery_normalized = normalizeData(processedData_academy_features_VsmCommentsCommentsAsQuery)\n",
    "#processedData_academy_features_VsmCommentsLogsAsQuery_normalized = normalizeData(processedData_academy_features_VsmCommentsLogsAsQuery)\n",
    "\n",
    "processedData_academy_features_VsmSvnJiraJiraAsQuery_normalized = normalizeData(processedData_academy_features_VsmSvnJiraJiraAsQuery)\n",
    "processedData_academy_features_VsmSvnJiraSvnAsQuery_normalized = normalizeData(processedData_academy_features_VsmSvnJiraSvnAsQuery)\n",
    "processedData_academy_features_VsmSvnSummarySvnAsQuery_normalized = normalizeData(processedData_academy_features_VsmSvnSummarySvnAsQuery)\n",
    "processedData_academy_features_VsmSvnSummarySummaryAsQuery_normalized = normalizeData(processedData_academy_features_VsmSvnSummarySummaryAsQuery)\n",
    "processedData_academy_features_VsmSvnDescriptionSvnAsQuery_normalized = normalizeData(processedData_academy_features_VsmSvnDescriptionSvnAsQuery)\n",
    "processedData_academy_features_VsmSvnDescriptionDescriptionAsQuery_normalized = normalizeData(processedData_academy_features_VsmSvnDescriptionDescriptionAsQuery)\n",
    "#processedData_academy_features_VsmSvnCommentsSvnAsQuery_normalized = normalizeData(processedData_academy_features_VsmSvnCommentsSvnAsQuery)\n",
    "#processedData_academy_features_VsmSvnCommentsCommentsAsQuery_normalized = normalizeData(processedData_academy_features_VsmSvnCommentsCommentsAsQuery)\n",
    "\n",
    "\n",
    "\n",
    "#Load IR-Related Features - bigram\n",
    "processedData_academy_features_VsmLogsJiraAsQuery_2gram_normalized = normalizeData(processedData_academy_features_VsmLogsJiraAsQuery_2gram)\n",
    "processedData_academy_features_VsmLogsLogAsQuery_2gram_normalized = normalizeData(processedData_academy_features_VsmLogsLogAsQuery_2gram)\n",
    "processedData_academy_features_VsmUnitNamesJiraAsQuery_2gram_normalized = normalizeData(processedData_academy_features_VsmUnitNamesJiraAsQuery_2gram)\n",
    "processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_2gram_normalized = normalizeData(processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_2gram)\n",
    "processedData_academy_features_VsmCommentsLogsAsQuery_2gram_normalized = normalizeData(processedData_academy_features_VsmCommentsLogsAsQuery_2gram)\n",
    "processedData_academy_features_VsmCommentsCommentsAsQuery_2gram_normalized = normalizeData(processedData_academy_features_VsmCommentsCommentsAsQuery_2gram)\n",
    "\n",
    "\n",
    "#Load Document Statistics Features\n",
    "processedData_JIRA_academyFeaturesUniqueWordCount_normalized = normalizeData(processedData_JIRA_academyFeaturesUniqueWordCount)\n",
    "processedData_SVN_academyFeaturesUniqueWordCount_normalized = normalizeData(processedData_SVN_academyFeaturesUniqueWordCount)\n",
    "processedData_JIRA_academyFeaturesTotalWordCount_normalized = normalizeData(processedData_JIRA_academyFeaturesTotalWordCount)\n",
    "processedData_SVN_academyFeaturesTotalWordCount_normalized = normalizeData(processedData_SVN_academyFeaturesTotalWordCount)\n",
    "processedData_JIRA_academyFeaturesOverlapPercentage_normalized = normalizeData(processedData_JIRA_academyFeaturesOverlapPercentage)\n",
    "processedData_SVN_academyFeaturesOverlapPercentage_normalized = normalizeData(processedData_SVN_academyFeaturesOverlapPercentage)\n",
    "processedData_UNION_academyFeaturesOverlapPercentage_normalized = normalizeData(processedData_UNION_academyFeaturesOverlapPercentage)\n",
    "\n",
    "#Load Query Quality Features\n",
    "processedData_SVN_academyFeaturesIDF_normalized = normalizeData(processedData_SVN_academyFeaturesIDF)\n",
    "processedData_SVNLogs_academyFeaturesIDF_normalized = normalizeData(processedData_SVNLogs_academyFeaturesIDF)\n",
    "processedData_SVNUnitNames_academyFeaturesIDF_normalized = normalizeData(processedData_SVNUnitNames_academyFeaturesIDF)\n",
    "processedData_JIRA_academyFeaturesIDF_normalized = normalizeData(processedData_JIRA_academyFeaturesIDF)\n",
    "processedData_JIRASummaries_academyFeaturesIDF_normalized = normalizeData(processedData_JIRASummaries_academyFeaturesIDF)\n",
    "processedData_JIRADescriptions_academyFeaturesIDF_normalized = normalizeData(processedData_JIRADescriptions_academyFeaturesIDF)\n",
    "#processedData_JIRAComments_academyFeaturesIDF_normalized = normalizeData(processedData_JIRAComments_academyFeaturesIDF)\n",
    "\n",
    "processedData_SVN_academyFeaturesICTF_normalized = normalizeData(processedData_SVN_academyFeaturesICTF)\n",
    "processedData_SVNLogs_academyFeaturesICTF_normalized = normalizeData(processedData_SVNLogs_academyFeaturesICTF)\n",
    "processedData_SVNUnitNames_academyFeaturesICTF_normalized = normalizeData(processedData_SVNUnitNames_academyFeaturesICTF)\n",
    "processedData_JIRA_academyFeaturesICTF_normalized = normalizeData(processedData_JIRA_academyFeaturesICTF)\n",
    "processedData_JIRASummaries_academyFeaturesICTF_normalized = normalizeData(processedData_JIRASummaries_academyFeaturesICTF)\n",
    "processedData_JIRADescriptions_academyFeaturesICTF_normalized = normalizeData(processedData_JIRADescriptions_academyFeaturesICTF)\n",
    "#processedData_JIRAComments_academyFeaturesICTF_normalized = normalizeData(processedData_JIRAComments_academyFeaturesICTF)\n",
    "\n",
    "processedData_SVN_academyFeaturesEntropy_normalized = normalizeData(processedData_SVN_academyFeaturesEntropy)\n",
    "processedData_SVNLogs_academyFeaturesEntropy_normalized = normalizeData(processedData_SVNLogs_academyFeaturesEntropy)\n",
    "processedData_SVNUnitNames_academyFeaturesEntropy_normalized = normalizeData(processedData_SVNUnitNames_academyFeaturesEntropy)\n",
    "processedData_JIRA_academyFeaturesEntropy_normalized = normalizeData(processedData_JIRA_academyFeaturesEntropy)\n",
    "processedData_JIRASummaries_academyFeaturesEntropy_normalized = normalizeData(processedData_JIRASummaries_academyFeaturesEntropy)\n",
    "processedData_JIRADescriptions_academyFeaturesEntropy_normalized = normalizeData(processedData_JIRADescriptions_academyFeaturesEntropy)\n",
    "#processedData_JIRAComments_academyFeaturesEntropy_normalized = normalizeData(processedData_JIRAComments_academyFeaturesEntropy)\n",
    "\n",
    "processedData_SVN_academyFeaturesQueryScope_normalized = normalizeData(processedData_SVN_academyFeaturesQueryScope)\n",
    "processedData_SVNLogs_academyFeaturesQueryScope_normalized = normalizeData(processedData_SVNLogs_academyFeaturesQueryScope)\n",
    "processedData_SVNUnitNames_academyFeaturesQueryScope_normalized = normalizeData(processedData_SVNUnitNames_academyFeaturesQueryScope)\n",
    "processedData_JIRA_academyFeaturesQueryScope_normalized = normalizeData(processedData_JIRA_academyFeaturesQueryScope)\n",
    "processedData_JIRASummaries_academyFeaturesQueryScope_normalized = normalizeData(processedData_JIRASummaries_academyFeaturesQueryScope)\n",
    "processedData_JIRADescriptions_academyFeaturesQueryScope_normalized = normalizeData(processedData_JIRADescriptions_academyFeaturesQueryScope)\n",
    "#processedData_JIRAComments_academyFeaturesQueryScope_normalized = normalizeData(processedData_JIRAComments_academyFeaturesQueryScope)\n",
    "\n",
    "processedData_SVN_academyFeaturesSCS_normalized = normalizeData(processedData_SVN_academyFeaturesSCS)\n",
    "processedData_SVNLogs_academyFeaturesSCS_normalized = normalizeData(processedData_SVNLogs_academyFeaturesSCS)\n",
    "processedData_SVNUnitNames_academyFeaturesSCS_normalized = normalizeData(processedData_SVNUnitNames_academyFeaturesSCS)\n",
    "processedData_JIRA_academyFeaturesSCS_normalized = normalizeData(processedData_JIRA_academyFeaturesSCS)\n",
    "processedData_JIRASummaries_academyFeaturesSCS_normalized = normalizeData(processedData_JIRASummaries_academyFeaturesSCS)\n",
    "processedData_JIRADescriptions_academyFeaturesSCS_normalized = normalizeData(processedData_JIRADescriptions_academyFeaturesSCS)\n",
    "#processedData_JIRAComments_academyFeaturesSCS_normalized = normalizeData(processedData_JIRAComments_academyFeaturesSCS)\n",
    "\n",
    "processedData_SVN_academyFeaturesSCQ_normalized = normalizeData(processedData_SVN_academyFeaturesSCQ)\n",
    "processedData_SVNLogs_academyFeaturesSCQ_normalized = normalizeData(processedData_SVNLogs_academyFeaturesSCQ)\n",
    "processedData_SVNUnitNames_academyFeaturesSCQ_normalized = normalizeData(processedData_SVNUnitNames_academyFeaturesSCQ)\n",
    "processedData_JIRA_academyFeaturesSCQ_normalized = normalizeData(processedData_JIRA_academyFeaturesSCQ)\n",
    "processedData_JIRASummaries_academyFeaturesSCQ_normalized = normalizeData(processedData_JIRASummaries_academyFeaturesSCQ)\n",
    "processedData_JIRADescriptions_academyFeaturesSCQ_normalized = normalizeData(processedData_JIRADescriptions_academyFeaturesSCQ)\n",
    "#processedData_JIRAComments_academyFeaturesSCQ_normalized = normalizeData(processedData_JIRAComments_academyFeaturesSCQ)\n",
    "\n",
    "processedData_SVN_academyFeaturesPMI_normalized = normalizeData(processedData_SVN_academyFeaturesPMI)\n",
    "processedData_SVNLogs_academyFeaturesPMI_normalized = normalizeData(processedData_SVNLogs_academyFeaturesPMI)\n",
    "processedData_SVNUnitNames_academyFeaturesPMI_normalized = normalizeData(processedData_SVNUnitNames_academyFeaturesPMI)\n",
    "processedData_JIRA_academyFeaturesPMI_normalized = normalizeData(processedData_JIRA_academyFeaturesPMI)\n",
    "processedData_JIRASummaries_academyFeaturesPMI_normalized = normalizeData(processedData_JIRASummaries_academyFeaturesPMI)\n",
    "processedData_JIRADescriptions_academyFeaturesPMI_normalized = normalizeData(processedData_JIRADescriptions_academyFeaturesPMI)\n",
    "#processedData_JIRAComments_academyFeaturesPMI_normalized = normalizeData(processedData_JIRAComments_academyFeaturesPMI)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-material",
   "metadata": {},
   "source": [
    "## 3.8 Preprocess Data - Load and transform feature families needed for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Merge features into 1 dataframe\n",
    "processedData_academyFeatures = pd.concat([processedData_academyFeaturesTime_normalized,\n",
    "                                                  processedData_academyFeaturesStakeholder_normalized,\n",
    "                                                  #IR-based\n",
    "                                                  processedData_academy_features_VsmLogsJiraAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmLogsLogAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmUnitNamesJiraAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_normalized,\n",
    "                                                #  processedData_academy_features_VsmUnitNamesCommentsCommentsAsQuery_normalized,\n",
    "                                                #  processedData_academy_features_VsmUnitNamesCommentsUnitNamesAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmUnitNamesDescriptionDescriptionAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmUnitNamesDescriptionUnitNamesAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmSummaryLogsSummaryAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmSummaryLogsLogsAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmSummaryUnitNamesSummaryAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmSummaryUnitNamesUnitNamesAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmDescriptionDescriptionAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmDescriptionLogsAsQuery_normalized,\n",
    "                                                 # processedData_academy_features_VsmCommentsCommentsAsQuery_normalized,\n",
    "                                                #  processedData_academy_features_VsmCommentsLogsAsQuery_normalized,\n",
    "                                                 # processedData_academy_features_VsmLogsJiraAsQuery_2gram_normalized,\n",
    "                                                 # processedData_academy_features_VsmLogsLogAsQuery_2gram_normalized,\n",
    "                                                 # processedData_academy_features_VsmUnitNamesJiraAsQuery_2gram_normalized,\n",
    "                                                 # processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_2gram_normalized,\n",
    "                                                  #processedData_academy_features_VsmVerbPruningUnitNamesJiraAsQuery_normalized,\n",
    "                                                 # processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmSvnJiraJiraAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmSvnJiraSvnAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmSvnSummarySvnAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmSvnSummarySummaryAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmSvnDescriptionSvnAsQuery_normalized,\n",
    "                                                  processedData_academy_features_VsmSvnDescriptionDescriptionAsQuery_normalized,\n",
    "                                                #  processedData_academy_features_VsmSvnCommentsSvnAsQuery_normalized,\n",
    "                                                #  processedData_academy_features_VsmSvnCommentsCommentsAsQuery_normalized,\n",
    "\n",
    "                                                  \n",
    "                                                  #Document Statistics\n",
    "                                                  processedData_JIRA_academyFeaturesUniqueWordCount_normalized,\n",
    "                                                  processedData_SVN_academyFeaturesUniqueWordCount_normalized,\n",
    "                                                  processedData_JIRA_academyFeaturesTotalWordCount_normalized,\n",
    "                                                  processedData_SVN_academyFeaturesTotalWordCount_normalized,\n",
    "                                                  processedData_JIRA_academyFeaturesOverlapPercentage_normalized,\n",
    "                                                  processedData_SVN_academyFeaturesOverlapPercentage_normalized,\n",
    "                                                  processedData_UNION_academyFeaturesOverlapPercentage_normalized,\n",
    "                                                 #Query Quality\n",
    "                                                  processedData_SVN_academyFeaturesIDF_normalized['SvnAsQuery_avgIDF'],\n",
    "                                                  processedData_SVN_academyFeaturesIDF_normalized['SvnAsQuery_maxIDF'],\n",
    "                                                  processedData_SVN_academyFeaturesIDF_normalized['SvnAsQuery_devIDF'],\n",
    "                                                  processedData_SVNLogs_academyFeaturesIDF_normalized['SvnLogsAsQuery_avgIDF'],\n",
    "                                                  processedData_SVNLogs_academyFeaturesIDF_normalized['SvnLogsAsQuery_maxIDF'],\n",
    "                                                  processedData_SVNLogs_academyFeaturesIDF_normalized['SvnLogsAsQuery_devIDF'],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesIDF_normalized['SvnUnitNamesAsQuery_avgIDF'],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesIDF_normalized['SvnUnitNamesAsQuery_maxIDF'],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesIDF_normalized['SvnUnitNamesAsQuery_devIDF'],\n",
    "                                                  processedData_JIRA_academyFeaturesIDF_normalized['JiraAsQuery_avgIDF'],\n",
    "                                                  processedData_JIRA_academyFeaturesIDF_normalized['JiraAsQuery_maxIDF'],\n",
    "                                                  processedData_JIRA_academyFeaturesIDF_normalized['JiraAsQuery_devIDF'],  \n",
    "                                                  processedData_JIRASummaries_academyFeaturesIDF_normalized['JiraSummariesAsQuery_avgIDF'],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesIDF_normalized['JiraSummariesAsQuery_maxIDF'],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesIDF_normalized['JiraSummariesAsQuery_devIDF'],  \n",
    "                                                  processedData_JIRADescriptions_academyFeaturesIDF_normalized['JiraDescriptionsAsQuery_avgIDF'],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesIDF_normalized['JiraDescriptionsAsQuery_maxIDF'],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesIDF_normalized['JiraDescriptionsAsQuery_devIDF'],  \n",
    "                                                #  processedData_JIRAComments_academyFeaturesIDF_normalized['JiraCommentsAsQuery_avgIDF'],\n",
    "                                                #  processedData_JIRAComments_academyFeaturesIDF_normalized['JiraCommentsAsQuery_maxIDF'],\n",
    "                                                #  processedData_JIRAComments_academyFeaturesIDF_normalized['JiraCommentsAsQuery_devIDF'],  \n",
    "                                                  \n",
    "                                                  processedData_SVN_academyFeaturesICTF_normalized[\"SvnAsQuery_avgICTF\"],\n",
    "                                                  processedData_SVN_academyFeaturesICTF_normalized[\"SvnAsQuery_maxICTF\"],\n",
    "                                                  processedData_SVN_academyFeaturesICTF_normalized[\"SvnAsQuery_devICTF\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesICTF_normalized[\"SvnLogsAsQuery_avgICTF\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesICTF_normalized[\"SvnLogsAsQuery_maxICTF\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesICTF_normalized[\"SvnLogsAsQuery_devICTF\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesICTF_normalized[\"SvnUnitNamesAsQuery_avgICTF\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesICTF_normalized[\"SvnUnitNamesAsQuery_maxICTF\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesICTF_normalized[\"SvnUnitNamesAsQuery_devICTF\"],\n",
    "                                                  processedData_JIRA_academyFeaturesICTF_normalized[\"JiraAsQuery_avgICTF\"],\n",
    "                                                  processedData_JIRA_academyFeaturesICTF_normalized[\"JiraAsQuery_maxICTF\"],\n",
    "                                                  processedData_JIRA_academyFeaturesICTF_normalized[\"JiraAsQuery_devICTF\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesICTF_normalized[\"JiraSummariesAsQuery_avgICTF\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesICTF_normalized[\"JiraSummariesAsQuery_maxICTF\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesICTF_normalized[\"JiraSummariesAsQuery_devICTF\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesICTF_normalized[\"JiraDescriptionsAsQuery_avgICTF\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesICTF_normalized[\"JiraDescriptionsAsQuery_maxICTF\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesICTF_normalized[\"JiraDescriptionsAsQuery_devICTF\"],\n",
    "                                              #    processedData_JIRAComments_academyFeaturesICTF_normalized[\"JiraCommentsAsQuery_avgICTF\"],\n",
    "                                              #    processedData_JIRAComments_academyFeaturesICTF_normalized[\"JiraCommentsAsQuery_maxICTF\"],\n",
    "                                              #    processedData_JIRAComments_academyFeaturesICTF_normalized[\"JiraCommentsAsQuery_devICTF\"],\n",
    "                                                  \n",
    "                                                  processedData_SVN_academyFeaturesEntropy_normalized[\"SvnAsQuery_avgEntropy\"],\n",
    "                                                  processedData_SVN_academyFeaturesEntropy_normalized[\"SvnAsQuery_medEntropy\"],\n",
    "                                                  processedData_SVN_academyFeaturesEntropy_normalized[\"SvnAsQuery_maxEntropy\"],\n",
    "                                                  processedData_SVN_academyFeaturesEntropy_normalized[\"SvnAsQuery_devEntropy\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesEntropy_normalized[\"SvnLogsAsQuery_avgEntropy\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesEntropy_normalized[\"SvnLogsAsQuery_medEntropy\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesEntropy_normalized[\"SvnLogsAsQuery_maxEntropy\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesEntropy_normalized[\"SvnLogsAsQuery_devEntropy\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesEntropy_normalized[\"SvnUnitNamesAsQuery_avgEntropy\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesEntropy_normalized[\"SvnUnitNamesAsQuery_medEntropy\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesEntropy_normalized[\"SvnUnitNamesAsQuery_maxEntropy\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesEntropy_normalized[\"SvnUnitNamesAsQuery_devEntropy\"],\n",
    "                                                  processedData_JIRA_academyFeaturesEntropy_normalized[\"JiraAsQuery_avgEntropy\"],\n",
    "                                                  processedData_JIRA_academyFeaturesEntropy_normalized[\"JiraAsQuery_medEntropy\"],\n",
    "                                                  processedData_JIRA_academyFeaturesEntropy_normalized[\"JiraAsQuery_maxEntropy\"],\n",
    "                                                  processedData_JIRA_academyFeaturesEntropy_normalized[\"JiraAsQuery_devEntropy\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesEntropy_normalized[\"JiraSummariesAsQuery_avgEntropy\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesEntropy_normalized[\"JiraSummariesAsQuery_medEntropy\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesEntropy_normalized[\"JiraSummariesAsQuery_maxEntropy\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesEntropy_normalized[\"JiraSummariesAsQuery_devEntropy\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesEntropy_normalized[\"JiraDescriptionsAsQuery_avgEntropy\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesEntropy_normalized[\"JiraDescriptionsAsQuery_medEntropy\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesEntropy_normalized[\"JiraDescriptionsAsQuery_maxEntropy\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesEntropy_normalized[\"JiraDescriptionsAsQuery_devEntropy\"],\n",
    "                                               #   processedData_JIRAComments_academyFeaturesEntropy_normalized[\"JiraCommentsAsQuery_avgEntropy\"],\n",
    "                                               #   processedData_JIRAComments_academyFeaturesEntropy_normalized[\"JiraCommentsAsQuery_medEntropy\"],\n",
    "                                               #   processedData_JIRAComments_academyFeaturesEntropy_normalized[\"JiraCommentsAsQuery_maxEntropy\"],\n",
    "                                               #   processedData_JIRAComments_academyFeaturesEntropy_normalized[\"JiraCommentsAsQuery_devEntropy\"],\n",
    "                                                  \n",
    "                                                  processedData_SVN_academyFeaturesQueryScope_normalized,\n",
    "                                                  processedData_SVNLogs_academyFeaturesQueryScope_normalized,\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesQueryScope_normalized,\n",
    "                                                  processedData_JIRA_academyFeaturesQueryScope_normalized,\n",
    "                                                  processedData_JIRASummaries_academyFeaturesQueryScope_normalized,\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesQueryScope_normalized,\n",
    "                                                #  processedData_JIRAComments_academyFeaturesQueryScope_normalized,\n",
    "                                                  \n",
    "                                                  processedData_SVN_academyFeaturesSCS_normalized,\n",
    "                                                  processedData_SVNLogs_academyFeaturesSCS_normalized,\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesSCS_normalized,\n",
    "                                                  processedData_JIRA_academyFeaturesSCS_normalized,\n",
    "                                                  processedData_JIRASummaries_academyFeaturesSCS_normalized,\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesSCS_normalized,\n",
    "                                                #  processedData_JIRAComments_academyFeaturesSCS_normalized,\n",
    "                                                  \n",
    "                                                  processedData_SVN_academyFeaturesSCQ_normalized[\"SvnAsQuery_avgSCQ\"],\n",
    "                                                  processedData_SVN_academyFeaturesSCQ_normalized[\"SvnAsQuery_maxSCQ\"],\n",
    "                                                  processedData_SVN_academyFeaturesSCQ_normalized[\"SvnAsQuery_sumSCQ\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesSCQ_normalized[\"SvnLogsAsQuery_avgSCQ\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesSCQ_normalized[\"SvnLogsAsQuery_maxSCQ\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesSCQ_normalized[\"SvnLogsAsQuery_sumSCQ\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesSCQ_normalized[\"SvnUnitNamesAsQuery_avgSCQ\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesSCQ_normalized[\"SvnUnitNamesAsQuery_maxSCQ\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesSCQ_normalized[\"SvnUnitNamesAsQuery_sumSCQ\"],\n",
    "                                                  processedData_JIRA_academyFeaturesSCQ_normalized[\"JiraAsQuery_avgSCQ\"],\n",
    "                                                  processedData_JIRA_academyFeaturesSCQ_normalized[\"JiraAsQuery_maxSCQ\"],\n",
    "                                                  processedData_JIRA_academyFeaturesSCQ_normalized[\"JiraAsQuery_sumSCQ\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesSCQ_normalized[\"JiraSummariesAsQuery_avgSCQ\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesSCQ_normalized[\"JiraSummariesAsQuery_maxSCQ\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesSCQ_normalized[\"JiraSummariesAsQuery_sumSCQ\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesSCQ_normalized[\"JiraDescriptionsAsQuery_avgSCQ\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesSCQ_normalized[\"JiraDescriptionsAsQuery_maxSCQ\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesSCQ_normalized[\"JiraDescriptionsAsQuery_sumSCQ\"],\n",
    "                                                 # processedData_JIRAComments_academyFeaturesSCQ_normalized[\"JiraCommentsAsQuery_avgSCQ\"],\n",
    "                                                #  processedData_JIRAComments_academyFeaturesSCQ_normalized[\"JiraCommentsAsQuery_maxSCQ\"],\n",
    "                                                #  processedData_JIRAComments_academyFeaturesSCQ_normalized[\"JiraCommentsAsQuery_sumSCQ\"],\n",
    "                                                  \n",
    "                                                  processedData_SVN_academyFeaturesPMI_normalized[\"SvnAsQuery_avgPMI\"],\n",
    "                                                  processedData_SVN_academyFeaturesPMI_normalized[\"SvnAsQuery_maxPMI\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesPMI_normalized[\"SvnLogsAsQuery_avgPMI\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesPMI_normalized[\"SvnLogsAsQuery_maxPMI\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesPMI_normalized[\"SvnUnitNamesAsQuery_avgPMI\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesPMI_normalized[\"SvnUnitNamesAsQuery_maxPMI\"],\n",
    "                                                  processedData_JIRA_academyFeaturesPMI_normalized[\"JiraAsQuery_avgPMI\"],\n",
    "                                                  processedData_JIRA_academyFeaturesPMI_normalized[\"JiraAsQuery_maxPMI\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesPMI_normalized[\"JiraSummariesAsQuery_avgPMI\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesPMI_normalized[\"JiraSummariesAsQuery_maxPMI\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesPMI_normalized[\"JiraDescriptionsAsQuery_avgPMI\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesPMI_normalized[\"JiraDescriptionsAsQuery_maxPMI\"],\n",
    "                                                #  processedData_JIRAComments_academyFeaturesPMI_normalized[\"JiraCommentsAsQuery_avgPMI\"],\n",
    "                                               #   processedData_JIRAComments_academyFeaturesPMI_normalized[\"JiraCommentssAsQuery_maxPMI\"],                                                  \n",
    "                                                 ], axis=1)\n",
    "#Set the NaN to 0\n",
    "processedData_academyFeatures = processedData_academyFeatures.fillna(0)\n",
    "\n",
    "#Saving feature names for later use\n",
    "processedData_academyFeatureNames = list(processedData_academyFeatures.columns)\n",
    "\n",
    "#Transform pandas data frame into numpy arrays\n",
    "processedData_academyFeatures = np.array(processedData_academyFeatures)\n",
    "\n",
    "#Load labels\n",
    "processedData_academyLabels = pd.read_pickle(r'../data/03_processed/processedData_academyLabels.pkl')\n",
    "processedData_academyLabels = np.array(processedData_academyLabels[\"is_valid\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "convertible-devon",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/03_processed/processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-7309e1c31026>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprocessedData_academy_features_VsmUnitNamesUnitNamesAsQuery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'../data/03_processed/processedData_academy_features_VsmUnitNamesUnitNamesAsQuery.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprocessedData_academy_features_VsmVerbPruningUnitNamesJiraAsQuery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'../data/03_processed/processedData_academy_features_VsmVerbPruningUnitNamesJiraAsQuery.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mprocessedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'../data/03_processed/processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mprocessedData_academy_features_VsmSummaryLogsSummaryAsQuery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'../data/03_processed/processedData_academy_features_VsmSummaryLogsSummaryAsQuery.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mprocessedData_academy_features_VsmSummaryLogsLogsAsQuery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'../data/03_processed/processedData_academy_features_VsmSummaryLogsLogsAsQuery.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\pandas\\io\\pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    183\u001b[0m     \"\"\"\n\u001b[0;32m    184\u001b[0m     \u001b[0mexcs_to_catch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m     with get_handle(\n\u001b[0m\u001b[0;32m    186\u001b[0m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python39\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    649\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/03_processed/processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery.pkl'"
     ]
    }
   ],
   "source": [
    "#Load Process-Related Features\n",
    "processedData_academyFeaturesTime = pd.read_pickle(r'../data/03_processed/processedData_academyFeaturesTime.pkl')\n",
    "processedData_academyFeaturesStakeholder = pd.read_pickle(r'../data/03_processed/processedData_academyFeaturesStakeholder.pkl')\n",
    "\n",
    "#Load IR-Related Features - unigram\n",
    "processedData_academy_features_VsmLogsJiraAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmLogsJiraAsQuery.pkl')\n",
    "processedData_academy_features_VsmLogsLogAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmLogsLogAsQuery.pkl')\n",
    "processedData_academy_features_VsmUnitNamesJiraAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmUnitNamesJiraAsQuery.pkl')\n",
    "processedData_academy_features_VsmUnitNamesUnitNamesAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmUnitNamesUnitNamesAsQuery.pkl')\n",
    "processedData_academy_features_VsmVerbPruningUnitNamesJiraAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmVerbPruningUnitNamesJiraAsQuery.pkl')\n",
    "processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery.pkl')\n",
    "processedData_academy_features_VsmSummaryLogsSummaryAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSummaryLogsSummaryAsQuery.pkl')\n",
    "processedData_academy_features_VsmSummaryLogsLogsAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSummaryLogsLogsAsQuery.pkl')\n",
    "processedData_academy_features_VsmSummaryUnitNamesSummaryAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSummaryUnitNamesSummaryAsQuery.pkl')\n",
    "processedData_academy_features_VsmSummaryUnitNamesUnitNamesAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSummaryUnitNamesUnitNamesAsQuery.pkl')\n",
    "processedData_academy_features_VsmSvnJiraJiraAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSvnJiraJiraAsQuery.pkl')\n",
    "processedData_academy_features_VsmSvnJiraSvnAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSvnJiraSvnAsQuery.pkl')\n",
    "processedData_academy_features_VsmSvnSummarySvnAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSvnSummarySvnAsQuery.pkl')\n",
    "processedData_academy_features_VsmSvnSummarySummaryAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSvnSummarySummaryAsQuery.pkl')\n",
    "processedData_academy_features_VsmSvnDescriptionSvnAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSvnDescriptionSvnAsQuery.pkl')\n",
    "processedData_academy_features_VsmSvnDescriptionDescriptionAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSvnDescriptionDescriptionAsQuery.pkl')\n",
    "#processedData_academy_features_VsmSvnCommentsSvnAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSvnCommentsSvnAsQuery.pkl')\n",
    "#processedData_academy_features_VsmSvnCommentsCommentsAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmSvnCommentsCommentsAsQuery.pkl')\n",
    "processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery.pkl')\n",
    "\n",
    "#Load IR-Related Features - bigram\n",
    "processedData_academy_features_VsmLogsJiraAsQuery_2gram = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmLogsJiraAsQuery_2gram.pkl')\n",
    "processedData_academy_features_VsmLogsLogAsQuery_2gram = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmLogsLogAsQuery_2gram.pkl')\n",
    "processedData_academy_features_VsmUnitNamesJiraAsQuery_2gram = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmUnitNamesJiraAsQuery_2gram.pkl')\n",
    "processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_2gram = pd.read_pickle(r'../data/03_processed/processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_2gram.pkl')\n",
    "\n",
    "\n",
    "\n",
    "#Load Document Statistics Features\n",
    "processedData_JIRA_academyFeaturesUniqueWordCount = pd.read_pickle(r\"../data/03_processed/processedData_JIRA_academyFeaturesUniqueWordCount.pkl\")\n",
    "processedData_SVN_academyFeaturesUniqueWordCount = pd.read_pickle(r\"../data/03_processed/processedData_SVN_academyFeaturesUniqueWordCount.pkl\")\n",
    "processedData_JIRA_academyFeaturesTotalWordCount = pd.read_pickle(r\"../data/03_processed/processedData_JIRA_academyFeaturesTotalWordCount.pkl\")\n",
    "processedData_SVN_academyFeaturesTotalWordCount = pd.read_pickle(r\"../data/03_processed/processedData_SVN_academyFeaturesTotalWordCount.pkl\")\n",
    "processedData_JIRA_academyFeaturesOverlapPercentage = pd.read_pickle(r\"../data/03_processed/processedData_JIRA_academyFeaturesOverlapPercentage.pkl\")\n",
    "processedData_SVN_academyFeaturesOverlapPercentage = pd.read_pickle(r\"../data/03_processed/processedData_SVN_academyFeaturesOverlapPercentage.pkl\")\n",
    "processedData_UNION_academyFeaturesOverlapPercentage = pd.read_pickle(r\"../data/03_processed/processedData_UNION_academyFeaturesOverlapPercentage.pkl\")\n",
    "\n",
    "#Load Query Quality Features\n",
    "processedData_academyFeaturesQueryQuality = pd.read_pickle(r'../data/03_processed/processedData_academyFeaturesQueryQuality.pkl')\n",
    "processedData_SVN_academyFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_SVN_academyFeaturesIDF.pkl')\n",
    "processedData_SVNLogs_academyFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_academyFeaturesIDF.pkl')\n",
    "processedData_SVNUnitNames_academyFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_academyFeaturesIDF.pkl')\n",
    "processedData_JIRA_academyFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_JIRA_academyFeaturesIDF.pkl')\n",
    "processedData_JIRASummaries_academyFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_academyFeaturesIDF.pkl')\n",
    "processedData_JIRADescriptions_academyFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_academyFeaturesIDF.pkl')\n",
    "#processedData_JIRAComments_academyFeaturesIDF = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_academyFeaturesIDF.pkl')\n",
    "\n",
    "processedData_SVNLogs_academyFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_academyFeaturesICTF.pkl')\n",
    "processedData_SVNUnitNames_academyFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_academyFeaturesICTF.pkl')\n",
    "processedData_JIRA_academyFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_JIRA_academyFeaturesICTF.pkl')\n",
    "processedData_JIRASummaries_academyFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_academyFeaturesICTF.pkl')\n",
    "processedData_JIRADescriptions_academyFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_academyFeaturesICTF.pkl')\n",
    "#processedData_JIRAComments_academyFeaturesICTF = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_academyFeaturesICTF.pkl')\n",
    "\n",
    "\n",
    "processedData_SVNLogs_academyFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_academyFeaturesEntropy.pkl')\n",
    "processedData_SVNUnitNames_academyFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_academyFeaturesEntropy.pkl')\n",
    "processedData_JIRA_academyFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_JIRA_academyFeaturesEntropy.pkl')\n",
    "processedData_JIRASummaries_academyFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_academyFeaturesEntropy.pkl')\n",
    "processedData_JIRADescriptions_academyFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_academyFeaturesEntropy.pkl')\n",
    "#processedData_JIRAComments_academyFeaturesEntropy = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_academyFeaturesEntropy.pkl')\n",
    "\n",
    "\n",
    "processedData_SVNLogs_academyFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_academyFeaturesQueryScope.pkl')\n",
    "processedData_SVNUnitNames_academyFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_academyFeaturesQueryScope.pkl')\n",
    "processedData_JIRA_academyFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_JIRA_academyFeaturesQueryScope.pkl')\n",
    "processedData_JIRASummaries_academyFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_academyFeaturesQueryScope.pkl')\n",
    "processedData_JIRADescriptions_academyFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_academyFeaturesQueryScope.pkl')\n",
    "#processedData_JIRAComments_academyFeaturesQueryScope = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_academyFeaturesQueryScope.pkl')\n",
    "\n",
    "\n",
    "processedData_SVNLogs_academyFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_academyFeaturesSCS.pkl')\n",
    "processedData_SVNUnitNames_academyFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_academyFeaturesSCS.pkl')\n",
    "processedData_JIRA_academyFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_JIRA_academyFeaturesSCS.pkl')\n",
    "processedData_JIRASummaries_academyFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_academyFeaturesSCS.pkl')\n",
    "processedData_JIRADescriptions_academyFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_academyFeaturesSCS.pkl')\n",
    "#processedData_JIRAComments_academyFeaturesSCS = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_academyFeaturesSCS.pkl')\n",
    "\n",
    "processedData_SVNLogs_academyFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_academyFeaturesSCQ.pkl')\n",
    "processedData_SVNUnitNames_academyFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_academyFeaturesSCQ.pkl')\n",
    "processedData_JIRA_academyFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_JIRA_academyFeaturesSCQ.pkl')\n",
    "processedData_JIRASummaries_academyFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_academyFeaturesSCQ.pkl')\n",
    "processedData_JIRADescriptions_academyFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_academyFeaturesSCQ.pkl')\n",
    "#processedData_JIRAComments_academyFeaturesSCQ = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_academyFeaturesSCQ.pkl')\n",
    "\n",
    "\n",
    "processedData_SVNLogs_academyFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_SVNLogs_academyFeaturesPMI.pkl')\n",
    "processedData_SVNUnitNames_academyFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_SVNUnitNames_academyFeaturesPMI.pkl')\n",
    "processedData_JIRA_academyFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_JIRA_academyFeaturesPMI.pkl')\n",
    "processedData_JIRASummaries_academyFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_JIRASummaries_academyFeaturesPMI.pkl')\n",
    "processedData_JIRADescriptions_academyFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_JIRADescriptions_academyFeaturesPMI.pkl')\n",
    "#processedData_JIRAComments_academyFeaturesPMI = pd.read_pickle(r'../data/03_processed/processedData_JIRAComments_academyFeaturesPMI.pkl')\n",
    "\n",
    "#Merge features into 1 dataframe\n",
    "processedData_academyFeatures = pd.concat([processedData_academyFeaturesTime,\n",
    "                                                  processedData_academyFeaturesStakeholder,\n",
    "                                                  #IR-based\n",
    "                                                  processedData_academy_features_VsmLogsJiraAsQuery,\n",
    "                                                  processedData_academy_features_VsmLogsLogAsQuery,\n",
    "                                                  processedData_academy_features_VsmUnitNamesJiraAsQuery,\n",
    "                                                  processedData_academy_features_VsmUnitNamesUnitNamesAsQuery,\n",
    "                                                 # processedData_academy_features_VsmUnitNamesCommentsCommentsAsQuery,\n",
    "                                                 # processedData_academy_features_VsmUnitNamesCommentsUnitNamesAsQuery,\n",
    "                                                  processedData_academy_features_VsmUnitNamesDescriptionDescriptionAsQuery,\n",
    "                                                  processedData_academy_features_VsmUnitNamesDescriptionUnitNamesAsQuery,\n",
    "                                                  processedData_academy_features_VsmSummaryLogsSummaryAsQuery,\n",
    "                                                  processedData_academy_features_VsmSummaryLogsLogsAsQuery,\n",
    "                                                  processedData_academy_features_VsmSummaryUnitNamesSummaryAsQuery,\n",
    "                                                  processedData_academy_features_VsmSummaryUnitNamesUnitNamesAsQuery,\n",
    "                                                  \n",
    "                                                 # processedData_academy_features_VsmLogsJiraAsQuery_2gram,\n",
    "                                                 # processedData_academy_features_VsmLogsLogAsQuery_2gram,\n",
    "                                                 # processedData_academy_features_VsmUnitNamesJiraAsQuery_2gram,\n",
    "                                                 # processedData_academy_features_VsmUnitNamesUnitNamesAsQuery_2gram,\n",
    "                                                 # processedData_academy_features_VsmVerbPruningUnitNamesJiraAsQuery,\n",
    "                                                 # processedData_academy_features_VsmVerbPruningUnitNamesUnitNamesAsQuery,\n",
    "                                                  processedData_academy_features_VsmSvnJiraJiraAsQuery,\n",
    "                                                  processedData_academy_features_VsmSvnJiraSvnAsQuery,\n",
    "                                                  processedData_academy_features_VsmSvnSummarySvnAsQuery,\n",
    "                                                  processedData_academy_features_VsmSvnSummarySummaryAsQuery,\n",
    "                                                  processedData_academy_features_VsmSvnDescriptionSvnAsQuery,\n",
    "                                                  processedData_academy_features_VsmSvnDescriptionDescriptionAsQuery,\n",
    "                                                #  processedData_academy_features_VsmSvnCommentsSvnAsQuery,\n",
    "                                                #  processedData_academy_features_VsmSvnCommentsCommentsAsQuery,\n",
    "\n",
    "                                                  \n",
    "                                                  #Document Statistics\n",
    "                                                  processedData_JIRA_academyFeaturesUniqueWordCount,\n",
    "                                                  processedData_SVN_academyFeaturesUniqueWordCount,\n",
    "                                                  processedData_JIRA_academyFeaturesTotalWordCount,\n",
    "                                                  processedData_SVN_academyFeaturesTotalWordCount,\n",
    "                                                  processedData_JIRA_academyFeaturesOverlapPercentage,\n",
    "                                                  processedData_SVN_academyFeaturesOverlapPercentage,\n",
    "                                                  processedData_UNION_academyFeaturesOverlapPercentage,\n",
    "                                                 #Query Quality\n",
    "                                                  processedData_SVN_academyFeaturesIDF['SvnAsQuery_avgIDF'],\n",
    "                                                  processedData_SVN_academyFeaturesIDF['SvnAsQuery_maxIDF'],\n",
    "                                                  processedData_SVN_academyFeaturesIDF['SvnAsQuery_devIDF'],\n",
    "                                                  processedData_SVNLogs_academyFeaturesIDF['SvnLogsAsQuery_avgIDF'],\n",
    "                                                  processedData_SVNLogs_academyFeaturesIDF['SvnLogsAsQuery_maxIDF'],\n",
    "                                                  processedData_SVNLogs_academyFeaturesIDF['SvnLogsAsQuery_devIDF'],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesIDF['SvnUnitNamesAsQuery_avgIDF'],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesIDF['SvnUnitNamesAsQuery_maxIDF'],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesIDF['SvnUnitNamesAsQuery_devIDF'],\n",
    "                                                  processedData_JIRA_academyFeaturesIDF['JiraAsQuery_avgIDF'],\n",
    "                                                  processedData_JIRA_academyFeaturesIDF['JiraAsQuery_maxIDF'],\n",
    "                                                  processedData_JIRA_academyFeaturesIDF['JiraAsQuery_devIDF'], \n",
    "                                                  processedData_JIRASummaries_academyFeaturesIDF['JiraSummariesAsQuery_avgIDF'],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesIDF['JiraSummariesAsQuery_maxIDF'],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesIDF['JiraSummariesAsQuery_devIDF'], \n",
    "                                                  processedData_JIRADescriptions_academyFeaturesIDF['JiraDescriptionsAsQuery_avgIDF'],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesIDF['JiraDescriptionsAsQuery_maxIDF'],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesIDF['JiraDescriptionsAsQuery_devIDF'], \n",
    "                                                #  processedData_JIRAComments_academyFeaturesIDF['JiraCommentsAsQuery_avgIDF'],\n",
    "                                               #   processedData_JIRAComments_academyFeaturesIDF['JiraCommentsAsQuery_maxIDF'],\n",
    "                                               #   processedData_JIRAComments_academyFeaturesIDF['JiraCommentsAsQuery_devIDF'], \n",
    "                                                  \n",
    "                                                  processedData_SVN_academyFeaturesICTF[\"SvnAsQuery_avgICTF\"],\n",
    "                                                  processedData_SVN_academyFeaturesICTF[\"SvnAsQuery_maxICTF\"],\n",
    "                                                  processedData_SVN_academyFeaturesICTF[\"SvnAsQuery_devICTF\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesICTF[\"SvnLogsAsQuery_avgICTF\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesICTF[\"SvnLogsAsQuery_maxICTF\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesICTF[\"SvnLogsAsQuery_devICTF\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesICTF[\"SvnUnitNamesAsQuery_avgICTF\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesICTF[\"SvnUnitNamesAsQuery_maxICTF\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesICTF[\"SvnUnitNamesAsQuery_devICTF\"],\n",
    "                                                  processedData_JIRA_academyFeaturesICTF[\"JiraAsQuery_avgICTF\"],\n",
    "                                                  processedData_JIRA_academyFeaturesICTF[\"JiraAsQuery_maxICTF\"],\n",
    "                                                  processedData_JIRA_academyFeaturesICTF[\"JiraAsQuery_devICTF\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesICTF[\"JiraSummariesAsQuery_avgICTF\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesICTF[\"JiraSummariesAsQuery_maxICTF\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesICTF[\"JiraSummariesAsQuery_devICTF\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesICTF[\"JiraDescriptionsAsQuery_avgICTF\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesICTF[\"JiraDescriptionsAsQuery_maxICTF\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesICTF[\"JiraDescriptionsAsQuery_devICTF\"],\n",
    "                                                 # processedData_JIRAComments_academyFeaturesICTF[\"JiraCommentsAsQuery_avgICTF\"],\n",
    "                                                #  processedData_JIRAComments_academyFeaturesICTF[\"JiraCommentsAsQuery_maxICTF\"],\n",
    "                                               #   processedData_JIRAComments_academyFeaturesICTF[\"JiraCommentsAsQuery_devICTF\"],\n",
    "                                                  \n",
    "                                                  processedData_SVN_academyFeaturesEntropy[\"SvnAsQuery_avgEntropy\"],\n",
    "                                                  processedData_SVN_academyFeaturesEntropy[\"SvnAsQuery_medEntropy\"],\n",
    "                                                  processedData_SVN_academyFeaturesEntropy[\"SvnAsQuery_maxEntropy\"],\n",
    "                                                  processedData_SVN_academyFeaturesEntropy[\"SvnAsQuery_devEntropy\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesEntropy[\"SvnLogsAsQuery_avgEntropy\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesEntropy[\"SvnLogsAsQuery_medEntropy\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesEntropy[\"SvnLogsAsQuery_maxEntropy\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesEntropy[\"SvnLogsAsQuery_devEntropy\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesEntropy[\"SvnUnitNamesAsQuery_avgEntropy\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesEntropy[\"SvnUnitNamesAsQuery_medEntropy\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesEntropy[\"SvnUnitNamesAsQuery_maxEntropy\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesEntropy[\"SvnUnitNamesAsQuery_devEntropy\"],\n",
    "                                                  processedData_JIRA_academyFeaturesEntropy[\"JiraAsQuery_avgEntropy\"],\n",
    "                                                  processedData_JIRA_academyFeaturesEntropy[\"JiraAsQuery_medEntropy\"],\n",
    "                                                  processedData_JIRA_academyFeaturesEntropy[\"JiraAsQuery_maxEntropy\"],\n",
    "                                                  processedData_JIRA_academyFeaturesEntropy[\"JiraAsQuery_devEntropy\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesEntropy[\"JiraSummariesAsQuery_avgEntropy\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesEntropy[\"JiraSummariesAsQuery_medEntropy\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesEntropy[\"JiraSummariesAsQuery_maxEntropy\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesEntropy[\"JiraSummariesAsQuery_devEntropy\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesEntropy[\"JiraDescriptionsAsQuery_avgEntropy\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesEntropy[\"JiraDescriptionsAsQuery_medEntropy\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesEntropy[\"JiraDescriptionsAsQuery_maxEntropy\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesEntropy[\"JiraDescriptionsAsQuery_devEntropy\"],\n",
    "                                                #  processedData_JIRAComments_academyFeaturesEntropy[\"JiraCommentsAsQuery_avgEntropy\"],\n",
    "                                                 # processedData_JIRAComments_academyFeaturesEntropy[\"JiraCommentsAsQuery_medEntropy\"],\n",
    "                                                 # processedData_JIRAComments_academyFeaturesEntropy[\"JiraCommentsAsQuery_maxEntropy\"],\n",
    "                                                 # processedData_JIRAComments_academyFeaturesEntropy[\"JiraCommentsAsQuery_devEntropy\"],\n",
    "                                                  \n",
    "                                                  processedData_SVN_academyFeaturesQueryScope,\n",
    "                                                  processedData_SVNLogs_academyFeaturesQueryScope,\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesQueryScope,\n",
    "                                                  processedData_JIRA_academyFeaturesQueryScope,\n",
    "                                                  processedData_JIRASummaries_academyFeaturesQueryScope,\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesQueryScope,\n",
    "                                                #  processedData_JIRAComments_academyFeaturesQueryScope,\n",
    "                                                  \n",
    "                                                  processedData_SVN_academyFeaturesSCS,\n",
    "                                                  processedData_SVNLogs_academyFeaturesSCS,\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesSCS,\n",
    "                                                  processedData_JIRA_academyFeaturesSCS,\n",
    "                                                  processedData_JIRASummaries_academyFeaturesSCS,\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesSCS,\n",
    "                                                 # processedData_JIRAComments_academyFeaturesSCS,\n",
    "                                                  \n",
    "                                                  processedData_SVN_academyFeaturesSCQ[\"SvnAsQuery_avgSCQ\"],\n",
    "                                                  processedData_SVN_academyFeaturesSCQ[\"SvnAsQuery_maxSCQ\"],\n",
    "                                                  processedData_SVN_academyFeaturesSCQ[\"SvnAsQuery_sumSCQ\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesSCQ[\"SvnLogsAsQuery_avgSCQ\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesSCQ[\"SvnLogsAsQuery_maxSCQ\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesSCQ[\"SvnLogsAsQuery_sumSCQ\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesSCQ[\"SvnUnitNamesAsQuery_avgSCQ\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesSCQ[\"SvnUnitNamesAsQuery_maxSCQ\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesSCQ[\"SvnUnitNamesAsQuery_sumSCQ\"],\n",
    "                                                  processedData_JIRA_academyFeaturesSCQ[\"JiraAsQuery_avgSCQ\"],\n",
    "                                                  processedData_JIRA_academyFeaturesSCQ[\"JiraAsQuery_maxSCQ\"],\n",
    "                                                  processedData_JIRA_academyFeaturesSCQ[\"JiraAsQuery_sumSCQ\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesSCQ[\"JiraSummariesAsQuery_avgSCQ\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesSCQ[\"JiraSummariesAsQuery_maxSCQ\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesSCQ[\"JiraSummariesAsQuery_sumSCQ\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesSCQ[\"JiraDescriptionsAsQuery_avgSCQ\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesSCQ[\"JiraDescriptionsAsQuery_maxSCQ\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesSCQ[\"JiraDescriptionsAsQuery_sumSCQ\"],\n",
    "                                                 # processedData_JIRAComments_academyFeaturesSCQ[\"JiraCommentsAsQuery_avgSCQ\"],\n",
    "                                                 # processedData_JIRAComments_academyFeaturesSCQ[\"JiraCommentsAsQuery_maxSCQ\"],\n",
    "                                                 # processedData_JIRAComments_academyFeaturesSCQ[\"JiraCommentsAsQuery_sumSCQ\"],\n",
    "                                                  \n",
    "                                                  processedData_SVN_academyFeaturesPMI[\"SvnAsQuery_avgPMI\"],\n",
    "                                                  processedData_SVN_academyFeaturesPMI[\"SvnAsQuery_maxPMI\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesPMI[\"SvnLogsAsQuery_avgPMI\"],\n",
    "                                                  processedData_SVNLogs_academyFeaturesPMI[\"SvnLogsAsQuery_maxPMI\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesPMI[\"SvnUnitNamesAsQuery_avgPMI\"],\n",
    "                                                  processedData_SVNUnitNames_academyFeaturesPMI[\"SvnUnitNamesAsQuery_maxPMI\"],\n",
    "                                                  processedData_JIRA_academyFeaturesPMI[\"JiraAsQuery_avgPMI\"],\n",
    "                                                  processedData_JIRA_academyFeaturesPMI[\"JiraAsQuery_maxPMI\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesPMI[\"JiraSummariesAsQuery_avgPMI\"],\n",
    "                                                  processedData_JIRASummaries_academyFeaturesPMI[\"JiraSummariesAsQuery_maxPMI\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesPMI[\"JiraDescriptionsAsQuery_avgPMI\"],\n",
    "                                                  processedData_JIRADescriptions_academyFeaturesPMI[\"JiraDescriptionsAsQuery_maxPMI\"],\n",
    "                                                  #processedData_JIRAComments_academyFeaturesPMI[\"JiraCommentsAsQuery_avgPMI\"],\n",
    "                                                  #processedData_JIRAComments_academyFeaturesPMI[\"JiraCommentssAsQuery_maxPMI\"],\n",
    "                                                 ], axis=1)\n",
    "#Set the NaN to 0\n",
    "processedData_academyFeatures = processedData_academyFeatures.fillna(0)\n",
    "\n",
    "#Saving feature names for later use\n",
    "processedData_academyFeatureNames = list(processedData_academyFeatures.columns)\n",
    "\n",
    "#Transform pandas data frame into numpy arrays\n",
    "processedData_academyFeatures = np.array(processedData_academyFeatures)\n",
    "\n",
    "#Load labels\n",
    "processedData_academyLabels = pd.read_pickle(r'../data/03_processed/processedData_academyLabels.pkl')\n",
    "processedData_academyLabels = np.array(processedData_academyLabels[\"is_valid\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-location",
   "metadata": {},
   "source": [
    "# 4. Modeling\n",
    "First select which data set to train:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-reducing",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = processedData_academyFeatures\n",
    "labels = processedData_academyLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(processedData_academyFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-senegal",
   "metadata": {},
   "source": [
    "## 4.1 Create a Test and Training set (OLD, only used for quick testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-meeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "(modelsData_trainFeatures, \n",
    " modelsData_testFeatures, \n",
    " modelsData_trainLabels, \n",
    " modelsData_testLabels) = train_test_split(features,\n",
    "                                           labels,\n",
    "                                           test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-boating",
   "metadata": {},
   "source": [
    "## 4.2 Modeling - Rebalancing the Training set (OLD, only used for quick testing)\n",
    "Select a dataset for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample with SMOTE and random undersample for imbalanced dataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "#Visualise class distribution before rebalancing\n",
    "summariseClassDistribution(modelsData_trainFeatures, \n",
    "                           modelsData_trainLabels)\n",
    "\n",
    "# define pipeline\n",
    "over = SMOTE(sampling_strategy=0.1)\n",
    "under = RandomUnderSampler(sampling_strategy = 0.5)\n",
    "steps = [('o', over),('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "# transform the dataset\n",
    "modelsData_trainFeatures, modelsData_trainLabels = pipeline.fit_resample(modelsData_trainFeatures, modelsData_trainLabels)\n",
    "\n",
    "#Visualise class distribution after rebalancing\n",
    "summariseClassDistribution(modelsData_trainFeatures, \n",
    "                           modelsData_trainLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-louisiana",
   "metadata": {},
   "source": [
    "## 4.3 Modeling - Random Forest (OLD, only used for quick testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate model with 100 decision trees\n",
    "rf = RandomForestClassifier(n_estimators = 1000, n_jobs=-1)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(modelsData_trainFeatures, modelsData_trainLabels.astype(bool));\n",
    "\n",
    "#Display the model performance    \n",
    "showModelPerformance(trainedModel = rf, \n",
    "                     testFeatures = modelsData_testFeatures, \n",
    "                     testLabels = modelsData_testLabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "start_time = time.time()\n",
    "importances = rf.feature_importances_\n",
    "std = np.std([\n",
    "    tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Elapsed time to compute the importances: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "forest_importances = pd.Series(importances, index=[processedData_academyFeatureNames])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-intellectual",
   "metadata": {},
   "source": [
    "## 4.4 Modeling - XGBoost (OLD, only used for quick testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Instantiate xgboost\n",
    "GXBoost = xgb.XGBClassifier(#scale_pos_weight=1,\n",
    "                            learning_rate=0.17,\n",
    "                            colsample_bytree = 0.4,\n",
    "                            subsample = 1.0,\n",
    "                            objective='binary:logistic',\n",
    "                            n_estimators=750,\n",
    "                            max_depth=12,\n",
    "                            gamma=0.03,\n",
    "                            n_jobs=-1\n",
    "                           # seed=27\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Train the model on training data\n",
    "GXBoost.fit(modelsData_trainFeatures, modelsData_trainLabels);\n",
    "\n",
    "#Display the model performance    \n",
    "showModelPerformance(trainedModel = GXBoost, \n",
    "                     testFeatures = modelsData_testFeatures, \n",
    "                     testLabels = modelsData_testLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-marsh",
   "metadata": {},
   "source": [
    "# OLD Model Pipeline - Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-tenant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Import the model we are using\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Instantiate Light GBM\n",
    "LightGBM_Model = lgb.LGBMClassifier(n_jobs=-1, n_estimators = 3400, max_depth = 25)                         \n",
    "\n",
    "# Train the model on training data\n",
    "LightGBM_Model.fit(modelsData_trainFeatures, modelsData_trainLabels);\n",
    "\n",
    "#Display the model performance    \n",
    "showModelPerformance(trainedModel = LightGBM_Model, \n",
    "                     testFeatures = modelsData_testFeatures, \n",
    "                     testLabels = modelsData_testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-store",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-immune",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-burton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "nasty-robertson",
   "metadata": {},
   "source": [
    "# Model - Pipeline for GXBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "GXBoostPipeline = Pipeline(steps = [#['smote', SMOTE(sampling_strategy = 0.1, n_jobs=2)],\n",
    "                                    #['under', RandomUnderSampler(sampling_strategy = 0.5)],\n",
    "                                ['classifier', xgb.XGBClassifier(n_jobs=2)]])\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5,shuffle=True)\n",
    "\n",
    "# define search space\n",
    "space = dict()\n",
    "space['classifier__n_estimators'] = [450, 500, 550, 600, 650, 700, 750, 800, 850, 900]\n",
    "space['classifier__max_depth'] = [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "space['classifier__subsample'] = [0.7, 0.8, 0.9, 1.0]\n",
    "space['classifier__learning_rate'] = [0.17, 0.18, 0.19, 0.2]\n",
    "space['classifier__colsample_bytree'] = [0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "space['classifier__gamma'] = [0.01, 0.02, 0.03, 0.04, 0.05]\n",
    "\n",
    "GXBoostSearch = RandomizedSearchCV(estimator = GXBoostPipeline, \n",
    "                            param_distributions=space, \n",
    "                            n_iter=100, \n",
    "                            scoring='f1', \n",
    "                            n_jobs=2, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "optimizedGXBoostModel = GXBoostSearch.fit(X_train, y_train)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = optimizedGXBoostModel.best_score_\n",
    "test_score = optimizedGXBoostModel.score(X_test, y_test)\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "print('Best Hyperparameters: %s' % optimizedGXBoostModel.best_params_)\n",
    "\n",
    "\n",
    "#Display the model performance    \n",
    "showModelPerformance(trainedModel = optimizedGXBoostModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-bangladesh",
   "metadata": {},
   "source": [
    "# Model - Pipeline for Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-communication",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps = [['smote', SMOTE(sampling_strategy=0.1, n_jobs=2)],\n",
    "                             ['under', RandomUnderSampler(sampling_strategy = 0.5)],\n",
    "                                ['classifier', RandomForestClassifier(n_jobs=2)]])\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5,shuffle=True)\n",
    "\n",
    "# define search space\n",
    "space = dict() \n",
    "space['classifier__n_estimators'] = [1000, 1100, 1200, 1300, 1400]\n",
    "space['classifier__max_depth'] = [9, 10, 11, 12, 14, 15, 16]\n",
    "space['classifier__min_samples_split'] = [1, 2, 3]\n",
    "\n",
    "\n",
    "search = RandomizedSearchCV(estimator = pipeline, \n",
    "                            param_distributions=space, \n",
    "                            n_iter=100, \n",
    "                            scoring='f1', \n",
    "                            n_jobs=2, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "optimizedRFModel = search.fit(X_train, y_train)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = optimizedRFModel.best_score_\n",
    "test_score = optimizedRFModel.score(X_test, y_test)\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "print('Best Hyperparameters: %s' % optimizedRFModel.best_params_)\n",
    "\n",
    "\n",
    "#Display the model performance    \n",
    "showModelPerformance(trainedModel = optimizedRFModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-sherman",
   "metadata": {},
   "source": [
    "# Model - Pipeline for Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "\n",
    "#Import feature selection stuff\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\n",
    "\n",
    "# Import the model we are using\n",
    "import lightgbm as lgb\n",
    "\n",
    "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "start_time = time.time()\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=labels)\n",
    "\n",
    "\n",
    "LightGBMPipeline = Pipeline(steps = [#['smote', SMOTE(sampling_strategy = 0.1, n_jobs=2)],\n",
    "                                    #['under', RandomUnderSampler(sampling_strategy = 0.5)],\n",
    "                                ['classifier', lgb.LGBMClassifier(n_jobs=2)]])\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5,shuffle=True)\n",
    "\n",
    "# define search space\n",
    "space = dict()\n",
    "space['classifier__num_leaves'] = [60, 70, 80, 90, 100]\n",
    "space['classifier__max_depth'] = [5, 6, 7, 8]\n",
    "space['classifier__min_data_in_leaf'] = [250, 500, 750, 1000, 1250, 1500]\n",
    "\n",
    "\n",
    "LightGBMSearch = RandomizedSearchCV(estimator = LightGBMPipeline, \n",
    "                            param_distributions=space, \n",
    "                            n_iter=100, \n",
    "                            scoring= ftwo_scorer, \n",
    "                            n_jobs=2, \n",
    "                            cv = stratified_kfold)\n",
    "\n",
    "optimizedLightGBMModel = LightGBMSearch.fit(X_train, y_train)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Elapsed time to compute best fit: \"\n",
    "      f\"{elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = optimizedLightGBMModel.best_score_\n",
    "test_score = optimizedLightGBMModel.score(X_test, y_test)\n",
    "print(f'Cross-validation score: {cv_score}\\nTest score: {test_score}')\n",
    "print('Best Hyperparameters: %s' % optimizedLightGBMModel.best_params_)\n",
    "\n",
    "\n",
    "#Display the model performance    \n",
    "showModelPerformance(trainedModel = optimizedLightGBMModel, \n",
    "                     testFeatures = X_test, \n",
    "                     testLabels = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-meditation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-picnic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
