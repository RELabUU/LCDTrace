{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mrmr import mrmr_classif\n",
    "\n",
    "import operator\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import heapq\n",
    "\n",
    "#Import self-written functions\n",
    "import os\n",
    "import sys\n",
    "src_dir = os.path.join(os.getcwd(), '..', 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from d04_model_evaluation.model_evaluation import *\n",
    "\n",
    "'''\n",
    "Parameters to configure\n",
    "'''\n",
    "\n",
    "#set dataset\n",
    "dataset = 'example'\n",
    "\n",
    "# Set the number of evaluation rounds that must be performed.\n",
    "n_runs = 10\n",
    "\n",
    "# Set number of items to return in list for top-n feature importance\n",
    "top_n = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get processed feature data\n",
    "features_all_df = pd.read_excel(f'../results/1. Trace Link Feature Data/features_non-normalized.xlsx')\n",
    "\n",
    "#Load label dataframe\n",
    "labels_df = pd.read_pickle(r'../data/03_processed/labels_df.pkl')\n",
    "#print(labels_df)\n",
    "\n",
    "# Encode Bool values of label to integers\n",
    "features_all_df['is_valid'] = labels_df['is_valid']\n",
    "features_all_df['is_valid'] = labels_df['is_valid'].values\n",
    "features_all_df['is_valid'] = features_all_df['is_valid'].astype(int)\n",
    "\n",
    "#Set the NaN to 0\n",
    "features_all_df = features_all_df.fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start MRMR feature selection for 40 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split\n",
    "X = features_all_df.drop(['is_valid'], axis=1)\n",
    "y = features_all_df['is_valid']\n",
    "K_features = 40\n",
    "\n",
    "selected_features = mrmr_classif(X, y, K = 40)\n",
    "\n",
    "# create subset of original dataframe on output of selection process\n",
    "feature_subset_df = features_all_df[selected_features]\n",
    "\n",
    "# Export subset of features as .xslx file\n",
    "feature_subset_df.to_excel(excel_writer = f\"../results/5. Feature selection subsets/{dataset}_subset_K{K_features}.xlsx\", index = False)\n",
    "\n",
    "file = open(f\"../results/5. Feature selection subsets/{dataset}_K{K_features}_selected_features.txt\", \"w\")\n",
    "for feature in selected_features:\n",
    "    file.write(feature + \"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform additonal processing to prepare for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get number of features to pass to importance_array (model_evalution.py)\n",
    "n_features_df = feature_subset_df.shape[1]\n",
    "\n",
    "#Saving feature names\n",
    "feature_name_df = list(feature_subset_df.columns)\n",
    "\n",
    "#Transform pandas dataframe into numpy arrays\n",
    "features_all_array = np.array(feature_subset_df)\n",
    "labels_array = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation for K = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['algorithm', 'Rebalancing', 'K (#features)', 'Accuracy', 'Precision', 'Recall', 'F1', 'F2', 'F0.5', 'Average Precision'])\n",
    "\n",
    "df_columns = ['algorithm'] + ['Rebalancing'] + ['K (#features)'] + feature_name_df\n",
    "importance_df_40 = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "feature_results, feature_importance = generate_evaluation_metrics(rebalancing_strategy = 'none', \n",
    "                                                                classification_algorithm = 'xg_boost', \n",
    "                                                                data = features_all_array, \n",
    "                                                                labels = labels_array, \n",
    "                                                                feature_names = feature_name_df,\n",
    "                                                                is_normalized = False,\n",
    "                                                                n_runs = n_runs,\n",
    "                                                                n_features = n_features_df,\n",
    "                                                                K_features = K_features)\n",
    "\n",
    "# Get averages of evaluation\n",
    "temp_list = feature_results.mean(axis=0)\n",
    "temp_list = temp_list.reset_index(drop=True)\n",
    "temp_list = temp_list.tolist()\n",
    "temp_list = ['xgboost'] + ['none'] + ['40'] + temp_list\n",
    "results_df.loc[len(results_df)] = temp_list\n",
    "\n",
    "results_df.loc[len(results_df)] = ['std below'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std']\n",
    "\n",
    "#Standard deviation\n",
    "temp_list = feature_results[['Accuracy', 'Precision', 'Recall', 'F1', 'F2', 'F0.5', 'Average Precision']].std()\n",
    "temp_list = temp_list.reset_index(drop=True)\n",
    "temp_list = temp_list.tolist()\n",
    "temp_list = ['xgboost'] + ['none'] + ['40'] + temp_list\n",
    "results_df.loc[len(results_df)] = temp_list\n",
    "\n",
    "temp_list = feature_importance.mean(axis=0)\n",
    "temp_list = temp_list.reset_index(drop=True)\n",
    "temp_list = temp_list.tolist()\n",
    "temp_list = ['xgboost'] + ['none'] + ['40'] + temp_list\n",
    "importance_df_40.loc[len(importance_df_40)] = temp_list\n",
    "\n",
    "feature_results, feature_importance = generate_evaluation_metrics(rebalancing_strategy = '5050', \n",
    "                                                                classification_algorithm = 'light_gbm', \n",
    "                                                                data = features_all_array, \n",
    "                                                                labels = labels_array, \n",
    "                                                                feature_names = feature_name_df,\n",
    "                                                                is_normalized = False,\n",
    "                                                                n_runs = n_runs,\n",
    "                                                                n_features = n_features_df,\n",
    "                                                                K_features = K_features)\n",
    "\n",
    "# Get averages of evaluation\n",
    "temp_list = feature_results.mean(axis=0)\n",
    "temp_list = temp_list.reset_index(drop=True)\n",
    "temp_list = temp_list.tolist()\n",
    "temp_list = ['lightgbm'] + ['5050'] + ['40'] + temp_list\n",
    "results_df.loc[len(results_df)] = temp_list\n",
    "\n",
    "results_df.loc[len(results_df)] = ['std below'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std']\n",
    "\n",
    "#Standard deviation\n",
    "temp_list = feature_results[['Accuracy', 'Precision', 'Recall', 'F1', 'F2', 'F0.5', 'Average Precision']].std()\n",
    "temp_list = temp_list.reset_index(drop=True)\n",
    "temp_list = temp_list.tolist()\n",
    "temp_list = ['lightgbm'] + ['5050'] + ['40'] + temp_list\n",
    "results_df.loc[len(results_df)] = temp_list\n",
    "\n",
    "temp_list = feature_importance.mean(axis=0)\n",
    "temp_list = temp_list.reset_index(drop=True)\n",
    "temp_list = temp_list.tolist()\n",
    "temp_list = ['lightgbm'] + ['5050'] + ['40'] + temp_list\n",
    "importance_df_40.loc[len(importance_df_40)] = temp_list\n",
    "\n",
    "importance_df_40.to_excel(excel_writer = f\"../results/5. Feature selection subsets/{dataset}_importance_subset_K40.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation for K = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split\n",
    "X = features_all_df.drop(['is_valid'], axis=1)\n",
    "y = features_all_df['is_valid']\n",
    "K_features = 50\n",
    "\n",
    "selected_features = mrmr_classif(X, y, K = 50)\n",
    "\n",
    "# create subset of original dataframe on output of selection process\n",
    "feature_subset_df = features_all_df[selected_features]\n",
    "\n",
    "# Export subset of features as .xslx file\n",
    "feature_subset_df.to_excel(excel_writer = f\"../results/5. Feature selection subsets/{dataset}_subset_K{K_features}.xlsx\", index = False)\n",
    "\n",
    "file = open(f\"../results/5. Feature selection subsets/{dataset}_K{K_features}_selected_features.txt\", \"w\")\n",
    "for feature in selected_features:\n",
    "    file.write(feature + \"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get number of features to pass to importance_array (model_evalution.py)\n",
    "n_features_df = feature_subset_df.shape[1]\n",
    "\n",
    "#Saving feature names\n",
    "feature_name_df = list(feature_subset_df.columns)\n",
    "\n",
    "#Transform pandas dataframe into numpy arrays\n",
    "features_all_array = np.array(feature_subset_df)\n",
    "labels_array = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_columns = ['algorithm'] + ['Rebalancing'] + ['K (#features)'] + feature_name_df\n",
    "importance_df_50 = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "feature_results, feature_importance = generate_evaluation_metrics(rebalancing_strategy = 'none', \n",
    "                                                                classification_algorithm = 'xg_boost', \n",
    "                                                                data = features_all_array, \n",
    "                                                                labels = labels_array, \n",
    "                                                                feature_names = feature_name_df,\n",
    "                                                                is_normalized = False,\n",
    "                                                                n_runs = n_runs,\n",
    "                                                                n_features = n_features_df,\n",
    "                                                                K_features = K_features)\n",
    "\n",
    "# Get averages of evaluation\n",
    "temp_list = feature_results.mean(axis=0)\n",
    "temp_list = temp_list.reset_index(drop=True)\n",
    "temp_list = temp_list.tolist()\n",
    "temp_list = ['xgboost'] + ['none'] + ['50'] + temp_list\n",
    "results_df.loc[len(results_df)] = temp_list\n",
    "\n",
    "results_df.loc[len(results_df)] = ['std below'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std']\n",
    "\n",
    "#Standard deviation\n",
    "temp_list = feature_results[['Accuracy', 'Precision', 'Recall', 'F1', 'F2', 'F0.5', 'Average Precision']].std()\n",
    "temp_list = temp_list.reset_index(drop=True)\n",
    "temp_list = temp_list.tolist()\n",
    "temp_list = ['xgboost'] + ['none'] + ['50'] + temp_list\n",
    "results_df.loc[len(results_df)] = temp_list\n",
    "\n",
    "temp_list = feature_importance.mean(axis=0)\n",
    "temp_list = temp_list.reset_index(drop=True)\n",
    "temp_list = temp_list.tolist()\n",
    "temp_list = ['xgboost'] + ['none'] + ['50'] + temp_list\n",
    "importance_df_50.loc[len(importance_df_50)] = temp_list\n",
    "\n",
    "feature_results, feature_importance = generate_evaluation_metrics(rebalancing_strategy = '5050', \n",
    "                                                                classification_algorithm = 'light_gbm', \n",
    "                                                                data = features_all_array, \n",
    "                                                                labels = labels_array, \n",
    "                                                                feature_names = feature_name_df,\n",
    "                                                                is_normalized = False,\n",
    "                                                                n_runs = n_runs,\n",
    "                                                                n_features = n_features_df,\n",
    "                                                                K_features = K_features)\n",
    "\n",
    "# Get averages of evaluation\n",
    "temp_list = feature_results.mean(axis=0)\n",
    "temp_list = temp_list.reset_index(drop=True)\n",
    "temp_list = temp_list.tolist()\n",
    "temp_list = ['lightgbm'] + ['5050'] + ['50'] + temp_list\n",
    "results_df.loc[len(results_df)] = temp_list\n",
    "\n",
    "results_df.loc[len(results_df)] = ['std below'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std']\n",
    "\n",
    "#Standard deviation\n",
    "temp_list = feature_results[['Accuracy', 'Precision', 'Recall', 'F1', 'F2', 'F0.5', 'Average Precision']].std()\n",
    "temp_list = temp_list.reset_index(drop=True)\n",
    "temp_list = temp_list.tolist()\n",
    "temp_list = ['lightgbm'] + ['5050'] + ['50'] + temp_list\n",
    "results_df.loc[len(results_df)] = temp_list\n",
    "\n",
    "temp_list = feature_importance.mean(axis=0)\n",
    "temp_list = temp_list.reset_index(drop=True)\n",
    "temp_list = temp_list.tolist()\n",
    "temp_list = ['lightgbm'] + ['5050'] + ['50'] + temp_list\n",
    "importance_df_50.loc[len(importance_df_50)] = temp_list\n",
    "\n",
    "importance_df_50.to_excel(excel_writer = f\"../results/5. Feature selection subsets/{dataset}_importance_subset_K50.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation for K = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split\n",
    "X = features_all_df.drop(['is_valid'], axis=1)\n",
    "y = features_all_df['is_valid']\n",
    "K_features = 60\n",
    "\n",
    "selected_features = mrmr_classif(X, y, K = 60)\n",
    "\n",
    "# create subset of original dataframe on output of selection process\n",
    "feature_subset_df = features_all_df[selected_features]\n",
    "\n",
    "# Export subset of features as .xslx file\n",
    "feature_subset_df.to_excel(excel_writer = f\"../results/5. Feature selection subsets/{dataset}_subset_K{K_features}.xlsx\", index = False)\n",
    "\n",
    "file = open(f\"../results/5. Feature selection subsets/{dataset}_K{K_features}_selected_features.txt\", \"w\")\n",
    "for feature in selected_features:\n",
    "    file.write(feature + \"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get number of features to pass to importance_array (model_evalution.py)\n",
    "n_features_df = feature_subset_df.shape[1]\n",
    "\n",
    "#Saving feature names\n",
    "feature_name_df = list(feature_subset_df.columns)\n",
    "\n",
    "#Transform pandas dataframe into numpy arrays\n",
    "features_all_array = np.array(feature_subset_df)\n",
    "labels_array = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_columns = ['algorithm'] + ['Rebalancing'] + ['K (#features)'] + feature_name_df\n",
    "importance_df_60 = pd.DataFrame(columns=df_columns)\n",
    "\n",
    "feature_results, feature_importance = generate_evaluation_metrics(rebalancing_strategy = 'none', \n",
    "                                                                classification_algorithm = 'xg_boost', \n",
    "                                                                data = features_all_array, \n",
    "                                                                labels = labels_array, \n",
    "                                                                feature_names = feature_name_df,\n",
    "                                                                is_normalized = False,\n",
    "                                                                n_runs = n_runs,\n",
    "                                                                n_features = n_features_df,\n",
    "                                                                K_features = K_features)\n",
    "\n",
    "# Get averages of evaluation\n",
    "temp_list = feature_results.mean(axis=0)\n",
    "temp_list = temp_list.reset_index(drop=True)\n",
    "temp_list = temp_list.tolist()\n",
    "temp_list = ['xgboost'] + ['none'] + ['60'] + temp_list\n",
    "results_df.loc[len(results_df)] = temp_list\n",
    "\n",
    "results_df.loc[len(results_df)] = ['std below'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std']\n",
    "\n",
    "#Standard deviation\n",
    "temp_list = feature_results[['Accuracy', 'Precision', 'Recall', 'F1', 'F2', 'F0.5', 'Average Precision']].std()\n",
    "temp_list = temp_list.reset_index(drop=True)\n",
    "temp_list = temp_list.tolist()\n",
    "temp_list = ['xgboost'] + ['none'] + ['50'] + temp_list\n",
    "results_df.loc[len(results_df)] = temp_list\n",
    "\n",
    "temp_list = feature_importance.mean(axis=0)\n",
    "temp_list = temp_list.reset_index(drop=True)\n",
    "temp_list = temp_list.tolist()\n",
    "temp_list = ['xgboost'] + ['none'] + ['60'] + temp_list\n",
    "importance_df_60.loc[len(importance_df_60)] = temp_list\n",
    "\n",
    "feature_results, feature_importance = generate_evaluation_metrics(rebalancing_strategy = '5050', \n",
    "                                                                classification_algorithm = 'light_gbm', \n",
    "                                                                data = features_all_array, \n",
    "                                                                labels = labels_array, \n",
    "                                                                feature_names = feature_name_df,\n",
    "                                                                is_normalized = False,\n",
    "                                                                n_runs = n_runs,\n",
    "                                                                n_features = n_features_df,\n",
    "                                                                K_features = K_features)\n",
    "\n",
    "# Get averages of evaluation\n",
    "temp_list = feature_results.mean(axis=0)\n",
    "temp_list = temp_list.reset_index(drop=True)\n",
    "temp_list = temp_list.tolist()\n",
    "temp_list = ['lightgbm'] + ['505'] + ['60'] + temp_list\n",
    "results_df.loc[len(results_df)] = temp_list\n",
    "\n",
    "results_df.loc[len(results_df)] = ['std below'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std'] + ['std']\n",
    "\n",
    "#Standard deviation\n",
    "temp_list = feature_results[['Accuracy', 'Precision', 'Recall', 'F1', 'F2', 'F0.5', 'Average Precision']].std()\n",
    "temp_list = temp_list.reset_index(drop=True)\n",
    "temp_list = temp_list.tolist()\n",
    "temp_list = ['lightgbm'] + ['5050'] + ['60'] + temp_list\n",
    "results_df.loc[len(results_df)] = temp_list\n",
    "\n",
    "temp_list = feature_importance.mean(axis=0)\n",
    "temp_list = temp_list.reset_index(drop=True)\n",
    "temp_list = temp_list.tolist()\n",
    "temp_list = ['lightgbm'] + ['5050'] + ['60'] + temp_list\n",
    "importance_df_60.loc[len(importance_df_60)] = temp_list\n",
    "\n",
    "importance_df_60.to_excel(excel_writer = f\"../results/5. Feature selection subsets/{dataset}_importance_subset_K60.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results of all runs together \n",
    "results_df.to_excel(excel_writer = f\"../results/5. Feature selection subsets/{dataset}_results_subset_K40_50_60.xlsx\", index = False)\n",
    "\n",
    "# Create top-10 file for feature importance\n",
    "importance_dfs = [importance_df_40, importance_df_50, importance_df_60]\n",
    "feature_importance = []\n",
    "\n",
    "for df_iteration in importance_dfs:\n",
    "    for row in df_iteration.itertuples():\n",
    "        row_local = list(row[4:])\n",
    "        top = heapq.nlargest(top_n, row_local)\n",
    "        feature_list = [row[1], row[2], row[3]]\n",
    "        for item in top:\n",
    "            index = row_local.index(item)\n",
    "            feature = df_iteration.columns[(index+3)]\n",
    "            feature_value = feature, item\n",
    "            feature_list.append(feature)\n",
    "            feature_list.append(item)\n",
    "        feature_importance.append(feature_list)\n",
    "\n",
    "feature_importance = pd.DataFrame(columns=['algorithm', 'balancing', 'K (#features)', '1', '1', '2', '2', '3', '3', '4', '4', '5', '5', '6', '6', '7', '7',' 8', '8', '9', '9', '10', '10'], data=feature_importance)\n",
    "feature_importance.to_excel(excel_writer= f\"../results/5. Feature selection subsets/{dataset}_feature_importance_top{top_n}_K40_50_60.xlsx\", index=False)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
