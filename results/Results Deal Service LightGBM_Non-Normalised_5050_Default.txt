Elapsed time to compute best fit: 57.708 seconds
Cross-validation score: 0.7105545080393222
Test score: 0.695364238410596
Best Hyperparameters: {}
1691.7539567947388
149979.2234814167
235673.1645128727
17426.596057772636
20713.711691737175
1474.9093775749207
104.73658895492554
552.333168387413
195.56883919239044
218.21107053756714
79.17222905158997
9.556679487228394
5615.988167285919
4357.139918804169
1581.1393331289291
0.0
1048.298981308937
0.0
143.5350602865219
52.05576980113983
9985.03824287653
543.0825569629669
11760.300513803959
68.83529007434845
196.59412944316864
61.62102007865906
96.10984945297241
116.98661983013153
3.1470799446105957
322.88509368896484
138.16284132003784
2246.6810250282288
8.066690444946289
78.33614444732666
38.19696021080017
2707.1454278230667
276.89971113204956
11.626759767532349
46.5734703540802
490.68151718378067
219.88128465414047
0.0
0.0
0.0
285.31105971336365
134.00525307655334
676.1053062677383
425.325630903244
476.9174426794052
447.86490213871
161.33931064605713
167.77821099758148
248.29450857639313
1208.1360968351364
0.0
27.16816020011902
0.0
0.0
0.0
1067.4315209388733
61.452298521995544
212.59631037712097
20.4102201461792
436.11464834213257
154.7737786769867
55.9269700050354
2394.271385848522
439.1353268623352
1206.704994916916
323.3020474910736
1018.7175028324127
86.08385062217712
79.67676949501038
105.94435238838196
127.62463998794556
84.87627935409546
1430.800929427147
443.2063157558441
39.65188014507294
1542.668217420578
97.0293298959732
103.65433943271637
44.7484917640686
1956.7331874370575
156.66697311401367
25.350380182266235
189.61434054374695
37.62738037109375
34.51414942741394
8.833728194236755
484.3530601263046
422.3930160999298
186.43421983718872
127.48382043838501
659.1933337450027
199.60997104644775
156.72082018852234
1087.268299818039
715.1874579191208
121.48480367660522
88.56070923805237
163.78100967407227
1240.95729970932
688.8029568195343
48.87003993988037
1322.727420449257
483.8149936199188
1736.1089409589767
77.9275598526001
828.1679493188858
538.4366507530212
904.3561429977417
118.56719970703125
63.997158885002136
10.218465089797974
506.67909371852875
210.74792194366455
0.0
882.2757044434547
8.440459966659546
217.3902304172516
0.0
162.13955903053284
421.1117238998413
0.0
171.4277623295784
334.76421761512756
0.0
189.98734843730927
1341.1691331863403
0.0
659.0250779390335
598.4440685510635
0.0
417.69427967071533
77.28605997562408
0.0
185.8504981994629
1599.6653944253922
0.0
78.79641020298004
129.92896020412445
581.1226187944412
299.0840117931366
213.42376935482025
101.56567919254303
3197.540826201439
1.8187099695205688
263.6263291835785
1409.297649383545
797.1081014871597
125.41898226737976
536.1184283494949
177.4171814918518
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision  Recall        F1        F2      F0.5  \
0  0.995798   0.538462    0.75  0.626866  0.695364  0.570652   

   Average Precision  
0           0.405023  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 57.495 seconds
Cross-validation score: 0.7218880870249123
Test score: 0.6969026548672568
Best Hyperparameters: {}
2174.511864066124
155867.5346056223
239596.66904515028
11963.614994049072
23466.40185403824
439.8442796468735
469.0916180610657
185.3794708251953
90.53212022781372
660.9011075496674
65.80926132202148
98.74294948577881
3883.8045266866684
1248.1709727048874
2486.0544461011887
0.0
754.6707601547241
0.0
111.5080007314682
31.634790539741516
9410.61790406704
522.7937816381454
7690.994915485382
430.63426399230957
51.917970418930054
16.395419597625732
34.5799103975296
81.37167060375214
32.84097909927368
496.7848584651947
32.31057095527649
702.773405790329
44.300668835639954
88.38839149475098
126.49478995800018
4318.399467587471
444.0559091567993
58.3497793674469
125.29452192783356
180.2981995344162
173.85185885429382
0.0
0.0
0.0
1093.523449420929
26.910500049591064
966.5003782510757
830.9402378797531
734.1451638936996
338.8779274225235
45.703529477119446
240.6239891052246
233.7950780391693
684.1285875439644
9.572790145874023
308.04672026634216
0.0
0.0
0.0
246.09186935424805
461.37297773361206
126.6185108423233
1.5258899927139282
259.0425102710724
109.32918906211853
8.380690097808838
125.36667132377625
213.88667356967926
1379.7789483070374
306.7275608778
154.0844211578369
225.44276022911072
27.67676019668579
140.5940066576004
2.476050019264221
341.82824659347534
1722.5921468734741
224.39944553375244
537.9407546520233
1089.8177205324173
68.078289270401
583.3067433834076
542.0214049816132
1065.891606092453
54.540279507637024
44.75862121582031
181.1535085439682
212.8269374370575
123.69426155090332
385.27926391363144
310.7965202331543
822.490859746933
130.86104941368103
317.83973145484924
584.8265696763992
806.1667408943176
1601.3405525684357
2055.9482481479645
318.04127156734467
51.018359661102295
350.4854497909546
267.98887753486633
1596.2471597194672
583.7077493667603
4.69566011428833
936.9441752433777
327.1368900537491
231.63226997852325
3111.6524287462234
835.0346647500992
1020.6874885559082
821.7511557340622
87.7952024936676
482.4164949655533
10.405120134353638
152.5909788608551
202.05725598335266
23.516309142112732
763.301292359829
15.5864896774292
77.43230068683624
0.0
428.4001976251602
801.8561065196991
0.0
50.593849897384644
211.99724566936493
0.0
144.11319935321808
1570.4781875610352
0.0
1876.199269413948
495.9385529756546
0.0
114.59608960151672
29.18476104736328
0.0
21.957700729370117
569.5762310028076
0.0
409.7661734819412
26.89861023426056
560.440243780613
50.8650598526001
171.5903822183609
113.61729216575623
4078.8298890590668
55.270649433135986
259.81505012512207
252.67441952228546
199.0150318145752
17.406450271606445
346.35721266269684
135.9133585691452
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision  Recall    F1        F2      F0.5  Average Precision
0  0.995854   0.543103    0.75  0.63  0.696903  0.574818           0.408504

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 53.011 seconds
Cross-validation score: 0.7054845174519475
Test score: 0.689655172413793
Best Hyperparameters: {}
2544.2495020627975
133422.76651024818
271972.73600780964
17670.988169431686
11241.41204071045
137.98440217971802
27.008159637451172
180.5853898525238
242.02332985401154
99.1354593038559
410.361319065094
55.23150062561035
8558.998079657555
4887.947501301765
1585.8926485776901
0.0
1177.098328948021
0.0
113.79557991027832
116.19248068332672
8700.525521874428
2076.538803458214
3059.000978946686
3467.426135778427
280.708562374115
70.12145972251892
631.8256102800369
50.69515907764435
56.0807991027832
377.8910734653473
149.5400184392929
15.82463026046753
479.02192890644073
199.63015115261078
422.5843015909195
537.9330712556839
162.154430270195
154.77565360069275
64.77692937850952
422.1628489494324
73.81614995002747
0.0
0.0
0.0
284.2253096103668
86.57578098773956
540.1052485704422
533.1520110368729
605.5075815916061
201.94053971767426
217.8213815689087
95.70648908615112
844.6322972774506
1056.6626601219177
676.1498707532883
612.6451585292816
0.0
0.0
0.0
182.61096060276031
436.544278383255
538.9483604431152
75.26342046260834
728.6569998264313
138.14536023139954
54.01467835903168
2023.1246964931488
101.2045624256134
2059.5970335006714
432.57185435295105
640.1398259401321
56.63186991214752
131.095379114151
112.19669020175934
23.771299839019775
2183.6978323459625
709.6889157295227
62.951988697052
468.5778458118439
809.1941055059433
117.25350034236908
98.28111922740936
618.2985752820969
1341.0936319828033
91.08522915840149
68.48555064201355
252.18436181545258
441.111249089241
39.3213996887207
107.7152214050293
201.87319707870483
850.8751630783081
712.1064751148224
452.0796595811844
481.6014093160629
182.53758323192596
9.386569857597351
748.6837128400803
532.5911972522736
82.68302845954895
73.19220960140228
289.3797857761383
512.2809810638428
249.8417307138443
49.52076053619385
1520.484474658966
493.23832607269287
241.4648209810257
262.74574971199036
241.49509143829346
1122.8051538467407
889.9751057624817
93.46448040008545
213.98759078979492
53.1446418762207
67.26124978065491
182.35747122764587
118.45112109184265
216.0132224559784
66.71088981628418
43.97707986831665
0.0
246.08915030956268
476.1469702720642
0.0
305.2892882823944
118.0723408460617
0.0
115.05875051021576
767.9771900177002
0.0
367.2857061624527
1433.2205185890198
0.0
289.83171248435974
154.19558024406433
0.0
76.08484888076782
789.4429415464401
0.0
68.45634126663208
129.33507776260376
746.3071464300156
133.51775777339935
67.10870975255966
105.99916970729828
214.694030046463
14.449910640716553
601.9831528663635
919.3326292037964
118.65503752231598
30.8754301071167
452.75966542959213
242.9083766937256
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2   F0.5  Average Precision
0   0.99647   0.606061  0.714286  0.655738  0.689655  0.625           0.434245

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 53.117 seconds
Cross-validation score: 0.7091625555178628
Test score: 0.7110609480812641
Best Hyperparameters: {}
3236.387597501278
150246.2698611021
237277.12231242657
16967.759829759598
22956.870848417282
276.65975069999695
49.93060040473938
91.50339114665985
196.98968970775604
160.91147029399872
2.0080299377441406
27.389700174331665
6106.08380317688
4317.719267964363
2224.829955101013
0.0
989.4213948249817
0.0
56.872390031814575
7.706130027770996
10946.198842048645
1274.6502739191055
8014.309833288193
313.9775675535202
10.751429915428162
2.7996599674224854
98.54897975921631
36.05873906612396
63.88266861438751
88.55707907676697
49.38592886924744
65.88987874984741
329.456135392189
292.5352705717087
31.951429843902588
831.3883757591248
826.9777433872223
61.4665904045105
95.14632165431976
403.16127026081085
164.8025017976761
0.0
0.0
0.0
390.1749655008316
618.2559263706207
671.4989206790924
184.12521922588348
478.65856659412384
190.06617832183838
68.68300104141235
76.14538908004761
588.5180546045303
565.1076409816742
24.58139991760254
523.7300723791122
0.0
0.0
0.0
3354.0569655895233
245.63682007789612
82.83099859952927
5.814370036125183
406.63481163978577
106.0128790140152
40.63602066040039
1652.0270198583603
490.19700253009796
1076.5108307003975
485.5453314781189
688.5681874752045
431.1369924545288
30.820499420166016
59.000789403915405
75.04211211204529
80.01485073566437
1528.6243458986282
202.0065393447876
460.84540581703186
647.5355293750763
33.13819062709808
380.60222864151
135.9689131975174
991.4977102279663
57.58873927593231
85.94889092445374
199.80386173725128
391.2855453491211
34.588709354400635
128.67869490385056
312.7234114408493
623.248138666153
97.23312044143677
117.18280017375946
717.5225887298584
123.70744347572327
30.54822075366974
728.1188770532608
672.1927615404129
48.08661329746246
396.9205791950226
444.699444770813
1766.1959256529808
829.9536868333817
78.63921117782593
4944.5035735964775
119.8902678489685
916.2911424636841
678.8572913408279
473.02838158607483
749.7357164621353
502.60629802942276
357.7895917892456
287.4914643764496
19.785240054130554
1063.884192943573
329.83439844846725
104.57545137405396
346.3147876262665
91.06891942024231
53.78083026409149
0.0
60.64966905117035
366.20076060295105
0.0
194.74847221374512
85.05446004867554
0.0
68.70643854141235
841.9218817949295
0.0
494.6172818541527
733.6913661956787
0.0
440.8710198402405
166.35066044330597
0.0
178.33676028251648
1202.3590638637543
0.0
153.86171370744705
69.41593909263611
490.4816947579384
241.49790132045746
41.14423966407776
403.2278858423233
3309.9435445070267
6.526130199432373
408.5909289121628
214.47949874401093
91.99175012111664
167.07340717315674
253.33788990974426
143.4435783624649
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision  Recall        F1        F2      F0.5  \
0  0.996358   0.588785    0.75  0.659686  0.711061  0.615234   

   Average Precision  
0           0.442765  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 53.865 seconds
Cross-validation score: 0.6903783956483964
Test score: 0.6862745098039216
Best Hyperparameters: {}
1878.9909065961838
135328.4435288906
254710.943744421
18730.46368598938
14180.158239006996
101.95273911952972
378.9626559019089
265.4709817171097
412.0682522058487
104.7374826669693
214.6531320810318
119.69368720054626
9330.955070972443
3860.6242728233337
449.4849672317505
0.0
1608.8105850219727
0.0
958.540706038475
25.35034942626953
10491.606840491295
1128.4987231492996
10776.371424078941
62.73912012577057
348.09823513031006
22.89222025871277
305.6418607234955
716.5133426189423
90.69599914550781
159.71233749389648
152.13562083244324
112.54630970954895
13.167240142822266
311.26308250427246
17.53326988220215
351.26142704486847
695.6530537605286
32.51303017139435
92.82144117355347
196.08943033218384
111.86887967586517
0.0
0.0
0.0
1757.3386088609695
294.75317335128784
321.18319058418274
453.63312888145447
919.8648679256439
418.3169347047806
88.72871005535126
406.65785455703735
314.69322991371155
415.2072693705559
1407.968744277954
417.2283229827881
0.0
0.0
0.0
734.6249408721924
952.712219953537
65.02962899208069
4.3852299451828
1025.1774979829788
125.91181886196136
54.539310932159424
4946.975432395935
343.1205036640167
1085.8670791387558
644.4983061552048
988.1205217838287
266.8987674713135
21.48337972164154
43.46629011631012
28.603599429130554
75.71306014060974
989.4171220064163
379.9418821334839
403.60316586494446
680.8861371278763
96.42347919940948
152.8693996667862
698.2486066818237
2717.8026601076126
149.71570920944214
8.832769870758057
78.07395017147064
63.9136598110199
24.405669927597046
121.4198807477951
209.67577469348907
865.1458027362823
453.4763342142105
121.53633797168732
595.8916826248169
330.1634795665741
13.255499958992004
2073.7001880407333
353.90097522735596
69.38800144195557
20.521629810333252
314.81043314933777
1714.9568462371826
332.9156446456909
204.0146335363388
839.1838133335114
215.1801801919937
211.59370923042297
322.20553636550903
777.6620756387711
241.16371870040894
680.8082579374313
583.96763920784
183.4318597316742
32.263920307159424
168.89162635803223
222.15831673145294
75.34833908081055
94.71264040470123
48.91652989387512
110.691579580307
0.0
365.2478469014168
247.3232781291008
0.0
258.415624499321
466.4425791501999
0.0
16.365450263023376
891.372608423233
0.0
762.8573511838913
1169.9008415937424
0.0
293.55801141262054
39.62731909751892
0.0
178.1977207660675
1254.078753709793
0.0
34.32054960727692
186.74574625492096
625.1069005727768
224.30608928203583
126.61333990097046
172.0806086063385
303.42190086841583
21.948639750480652
330.26859390735626
667.6295704841614
934.2268899679184
37.10350060462952
384.9924261569977
437.3357983827591
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision  Recall        F1        F2      F0.5  \
0  0.995461   0.512195    0.75  0.608696  0.686275  0.546875   

   Average Precision  
0           0.385323  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 54.251 seconds
Cross-validation score: 0.6936793446337859
Test score: 0.7375271149674621
Best Hyperparameters: {}
3157.2748984098434
137845.08657336235
258573.2029414177
16466.745473742485
15297.899621367455
455.5222508907318
142.2382274866104
104.49284160137177
129.1149207353592
85.22014033794403
251.0562874674797
50.938069343566895
10032.948665380478
853.9764157533646
2494.0308508872986
0.0
365.58004879951477
0.0
48.58413004875183
205.5303990840912
9565.282497525215
3133.9459631443024
4463.957021951675
767.4848990440369
42.91633999347687
29.379600524902344
707.2295104265213
112.21511030197144
55.95924115180969
47.69255006313324
82.31371974945068
47.92171037197113
14.906110048294067
342.1572914123535
47.04521930217743
1000.4945809841156
688.3701055049896
33.40995895862579
85.09962928295135
762.7487018108368
96.2347491979599
0.0
0.0
0.0
507.1260418891907
975.8610593080521
447.3053505420685
1135.8355032205582
279.26704728603363
214.71251130104065
284.91702902317047
93.4198694229126
509.6306540966034
1339.7923846244812
1728.140593290329
220.4111626148224
0.0
0.0
0.0
386.0204852819443
159.1658982038498
92.99596095085144
1.653190016746521
636.317956328392
278.4814120531082
148.64701735973358
4079.1736372709274
502.73800361156464
1592.153414964676
488.3639621734619
321.88952255249023
114.82159996032715
0.0
281.9824016094208
47.845890522003174
40.3175995349884
2069.222153186798
289.46973979473114
251.66230511665344
1100.8949732780457
107.49746704101562
567.5014505386353
614.317217707634
1782.6065644025803
88.72866082191467
30.550950050354004
119.52248167991638
205.23565864562988
117.40090847015381
142.59854233264923
277.6571875810623
568.721626162529
294.72972095012665
238.00421273708344
290.48366928100586
526.2850865125656
99.53109192848206
946.7912955284119
409.911572098732
14.721510171890259
0.0
202.4047600030899
2262.691963195801
201.11883902549744
42.37020981311798
1191.9394369125366
296.2999299764633
267.5424229502678
530.7657141685486
268.0005223751068
158.39592564105988
489.22835397720337
720.5537037849426
244.47925651073456
63.05385947227478
498.43583726882935
259.28052055835724
3.563839912414551
320.21103179454803
45.12604022026062
157.3160421848297
0.0
223.53981482982635
827.1623215675354
0.0
281.8065376281738
104.92763674259186
0.0
130.3160216808319
981.1578861474991
0.0
988.2729802131653
1533.1999720335007
0.0
20.518609523773193
112.24385952949524
0.0
192.35650062561035
1208.8060244321823
0.0
94.47649109363556
81.16763627529144
330.06328868865967
570.6136512756348
356.8072781562805
52.90912067890167
54.04709982872009
174.2789089679718
1347.5791770219803
381.3637320995331
1338.8697953224182
75.92381930351257
215.4717195034027
373.88987493515015
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0   0.99591      0.544  0.809524  0.650718  0.737527  0.582192   

   Average Precision  
0           0.441277  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 53.988 seconds
Cross-validation score: 0.6873813557758857
Test score: 0.738255033557047
Best Hyperparameters: {}
2252.7091739177704
141093.12742614746
248467.31524932384
19448.706077098846
20454.279879450798
197.44660067558289
427.05007672309875
352.1634397506714
734.4268679618835
376.2204908132553
52.84660077095032
4.466770172119141
6738.120091557503
3468.948156118393
2147.627535700798
0.0
461.54782950878143
0.0
81.44123089313507
11.988929986953735
10774.931494951248
1466.7596153020859
5123.288551092148
758.0868626832962
4.24783992767334
0.0
19.40957999229431
526.1581898927689
4.685269832611084
382.49175918102264
308.293216586113
93.68420195579529
42.28456008434296
198.67558181285858
1513.6938779354095
1959.24343085289
412.89355742931366
74.23894083499908
63.74199056625366
1123.3771034479141
219.71051037311554
0.0
0.0
0.0
1023.1042351722717
466.1732831001282
326.5414102077484
658.7239474058151
772.1292366981506
201.10170722007751
51.80457019805908
329.3277678489685
473.3902015686035
845.735969543457
0.0
266.7906142473221
0.0
0.0
0.0
137.68712198734283
1130.035805106163
899.0787642002106
42.76661038398743
623.5323631763458
111.54235172271729
14.74679970741272
2394.799645781517
309.4080089330673
1701.5944324731827
319.29431760311127
303.21061193943024
130.06528234481812
1.0992100238800049
83.13380992412567
45.35683035850525
109.75757110118866
2209.520116686821
615.2097480297089
185.74584877490997
1148.8455431461334
143.949640750885
771.1624450683594
341.9396822452545
2173.6338279247284
316.54680716991425
237.52519941329956
399.7963413000107
113.46616959571838
148.94998836517334
38.203269720077515
290.9648611545563
623.9955996274948
241.45433497428894
201.38781785964966
861.3927004337311
226.52339029312134
49.047029972076416
1279.8671246767044
888.908080458641
157.55419087409973
44.53317046165466
501.91923666000366
1180.0317519903183
1034.932562828064
33.009589314460754
531.5060210227966
292.0696840286255
323.68618083000183
929.9408091306686
580.8262730836868
231.94046783447266
903.7974107265472
426.46212697029114
308.42961156368256
17.55610954761505
468.760133266449
118.47395014762878
84.57435131072998
100.26225161552429
20.017510175704956
375.33669233322144
0.0
391.9897767305374
982.5553101301193
0.0
104.02732861042023
34.922250270843506
0.0
111.66930198669434
1613.2287365198135
0.0
1168.4718135595322
369.0130150318146
0.0
358.30219054222107
56.43972158432007
0.0
140.3362513780594
1011.3744395971298
0.0
73.30705952644348
36.62465000152588
357.6437602043152
81.84969937801361
220.6764533519745
256.7006994485855
347.4532608985901
212.8987376689911
200.81501805782318
213.7840211391449
243.5578316450119
163.5164031982422
293.5519388914108
43.667429089546204
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2   F0.5  Average Precision
0   0.99647   0.594595  0.785714  0.676923  0.738255  0.625            0.46819

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\metrics\_plot\precision_recall_curve.py:125: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots()
C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 54.345 seconds
Cross-validation score: 0.6984910680639635
Test score: 0.7415730337078651
Best Hyperparameters: {}
3722.215279817581
155191.79069387913
237149.15486359596
11538.183547139168
23601.78685748577
57.178030014038086
203.5238060951233
77.20841038227081
241.9399769306183
98.5047402381897
35.323100328445435
10.789340019226074
6622.028887152672
2710.280860066414
443.2142322063446
0.0
1109.0640540122986
0.0
52.92313075065613
88.62954902648926
11188.44808125496
903.1818770170212
11942.982409119606
53.32759976387024
109.70376014709473
0.0
79.4762601852417
175.36040878295898
20.545700311660767
296.7032344341278
57.707369327545166
1.1208200454711914
243.1938464641571
108.99409008026123
15.212249636650085
1195.8838136196136
497.82521080970764
111.4004510641098
78.56417965888977
569.885409116745
143.90205025672913
0.0
0.0
0.0
815.6362901926041
159.28425002098083
1178.290763616562
65.82748854160309
768.061959028244
127.04481053352356
93.83754014968872
116.31738018989563
194.32064855098724
1088.0590769052505
0.0
123.58275032043457
0.0
0.0
0.0
242.42243760824203
136.53626096248627
68.11785358190536
17.280920028686523
237.39372491836548
130.04414051771164
48.776740312576294
1990.4793511629105
218.0937911272049
1047.3377953767776
346.3849768638611
1302.25101852417
107.9689793586731
72.666348695755
546.0152108669281
81.80442976951599
29.8624906539917
1691.9531259536743
41.99643111228943
187.93727922439575
952.1804970502853
87.01141893863678
284.42754673957825
218.91683769226074
1645.2658321857452
21.645010352134705
96.08907043933868
186.5455722808838
99.38644063472748
16.04119038581848
98.87126934528351
380.321351647377
1014.8185240030289
500.950129032135
74.69338059425354
229.141268491745
333.5570442676544
3.8112199306488037
1630.5214154720306
458.12082183361053
19.8242906332016
312.47345447540283
361.883341550827
2432.978994846344
228.19289100170135
24.244289875030518
1300.9818464517593
311.621679186821
499.87590289115906
352.5714637041092
524.4097446203232
158.62528228759766
284.87042927742004
372.8071140050888
236.05650091171265
80.09573912620544
184.83346104621887
151.8013293147087
98.36181831359863
748.9979461431503
70.40795755386353
73.10348081588745
0.0
448.9097800254822
1279.3265209197998
0.0
68.36287093162537
18.61589014530182
0.0
73.6065731048584
1759.1067733764648
0.0
319.8617990016937
1524.783225774765
0.0
508.6040152311325
0.0
0.0
241.72551894187927
1337.2697496414185
0.0
1010.133388876915
697.6552724838257
180.12799990177155
119.73152995109558
360.7649539709091
389.8200833797455
2312.781681895256
179.8984501361847
260.5015162229538
453.8054664134979
1077.1416234970093
12.284549713134766
575.9704495668411
614.6346282958984
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.996582   0.605505  0.785714  0.683938  0.741573  0.634615   

   Average Precision  
0           0.476762  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 54.360 seconds
Cross-validation score: 0.6866604652062805
Test score: 0.734966592427617
Best Hyperparameters: {}
2861.35724568367
128538.73804318905
268009.34434115887
16776.923088550568
12700.879333615303
322.8854936361313
176.69921123981476
377.32830476760864
579.3606584072113
430.41372060775757
1640.660495519638
32.685139417648315
11541.899559855461
2567.136843264103
4998.806393861771
0.0
1172.116563796997
0.0
29.970900058746338
29.159340023994446
8154.904579758644
2151.7170304059982
5382.110352873802
72.09921050071716
161.52788305282593
0.0
326.6382131576538
210.67675364017487
25.33989989757538
83.618159532547
160.62774848937988
157.9450067281723
12.63916003704071
295.59054839611053
13.104740262031555
942.0429701805115
285.2928395271301
24.14579999446869
106.00484013557434
300.6497005224228
143.7249904870987
0.0
0.0
0.0
720.1153317689896
478.4620018005371
361.10250174999237
376.93102192878723
1072.4060187339783
147.63784086704254
61.75092017650604
94.33844828605652
230.1008735895157
499.9202650785446
1415.3799800872803
203.54642844200134
0.0
0.0
0.0
242.8867689371109
889.5196663141251
134.1373689174652
0.0
265.89865124225616
259.19018256664276
19.193199157714844
3502.890845298767
149.7653684616089
2233.4053171873093
299.95428907871246
418.1725208759308
362.0155979394913
147.46945023536682
167.68914830684662
297.80770921707153
753.4873290061951
882.6622860431671
89.50779330730438
128.0820803642273
709.7591577768326
56.31917977333069
1251.937923669815
346.3784347772598
1515.2680920362473
89.83726894855499
49.49796950817108
159.83621954917908
187.14263677597046
21.489899516105652
51.88307023048401
186.49794948101044
1642.1260191202164
973.9139145612717
492.3812880516052
225.06155002117157
400.5282869338989
86.96603083610535
1083.4083343744278
410.6895283460617
28.11218023300171
95.46954083442688
571.4780712127686
1536.5071893930435
686.1269401311874
89.10271835327148
1122.9509394168854
97.14286923408508
814.1803656816483
326.98612844944
219.10563957691193
324.4601876735687
398.24098575115204
494.93331480026245
125.84556972980499
72.41211104393005
147.9449760913849
136.99414813518524
40.31218123435974
187.6254563331604
55.94452095031738
150.07228064537048
0.0
130.6467788219452
1182.64848446846
0.0
265.9624308347702
41.6582305431366
0.0
16.72010040283203
879.5196598768234
0.0
1627.2077778577805
934.2871021032333
0.0
175.94544124603271
234.91338324546814
0.0
96.3360824584961
970.832233786583
0.0
208.70871138572693
530.8179588317871
236.28530836105347
258.00556921958923
193.01558363437653
80.29889953136444
814.2574287652969
149.29318714141846
183.3795589208603
171.0511293411255
495.8981420993805
33.44833993911743
430.60576432943344
268.8720054626465
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.996358   0.584071  0.785714  0.670051  0.734967  0.615672   

   Average Precision  
0           0.459921  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 56.241 seconds
Cross-validation score: 0.6846424359435532
Test score: 0.717439293598234
Best Hyperparameters: {}
4174.581300139427
144017.23649203777
241176.48760032654
13822.66507267952
23563.62700331211
1150.5516673326492
224.19543778896332
51.54442059993744
345.49330282211304
41.195980191230774
348.96441888809204
32.86320114135742
5326.395767092705
5549.780281662941
463.42190647125244
0.0
774.7814869880676
0.0
44.20700001716614
22.942800521850586
9521.466292142868
2766.0552386045456
7018.803751587868
1047.4462715387344
12.898450136184692
18.00963056087494
86.06837093830109
372.474488735199
138.18861865997314
111.32502889633179
301.1248288154602
32.42874085903168
168.1752473115921
512.7568306922913
10.821030139923096
1300.0443396568298
181.0626004934311
268.09824430942535
56.87033998966217
880.5995662212372
170.39414846897125
0.0
0.0
0.0
863.7632981538773
440.8727388381958
597.3357789516449
579.3347616195679
346.8511083126068
247.0486120581627
6.89870023727417
440.0114697217941
281.0509514808655
1467.942342042923
226.5345973968506
172.8747445344925
0.0
0.0
0.0
300.5530790090561
294.71892511844635
394.8771275281906
54.22389101982117
734.1670617461205
230.62464308738708
56.38933849334717
5396.876000881195
424.97301161289215
1135.1730930805206
201.46769988536835
659.9101598262787
85.20968043804169
0.0
467.2720032930374
56.76498889923096
391.5436987876892
1672.486095905304
63.76714098453522
304.8481447696686
1211.642807483673
143.09889829158783
1019.707270860672
772.8388853669167
1717.4103116989136
85.3067216873169
31.95627999305725
147.67760968208313
308.4678635597229
1.7613099813461304
11.056319952011108
1243.4836065769196
286.39050817489624
184.4184433221817
53.21058011054993
465.1832104921341
319.27241003513336
114.02502012252808
1234.9861068725586
452.2989151477814
33.945799827575684
16.263010263442993
525.131778717041
1796.17336165905
427.97038531303406
94.48782086372375
1572.0660846233368
209.27190268039703
518.4094562530518
508.7507631778717
338.1052039861679
599.7551159858704
627.9312881827354
176.52955186367035
340.32282292842865
160.15067219734192
238.949937582016
69.41914856433868
4.0982301235198975
124.88368821144104
100.09523057937622
78.41065979003906
0.0
555.1202971935272
769.2543271780014
0.0
256.0001505613327
166.77153301239014
0.0
322.4856786727905
637.5559149980545
0.0
796.0065426826477
649.2456949949265
0.0
297.86910450458527
7.521850109100342
0.0
7.2768402099609375
1159.1764172315598
0.0
254.19566941261292
22.460910081863403
387.93893826007843
96.45223212242126
211.5705680847168
53.603129744529724
4246.697485923767
48.570828914642334
274.90092265605927
544.7110087871552
864.9383515119553
46.5348105430603
310.75676333904266
859.9979939460754
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision   Recall        F1        F2      F0.5  \
0  0.996022   0.555556  0.77381  0.646766  0.717439  0.588768   

   Average Precision  
0           0.430959  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 53.832 seconds
Cross-validation score: 0.6962648425944002
Test score: 0.7330415754923415
Best Hyperparameters: {}
2889.1719056367874
122308.46171331406
255311.35692429543
20691.58080327511
15056.027174830437
83.30736112594604
284.2604864835739
127.27752101421356
22.427950859069824
130.73511016368866
1305.9792560338974
10.258190035820007
4555.579457163811
15863.59726691246
932.2402563095093
0.0
1646.5236414670944
0.0
205.82464706897736
16.744019627571106
7281.2573791742325
1012.5732032060623
15101.783587694168
62.59190034866333
110.33935117721558
27.21623945236206
175.80172634124756
371.1650085449219
20.18366050720215
113.90492033958435
228.5456018447876
53.000099182128906
144.97120893001556
848.5116727948189
15.087030053138733
1010.4373327493668
519.9888820648193
39.38249087333679
77.02127993106842
1045.8695483207703
73.8945482969284
0.0
0.0
0.0
1017.0896947383881
80.02089881896973
912.3768810033798
262.07448399066925
519.8183754682541
207.7091588973999
67.69097137451172
56.94544005393982
789.0282434225082
1505.1774464845657
20.979759693145752
500.63180124759674
0.0
0.0
0.0
483.62323093414307
566.216187119484
75.11511474847794
8.62794017791748
1081.5588183403015
64.41824102401733
9.107660293579102
4091.4835361242294
580.2761342525482
2051.843757033348
485.8647847175598
369.0045315027237
96.22482204437256
309.96198534965515
390.43644881248474
49.7793402671814
137.22092056274414
2503.8681610822678
33.03492045402527
286.6579874753952
1470.5789989233017
103.29435014724731
678.1633970737457
362.8794323205948
1386.7186618447304
134.11719012260437
398.62984108924866
118.97001135349274
486.0640068054199
21.221799790859222
114.88607931137085
92.7403724193573
730.463071346283
213.45902848243713
390.2980468273163
512.4492527246475
237.83613693714142
60.54400932788849
2307.2928017377853
327.0754086971283
24.837680339813232
70.09072995185852
165.27297163009644
1503.3535529375076
624.1751091480255
28.714540004730225
882.2045353651047
216.04059100151062
95.51800847053528
533.8162730932236
518.5055663585663
1000.91565990448
586.3741207122803
975.7811472415924
149.01888704299927
11.88971996307373
393.85300040245056
73.12593936920166
11.605899810791016
188.40167605876923
31.614519834518433
18.714100122451782
0.0
1297.0012085437775
639.1272169351578
0.0
237.6073888540268
36.67901957035065
0.0
40.93485987186432
659.5174559354782
0.0
617.7702768445015
534.6988272666931
0.0
87.76065301895142
45.05944895744324
0.0
103.37562775611877
1182.6687409877777
0.0
316.5784983634949
48.885169982910156
368.53176951408386
32.75802028179169
166.31340992450714
221.24067997932434
867.2589716911316
38.00477051734924
149.69328844547272
697.8248782157898
85.94713878631592
100.97379922866821
466.9519704580307
281.174329996109
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.996022   0.553719  0.797619  0.653659  0.733042  0.589789   

   Average Precision  
0           0.442609  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 53.678 seconds
Cross-validation score: 0.7064650757894545
Test score: 0.662251655629139
Best Hyperparameters: {}
1219.647206544876
149222.53348994255
244801.1133018732
13115.838015317917
23716.380512475967
66.71231877803802
220.33146607875824
101.2198292016983
176.1422808766365
123.84819102287292
259.21361911296844
97.41698980331421
3875.9051163196564
4046.4892731904984
1385.5904732942581
0.0
677.6518997550011
0.0
94.85032939910889
11.31099021434784
10311.029451012611
1721.7969117164612
5521.363711595535
59.54477047920227
874.9942760467529
30.054539561271667
126.97450590133667
306.13339018821716
38.592928767204285
1265.7194484472275
173.25000858306885
23.673179864883423
57.086230874061584
116.34409999847412
116.72724068164825
216.33380115032196
333.6269781589508
291.12992548942566
76.23096013069153
1556.963602900505
141.1973397731781
0.0
0.0
0.0
1373.8823368549347
297.5270403623581
1006.6137694120407
288.03857004642487
1401.2103219032288
181.51371014118195
107.97081661224365
101.63292193412781
442.043160200119
543.2541617155075
33.716400146484375
586.393083691597
0.0
0.0
0.0
908.1497464179993
557.1086977720261
119.91463887691498
9.602310180664062
785.7031955718994
71.70318150520325
13.720810174942017
3147.8980692625046
334.55916678905487
1434.5098885297775
84.43060910701752
307.1017405986786
167.28244185447693
39.97766065597534
146.1617008447647
12.73082971572876
50.22308099269867
909.7412612438202
164.77313947677612
304.31052953004837
1827.969991326332
363.288729429245
251.74134695529938
261.3762423992157
1371.7430893182755
51.12049901485443
127.92695891857147
290.74923968315125
22.530280351638794
92.57311868667603
217.55510860681534
679.6756582260132
986.8873673677444
817.1266062259674
353.2099539041519
233.39538741111755
1221.9456886053085
129.36975049972534
1046.368530869484
408.83350670337677
173.82916867733002
98.52269911766052
377.3018471002579
1532.0454610586166
1016.9495923519135
213.71594905853271
940.990391254425
144.42599630355835
386.53103160858154
1439.294550895691
343.74793100357056
364.7052261829376
602.5465115308762
597.9047192335129
122.85093903541565
64.62801110744476
233.51516234874725
596.9730328321457
22.897659301757812
540.1490163803101
79.62155032157898
33.78030014038086
0.0
190.98600947856903
413.9155558347702
0.0
214.57077825069427
108.54873943328857
0.0
255.10503935813904
1172.8603497743607
0.0
464.89746141433716
800.4034506082535
0.0
373.8297052383423
26.00542986392975
0.0
265.7766134738922
1103.6866089105606
0.0
375.03769409656525
2192.475476861
261.33218562602997
95.32739865779877
338.36119866371155
49.8658105134964
2544.940050005913
541.0961527824402
113.41813158988953
337.2523078918457
731.5551611185074
518.7789750099182
77.6874395608902
280.4454734325409
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.995461   0.512821  0.714286  0.597015  0.662252  0.543478   

   Average Precision  
0           0.367645  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 53.704 seconds
Cross-validation score: 0.6987272805984902
Test score: 0.6847826086956521
Best Hyperparameters: {}
2301.53071475029
146925.96407437325
243305.1603615284
16440.786558270454
22097.57453942299
120.8225793838501
450.8263591527939
67.14533996582031
237.75285267829895
278.16718769073486
615.7754967212677
11.608839750289917
8484.974044680595
2612.6918016672134
965.5292731523514
0.0
1285.6211214065552
0.0
54.2263605594635
41.530229449272156
12001.931553721428
2093.739401817322
6105.720474123955
254.27391397953033
57.58717966079712
35.53544008731842
99.15924108028412
199.57871067523956
60.3755784034729
62.0228306055069
104.25435948371887
7.364240050315857
12.92287015914917
111.30349159240723
87.22981119155884
694.9087519645691
673.4191942214966
132.14824068546295
64.6019594669342
676.6495212316513
375.7220402956009
0.0
0.0
0.0
739.8361288309097
99.15348792076111
970.4163500070572
861.350170135498
1955.208149433136
131.5967400074005
14.877549886703491
76.36266887187958
554.5757840871811
738.8230875730515
374.99868524074554
373.00879633426666
0.0
0.0
0.0
58.49462878704071
1734.312799692154
427.80473232269287
28.88832998275757
835.4037957191467
17.3684298992157
21.12869954109192
1569.7918021678925
673.3960981369019
1374.38143658638
502.2288212776184
214.14828753471375
65.65810012817383
26.12967038154602
214.8153419494629
3.38726007938385
75.52339005470276
1362.8386924266815
113.63328945636749
147.00394010543823
794.2977133989334
94.91083121299744
530.6271005868912
444.73635840415955
1376.1712696552277
396.8778592348099
87.86380875110626
63.69631975889206
220.43747973442078
16.578150391578674
54.917951583862305
463.7678236961365
1029.7178568840027
184.86748242378235
796.7711678743362
860.0636098384857
459.10743844509125
481.8401892185211
805.1637377142906
409.3624540567398
25.233298361301422
28.295809984207153
292.3328061103821
1554.2035900354385
842.1607576608658
363.8939563035965
1761.357468187809
384.26924335956573
729.1691139936447
768.9723881483078
1426.6363686323166
221.4919033050537
427.1938325166702
121.11634612083435
240.97861671447754
6.202629804611206
137.43318283557892
290.40683937072754
8.991440057754517
197.13426822423935
29.1222802400589
137.77058643102646
0.0
99.23914897441864
646.0641596317291
0.0
77.83715832233429
98.57683157920837
0.0
30.396970748901367
940.7439054250717
0.0
1753.593445777893
591.253156542778
0.0
582.8879731893539
55.1687912940979
0.0
116.76101684570312
1216.1287087202072
0.0
239.2689814567566
49.55568051338196
288.2939633131027
54.38378047943115
106.48040997982025
179.79391288757324
1131.3502999544144
4.595929980278015
899.4029039144516
449.1137430667877
262.9406987428665
233.37070834636688
218.3141084909439
564.1695027351379
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision  Recall        F1        F2      F0.5  \
0  0.995405   0.508065    0.75  0.605769  0.684783  0.543103   

   Average Precision  
0           0.382225  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 54.034 seconds
Cross-validation score: 0.7175409603134323
Test score: 0.6361607142857142
Best Hyperparameters: {}
2581.7788075208664
148005.30708503723
239713.7173165083
15668.370510220528
25068.739595294
38.20666015148163
338.3208485841751
205.14942955970764
41.71120059490204
53.48224055767059
120.62133884429932
28.403559923171997
5532.490576863289
3779.934240579605
898.0904107093811
0.0
521.4976803064346
0.0
82.08055937290192
69.06650924682617
13520.433056116104
592.5631921291351
8959.599259734154
166.12857019901276
13.445890307426453
35.43732953071594
368.0888305902481
429.8753527402878
65.50434231758118
84.62394142150879
62.888171672821045
54.38869857788086
215.33863162994385
95.36261987686157
102.46437895298004
1025.865383386612
635.9275770187378
63.59560024738312
262.72343695163727
1217.041979432106
314.90046656131744
0.0
0.0
0.0
537.9220597743988
447.78873574733734
955.2222898006439
214.87936115264893
583.9288566112518
272.9520835876465
70.07781791687012
158.91660809516907
498.29880714416504
383.82386016845703
4.08266019821167
632.2346091270447
0.0
0.0
0.0
101.69546735286713
561.0195976495743
387.787854552269
63.30093002319336
919.5530561208725
73.81543028354645
2.3654301166534424
2301.382071375847
970.6557668447495
1691.0813014507294
526.6143336296082
199.25251960754395
111.84732103347778
52.39637005329132
616.8180055618286
308.16422963142395
147.00311958789825
819.313944876194
283.78168201446533
74.08148956298828
633.0056138038635
86.88955855369568
573.0284003019333
543.1681509017944
1129.0124541521072
42.57799005508423
15.762020349502563
256.3489080667496
79.20826983451843
130.41206336021423
146.7981995344162
135.26339983940125
438.75514113903046
94.17840993404388
1072.7829122543335
654.0728056430817
235.6390619277954
51.127880334854126
1027.7837368249893
498.07632327079773
61.5185911655426
301.4545794725418
433.1130783557892
993.2739336490631
488.9557375907898
75.90768051147461
1038.6241074800491
233.23958253860474
396.1306564807892
1877.0525863170624
445.1724976301193
804.6241641044617
473.30551624298096
2599.61759185791
173.91952180862427
28.36015009880066
656.9050133228302
191.6491014957428
49.84564924240112
237.773108959198
55.352901577949524
146.25321912765503
0.0
93.99182856082916
658.9369411468506
0.0
163.88852083683014
12.143724977970123
0.0
106.00648975372314
641.1519503593445
0.0
596.1917713880539
416.49239325523376
0.0
75.65970802307129
47.566609382629395
0.0
235.16600036621094
677.1492240428925
0.0
696.707239985466
35.37321996688843
230.59751957654953
434.48963272571564
210.75330722332
237.06709170341492
3591.1466360092163
93.72754836082458
310.0054030418396
406.5422697067261
807.827055811882
4.466479778289795
91.62991034984589
542.0803487300873
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.995405   0.508929  0.678571  0.581633  0.636161  0.535714   

   Average Precision  
0           0.346857  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 53.300 seconds
Cross-validation score: 0.6956993809391421
Test score: 0.7000000000000001
Best Hyperparameters: {}
2593.3725578784943
130447.715549469
266317.10319030285
16563.37784731388
17605.287324547768
22.918699979782104
29.418609857559204
85.21648943424225
706.9649167060852
153.55303692817688
78.85253930091858
5.4847002029418945
6053.498778700829
6400.218421459198
2558.415020108223
0.0
1130.24289894104
0.0
32.0484904050827
20.228840470314026
5704.560074567795
2977.5870583057404
5977.199011802673
224.8377549648285
59.813199520111084
46.76104927062988
379.5062954425812
54.77476990222931
270.59238946437836
593.9083745479584
49.65984010696411
40.11221992969513
1002.0602869987488
193.39833450317383
50.906458497047424
637.0498571395874
262.95980417728424
44.59301948547363
138.98032939434052
812.9465143680573
177.8056824207306
0.0
0.0
0.0
284.13804590702057
136.86184239387512
483.8311336040497
996.8723373413086
252.00330185890198
222.25981080532074
260.5235558748245
99.75150072574615
422.76743030548096
529.5013167858124
1041.500536441803
439.36538231372833
0.0
0.0
0.0
212.65627872943878
749.3136963844299
26.95016074180603
0.0
1054.9756984710693
220.4175089597702
46.02206826210022
2039.2302932739258
128.6757311820984
1956.347541809082
298.8833227157593
631.532877445221
126.79010009765625
11.539600372314453
28.96120035648346
75.53832840919495
44.95957946777344
2683.6518816947937
478.2810609340668
318.07613730430603
344.09015822410583
259.0071132183075
163.8433609008789
547.9887406826019
2162.0237736701965
60.019847989082336
125.60157573223114
352.5330455303192
217.6546117067337
19.46992027759552
127.14624035358429
564.4979201555252
726.0834699869156
174.9500470161438
688.3322229385376
417.6071128845215
255.2310392856598
54.76596021652222
1462.0295149087906
546.1348875761032
34.45020008087158
3.9305200576782227
382.84027099609375
1234.0843900442123
453.14102578163147
105.35373067855835
668.0479398965836
1139.9413802623749
515.9972132444382
109.92170095443726
788.9683437347412
510.8527088165283
1091.329115986824
993.5837297439575
248.00273859500885
4.647700071334839
163.0179796218872
107.19641041755676
50.33059883117676
230.05875086784363
65.10626935958862
198.7734305858612
0.0
158.38972651958466
429.79185485839844
0.0
104.34189200401306
290.59847366809845
0.0
104.70276129245758
1333.8603775501251
0.0
649.3266490697861
576.0619515180588
0.0
328.00066804885864
324.88982582092285
0.0
301.1878433227539
637.9380804300308
0.0
143.4961884021759
65.47887992858887
674.1598145961761
220.75994896888733
117.36572766304016
161.86877346038818
132.7882398366928
440.71472573280334
529.3892366886139
142.78671646118164
2983.149151325226
23.267099380493164
503.290443778038
435.98219060897827
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision  Recall        F1   F2      F0.5  Average Precision
0  0.995966   0.552632    0.75  0.636364  0.7  0.583333            0.41565

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 53.106 seconds
Cross-validation score: 0.6903782891356032
Test score: 0.7300884955752213
Best Hyperparameters: {}
2984.646896004677
147695.17694592476
242943.323905468
13236.89033138752
25156.231934905052
87.84230983257294
202.53012573719025
119.03886067867279
632.4900770187378
68.88598918914795
144.17308819293976
5.0995399951934814
6122.220570802689
1030.4445313215256
1503.9898080825806
0.0
2001.6947047710419
0.0
115.92563009262085
21.142280340194702
9617.358505368233
1631.243192434311
5885.158134698868
406.8154842853546
135.68094944953918
28.48751950263977
52.37913954257965
238.8282458782196
79.90575838088989
106.79436123371124
195.41213130950928
0.0
85.28315234184265
431.7216920852661
590.1573152542114
1900.9138720035553
1282.1665532588959
74.35301148891449
171.51128697395325
690.233415722847
122.54564082622528
0.0
0.0
0.0
787.7200882434845
213.31229829788208
488.6385097503662
418.4275996685028
929.2695716619492
216.48891067504883
42.04257929325104
166.99015486240387
554.37570977211
495.8732125759125
478.09500885009766
325.907706618309
0.0
0.0
0.0
294.64182436466217
535.0336050987244
264.5075558423996
0.0
521.3269394636154
134.2845311164856
4.102570056915283
4202.74239385128
290.67220759391785
2185.503350496292
260.68612408638
816.2631009817123
125.29154121875763
18.377939343452454
72.29972183704376
31.47412919998169
177.95326268672943
3693.8223782777786
261.3838882446289
296.65045392513275
1113.307792186737
67.34112000465393
215.6215089559555
1197.5864256620407
1531.4695972204208
212.4599175453186
28.008050441741943
249.87408077716827
375.800585269928
22.32301926612854
61.49843943119049
665.2710268497467
1118.1161161661148
417.62239253520966
384.78006279468536
197.92336106300354
161.11764085292816
352.3176931142807
1190.3833162784576
576.5862611532211
189.91434121131897
52.713799476623535
441.3102970123291
1213.0351287126541
783.5104789733887
335.4180051088333
570.3956139087677
162.08073449134827
623.7151762247086
447.3538326025009
458.6339933872223
1214.2925390005112
623.2282422780991
1117.9280539751053
1227.1670042276382
4.342000126838684
145.75410842895508
252.78674232959747
44.27610111236572
106.84507322311401
28.485239386558533
108.19323945045471
0.0
363.4639300107956
194.54591155052185
0.0
105.56821167469025
202.61411082744598
0.0
16.528299808502197
687.0560418367386
0.0
498.2034125328064
500.8646157979965
0.0
236.86292898654938
59.436309933662415
0.0
180.68365049362183
1404.3255562782288
0.0
150.38470768928528
32.41037940979004
284.4727478027344
123.86251616477966
299.71179938316345
217.33305025100708
1322.6764205694199
580.3275862932205
479.0759733915329
172.39238119125366
505.4639402627945
195.22147703170776
246.58352041244507
478.0635392665863
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall    F1        F2     F0.5  Average Precision
0   0.99619   0.568966  0.785714  0.66  0.730088  0.60219           0.448053

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 53.631 seconds
Cross-validation score: 0.6858569938239052
Test score: 0.7467532467532467
Best Hyperparameters: {}
2286.801043152809
105791.29699957371
262603.0291401148
20741.450212717056
16934.825251698494
403.88735246658325
1745.0040380954742
311.1448584794998
198.31125116348267
76.58415019512177
147.8825124502182
9.706629753112793
4755.636685371399
29244.55186676979
1444.1446479558945
0.0
634.6515829563141
0.0
150.61019790172577
23.78980016708374
9666.835318803787
9172.252874493599
1686.6420142650604
541.2510061264038
3.5191400051116943
5.932899832725525
27.97303742170334
26.680780291557312
12.949080109596252
403.65802931785583
5.062459945678711
1.097000002861023
208.81302642822266
198.5662261247635
539.6446768045425
265.37777864933014
57.9408495426178
98.79511189460754
139.17040836811066
912.0452058315277
177.0819994211197
0.0
0.0
0.0
537.1265610456467
571.3218855857849
362.1497231721878
305.1386761665344
694.6083886623383
242.6796417236328
58.71732985973358
129.21057081222534
531.9191612005234
1090.2454344034195
3.1366701126098633
216.51474833488464
0.0
0.0
0.0
240.58481097221375
1121.5205171108246
58.354199290275574
2.171060085296631
538.4273216724396
163.7543489933014
10.014080047607422
2139.587813138962
1170.8517402410507
1053.4004501104355
601.3755139112473
574.6356565952301
144.63519859313965
14.898139715194702
261.517315864563
134.9373083114624
4.729420185089111
3178.8262292146683
37.7540500164032
223.3991619348526
1235.467164516449
70.99241018295288
470.6517403125763
781.1528255939484
2373.8239529132843
176.67176938056946
48.756301164627075
219.06336724758148
115.80555891990662
5.92753005027771
277.56790113449097
154.48053097724915
847.5187486410141
222.1757595539093
259.6487033367157
681.2053029537201
33.84725046157837
460.77480697631836
1672.3765313625336
235.5174092054367
122.70474803447723
114.8901025056839
251.02976882457733
976.6653079986572
202.3771321773529
92.92387127876282
317.67169857025146
428.9938932657242
1080.841427564621
245.9248230457306
636.3239297866821
832.8172750473022
1169.4287182092667
210.67670011520386
745.2205930948257
30.446319699287415
142.29645490646362
452.7845221757889
15.30679988861084
174.81368935108185
24.721920013427734
93.08647179603577
0.0
169.502366065979
927.6803047060966
0.0
174.2217869758606
278.32753562927246
0.0
66.77974820137024
509.4884042739868
0.0
981.500584602356
610.5162793397903
0.0
433.31486082077026
82.36812841892242
0.0
0.0
1466.3436212539673
0.0
24.14389991760254
36.3701137304306
134.81643974781036
142.9300595521927
203.05881869792938
247.62071919441223
680.5731451511383
174.71272706985474
431.56643652915955
219.4418568611145
908.9330271482468
334.31321251392365
263.8071172237396
512.9129848480225
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.995966   0.547619  0.821429  0.657143  0.746753  0.586735   

   Average Precision  
0            0.45067  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 52.170 seconds
Cross-validation score: 0.6976676895415073
Test score: 0.7284768211920529
Best Hyperparameters: {}
2594.3459461927414
147354.85586994886
249155.57006967068
17232.005200386047
17202.35120600462
42.84611093997955
132.06310081481934
176.20739269256592
210.99955809116364
89.22501909732819
143.99140977859497
35.7960901260376
8661.180857896805
3908.855020403862
1764.9000554084778
0.0
493.09954392910004
0.0
43.98745942115784
22.614680290222168
10636.146993756294
3093.7511281967163
5613.820018172264
157.69293212890625
81.4882915019989
38.07845067977905
87.82360136508942
216.62050831317902
19.84519052505493
387.77134573459625
30.657229781150818
2.4694159626960754
146.25528919696808
238.20471918582916
67.517791390419
2211.991615355015
1342.733693242073
106.636549949646
87.87331998348236
68.8788194656372
187.59026181697845
0.0
0.0
0.0
142.2184386253357
680.7895216941833
420.35328710079193
297.5284615755081
827.1378469467163
137.2994383573532
37.18758034706116
97.80173015594482
365.7989294528961
865.8010921478271
680.1789932250977
64.70512986183167
0.0
0.0
0.0
39.42361009120941
245.47135174274445
52.414050459861755
7.8155999183654785
417.3989874124527
247.8147188425064
77.62757921218872
2445.3638076782227
397.8057632446289
1952.0519515275955
1022.497488617897
619.6628029346466
226.30269145965576
77.33589041233063
167.41293954849243
194.83300113677979
102.27202081680298
1174.4057649970055
298.5307205915451
135.9443951845169
932.6360162496567
204.1684068441391
361.87580966949463
108.336949467659
1461.5765857696533
20.06985032558441
122.52521979808807
36.18923008441925
271.892404794693
80.82341969013214
7.9917298555374146
567.1224664449692
603.7653920650482
501.5169882774353
17.96295940876007
791.5862663984299
171.74470472335815
23.821459531784058
1317.061283826828
200.8488907814026
58.233511209487915
182.03921115398407
297.5448921918869
1746.1645715236664
285.24291145801544
41.41227066516876
765.275403380394
522.1646144390106
542.0438170433044
92.24178051948547
1119.8309817314148
755.1725952625275
393.86354291439056
410.0639181137085
274.61583852767944
16.874039888381958
168.915318608284
91.04672193527222
7.859230041503906
547.0902704000473
221.59523272514343
91.83296966552734
0.0
538.7567821741104
291.4488892555237
0.0
134.84781086444855
22.10238003730774
0.0
132.0892094373703
1501.5191591978073
0.0
699.3940460681915
234.6703518629074
0.0
481.3038718700409
14.27534008026123
0.0
291.09084725379944
1205.4150100946426
0.0
513.0666718482971
81.7616114616394
363.93135011196136
95.7551326751709
205.05835127830505
231.7360600233078
2545.0261192321777
293.8277369737625
219.11762976646423
442.611209154129
768.5492901802063
60.30023908615112
529.0472234487534
151.43930101394653
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.996134   0.564103  0.785714  0.656716  0.728477  0.597826   

   Average Precision  
0           0.444232  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 53.589 seconds
Cross-validation score: 0.6991129937298133
Test score: 0.7387580299785865
Best Hyperparameters: {}
1690.5405731201172
145559.09404695034
232233.19432091713
13801.14895939827
24551.375772953033
375.20343136787415
465.11716628074646
351.8389939069748
224.31599915027618
275.94690477848053
316.35031497478485
100.91706049442291
4597.102937459946
4394.4001433849335
1349.0884767770767
0.0
661.1579749584198
0.0
56.443461418151855
56.46437168121338
10086.488343000412
2406.560291290283
8221.092591524124
257.5575119256973
85.94737029075623
8.502620220184326
90.17491829395294
80.02549958229065
14.106030464172363
74.48123955726624
93.04367256164551
79.71326994895935
19.768490076065063
222.97273886203766
116.60813820362091
4601.31586432457
1207.6939648389816
58.32797980308533
257.72715198993683
795.8007414340973
74.45935130119324
0.0
0.0
0.0
803.0476677417755
83.17750883102417
482.2183014154434
166.35068917274475
1516.5687779188156
335.6852003335953
29.333200454711914
174.5997005701065
620.7104229927063
1328.9251512289047
0.0
575.604056596756
0.0
0.0
0.0
809.6020082235336
362.7824088335037
162.59125798940659
52.12683963775635
876.2224417924881
122.29972088336945
4.802670001983643
6977.934972405434
731.9377275705338
1383.9058258533478
391.0335624217987
218.6271255016327
12.102189779281616
8.32190990447998
198.65308940410614
168.91138172149658
166.23078954219818
1132.2066892385483
154.64897346496582
361.2157917022705
1543.3680070638657
91.51868033409119
754.3857293128967
502.05203080177307
1829.8837136030197
76.00124025344849
540.6228575706482
89.05942296981812
124.71754050254822
15.173320055007935
160.24439227581024
248.18508517742157
916.6850672960281
243.93959212303162
370.25962030887604
287.25161027908325
1043.2459325790405
309.9522955417633
2768.2898213863373
572.6840512752533
80.0143313407898
49.639310359954834
541.8630501031876
1952.4840487241745
320.2825812101364
103.6403397321701
385.2127228975296
607.8317828178406
119.67453944683075
684.9959201812744
607.947872042656
45.691250801086426
557.36647772789
65.07434093952179
382.42618215084076
17.35945963859558
369.6530715227127
103.28876078128815
81.99220085144043
35.57019090652466
31.315149784088135
75.18029034137726
0.0
866.4744511842728
386.4710602760315
0.0
420.2489113807678
194.12340104579926
0.0
338.9334582090378
1698.7241082191467
0.0
918.8091809749603
1905.2000005245209
0.0
225.50885981321335
93.41896831989288
0.0
427.16858100891113
1369.1017370224
0.0
58.93918037414551
76.79625189304352
592.9512164592743
37.13138997554779
36.55638015270233
188.5528291463852
3596.9206285476685
29.231070041656494
317.1976090669632
1317.2935214042664
772.8096622228622
30.52449941635132
316.2566487789154
695.1499009132385
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall       F1        F2      F0.5  \
0  0.995686   0.526718  0.821429  0.64186  0.738758  0.567434   

   Average Precision  
0           0.433501  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 52.375 seconds
Cross-validation score: 0.7058899499157577
Test score: 0.7048458149779735
Best Hyperparameters: {}
2246.8712508678436
155972.75914168358
242589.32874393463
12680.042575478554
22111.48097026348
53.353941440582275
599.6161727905273
125.25673794746399
344.03188610076904
58.932820439338684
431.1926363706589
114.48402035236359
7404.741802930832
1067.5534850358963
2281.1813801527023
0.0
384.56039822101593
0.0
144.34271144866943
17.681909918785095
11507.253069519997
777.6464490890503
6863.0195199251175
78.00651025772095
59.49279975891113
2.183109998703003
261.4835834503174
36.658719539642334
56.726460456848145
301.31769466400146
89.46582174301147
33.39584040641785
148.79256224632263
112.7650797367096
96.71039938926697
644.5023810863495
1098.836990237236
67.69130098819733
289.88047301769257
177.68549728393555
43.37111419439316
0.0
0.0
0.0
525.9658670425415
332.6116678714752
685.9194855690002
383.8232388496399
1559.1235953569412
174.30584025382996
79.59340190887451
61.89129030704498
471.7131540775299
810.3098645210266
0.0
1366.598240017891
0.0
0.0
0.0
107.25126051902771
239.62073892354965
262.038032412529
15.085880279541016
163.86628246307373
154.96656894683838
80.71517038345337
335.1553725004196
295.7948395013809
1410.8565112352371
663.1677606105804
513.1929392814636
102.76579856872559
0.0
656.6767234802246
51.008399963378906
33.97688055038452
630.1791815757751
283.22138810157776
231.9605894088745
1501.833188533783
103.18905359506607
213.81716853380203
369.23689234256744
1534.467435002327
62.72489035129547
49.97162055969238
82.30450093746185
170.21742987632751
57.824931144714355
268.835412979126
548.1209834814072
647.6211560964584
409.13795590400696
554.804360628128
427.4442081451416
10.082610130310059
54.04518914222717
1537.73357629776
517.5289993286133
28.98786973953247
124.47490310668945
307.53207874298096
1026.3957287073135
453.3260853290558
47.31458067893982
816.3303536176682
425.30054849386215
222.23295176029205
975.6931194067001
671.1479949951172
138.62084865570068
856.5531620979309
120.31626176834106
136.90907114744186
64.40601968765259
1464.4825276136398
118.4670078754425
10.296950101852417
188.2011432647705
20.76591944694519
55.769439697265625
0.0
218.146016061306
584.5057871341705
0.0
68.33994030952454
73.44817912578583
0.0
54.52376127243042
1159.4040197134018
0.0
820.2879853248596
1014.9452674388885
0.0
161.96502161026
20.23731029033661
0.0
384.06496930122375
671.9905849695206
0.0
495.6106059551239
149.85502994060516
355.3022029995918
121.65842139720917
240.0579913854599
153.62337923049927
2063.185901284218
1417.9398037195206
668.6110612154007
1430.7168152332306
2332.1803535223007
152.348450422287
371.46237874031067
403.89867997169495
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2     F0.5  \
0  0.995854   0.542373  0.761905  0.633663  0.704846  0.57554   

   Average Precision  
0           0.414357  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 53.674 seconds
Cross-validation score: 0.6872945931224906
Test score: 0.7126948775055679
Best Hyperparameters: {}
3363.254138946533
144936.36673164368
246391.71668338776
15920.891573905945
19412.75665831566
163.24363720417023
100.99251854419708
255.5433567762375
231.7598373889923
43.85210037231445
344.9525500535965
20.881500244140625
6098.311387002468
4274.884099841118
1382.280972123146
0.0
498.464723944664
0.0
159.8553512096405
7.279220223426819
8011.864901781082
2060.6886934041977
7165.2582840919495
151.30109918117523
157.17710733413696
22.530070185661316
127.24715089797974
185.93274974822998
9.05508017539978
341.6246418952942
47.424800872802734
17.19199013710022
390.94677901268005
223.17061948776245
63.736520409584045
363.4522497653961
968.1013543605804
52.583149671554565
40.46035075187683
195.9826601743698
83.72021007537842
0.0
0.0
0.0
446.3153781890869
431.99142467975616
1101.9236004948616
544.1026937961578
1194.8370356559753
202.64158844947815
131.7910122871399
110.21236777305603
969.4227741956711
1127.1142785549164
135.78799438476562
249.75409138202667
0.0
0.0
0.0
2505.160941362381
432.1578137874603
170.0187704563141
10.175769805908203
614.3281052112579
356.79738318920135
152.26700675487518
2280.483083963394
488.59814405441284
895.9145460128784
169.9825896024704
2141.0646238327026
57.6637020111084
152.50285232067108
211.83488249778748
51.603039383888245
446.59251749515533
481.04137420654297
94.64735126495361
397.80317783355713
2186.5919818878174
123.79837918281555
612.2375588417053
224.97235143184662
1590.1950244903564
423.4228299856186
40.344260454177856
162.9236297607422
122.79761838912964
38.4723014831543
399.8348424434662
174.81036496162415
929.6215400695801
176.91592359542847
77.96344041824341
560.131214261055
221.7900915145874
349.7794179916382
1582.9612013101578
374.8297880887985
86.58815789222717
29.895769357681274
138.97687029838562
2045.4669951200485
544.2707591056824
100.81791996955872
897.7467402219772
386.22579538822174
405.3200716972351
844.3293633460999
501.8694831132889
201.14780044555664
192.09735524654388
35.454689741134644
381.7815076112747
1.568310022354126
276.2312306165695
234.623579621315
7.540210008621216
479.7253555059433
123.35376107692719
232.80542254447937
0.0
338.2766534090042
191.61598992347717
0.0
357.9428924918175
312.0625219345093
0.0
26.5552396774292
1701.651918888092
0.0
964.1144306659698
793.1027112007141
0.0
425.604168176651
24.515119791030884
0.0
541.0308833122253
1820.9014612436295
0.0
348.79521131515503
519.9003188610077
470.94976341724396
45.59450018405914
236.6476080417633
534.7394847869873
3724.5651239156723
108.98064339160919
188.13296735286713
193.97391963005066
541.9347542524338
158.67648100852966
506.85950803756714
258.9807996749878
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.996134   0.566372  0.761905  0.649746  0.712695  0.597015   

   Average Precision  
0           0.432642  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 52.505 seconds
Cross-validation score: 0.7030159400477161
Test score: 0.6787330316742081
Best Hyperparameters: {}
2694.312331199646
154736.8475471735
235665.58253383636
13025.834511756897
25023.563223958015
52.305988788604736
287.0702414512634
282.0418083667755
698.3773438930511
104.24141895771027
828.7820372581482
60.60602951049805
4837.520389080048
2252.7978633642197
1213.6391987800598
0.0
943.2977247238159
0.0
20.98865020275116
79.01598167419434
12011.180002212524
582.6715377569199
6587.71846985817
2158.901060461998
66.12837994098663
55.67742991447449
144.25971066951752
372.48470520973206
58.3294403553009
975.9678559303284
220.6368796825409
1.4835000038146973
180.02729165554047
274.79138773679733
194.3382898569107
574.4073580503464
107.23038160800934
86.84707069396973
43.228880763053894
132.41615176200867
82.17312133312225
0.0
0.0
0.0
70.02870070934296
64.86579918861389
1019.0892397165298
229.04147148132324
319.9233899116516
247.63154006004333
3.5208499431610107
20.526560306549072
129.94362115859985
1689.0781594514847
0.0
318.05025255680084
0.0
0.0
0.0
756.3366097211838
751.5394545793533
143.19309961795807
2.111150026321411
489.74958848953247
154.70258784294128
80.85609042644501
1844.1655445098877
642.1978845596313
1478.9515618085861
549.1570016145706
342.80781412124634
83.75526213645935
15.885100245475769
450.3796235322952
315.2302477359772
28.741130828857422
2018.5731226205826
43.488879680633545
216.11786365509033
1468.972299695015
9.178839921951294
392.2086112499237
963.974534869194
2391.0357551574707
90.73589968681335
12.378299713134766
124.413649559021
115.23551964759827
15.916790127754211
61.35540986061096
369.7719428539276
918.052366733551
371.89699935913086
91.69268894195557
377.3257052898407
523.0641583204269
319.9496719837189
1859.9473301768303
418.1652271747589
123.76533782482147
60.89233100414276
269.41295289993286
1907.7373601198196
315.3353216648102
54.97716963291168
688.4617838859558
464.40755546092987
601.470826625824
699.2237572669983
817.2991189956665
345.2869563102722
192.7263501882553
646.6381068229675
165.65015268325806
10.047699928283691
221.96592164039612
178.99757957458496
64.7833616733551
735.8072360754013
28.815879940986633
47.92034995555878
0.0
374.212033867836
242.4559119939804
0.0
176.05983984470367
195.20947110652924
0.0
0.0
1479.8055721521378
0.0
600.6522827148438
684.9173150062561
0.0
539.507963180542
89.0266284942627
0.0
418.3982753753662
568.5080591440201
0.0
1925.587459564209
1393.8783462047577
639.6185171604156
115.92844951152802
158.40280973911285
180.9955314397812
3144.448375582695
426.6715189218521
261.634001493454
226.2582483291626
43.676730155944824
62.78756856918335
498.3294287919998
687.2655135393143
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.996078   0.566038  0.714286  0.631579  0.678733  0.590551   

   Average Precision  
0           0.405657  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 53.377 seconds
Cross-validation score: 0.6818558707159875
Test score: 0.7657657657657657
Best Hyperparameters: {}
1583.9369999170303
147166.37622964382
232860.88075959682
13651.502855539322
26962.25565457344
80.573211312294
494.08562779426575
154.67887008190155
115.57036101818085
283.2613376379013
1329.032060623169
0.0
9634.248098373413
2235.7380356788635
1341.7334599494934
0.0
495.2334070801735
0.0
120.921719789505
13.60657012462616
10150.205285072327
2439.270948767662
5312.677329540253
55.84843921661377
46.552650928497314
38.62742066383362
200.39102184772491
72.2330596446991
355.48049771785736
249.7367012500763
314.8822021484375
100.11362028121948
25.75842022895813
52.95682942867279
113.17580986022949
2975.6258521080017
1778.6246761083603
95.53069972991943
55.389259696006775
637.3270523548126
682.527280330658
0.0
0.0
0.0
1036.1065567731857
192.64520382881165
820.6118502616882
352.8629057407379
492.2294979095459
276.9775810241699
15.361730098724365
48.76132917404175
174.4025512933731
1302.1757714748383
0.0
745.4980419874191
0.0
0.0
0.0
115.85413944721222
554.6762311458588
152.57118964195251
16.05766010284424
851.571645617485
164.595397233963
46.11949062347412
6639.394406080246
423.63152408599854
1608.7229322195053
561.5275514125824
257.16606092453003
68.60647010803223
40.745500564575195
198.34496974945068
127.79276740550995
102.09902858734131
392.3705291748047
110.68832159042358
494.302419424057
1026.1371983289719
141.23574018478394
700.6950392723083
262.8996613025665
1784.2482149600983
108.53225934505463
49.57602095603943
68.39397168159485
263.03858709335327
0.0
76.4063800573349
203.74787151813507
390.5483692884445
766.495175242424
347.28110218048096
774.9486790895462
139.98834931850433
103.7034182548523
1926.6647719144821
608.5821753740311
145.22694158554077
42.83530139923096
416.9392731189728
1897.829360485077
461.29631888866425
26.454970359802246
839.1056880950928
358.84545826911926
339.50494134426117
643.1153254508972
449.7440506219864
1054.3233489990234
598.6897283792496
684.0318806171417
200.33695828914642
64.3941502571106
191.89582979679108
232.76087939739227
44.60790014266968
101.03830683231354
60.03039062023163
654.9772863388062
0.0
73.31170070171356
863.4005156755447
0.0
117.57845902442932
401.04037177562714
0.0
53.65600109100342
629.9762500524521
0.0
910.3833174705505
1123.2784950733185
0.0
99.76339983940125
108.28545808792114
0.0
100.53157091140747
1237.779309630394
0.0
41.96004867553711
91.31443011760712
177.7280306816101
62.81049919128418
627.9639650583267
197.45390963554382
3991.8452463150024
94.68151986598969
605.4098507761955
1386.1376008987427
1310.6450701355934
99.43614864349365
346.7885024547577
256.2190862298012
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.996862    0.62963  0.809524  0.708333  0.765766  0.658915   

   Average Precision  
0           0.510597  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 52.552 seconds
Cross-validation score: 0.7030583971070905
Test score: 0.6853932584269662
Best Hyperparameters: {}
2921.0482711195946
145030.30646407604
238331.43130338192
12567.454047322273
26206.10315811634
44.12788128852844
22.33662986755371
320.92982918024063
647.5715218186378
97.65153980255127
894.6199526786804
50.487098693847656
3021.5654208660126
10716.207043588161
393.34558242559433
0.0
876.3506315946579
0.0
271.10294902324677
26.29302978515625
12224.096574664116
4699.3448650836945
5988.166982412338
1702.448897242546
173.82756316661835
15.688460350036621
130.59242844581604
115.03209972381592
25.376410961151123
225.87648165225983
68.27977919578552
52.83826208114624
56.157631158828735
378.03390830755234
165.36892473697662
4117.428367614746
893.4048186540604
99.96071946620941
92.18248093128204
414.0947787761688
43.41489666700363
0.0
0.0
0.0
599.821927189827
974.7006152868271
296.11260282993317
742.6183257102966
114.53959226608276
73.8220043182373
103.29342186450958
187.63594150543213
131.74768042564392
1498.8079133033752
2.5485100746154785
590.1469124555588
0.0
0.0
0.0
565.6539214849472
350.63530802726746
270.49341809749603
0.0
1101.4582526683807
61.24640882015228
42.15362823009491
3281.518584728241
946.0961997509003
1121.2148844003677
427.0360976457596
162.60734069347382
25.680859923362732
70.33903002738953
153.54343056678772
89.26542067527771
35.61011075973511
1420.2200628519058
36.955660820007324
211.2457721233368
1191.0897544622421
66.84264081716537
288.32831943035126
770.156963467598
1330.2355662584305
63.84385919570923
54.429710149765015
365.4515526294708
336.31489086151123
16.27050018310547
201.45184993743896
127.72976899147034
231.09912049770355
283.80132937431335
687.9808366298676
388.2206246852875
1403.2126579284668
151.08753275871277
877.9581071138382
286.17659068107605
220.51356101036072
215.39537000656128
1007.1168931722641
1564.286248922348
383.18035864830017
47.8007493019104
480.30706906318665
118.57154649496078
202.1517709493637
1131.717450618744
590.6972997188568
605.0484013557434
558.2606095075607
47.197630882263184
551.9647054076195
47.89776021242142
186.82240283489227
249.78132331371307
0.0
147.86927843093872
103.39495921134949
176.33684301376343
0.0
130.33451068401337
325.8838609457016
0.0
56.23708987236023
133.12127077579498
0.0
13.130930185317993
1037.716200530529
0.0
786.5581964254379
891.9249514341354
0.0
21.360639810562134
53.69241988658905
0.0
138.86987668275833
600.4969017505646
0.0
76.61920142173767
0.0
150.3280680179596
461.52170300483704
1250.1631335616112
104.15112179517746
1148.9057294130325
36.5567307472229
543.6478364467621
121.35580956935883
73.97384011745453
76.07103300094604
88.81884253025055
1199.3061084747314
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision   Recall        F1        F2      F0.5  \
0  0.996022   0.559633  0.72619  0.632124  0.685393  0.586538   

   Average Precision  
0           0.407689  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 52.914 seconds
Cross-validation score: 0.697145128409703
Test score: 0.6791569086651054
Best Hyperparameters: {}
2733.692200422287
131434.96887171268
265582.89460885525
21384.72321641445
14357.560204863548
312.2440838813782
68.0671101808548
1664.198456287384
97.4188392162323
113.31291091442108
1280.8843874931335
30.94844949245453
5197.815178394318
1851.35462808609
1486.687764763832
0.0
730.9276151657104
0.0
121.76761996746063
16.51191997528076
7009.42676448822
1742.174318432808
3815.653604745865
4889.5514315366745
223.51061487197876
109.78137230873108
17.724849820137024
21.24404001235962
30.420950412750244
63.47283065319061
56.30179977416992
111.41862738132477
81.79707884788513
139.22666037082672
33.70522928237915
1000.7732102870941
316.18083095550537
26.70221984386444
142.88979172706604
347.9286346435547
243.331538438797
0.0
0.0
0.0
600.0237641334534
128.29937171936035
413.0151352882385
294.8711527585983
338.0434910058975
422.42704021930695
42.64738893508911
92.78822898864746
753.8113044500351
1066.0295498371124
312.1500015258789
338.4957183599472
0.0
0.0
0.0
179.02809953689575
280.78649616241455
316.76665711402893
3.0473300218582153
340.63161158561707
267.7424750328064
19.99226999282837
2222.070329785347
812.5240355730057
2008.2916773557663
870.8151860237122
436.28669118881226
273.86430072784424
63.57441997528076
197.32423055171967
186.89859771728516
4350.13382267952
913.8888640403748
93.66743898391724
173.7517125606537
1536.237783074379
158.92766332626343
338.5258215665817
1352.3545258045197
1935.9582690000534
433.58504700660706
39.467090129852295
181.45993030071259
195.01201224327087
8.803699970245361
64.21279072761536
288.76495110988617
603.4443538188934
345.57472002506256
482.9593027830124
580.3330307006836
792.0076205730438
138.37336099147797
774.9225982427597
689.9881640672684
52.65569877624512
34.02204990386963
124.63180017471313
691.1480263471603
264.9428884983063
26.923980116844177
840.0408769845963
281.44823014736176
208.71464133262634
244.12365078926086
692.3187973499298
1222.0550737380981
974.1974552869797
306.5543817281723
260.9766228199005
11.944370150566101
328.52645659446716
206.45908045768738
44.958730697631836
405.0543305873871
66.73277962207794
60.83339023590088
0.0
269.0594892501831
429.3315335512161
0.0
214.82110905647278
101.3282401561737
0.0
7.1239399909973145
1939.2899882793427
0.0
1123.309716463089
1188.5903940200806
0.0
521.7283767461777
29.36479091644287
0.0
41.09343898296356
953.2629860639572
0.0
57.4952996969223
665.6288032531738
447.5359184741974
150.17872071266174
85.80008161067963
228.1781280040741
631.8831300735474
296.96271300315857
188.90129792690277
382.22415685653687
381.0581798553467
101.53834986686707
378.00743424892426
139.36063075065613
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.996694   0.637363  0.690476  0.662857  0.679157  0.647321   

   Average Precision  
0           0.441541  

--------------------------------------------------------------------
