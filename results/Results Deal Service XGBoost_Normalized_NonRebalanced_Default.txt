[21:14:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 238.315 seconds
Cross-validation score: 0.7241761810003734
Test score: 0.821917808219178
Best Hyperparameters: {}
0.011545261
0.042109087
0.032460194
0.024023259
0.0100542875
0.0045275493
0.0030212882
0.0059053823
0.0091303885
0.0065027256
0.0007432478
0.0048113815
0.009638354
0.010979719
0.01502928
0.0
0.002372097
0.0
0.0046250327
0.004705933
0.015802005
0.027294233
0.005683826
0.014449548
0.006846238
0.0036342167
0.0061118365
0.0034851483
0.007526563
0.006704447
0.029717837
0.009913791
0.00582257
0.013796611
0.0033609648
0.001321584
0.0057914066
0.0048695477
0.0025316654
0.00083743694
0.005214792
0.0
0.0
0.0
0.014612653
0.0
0.0050056544
0.0051711123
0.007638311
0.010318373
0.0077581764
0.0
0.0025656945
0.01093504
0.0
0.0050930907
0.0
0.0
0.0
0.0058888085
0.006041138
0.0038697713
0.007796024
0.0037833792
0.005315259
0.01466019
0.008159077
0.008456726
0.008173017
0.009864982
0.00364454
0.0045919903
0.004773589
0.0013397434
0.008454562
0.014462668
0.012776283
0.0048662885
0.0053616753
0.00061845896
0.01108794
0.0036596358
0.0062580556
0.010596911
0.00695405
0.0019410539
0.006779281
0.0016420152
0.007667763
0.007102211
0.0026623649
0.0019045981
0.0049079554
0.010269054
0.010206144
0.0032071318
0.00884126
0.0017642917
0.0063300948
0.0
0.0014424823
0.0122413635
0.008432558
0.0
0.0037504078
0.013185497
0.0043425355
0.004421047
0.006537594
0.009087216
0.017077904
0.015808731
0.007885049
0.0042845854
0.00718937
0.001578595
0.007397759
0.0019036563
0.008149149
0.006362453
0.008514812
0.0
0.0034885271
0.0043402174
0.0
0.004062498
0.0024907396
0.0
0.0022849133
0.008707699
0.0
0.0029241247
0.008034571
0.0
0.016699538
0.004228275
0.0
0.00062751165
0.0071785985
0.0
0.009511716
0.0033520262
0.0015182848
0.0053491346
0.003340801
0.006962497
0.002733285
0.0
0.0059711034
0.002325954
0.0145170195
0.00058301137
0.00484298
0.015653433
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997759   0.923077  0.571429  0.705882  0.618557  0.821918   

   Average Precision  
0            0.52949  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[21:18:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 237.733 seconds
Cross-validation score: 0.7529669362532648
Test score: 0.7666666666666667
Best Hyperparameters: {}
0.009238725
0.038860288
0.043835547
0.023601266
0.010081226
0.004392968
0.00335974
0.0056575355
0.0045662895
0.0038216566
0.011503378
0.002624296
0.014389529
0.012071551
0.013388372
0.0
0.0041380706
0.0
0.0018081787
0.007975556
0.0148659535
0.034877885
0.0039521805
0.010386786
0.0055537974
0.0033023106
0.00793298
0.006712034
0.0058057667
0.005592005
0.02106405
0.00256945
0.0024021962
0.012239389
0.0034775725
0.00348534
0.0
0.0077978056
0.0045013935
0.0047335983
0.006357554
0.0
0.0
0.0
0.0011290712
0.01082924
0.0095065795
0.009691108
0.02657144
0.010619377
0.007791456
0.0
0.0053941486
0.006217726
0.0
0.0070032184
0.0
0.0
0.0
0.0047107353
0.005998634
0.0035724146
0.0008754837
0.0060218223
0.0048498036
0.009901182
0.0068739927
0.008816884
0.0065567857
0.0111398725
0.004324765
0.0089151105
0.0018341733
0.006115815
0.01985896
0.013069604
0.00950178
0.008694309
0.0018436327
0.001714709
0.0050047887
0.0050334893
0.0051274607
0.00054748467
0.0023221252
0.0007665923
0.0031782377
0.0
0.006157928
0.0027525474
0.0073902286
0.0016311763
0.0035936895
0.0038279386
0.011719527
0.0035891822
0.0009429073
0.0057550967
0.0032924563
0.0
0.003116713
0.00599704
0.006275394
0.0
0.006179116
0.01562571
0.0031701066
0.0015184421
0.014170763
0.009985525
0.0119117545
0.014082466
0.0065463316
0.004233699
0.0052087293
0.0047949958
0.0058459556
0.008279095
0.008182096
0.018949829
0.0074427933
0.0
0.0045076865
0.0029662873
0.0
0.0055017355
0.0043554828
0.0
0.0
0.00892909
0.0
0.0060695275
0.0070736986
0.0
0.00023966271
0.003002928
0.0
0.0041832365
0.009108925
0.0
0.0051256367
0.0034511855
0.0025889555
0.00343763
0.0071729524
0.0117453495
0.00501643
0.007817289
0.009170986
0.0030122614
0.005468009
0.0
0.010120929
0.012916653
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997423   0.851852  0.547619  0.666667  0.589744  0.766667   

   Average Precision  
0            0.46862  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[21:22:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 236.129 seconds
Cross-validation score: 0.7726055732262597
Test score: 0.7407407407407408
Best Hyperparameters: {}
0.007576944
0.04186577
0.030839203
0.01985095
0.008006854
0.0044342047
0.002954255
0.009901637
0.006960442
0.0049178074
0.013214669
0.0051943436
0.013097185
0.009817367
0.01222059
0.0
0.0075675864
0.0
0.007233262
0.0035291004
0.025861936
0.018914126
0.004446535
0.009682803
0.00975913
0.00796073
0.0037920687
0.0018724478
0.008707757
0.0036887552
0.012599639
0.023729553
0.0051559582
0.00901128
0.0068139634
0.0048844246
0.0067228964
0.0034976066
0.0023809874
0.005424428
0.0030540193
0.0
0.0
0.0
0.011373921
0.0
0.0115230465
0.009133741
0.00035611293
0.0115196835
0.03383893
0.0
0.0035526976
0.006658075
0.0
0.009478712
0.0
0.0
0.0
0.0051766336
0.004157157
0.0019418881
0.005434114
0.0015370846
0.0073115216
0.0076075783
0.004409917
0.006582741
0.007814411
0.0057664947
0.0024439467
0.0014781376
0.005888692
0.002338298
0.009445144
0.013874429
0.00920197
0.005668032
0.006032585
0.02186632
0.007724921
0.00658021
0.004475802
0.009815368
0.0028220501
0.0014551843
0.004402476
0.0
0.0008917636
0.00884925
0.0054977834
0.0014246907
0.0079478035
0.008522284
0.012023749
0.005233419
0.0019603982
0.002515284
0.009538949
0.0004310586
0.005285209
0.00748541
0.010751155
0.0
0.0050108163
0.01074631
0.003194818
0.0053692367
0.0060178977
0.010218621
0.030126834
0.008832841
0.0085816365
0.0035241658
0.0040708347
0.005804481
0.0071826708
0.0011743065
0.010041321
0.0018781878
0.0061047995
0.0
0.004273802
0.0043094466
0.0
0.0035524482
0.0026724199
0.0
0.0
0.012865781
0.0
0.004238132
0.009785489
0.0
0.001386802
0.0011365799
0.0
0.0007487825
0.0068417117
0.0
0.0023957693
0.003327888
0.0023468079
0.0010886526
0.004627635
0.009603845
0.0032552218
0.0041411067
0.0068298825
0.0036050645
0.010092736
0.0027433499
0.0069094975
0.013151824
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0   0.99731        0.8  0.571429  0.666667  0.606061  0.740741   

   Average Precision  
0            0.45916  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[21:26:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 240.281 seconds
Cross-validation score: 0.7426579118334623
Test score: 0.8189655172413792
Best Hyperparameters: {}
0.009026002
0.045625895
0.042712588
0.022082685
0.0073393546
0.0049579567
0.003744831
0.01090195
0.008106742
0.0016400488
0.0102044875
0.0026021653
0.009727009
0.009547739
0.007956301
0.0
0.00291962
0.0
0.003399823
0.0053814845
0.022152126
0.02438723
0.0038426952
0.01384514
0.0037197338
0.0047548986
0.0055257436
0.005179752
0.0023939852
0.005023672
0.0062145316
0.005452348
0.0075310096
0.011303604
0.005257029
0.00523882
0.0011791596
0.013886787
0.004483004
0.0027249658
0.005211229
0.0
0.0
0.0
0.0022364769
0.011804292
0.011994061
0.0035504892
0.0
0.0059832907
0.004463992
0.0006981171
0.0034762854
0.008873273
0.0
0.005436011
0.0
0.0
0.0
0.0055175484
0.0041433307
0.0028121755
0.014959866
0.0043279845
0.0062052696
0.0016245036
0.009301514
0.0061385976
0.006068545
0.008038545
0.00861139
0.012616966
0.0014134273
0.0028689213
0.0060794908
0.010044268
0.010797839
0.0053144163
0.007634169
0.0
0.0031856783
0.002826341
0.0040949634
0.017274618
0.005489172
0.0033185466
0.0044779917
0.00048688578
0.009186484
0.0044850954
0.014708376
0.0013428169
0.009421709
0.0057100873
0.013441316
0.0015107826
0.006413556
0.0040547145
0.0074958783
0.0041032736
0.0055883867
0.009792758
0.0064285602
0.0
0.0077077285
0.0003653584
0.002121837
0.0043232474
0.0031490673
0.00927986
0.0110128755
0.0048054033
0.010060464
0.0033801228
0.0039122757
0.0017565157
0.009737338
0.0006382434
0.006136083
0.0040965076
0.00626359
0.0
0.0051960195
0.0040979316
0.0
0.0030982739
0.0026204928
0.0
0.025735715
0.017472968
0.0
0.005524174
0.010370735
0.0
0.0010939199
0.011714114
0.0
0.00094144535
0.005333568
0.0
0.006944922
0.008155347
0.0043054908
0.0034207816
0.0025991506
0.0050829253
0.010831187
0.0
0.006835897
0.0076945988
0.022926074
0.0064012804
0.009620098
0.018179163
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall    F1        F2      F0.5  Average Precision
0  0.997983   0.863636  0.678571  0.76  0.708955  0.818966           0.587552

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[21:30:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 234.940 seconds
Cross-validation score: 0.7719840444670948
Test score: 0.8059210526315789
Best Hyperparameters: {}
0.012045181
0.03429093
0.03249447
0.022385323
0.006408899
0.0056514884
0.0033415623
0.009856705
0.007896958
0.0030637481
0.0077007916
0.0018062243
0.0104989
0.009893627
0.011510258
0.0
0.0037132872
0.0
0.0030675002
0.002913478
0.02538104
0.010738128
0.0041004103
0.013310694
0.0023953768
0.001720036
0.0066335304
0.0042909826
0.038499665
0.0070611625
0.0076991147
0.009137014
0.0032477314
0.009525347
0.0062188334
0.001460049
0.0023141005
0.0039633736
0.0026771922
0.0012568206
0.0034351996
0.0
0.0
0.0
0.010462981
0.03180757
0.00983235
0.0043243095
0.003226094
0.0036484096
0.001604003
0.0
0.004356948
0.008646477
0.0
0.009354732
0.0
0.0
0.0
0.0036183328
0.00424301
0.0027464854
0.012050172
0.0
0.00662971
0.019498484
0.007834247
0.0052531534
0.006715842
0.0051203314
0.0009757639
0.022393847
0.002533072
0.0018026421
0.008650842
0.035558186
0.010674062
0.0023002434
0.004648252
0.00045611127
0.008954165
0.0035183618
0.003372261
0.0009191259
0.0035215355
0.0022014682
0.0049704816
0.0
0.002141865
0.0071311616
0.0036218371
0.0
0.0048504896
0.0036964978
0.013176221
0.0047190012
0.0123955235
0.0045426413
0.011329749
8.563937e-05
0.0007432724
0.004076917
0.004154667
0.0
0.0064335205
0.0102935145
0.0035029084
0.0034775583
0.010920687
0.006574875
0.008877424
0.0023393282
0.0057055755
0.002638892
0.0011039277
0.0010362812
0.00839284
0.02275044
0.009139144
0.0066871434
0.004290255
0.0
0.00406368
0.0056659346
0.0
0.0019442503
0.0033074478
0.0
0.008908957
0.008330751
0.0
0.0048758644
0.00396434
0.0
0.016428309
0.0018535446
0.0
0.034204975
0.006781061
0.0
0.004278947
0.0047835107
0.0027060495
0.0039105066
0.0020122326
0.007027975
0.0044886554
0.01696263
0.006387526
0.0025548479
0.011736754
0.0
0.007174949
0.002787347
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997703   0.890909  0.583333  0.705036  0.626598  0.805921   

   Average Precision  
0           0.521658  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[21:34:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 238.749 seconds
Cross-validation score: 0.7527193726261281
Test score: 0.8388157894736843
Best Hyperparameters: {}
0.0094743315
0.0422937
0.036421318
0.027135376
0.011909982
0.0038752959
0.0031944788
0.00700044
0.005054274
0.012630226
0.018778415
0.0033942237
0.010852825
0.011495513
0.01360406
0.0
0.004497877
0.0
0.004640628
0.0039487174
0.020264372
0.040999234
0.006510315
0.018953066
0.004414772
0.0037750315
0.006652563
0.008154327
0.010245131
0.006004436
0.0014880572
0.0014911229
0.012479668
0.006845217
0.0052915993
0.0046147187
0.011725499
0.011081815
0.0023652627
0.001007251
0.003916811
0.0
0.0
0.0
0.009159564
0.0
0.011115226
0.0076728975
0.0027081813
0.004190605
0.0017486415
0.0
0.010243265
0.010153467
0.0
0.008339327
0.0
0.0
0.0
0.004567374
0.0051571587
0.0049518268
0.006377853
0.0007885666
0.0036284144
0.0056038946
0.0023630427
0.009685895
0.0042293444
0.0094232205
0.005555612
0.010394222
0.0030772374
0.0029392417
0.0061773867
0.014921066
0.012140456
0.004281595
0.0024651804
0.00540078
0.007589249
0.006813423
0.0068436447
0.0
0.005258299
0.0014109821
0.003960065
0.0
0.0035019168
0.009485985
0.00961639
0.0
0.0038102851
0.0064597167
0.011568829
0.004364637
0.007987927
0.0018955282
0.008630442
0.0060246657
0.008286662
0.008666327
0.012707434
0.00091602403
0.00881752
0.0037302347
0.002686518
0.0056349398
0.0044579953
0.0033286456
0.005128278
0.017193127
0.0038706034
0.0031638658
0.00054344715
0.004095007
0.0040020705
0.009357715
0.0047876113
0.008442335
0.0070195636
0.0
0.0053357463
0.0023667451
0.0
0.0027226629
0.004197217
0.0
0.0020855323
0.012156522
0.0
0.008069713
0.0090314215
0.0
0.0013161155
0.00056308345
0.0
0.007274649
0.007740742
0.0
0.0051080924
0.0013709841
0.0047618574
0.0054346384
0.003979992
0.009003741
0.017411971
0.0
0.008138
0.015597001
0.0079433825
0.0
0.011795025
0.006594701
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997927   0.927273  0.607143  0.733813  0.652174  0.838816   

   Average Precision  
0           0.564836  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[21:38:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 234.212 seconds
Cross-validation score: 0.777233322140633
Test score: 0.7401315789473684
Best Hyperparameters: {}
0.00977925
0.039619055
0.0319911
0.02636575
0.0066966205
0.0073311278
0.004183823
0.01415195
0.0
0.0014007455
0.0068578827
0.0011155849
0.015691735
0.010428494
0.014843094
0.0
0.0066487268
0.0
0.0031721394
0.005516678
0.017714342
0.017098334
0.0044374177
0.012157779
0.0017865741
0.0054186736
0.008399482
0.0081247995
0.0049166023
0.0044988655
0.020255094
0.014698256
0.001054984
0.0064448416
0.006290163
0.0037367814
0.0042941184
0.010810834
0.0062097334
0.004445193
0.0028801472
0.0
0.0
0.0
0.022596562
0.0
0.010947027
0.007243562
0.0021557647
0.008618829
0.0011394412
0.0010009189
0.010988632
0.010253004
0.0
0.0075333905
0.0
0.0
0.0
0.0050665806
0.005871496
0.0018571822
0.0035012406
0.0013687887
0.004563872
0.012647266
0.009272654
0.009835601
0.008041877
0.004232228
0.008236911
0.012444603
0.00079812214
0.008438275
0.008816663
0.012545335
0.007837517
0.0010016665
0.0029497244
0.0031248734
0.0059521403
0.003110208
0.0042326935
0.015222191
0.0026007025
0.0072044423
0.0041999267
0.0
0.001686805
0.007414071
0.015612312
0.0
0.0030079228
0.004252836
0.011504987
0.00645697
0.008408252
0.0049239607
0.008360462
0.009047382
0.0025232842
0.006229227
0.010886718
0.0
0.002212856
0.0074725496
0.0018048503
0.008668053
0.009691533
0.012370079
0.0036645704
0.018830938
0.0065508834
0.003036051
0.0033566786
0.0006513513
0.008592672
0.016426377
0.007922366
0.0012286482
0.0018885828
0.0
0.002006356
0.0048980503
0.0
0.0020178151
0.0035848136
0.0
0.0026871588
0.010895264
0.0
0.0052498654
0.003689415
0.0
0.018857064
0.0036914821
0.0
0.0076715993
0.004883162
0.0
0.0061327317
0.0027702558
0.004223038
0.0033899196
0.005643191
0.0073281135
0.011145437
0.013264081
0.008129338
0.0055236737
0.009117163
0.0
0.005088511
0.004509615
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997254   0.818182  0.535714  0.647482  0.575448  0.740132   

   Average Precision  
0           0.440497  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\metrics\_plot\precision_recall_curve.py:125: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots()
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[21:42:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 233.859 seconds
Cross-validation score: 0.7532502391658553
Test score: 0.7666666666666667
Best Hyperparameters: {}
0.010503417
0.037413273
0.035597734
0.026621496
0.013948199
0.0049398923
0.00810508
0.008177729
0.0023079317
0.0057069296
0.0034875853
0.0020947375
0.009277761
0.00884061
0.007352341
0.0
0.0030560526
0.0
0.0026388427
0.0043077343
0.019554706
0.032339904
0.0072938115
0.017710734
0.0010091715
0.0008723892
0.009896608
0.008004374
0.0022745633
0.0
0.027238168
0.0006091684
0.0055967052
0.0051828506
0.0066817557
0.0022602633
0.016773986
0.008173648
0.003284427
0.00799916
0.003491088
0.0
0.0
0.0
0.012304261
0.0010854388
0.003960182
0.0061346777
0.0010277214
0.009069753
0.0052689468
0.0053095263
0.0023846845
0.009461253
0.008899408
0.013282255
0.0
0.0
0.0
0.0038307356
0.007126222
0.005853185
0.012481116
0.0030695687
0.0054385015
0.0054895887
0.005610208
0.0086507285
0.009254601
0.011994896
0.0053612012
0.014603407
0.00057219976
0.006487416
0.020295866
0.023557188
0.010690675
0.006462705
0.004279914
0.0
0.0077418024
0.00507964
0.0046774843
0.0033081372
0.0020677147
0.0015072457
0.0072131655
0.0
0.002567208
0.0022143463
0.006090974
0.0049512996
0.0073463665
0.006149754
0.008092684
0.0064416253
0.008824105
0.003288972
0.0077375458
0.0008978144
0.0041687954
0.009215238
0.004695529
0.0
0.0031443092
0.0027804268
0.0028561905
0.0028347704
0.009472013
0.011407368
0.008319809
0.012583488
0.0055320547
0.005206257
0.0072838436
0.0055314456
0.006703696
0.012763817
0.0074547757
0.013259374
0.005688684
0.0
0.00240736
0.0014717607
0.0
0.0022972682
0.003808031
0.0
0.0014495238
0.013465996
0.0
0.00824747
0.0044613644
0.0
0.0010734131
0.005406302
0.0
0.008603867
0.0023647377
0.0
0.0055080377
0.006054809
0.0042981035
0.003992922
0.004657236
0.011259167
0.0072392332
0.0
0.01148903
0.005462788
0.005492017
0.001073812
0.010551572
0.0008414927
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997423   0.851852  0.547619  0.666667  0.589744  0.766667   

   Average Precision  
0            0.46862  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[21:46:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 246.533 seconds
Cross-validation score: 0.765478087386412
Test score: 0.7765151515151515
Best Hyperparameters: {}
0.0069652917
0.03621106
0.037744667
0.024440581
0.010457708
0.008698391
0.008309198
0.011828626
0.0011880773
0.0027885383
0.016114997
0.002351341
0.0102363
0.0148702115
0.008417688
0.0
0.0019841122
0.0
0.0030462313
0.0030617153
0.020987445
0.021822358
0.0029278188
0.009997598
0.00048654142
0.0027361696
0.0057005654
0.009678029
0.003351778
0.005339248
0.00047433225
0.0023363295
0.006484067
0.00980743
0.0041896664
0.008158763
0.0053972295
0.0041501
0.0032548443
0.0034618443
0.003527433
0.0
0.0
0.0
0.017879114
0.0
0.00772704
0.008850062
0.0
0.0057150386
0.027657876
0.0
0.0070735724
0.008690711
0.0
0.00894913
0.0
0.0
0.0
0.0043259575
0.005894605
0.004696773
0.012429345
0.00094723096
0.008322255
0.0032724058
0.006320043
0.0069319243
0.008148688
0.0048911776
0.001768263
0.01760637
0.008098508
0.0028003622
0.0039346255
0.02202515
0.0100693535
0.005789261
0.005853516
0.0027631863
0.008039538
0.004172464
0.004817222
0.0043834555
0.0054508047
0.009502078
0.0056508672
0.0
0.0027815143
0.010127609
0.0033003918
0.0054329727
0.007733185
0.011959373
0.012205954
0.004668096
0.0086647635
0.004535348
0.014632452
0.00050759333
0.0059909564
0.0039468464
0.0048559085
0.0012834566
0.011553403
0.011634365
0.0056845103
0.0071471715
0.008864032
0.0104353
0.016835006
0.0049996423
0.009940329
0.0029373893
0.0028550373
0.00063451746
0.006201896
0.0011728628
0.0044405656
0.0016073161
0.0037265008
0.0
0.0056060795
0.0030260375
0.0
0.0040052184
0.003351768
0.0
0.0024340602
0.011891729
0.0
0.010141998
0.010155264
0.0
0.016638856
0.0016620145
0.0
0.0016563905
0.0071856314
0.0
0.003971156
0.002387308
0.00492972
0.0023747159
0.0012276568
0.003476424
0.012422601
0.008452714
0.0031521744
0.007849483
0.011950716
0.0017108591
0.0040574893
0.016553337
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997367   0.911111  0.488095  0.635659  0.538058  0.776515   

   Average Precision  
0           0.447118  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[21:50:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 236.793 seconds
Cross-validation score: 0.7747117197974607
Test score: 0.71875
Best Hyperparameters: {}
0.009685482
0.043815225
0.03311933
0.023115562
0.0147134885
0.0033191203
0.004934986
0.007843942
0.0064141154
0.0033716548
0.010826889
0.001215436
0.015225032
0.008208574
0.008299368
0.0
0.0057073766
0.0
0.004557125
0.00848013
0.023611361
0.014636684
0.006072724
0.017418806
0.004354031
0.0045523103
0.0077338032
0.0045353267
0.0024838326
0.0080934595
0.03169911
0.001955493
0.0019275886
0.012855277
0.0057863984
0.0026829815
0.014958887
0.0065672845
0.006166117
0.0033544998
0.004591606
0.0
0.0
0.0
0.0035194193
0.007781373
0.010502554
0.010536097
0.0063607683
0.0028782669
0.011658916
0.00080660736
0.0030591048
0.0111415805
0.0
0.005012443
0.0
0.0
0.0
0.003735083
0.0052189054
0.0062412093
0.010942965
0.0005643234
0.0042643636
0.006755599
0.0065255505
0.007796215
0.0040576304
0.0040449062
0.0065563694
0.0116298525
0.00824818
0.0048406688
0.01129286
0.00784406
0.013489744
0.008431527
0.0033668173
0.00055777305
0.0016035654
0.0029202555
0.0064842575
0.002770383
0.00477269
0.00086404086
0.004916866
0.0
0.0030429587
0.007115071
0.0042189835
0.0
0.004001296
0.006843752
0.013948521
0.015045856
0.0076742386
0.0033486283
0.010412027
0.00022891248
0.0044352845
0.0036752403
0.010402187
0.0003910608
0.005055737
0.0071418947
0.003492794
0.0061701774
0.0052940804
0.008807378
0.00027473463
0.0069189053
0.0069514266
0.0053945687
0.0020763576
0.0009123459
0.008358723
0.0025954838
0.005365693
0.014410014
0.003139186
0.0
0.0032972232
0.001628884
0.0
0.0049263206
0.006046855
0.0
0.0006224252
0.008326375
0.0
0.005143901
0.007266923
0.0
0.0007933438
0.0029865764
0.0
0.0049963086
0.00426905
0.0
0.006361571
0.0027475618
0.0039731585
0.002041992
0.00497852
0.008765946
0.004109465
0.012008594
0.0068436824
0.018131265
0.020599255
0.0
0.0072260736
0.031880975
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2     F0.5  \
0  0.997142   0.779661  0.547619  0.643357  0.582278  0.71875   

   Average Precision  
0           0.429086  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[21:54:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 240.319 seconds
Cross-validation score: 0.7575474744645417
Test score: 0.7716049382716049
Best Hyperparameters: {}
0.008728056
0.039260115
0.03232463
0.021813935
0.010969422
0.0078576915
0.016454676
0.007705561
0.0027473124
0.00669731
0.013782366
0.0022105887
0.010659094
0.010021201
0.011229521
0.0
0.0062560663
0.0
0.001955147
0.0046455166
0.017974004
0.009090406
0.0045343554
0.017016988
0.0041826554
0.0015827834
0.004092704
0.0052022077
0.002388358
0.007599078
0.038004905
0.0022142942
0.0014432583
0.008850282
0.003923251
0.0051418752
0.0028206704
0.006547405
0.004935198
0.003462638
0.003672071
0.0
0.0
0.0
0.008937739
0.0006472043
0.007519683
0.0069032316
0.0
0.005589215
0.002940463
0.0
0.00285651
0.010337016
0.0
0.008336576
0.0
0.0
0.0
0.0015343424
0.0045558624
0.0036385295
0.017064393
0.013302211
0.003937347
0.0054451893
0.007879355
0.007831761
0.0070478
0.0047683455
0.00093703356
0.00874213
0.01543251
0.0036854486
0.010417783
0.020342853
0.015003384
0.0067989915
0.0048829997
0.0
0.0047276844
0.0031888576
0.009040635
0.0
0.0031434062
0.01100335
0.0054829866
0.0
0.0007838572
0.0030354767
0.0076705464
0.0
0.0059077577
0.005584593
0.012860111
0.0050305445
0.013142425
0.002937342
0.007991773
0.009439514
0.004554453
0.01145541
0.005595462
0.028860731
0.008120899
0.007046244
0.0035147048
0.0029076098
0.025201704
0.010672654
0.01636982
0.014532379
0.008353098
0.0036251012
0.00715779
0.002952709
0.0073575685
0.00096005265
0.0050223772
0.0039180866
0.003445892
0.0
0.0026838288
0.0023889835
0.0
0.0038019505
0.005925059
0.0
0.0019652785
0.0084035685
0.0
0.007824884
0.0060725077
0.0
0.004843652
0.005600728
0.0
0.0045128027
0.0041017374
0.0
0.0032419222
0.002095873
0.0029838088
0.005447624
0.0032276837
0.0069114775
0.0077012554
0.0008039606
0.0055304845
0.0016525899
0.014355962
0.0013318695
0.006681355
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997535   0.833333  0.595238  0.694444  0.631313  0.771605   

   Average Precision  
0           0.497937  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[21:58:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 236.938 seconds
Cross-validation score: 0.7491222976765749
Test score: 0.7720588235294118
Best Hyperparameters: {}
0.008242885
0.047411032
0.035964664
0.031025995
0.010379853
0.005913444
0.006276181
0.0051223114
0.005595115
0.0072319284
0.008264074
0.0014569453
0.012357809
0.0097228745
0.014334571
0.0
0.0041925088
0.0
0.0037122224
0.0015169319
0.02356428
0.019875297
0.0076932325
0.012270713
0.0028286835
0.0047602965
0.0033168828
0.0045447517
0.004413119
0.0024386093
0.025562173
0.0018591601
0.0038780754
0.011544389
0.0049757836
0.0042743343
0.004181824
0.009547788
0.0046832077
0.0037535783
0.0022146078
0.0
0.0
0.0
0.01394339
0.0
0.01092425
0.004156229
0.008670118
0.01317196
0.00501355
0.0
0.004540543
0.010897174
0.0
0.0105771795
0.0
0.0
0.0
0.0031542068
0.006412453
0.0031833912
0.007960389
0.0035410698
0.004539923
0.0036907082
0.0115711
0.0051037488
0.005476375
0.005442671
0.006600878
0.0079915635
0.0019676748
0.009571849
0.008843376
0.025416788
0.010557054
0.0073330305
0.0055951574
0.0
0.0031100812
0.003683687
0.00767134
0.013594691
0.0054639457
0.0051883603
0.0057629785
0.0
0.0011722374
0.0030791173
0.005984538
0.0006223758
0.006279352
0.01295804
0.01666204
0.0050574294
0.0010588658
0.003359526
0.012179244
0.0022202088
0.0046084686
0.005528797
0.0057280203
0.012537146
0.0052084094
0.0050589857
0.0045731906
0.0055717006
0.0030120278
0.0047336454
0.018387388
0.0036150024
0.00911463
0.0038015852
0.0045038857
0.0017412379
0.006974195
0.0091168415
0.010694803
0.021177923
0.004069734
0.0
0.0036734254
0.006473432
0.0
0.003394235
0.0057635033
0.0
0.004406668
0.0121603785
0.0
0.0062932605
0.006250363
0.0
0.0061593335
0.0017448612
0.0
0.0020338476
0.0039464915
0.0
0.0011390791
0.0019647712
0.0051676403
0.0019298936
0.0045892396
0.005455828
0.005188987
0.0034111761
0.010701943
0.0018552624
0.01047555
0.0
0.0073631653
0.006842124
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision  Recall        F1        F2      F0.5  \
0  0.997367   0.893617     0.5  0.641221  0.548303  0.772059   

   Average Precision  
0           0.449162  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[22:02:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 237.488 seconds
Cross-validation score: 0.7519617536991169
Test score: 0.777439024390244
Best Hyperparameters: {}
0.009228684
0.04343955
0.03711582
0.02306211
0.010898874
0.0047111944
0.004170852
0.00828839
0.011895003
0.002202741
0.02008089
0.00452195
0.011266363
0.009508059
0.012353039
0.0
0.003591543
0.0
0.007951316
0.0025491107
0.021656098
0.018759014
0.0052745836
0.014424639
0.010471819
0.0028854795
0.0030627607
0.0059850444
0.008024713
0.00020492203
0.03406007
0.012078942
0.0036649907
0.010909197
0.0067529404
0.0025516544
0.005494226
0.0057542617
0.00552401
0.0035985727
0.0027717713
0.0
0.0
0.0
0.0121299215
0.0
0.011680941
0.0049122553
0.0
0.006294205
0.00047372546
0.0
0.008388487
0.008787222
0.0
0.008361798
0.0
0.0
0.0
0.0029885778
0.005144131
0.002590183
0.008810601
0.0019956175
0.0037698178
0.005691012
0.012234622
0.0076980283
0.0077046603
0.00327105
0.005752528
0.0219325
0.004058056
0.0005774423
0.005033965
0.0301865
0.010552292
0.006701396
0.0062129633
0.00038634046
0.002316888
0.004435842
0.010613485
0.0
0.0048614955
0.0065271365
0.0059221652
0.0
0.0044453065
0.0052281637
0.0053105447
0.0
0.007419949
0.005845558
0.010184884
0.0013327192
0.006484726
0.0043181702
0.013395387
0.0024809865
0.0010828164
0.0049326094
0.008917813
0.0021572846
0.00524503
0.003773394
0.0022133703
0.004090823
0.007763154
0.0053184796
0.010889303
0.019525629
0.005483369
0.0047036447
0.0026630533
0.0068074237
0.009334494
0.0017480048
0.011396077
0.01223356
0.0034497634
0.0
0.0076906155
0.0041590766
0.0
0.0016443684
0.0049346564
0.0
0.0
0.0145528745
0.0
0.004077285
0.010991899
0.0
0.004121698
0.0016492533
0.0
0.002597113
0.009031082
0.0
0.0040100673
0.0018521039
0.0030253332
0.0020958695
0.0064493585
0.0048832404
0.0025033855
0.0062109344
0.016889019
0.011270344
0.0069651753
0.001046472
0.007430233
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997591   0.836066  0.607143  0.703448  0.642317  0.777439   

   Average Precision  
0            0.50946  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[22:05:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 235.983 seconds
Cross-validation score: 0.7747103731473266
Test score: 0.7534246575342466
Best Hyperparameters: {}
0.0076834415
0.035588186
0.0403906
0.025385687
0.0124624
0.0048290296
0.00565445
0.01522305
0.0050410484
0.0057201236
0.009906488
0.00930056
0.010920205
0.010015811
0.013934049
0.0
0.005952305
0.0
0.0068410137
0.0047786855
0.020744087
0.014045061
0.00497163
0.0165407
0.005199275
0.007935389
0.007681306
0.00549315
0.007141008
0.012254578
0.052280653
0.0051407553
0.004901888
0.010687678
0.005324508
0.007062723
0.0007925634
0.005402847
0.0042530713
0.0054306593
0.004721686
0.0
0.0
0.0
0.0109057035
0.0
0.012581213
0.006253645
0.0
0.0060494468
0.0070725135
0.0
0.013428436
0.00949428
0.0
0.0047187796
0.0
0.0
0.0
0.0028320535
0.007514599
0.0037086732
0.0050257677
0.0057950024
0.0050382414
0.004427713
0.009507967
0.01100025
0.0099204425
0.011514433
0.0019279498
0.008219113
0.0014455437
0.00032761143
0.011043155
0.022771364
0.009761031
0.0043448843
0.0023029754
0.0
0.0037338615
0.0042117243
0.0062556993
0.0037698965
0.004266513
0.0029154266
0.008325307
0.0
0.003389173
0.0032310132
0.007335211
0.0027849367
0.004378917
0.0028366002
0.0055316454
0.0037554156
0.0052253613
0.0026633022
0.010108693
0.0
0.010810258
0.006241769
0.010572644
0.0
0.0013468793
0.0035379415
0.0044529736
0.004882172
0.0032098545
0.008633488
0.0052978
0.0007986292
0.010029344
0.0033860146
0.005270468
0.0014077108
0.0077876616
0.0014799264
0.004360777
0.019932413
0.0048424746
0.0
0.0029169873
0.0022411572
0.0
0.0028051822
0.0036425493
0.0
0.0039808024
0.012691003
0.0
0.0049680606
0.005699605
0.0
0.017402906
0.006482588
0.0
0.0027863053
0.007950395
0.0
0.0052710273
0.003408152
0.0033662019
0.0030287756
0.0056651756
0.01322384
0.0055704387
0.0008728682
0.011454628
0.00057594426
0.011492714
0.0
0.008883872
0.0040537487
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision   Recall        F1       F2      F0.5  \
0   0.99731   0.846154  0.52381  0.647059  0.56701  0.753425   

   Average Precision  
0           0.445465  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[22:10:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 242.502 seconds
Cross-validation score: 0.7900365885349453
Test score: 0.6678082191780822
Best Hyperparameters: {}
0.008007223
0.045405
0.03231521
0.023578858
0.011867255
0.009033974
0.004499689
0.00612176
0.0036829053
0.0023540906
0.015215357
0.008979182
0.011449106
0.009267711
0.017581536
0.0
0.0030367945
0.0
0.006477752
0.0039043743
0.021651102
0.023886682
0.0068224496
0.0136549
0.01097107
0.0013087073
0.004469205
0.0032304071
0.015016005
0.017297955
0.032586474
0.010845251
0.0031652108
0.009467452
0.004948805
0.0047386717
0.011004778
0.007944955
0.002347205
0.002684493
0.0031339112
0.0
0.0
0.0
0.01036472
0.00021579127
0.0070977644
0.012181466
0.0014330221
0.0037708676
0.002000458
0.0
0.005499169
0.0057455976
0.008061622
0.0061381855
0.0
0.0
0.0
0.0032948968
0.0032988633
0.0026732625
0.005920787
0.003156261
0.005808831
0.0071976096
0.006247234
0.0053855055
0.0053433655
0.0022012808
0.0038677803
0.0013948613
0.0041263476
0.0036883682
0.0048005353
0.01978194
0.011286102
0.00783091
0.0021164315
0.0020127469
0.0065263854
0.0052959477
0.0047629657
0.0
0.0053806864
0.0061439076
0.0046784827
0.0025462168
0.005446458
0.0114852935
0.01044248
0.00079909083
0.003761948
0.0045165424
0.01051092
0.0042093187
0.0059092385
0.003951364
0.01529929
0.0042884327
0.015263042
0.006145704
0.005976883
0.0
0.0017777286
0.003908858
0.0022888437
0.0012729258
0.0052580866
0.010323444
0.0053178756
0.011184834
0.016355468
0.0035259724
0.0059335716
0.003389014
0.0025829563
0.006466637
0.0053890585
0.005639851
0.0024835109
0.0
0.0031229674
0.003253192
0.0
0.00042850192
0.0047356617
0.0
0.0020240333
0.010392994
0.0
0.0067851096
0.012248272
0.0
0.00369234
0.010173483
0.0
0.011227911
0.011729821
0.0
0.0045627016
0.002108447
0.003526211
0.0021625469
0.005212073
0.0058978535
0.0073058554
0.015717946
0.0117731085
0.0
0.007645695
0.0
0.005073176
0.004864753
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0   0.99675       0.75  0.464286  0.573529  0.502577  0.667808   

   Average Precision  
0           0.350736  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[22:13:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 237.740 seconds
Cross-validation score: 0.7566931928321492
Test score: 0.746951219512195
Best Hyperparameters: {}
0.0060305675
0.04696777
0.030220818
0.024887893
0.010401501
0.0037319707
0.0030756409
0.0047640707
0.005380492
0.0041041365
0.024360023
0.002543437
0.010711863
0.006794009
0.0049653845
0.0
0.0049812873
0.0
0.0036928505
0.0062555075
0.019695817
0.022479929
0.005214315
0.024143402
0.008327282
0.0052224738
0.011478963
0.005904443
0.0020332204
0.01826853
0.021080825
0.004643911
0.0023460472
0.014710657
0.0052988683
0.0028153409
0.0055132797
0.008260423
0.0016894055
0.0016620416
0.004004527
0.0
0.0
0.0
0.008844484
0.0
0.011597051
0.008717125
0.0
0.012071887
0.0043405266
0.023430165
0.006959389
0.0057482393
0.0
0.005375197
0.0
0.0
0.0
0.003914405
0.003458351
0.0032623324
0.0011873867
0.012214563
0.005829628
0.0041352618
0.006666231
0.0060555064
0.0063401875
0.010496557
0.0031830536
0.010839218
0.00031421246
0.0031495686
0.0032303147
0.0006949255
0.0072815265
0.011302756
0.0053362935
0.017784964
0.005056996
0.004714017
0.005017701
0.0011056385
0.0056251707
0.007456274
0.008199221
0.00010134929
0.0023615058
0.008729955
0.005828656
0.0
0.003099702
0.0022963008
0.011165137
0.005731112
0.0026941884
0.0024046092
0.02131934
0.005125861
0.009295676
0.007811937
0.0020147702
0.0
0.0026541746
0.0028330437
0.0021195326
0.0022754637
0.0053492687
0.020980973
0.013700625
0.0006667027
0.008528055
0.004628657
0.006394996
0.0072535356
0.005738216
0.0011540256
0.012900135
0.0029772585
0.0019062044
0.0
0.0065931557
0.004101786
0.0
0.0057582743
0.003487899
0.0
0.0004710106
0.008118494
0.0
0.008461741
0.00468529
0.0
0.003403649
0.0062485063
0.0
0.0027141548
0.00415861
0.0
0.0039543603
0.0042054364
0.0016533333
0.003731465
0.005395987
0.0057677873
0.007454494
0.009708142
0.011413403
0.0028071266
0.008067038
0.00029878016
0.0074538914
0.028245945
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997367   0.803279  0.583333  0.675862  0.617128  0.746951   

   Average Precision  
0            0.47054  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[22:17:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 239.086 seconds
Cross-validation score: 0.7595344971441247
Test score: 0.8179012345679012
Best Hyperparameters: {}
0.007939016
0.039340254
0.037819196
0.024691645
0.007499117
0.008176713
0.0076928996
0.004961179
0.007841273
0.005867816
0.010680887
0.003233624
0.013398582
0.009374184
0.011212784
0.0
0.003258526
0.0
0.0044747917
0.002963369
0.016874272
0.026835768
0.00552486
0.0063446662
0.0042328723
0.0056058234
0.0052974527
0.0076026833
0.0055779843
0.010569287
0.024916148
0.02967644
0.0042853425
0.015248226
0.0031071757
0.0020546417
0.0042146267
0.0054236804
0.0040836534
0.0028670258
0.0046534534
0.0
0.0
0.0
0.00847935
0.0058942847
0.0103630265
0.0037577697
0.0
0.004780438
0.0017143933
0.0029031725
0.014623489
0.00976436
0.0
0.007072193
0.0
0.0
0.0
0.0042799986
0.004761296
0.004458259
0.006560382
0.001230228
0.0037114106
0.008442408
0.0042163497
0.007564782
0.007988625
0.0026420334
0.0027297002
0.004178932
0.00091580837
0.0059081027
0.0076423376
0.013332148
0.020820484
0.008165689
0.004219181
0.00032372007
0.005030878
0.0044212835
0.006009948
0.0
0.003814188
0.011500413
0.007513995
0.0
0.0062360666
0.010905456
0.0046310537
0.0027920157
0.010277414
0.0046279924
0.009881948
0.0053454097
0.011276264
0.0042629517
0.007353547
0.0009416063
0.0020526787
0.008916488
0.005887234
0.0
0.012619106
0.0036955313
0.0033746946
0.002904571
0.0068189683
0.009119565
0.02390412
0.00487998
0.006361951
0.0032859205
0.008006117
0.0014791834
0.011809705
0.00045509514
0.0052631483
0.006815694
0.001990327
0.0
0.0016899002
0.0025505808
0.0
0.002258667
0.0025147363
0.0
0.0029860137
0.009234769
0.0
0.010494234
0.012010688
0.0
0.0006811606
0.0019660678
0.0
0.008375287
0.008417231
0.0
0.005807529
0.0032490129
0.004593346
0.004112283
0.001286317
0.0046346723
0.008311519
0.001209664
0.0074874237
0.01278699
0.012950348
0.0021209817
0.008630282
0.014311479
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997871   0.883333  0.630952  0.736111  0.669192  0.817901   

   Average Precision  
0           0.559078  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[22:22:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 241.817 seconds
Cross-validation score: 0.7626145452509366
Test score: 0.8390410958904111
Best Hyperparameters: {}
0.009536606
0.03640128
0.031810336
0.025094708
0.011288948
0.0063470756
0.001814375
0.008920877
0.006789731
0.0037116006
0.0027627496
0.0005194965
0.0093894955
0.009584536
0.014917071
0.0
0.006252016
0.0
0.0069830474
0.0012404666
0.022925751
0.02489568
0.0019845162
0.008447859
0.0038967717
0.00049914676
0.006059481
0.003955394
0.0050450214
0.005721408
0.026689798
0.0017845941
0.0027649344
0.007874441
0.0030637293
0.0029232241
0.0074245473
0.008759101
0.0037703866
0.01091823
0.004051675
0.0
0.0
0.0
0.0068838275
0.0067346888
0.009108053
0.006788803
0.0
0.00744147
0.024692122
0.0
0.0018340056
0.012262916
0.0
0.0035896648
0.0
0.0
0.0
0.0038787164
0.0065819845
0.0025646235
0.004675895
0.01762473
0.0030896433
0.008497864
0.003926356
0.007117614
0.011373033
0.0059599075
0.0009952184
0.0048516095
0.0017482647
0.005027355
0.0055000735
0.023340221
0.007901712
0.0022887879
0.006784354
0.001991578
0.00094271026
0.0035910227
0.005545447
0.0
0.0031322867
0.008372999
0.0056200637
0.0011286467
0.00404216
0.0068471185
0.004923012
0.0
0.0027173741
0.0040083327
0.007805203
0.013025622
0.0040810145
0.0035809316
0.0024904497
0.018358031
0.0030718127
0.007503461
0.00421697
0.00062686065
0.005567073
0.0068473085
0.005493465
0.0031341366
0.003981152
0.011226903
0.014372695
0.00050803804
0.003976098
0.005314224
0.006468758
0.0047440263
0.0063064205
0.0031346448
0.005561652
0.001388753
0.0017030197
0.0
0.0058324696
0.0024551118
0.0
0.0013095001
0.0046929386
0.0
0.031727776
0.0129371695
0.0
0.005329502
0.010545038
0.0
0.009448182
0.025264455
0.0
0.0037400431
0.0076496582
0.0
0.0036402731
0.005185921
0.0021642884
0.0031815919
0.0028876339
0.0034009642
0.0041442933
0.017181918
0.010318082
0.0074447845
0.017706674
0.0009246732
0.01161818
0.012033821
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997871   0.942308  0.583333  0.720588  0.631443  0.839041   

   Average Precision  
0           0.551641  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[22:25:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 238.096 seconds
Cross-validation score: 0.745497820750454
Test score: 0.7379518072289156
Best Hyperparameters: {}
0.008300265
0.042390272
0.033320405
0.023727827
0.0076485085
0.0029935339
0.0051905396
0.0051657334
0.007041952
0.005545773
0.0124365445
0.003803363
0.011227352
0.008794856
0.012908485
0.0
0.004301614
0.0
0.003903002
0.0023803657
0.020380795
0.017401354
0.005309635
0.020539902
0.0014983342
0.0042837323
0.0083260685
0.004385073
0.0029327197
0.0027944862
0.015340695
0.0028874688
0.004806877
0.015751587
0.0032089124
0.0023792186
0.0058382703
0.011912702
0.0034795403
0.005913841
0.004544645
0.0
0.0
0.0
0.017434647
0.008715589
0.015144944
0.008491676
0.02868514
0.0056711435
0.0018182503
0.0
0.006528195
0.0065020095
0.0
0.0032954835
0.0
0.0
0.0
0.003156983
0.009017442
0.004232398
0.007353854
0.005298342
0.002686302
0.0035635713
0.005904737
0.013647686
0.0037971218
0.0021456345
0.0020436258
0.008225273
0.01826635
0.008092977
0.0041321996
0.03327609
0.011544376
0.0042191325
0.0026976548
0.0048883283
0.004059659
0.0023391375
0.004545024
0.0028817155
0.011276608
0.002111934
0.003847018
0.00025548565
0.0046506445
0.0060978136
0.005089121
0.00042354452
0.002493654
0.003502442
0.011524741
0.0068117464
0.007675757
0.0031200063
0.008541215
0.0
0.001981503
0.009315485
0.011129382
0.0024735143
0.005310681
0.010719762
0.0020552634
0.0028714414
0.0054438123
0.0044583357
0.008734571
0.00254235
0.0069757635
0.004359319
0.0037072056
0.0009909087
0.007338505
0.008874982
0.0046519483
0.00240148
0.0038872636
0.0
0.0017910695
0.0034168332
0.0
0.014287815
0.0037307334
0.0
0.0
0.008379397
0.0
0.00210711
0.008501397
0.0
0.014987317
0.0069638826
0.0
0.00085412484
0.0059590414
0.0
0.0047771097
0.0040801656
0.003574776
0.003279235
0.0064458633
0.0029528916
0.0048520784
0.0021540406
0.01137248
0.003204301
0.009117485
0.025771925
0.007195181
0.013299531
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0   0.99731   0.790323  0.583333  0.671233  0.615578  0.737952   

   Average Precision  
0           0.462983  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[22:30:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 245.029 seconds
Cross-validation score: 0.7619649048725481
Test score: 0.8098591549295775
Best Hyperparameters: {}
0.0073973048
0.040193927
0.035661124
0.02136564
0.01057534
0.0044776206
0.004504934
0.005393358
0.00783372
0.0073868423
0.007180186
0.0024946956
0.007930131
0.012285658
0.00889324
0.0
0.0036000214
0.0
0.005693188
0.003474015
0.01892036
0.03222795
0.0036427265
0.014953841
0.0030852526
0.0064543104
0.009034835
0.0019383612
0.0075701973
0.0020860902
0.054690953
0.007202866
0.0028366798
0.0092152
0.009084414
0.0038984537
0.002224482
0.0049713627
0.0050698076
0.0018742665
0.0027579174
0.0
0.0
0.0
0.009053571
0.004907778
0.007474753
0.005281236
0.0
0.0077340584
0.0035054195
0.0
0.001905582
0.0064266454
0.0
0.0048487918
0.0
0.0
0.0
0.0044516874
0.0057220557
0.0052996
0.024377858
0.015542925
0.0037987682
0.01216994
0.0053769997
0.004179094
0.004016998
0.003443972
0.009008798
0.011560169
0.0037741573
0.0029206928
0.044128582
0.013449728
0.01283349
0.005593183
0.0038832186
0.0071981605
0.0019561143
0.0046364227
0.0045705107
0.0
0.004070635
0.0057225944
0.00612752
0.0
0.001109378
0.004183008
0.0072722756
0.0019465042
0.0030711924
0.0056254477
0.0120932
0.005612413
0.0066733016
0.0037032806
0.0073831216
0.0001584257
0.002594122
0.010045611
0.0068484824
0.002156475
0.010312083
0.005424218
0.0028921617
0.001044407
0.0074199066
0.0043361792
0.0043920605
0.024469897
0.009971912
0.0039434466
0.006043709
0.0026717756
0.0061821393
0.0007612354
0.0063578635
0.009174298
0.0068403985
0.0
0.0049426733
0.003023276
0.0
0.002096018
0.0051785936
0.0
0.0002562626
0.012499794
0.0
0.0043054596
0.005077691
0.0
0.010360317
0.0020592695
0.0
0.0052350755
0.003861421
0.0
0.0034376
0.0026049395
0.0015998413
0.0024069778
0.0023074471
0.010387239
0.0048062126
0.0046003307
0.01116209
0.0020176193
0.007974517
0.0
0.005990239
0.008062226
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997647       0.92  0.547619  0.686567  0.595855  0.809859   

   Average Precision  
0           0.505939  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[22:34:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 239.359 seconds
Cross-validation score: 0.7830984913372292
Test score: 0.7118055555555556
Best Hyperparameters: {}
0.0139143225
0.037620027
0.035405193
0.026085602
0.010486905
0.005758603
0.004872452
0.01423244
0.016969996
0.0038448635
0.00038197188
0.001093153
0.012276813
0.012419245
0.007687099
0.0
0.004073291
0.0
0.0037449577
0.0018313224
0.018407915
0.034408532
0.004880064
0.018454673
0.015744284
0.004303061
0.005256077
0.008667877
0.0083001405
0.01536367
0.0181786
0.011454393
0.0024197232
0.012730946
0.007626873
0.0035000364
0.0019522336
0.0051108105
0.0029193156
0.0012847288
0.005184256
0.0
0.0
0.0
0.0059814258
0.0
0.01129525
0.008902469
0.0
0.007806472
0.0139165595
0.0
0.005444228
0.0064772055
0.0
0.0081842095
0.0
0.0
0.0
0.005455852
0.005349527
0.002187524
0.008156034
0.0
0.0057207854
0.0046833055
0.007875002
0.004534381
0.008290745
0.003643839
0.0017348013
0.011099806
0.00029393885
0.0006287196
0.007323774
0.0
0.012321177
0.0056585213
0.0021547526
0.0058807787
0.003449297
0.005951593
0.0032534145
0.0015417206
0.0026456062
0.0058903433
0.0056466805
0.0
0.009646033
0.0038092283
0.004189433
0.0
0.0036239186
0.0131117515
0.011984448
0.006891984
0.0054644137
0.008964682
0.011290741
0.0056884307
0.000164836
0.010698311
0.0063346773
0.027221838
0.0047758245
0.00415078
0.0072940434
0.003375783
0.0056792796
0.008003014
0.018427948
0.010068787
0.0050064595
0.0023143077
0.005032336
0.0013797729
0.006999462
0.0007621333
0.0053287516
0.001625583
0.00726806
0.0
0.0032744636
0.0061783283
0.0
0.012461744
0.002921727
0.0
0.0028657797
0.011541876
0.0
0.005729828
0.010459812
0.0
0.01888662
0.0022029236
0.0
0.003466327
0.0061715306
0.0
0.005697739
0.001225876
0.0022589294
0.0012203115
0.0043665124
0.0056935214
0.009795894
0.0055873035
0.005783387
0.00021536372
0.008772561
0.0
0.0078369025
0.010581502
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0   0.99703   0.803922  0.488095  0.607407  0.529716  0.711806   

   Average Precision  
0             0.3948  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[22:38:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 246.060 seconds
Cross-validation score: 0.7748127780684879
Test score: 0.7852564102564101
Best Hyperparameters: {}
0.01000436
0.03874173
0.03331721
0.02351629
0.007211721
0.0045948816
0.0038312124
0.010256169
0.002421896
0.0054850844
0.010660721
0.004922956
0.011554891
0.011878621
0.015090925
0.0
0.005073004
0.0
0.0033888463
0.0026518535
0.016130537
0.021481177
0.0036416634
0.010727008
0.0055528977
0.0075488733
0.0033098583
0.00545363
0.012345409
0.019955687
0.020082733
0.029079136
0.0031208466
0.010829323
0.0055925827
0.0061583105
0.0031705578
0.008658811
0.0015837001
0.0014906331
0.0024980272
0.0
0.0
0.0
0.008861679
0.0
0.012166112
0.0032211852
0.003261717
0.010746543
0.0068119606
0.0
0.005121485
0.009617121
0.0
0.0062705907
0.0
0.0
0.0
0.0035761835
0.0052385023
0.003111949
0.005240887
0.004453187
0.005169232
0.016443092
0.0035004667
0.0064278687
0.006694043
0.005602043
0.0042851013
0.015581492
0.0009860304
0.0036491363
0.008645706
0.013467719
0.009466873
0.005915876
0.0032548388
0.009111474
0.003551149
0.0032573505
0.00659707
0.002928161
0.0050577205
0.0123169655
0.00759036
0.0
0.0002214399
0.004810766
0.001657183
0.002016927
0.0041409954
0.0064880606
0.006139686
0.0036711898
0.0017891021
0.010983362
0.011699935
0.0054710973
0.0028415762
0.015116209
0.0076426775
0.0013039106
0.0062604337
0.0077501624
0.004643379
0.0069866786
0.008146493
0.010269959
0.008960295
0.0076017966
0.009765552
0.0032632437
0.0041400087
0.0036211673
0.009020485
0.00883386
0.0068266154
0.012166102
0.0068820585
0.0
0.0021269715
0.004607376
0.0
0.0014849964
0.004116561
0.0
0.00048651494
0.010198807
0.0
0.005163792
0.014806072
0.0
0.0
0.007209091
0.0
0.00063581386
0.008279445
0.0
0.003386169
0.0024543568
0.003514523
0.0019623914
0.0056692394
0.009287535
0.00990206
0.0
0.0101540815
0.008894725
0.012380014
0.0057597104
0.0040410864
0.0021335485
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1       F2      F0.5  \
0  0.997591   0.859649  0.583333  0.695035  0.62341  0.785256   

   Average Precision  
0           0.503423  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[22:42:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 238.528 seconds
Cross-validation score: 0.7410984982032403
Test score: 0.7407407407407408
Best Hyperparameters: {}
0.00930637
0.040618856
0.030123526
0.02347175
0.014980271
0.0038528333
0.010773211
0.012392265
0.0092100855
0.0050948937
0.01500516
0.003177957
0.011748735
0.009073512
0.0073984303
0.0
0.002583079
0.0
0.0058030672
0.0028439674
0.016357217
0.020002862
0.004909431
0.011129809
0.0048814565
0.00019088012
0.0031208072
0.00486014
0.0022200558
0.011724815
0.0009848913
0.013527278
0.0029447938
0.012602134
0.006001145
0.002851591
0.002763173
0.0068966127
0.004415281
0.00059731863
0.0038765138
0.0
0.0
0.0
0.012834798
0.010066525
0.010870133
0.00598382
0.0020020327
0.005052069
0.022945618
0.0043564006
0.0021151458
0.00942446
0.005075781
0.004415243
0.0
0.0
0.0
0.007827776
0.0068638786
0.0026067486
0.02279395
0.0005506185
0.0032694966
0.011748185
0.008009339
0.006266982
0.005624941
0.0036373923
0.0030771592
0.02097397
0.0
0.01334786
0.006340382
0.02590387
0.014146021
0.003787821
0.0098620355
0.0048376597
0.004951664
0.003918558
0.0033893879
0.0
0.0040012947
0.00043107427
0.004502251
0.0
0.00348824
0.0060998374
0.008913778
0.0019670753
0.0033474811
0.0026310468
0.015379853
0.0023285467
0.0033429954
0.0014503498
0.013284706
0.0
0.010954763
0.005463859
0.00864138
0.028145488
0.0063540093
0.011860836
0.0022322694
0.003829049
0.007756278
0.008917099
0.015136878
0.004644463
0.0047718934
0.0024133276
0.009345162
0.0015111024
0.014612706
0.0091981655
0.0052489503
0.0030173052
0.0016873282
0.0
0.002896567
0.0024638711
0.0
0.00096386526
0.0034135035
0.0
0.000666136
0.008366677
0.0
0.0047865342
0.0033600559
0.0
0.004713589
0.005344856
0.0
0.0036965518
0.0051983353
0.0
0.00207309
0.0032309918
0.0033563117
0.005483235
0.0046098474
0.00089330826
0.0020156545
0.00986719
0.007684916
0.0037871315
0.006354465
0.0
0.009974737
0.01469394
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0   0.99731        0.8  0.571429  0.666667  0.606061  0.740741   

   Average Precision  
0            0.45916  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[22:46:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 239.888 seconds
Cross-validation score: 0.7635936535695024
Test score: 0.7833333333333334
Best Hyperparameters: {}
0.0089586405
0.037700184
0.041566502
0.018122979
0.012502769
0.00423115
0.0092713805
0.0032030472
0.006623295
0.0024566855
0.012974135
0.0022522113
0.0067036785
0.0153727
0.009093697
0.0
0.0038235555
0.0
0.0041392203
0.003086922
0.018894121
0.018536512
0.0054164995
0.018670557
0.012660591
0.00515471
0.0033996901
0.0061540855
0.010053467
0.011783193
0.0015835022
0.0003381177
0.0067709056
0.0076402323
0.0045430814
0.004027296
0.0024455274
0.007267381
0.0050136573
0.014497945
0.0052408245
0.0
0.0
0.0
0.011190382
0.0
0.008187504
0.0067686522
0.0
0.0049660965
0.03568408
0.0
0.0070294114
0.015124054
0.0044363663
0.0041195573
0.0
0.0
0.0
0.0049626627
0.004216352
0.0032576455
0.012607586
0.004199703
0.0044416087
0.007857973
0.0060630883
0.010823705
0.005561033
0.0022106152
0.0038121333
0.016785542
0.0004216162
0.0013882748
0.0085275145
0.011338113
0.013123546
0.004211076
0.004645808
0.022055712
0.004956339
0.0034112178
0.0061825546
0.0
0.006222059
0.01346664
0.0052920887
0.0
0.00891161
0.007157064
0.0065839808
0.0029509044
0.0042732493
0.004779455
0.009692206
0.008335505
0.0036028477
0.0018227518
0.009208121
0.0007174134
0.008016834
0.017589375
0.0038622282
0.0
0.0013801446
0.00628484
0.0021542064
0.005179789
0.0038974083
0.006883199
0.007502261
0.00046801983
0.009679812
0.004171932
0.007685001
0.010577368
0.005667106
0.0021041892
0.004781876
0.005505901
0.0038442877
0.0
0.0040289727
0.0032581238
0.0
0.004073311
0.003428029
0.0
0.0
0.017234052
0.0
0.005840566
0.012567227
0.0
0.001168692
0.0077881315
0.0
0.0071851346
0.007416123
0.0
0.0027318916
0.0030851283
0.0019890724
0.0019886869
0.00540558
0.0091781495
0.0056982823
0.013890583
0.011243101
0.0010816191
0.007791377
0.00060995604
0.007701997
0.0066223987
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997535    0.87037  0.559524  0.681159  0.602564  0.783333   

   Average Precision  
0           0.489066  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[22:50:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 235.308 seconds
Cross-validation score: 0.7659443993937856
Test score: 0.7705479452054794
Best Hyperparameters: {}
0.008295736
0.040805895
0.038585264
0.026535152
0.01350965
0.003841302
0.0019859495
0.013813469
0.006969019
0.0028107436
0.0016741649
0.015416794
0.008937684
0.009965051
0.0135813
0.0
0.0027130411
0.0
0.0050257766
0.0008897502
0.010901451
0.033194102
0.0037206719
0.012009945
0.0071513685
0.003979287
0.0034003726
0.0053440295
0.0050204573
0.0030148998
0.029114177
0.0031634767
0.007898163
0.008963496
0.0028548941
0.0048494157
0.002246242
0.006783373
0.0028327412
0.007732093
0.0045538777
0.0
0.0
0.0
0.0026851855
0.010300113
0.008589487
0.00848787
0.0018965864
0.004584047
0.021437863
0.0
0.0023489704
0.015418798
0.0
0.0043649464
0.0
0.0
0.0
0.0026875474
0.0050884546
0.0044603166
0.014011381
0.015335574
0.0072900085
0.006093643
0.007478286
0.012122508
0.004037706
0.0028875163
0.0023969484
0.006498722
0.014641589
0.011702167
0.016708964
0.006260445
0.010567244
0.012031149
0.0031951352
0.0010622938
0.003767798
0.0020125601
0.0053223297
0.005071199
0.0016072777
0.0046685226
0.003995643
0.0
0.0010436442
0.0045964243
0.006228649
0.0043506683
0.00267293
0.008495518
0.009907885
0.0050623855
0.009233202
0.0022255005
0.0028349108
0.008252779
0.0016252144
0.0113942195
0.009158476
0.0006227507
0.0049859197
0.012612514
0.005506407
0.0073346435
0.0029543028
0.012716108
0.013307232
0.000510106
0.010492612
0.0030424867
0.0074417093
0.0013707527
0.00784538
0.0037970664
0.009031183
0.0028261915
0.0021215486
0.0
0.0032570316
0.0035382397
0.0
0.0026301532
0.0044285585
0.0
0.00023619858
0.008055926
0.0
0.006934343
0.00485589
0.0
0.009161655
0.00208772
0.0
0.0040210495
0.0043518557
0.0
0.0035389306
0.0049432614
0.003313883
0.0014244146
0.0025384505
0.01314816
0.0064527118
0.010509362
0.0052672746
0.004652089
0.0067444406
0.0
0.0057516056
0.025354434
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997423   0.865385  0.535714  0.661765  0.579897  0.770548   

   Average Precision  
0           0.465784  
