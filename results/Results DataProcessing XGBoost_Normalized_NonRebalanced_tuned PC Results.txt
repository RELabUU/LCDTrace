[00:49:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 2545.430 seconds
Cross-validation score: 0.8167223944855134
Test score: 0.8128078817733991
Best Hyperparameters: {'classifier__min_child_weight': 1, 'classifier__max_depth': 16, 'classifier__learning_rate': 0.15, 'classifier__gamma': 0.3, 'classifier__colsample_bytree': 0.7}
0.007281476
0.018464351
0.023875607
0.025997376
0.04181718
0.005465189
0.00510045
0.0046661585
0.007331195
0.013865477
0.0037738648
0.0054520844
0.007657931
0.007862103
0.0037783044
0.0026105952
0.0035038418
0.003043904
0.021746086
0.012079642
0.018516544
0.0045451475
0.009676939
0.0068575037
0.00608373
0.0034997123
0.011626655
0.008682646
0.017088542
0.014224678
0.0070337555
0.00276485
0.0046149
0.008429971
0.0035767406
0.00539079
0.0050150133
0.005671814
0.0036887033
0.002979857
0.0043654754
0.007088783
0.0
0.003905679
0.009598634
0.0014832879
0.006329875
0.005681125
0.014328835
0.0088019455
0.009874722
0.011482893
0.0065689287
0.010970837
0.0
0.0077664787
0.0
0.0
0.0
0.0040677343
0.0038701822
0.0040787873
0.0046706316
0.0
0.00807826
0.002108511
0.0047089127
0.005709707
0.008179608
0.005472497
0.009737985
0.00411893
0.0068980237
0.0045280363
0.006725495
0.004572494
0.0126924105
0.0062883934
0.0079527525
0.0029297033
0.0051417737
0.005400914
0.007037802
0.00619941
0.0041847876
0.0064553577
0.0036697525
0.0
0.0053748335
0.007796145
0.008642849
0.0
0.005000917
0.004431159
0.0051921927
0.0020208284
0.008125862
0.004329471
0.006625227
0.008100025
0.00584648
0.008122274
0.0077299536
0.0
0.0062679253
0.0060893656
0.0043691252
0.006926321
0.0050204075
0.0038770905
0.007051229
0.002866152
0.009350195
0.0038463478
0.0046173106
0.0032190431
0.016763289
0.002919023
0.008029485
0.0040237363
0.005021379
0.0012766356
0.006140716
0.0048068026
0.003149854
0.0038443364
0.0057473737
0.005455708
0.0038520815
0.006191702
0.0061320662
0.01107318
0.0060714833
0.011457845
0.0040643592
0.008763603
0.0062991893
0.004901492
0.0058082733
0.0
0.0064569875
0.007992352
0.0040650372
0.005297134
0.008113638
0.003667282
0.0033066424
0.0
0.014178081
0.0015972006
0.005833188
0.0037437442
0.0040486334
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision  Recall        F1        F2      F0.5  \
0  0.990653   0.891892     0.6  0.717391  0.642023  0.812808   

   Average Precision  
0           0.543045  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[01:30:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 2435.033 seconds
Cross-validation score: 0.8043926061817877
Test score: 0.829596412556054
Best Hyperparameters: {'classifier__min_child_weight': 4, 'classifier__max_depth': 16, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0.7, 'classifier__colsample_bytree': 0.8}
0.007676951
0.020668982
0.020259239
0.022689521
0.034904808
0.0067764833
0.0063074995
0.0023434036
0.0058383266
0.010452184
0.005129533
0.0061474084
0.013609461
0.0073813004
0.0019136032
0.0070417835
0.0041104276
0.0029599022
0.032316633
0.010640346
0.029556386
0.008166616
0.0062688044
0.0057428805
0.002693792
0.0032636842
0.0041357186
0.016072247
0.00872256
0.006401137
0.011182345
0.0037604042
0.004203137
0.011240024
0.0036751942
0.006074454
0.003247153
0.011399527
0.004682409
0.0041929204
0.0058479263
0.0058811433
0.0
0.007428411
0.010870572
0.0
0.0056552193
0.004142797
0.00374816
0.008539002
0.007151013
0.0
0.005390185
0.0067672753
0.0
0.012496504
0.0
0.0
0.0
0.0045547956
0.00291252
0.0058642486
0.0026625355
0.0014204965
0.0051142513
0.0036785516
0.0
0.0054834955
0.008347958
0.008256536
0.005891752
0.0051255655
0.006771781
0.0077662603
0.0060588117
0.0049960697
0.007367633
0.009719374
0.007101587
0.0026593045
0.0059911963
0.005669507
0.00659926
0.00667466
0.0056060664
0.008308733
0.0022047516
0.0
0.0018098106
0.006620668
0.004523365
0.0068865325
0.0038695715
0.0058089783
0.005459038
0.020313915
0.0041803773
0.0046015545
0.0038981838
0.0
0.0054702642
0.005064874
0.006734317
0.0018738483
0.0031448517
0.00833941
0.005737698
0.006508185
0.0016914433
0.006546031
0.0025485568
0.013825292
0.00550072
0.0053334213
0.0054794783
0.00424258
0.013694078
0.0041945633
0.007997109
0.0029190897
0.0032153015
0.009243492
0.0029625602
0.006912458
0.0027842668
0.0043558846
0.0048580877
0.005651767
0.0011921256
0.0069419118
0.0
0.012654885
0.009158007
0.017409962
0.0075681102
0.0113522485
0.007867781
0.0059942976
0.0063517587
0.0
0.0044431826
0.0075583635
0.0047689877
0.0042420337
0.007987084
0.0067751734
0.0029011515
0.0
0.009752134
0.006691978
0.0056644375
0.0
0.007347645
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.991731   0.880952  0.672727  0.762887  0.706107  0.829596   

   Average Precision  
0           0.599112  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[02:09:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 2363.527 seconds
Cross-validation score: 0.8149319815197398
Test score: 0.8296943231441049
Best Hyperparameters: {'classifier__min_child_weight': 2, 'classifier__max_depth': 20, 'classifier__learning_rate': 0.15, 'classifier__gamma': 0.1, 'classifier__colsample_bytree': 0.5}
0.009290264
0.023150334
0.026473453
0.02938298
0.03314019
0.0036572267
0.00636691
0.0048460304
0.008115809
0.0069916667
0.007915451
0.003452132
0.011512684
0.009608752
0.0043348446
0.003821761
0.0037822563
0.0038563034
0.020725083
0.012167715
0.02161679
0.0113908965
0.005045168
0.0062256344
0.0035850066
0.005472013
0.0133123165
0.012435592
0.007815735
0.0030488058
0.006082208
0.01423042
0.004617167
0.011592808
0.004046041
0.0053893225
0.0057472913
0.0031711252
0.005456679
0.0041891946
0.003267553
0.006007318
0.0013026813
0.0065930774
0.008383867
0.0
0.005307929
0.008118605
0.0012664676
0.0056497627
0.004331195
0.0
0.0055342983
0.0042383554
0.0
0.012280448
0.0
0.0
0.0
0.0036519694
0.0036398272
0.004439058
0.0061964933
0.005067387
0.0045281556
0.0072569144
0.007818993
0.005954236
0.0068920683
0.002172096
0.007278679
0.0045509776
0.0027429878
0.0030655223
0.005513518
0.005886204
0.007967054
0.007899069
0.009581029
0.010075197
0.00598538
0.0033783745
0.0054434678
0.007384017
0.0042525954
0.0076590097
0.004646673
0.006563862
0.008079096
0.0048569245
0.010358084
0.0
0.008836918
0.0072979853
0.007046015
0.022126086
0.005392594
0.0056039444
0.0049753417
0.010497709
0.0036296677
0.012365243
0.011461619
0.007878645
0.0022086648
0.007901777
0.003831155
0.0069134007
0.0
0.004080775
0.004136916
0.0033702068
0.0065618358
0.004783985
0.0035757676
0.0066884053
0.009584494
0.0055238754
0.007474865
0.0062905103
0.004738917
0.00525364
0.00409462
0.0039039953
0.005008809
0.0028358174
0.00546469
0.0038465727
0.0023259076
0.0058917524
0.0062974216
0.0069084624
0.0066707125
0.011470613
0.004663719
0.009673982
0.0024203253
0.0065866606
0.003569859
0.0011388607
0.003961673
0.0055209296
0.004422499
0.0028830683
0.0047486387
0.00625897
0.003126755
0.0
0.006947534
0.00467531
0.007691223
0.0018613295
0.004969777
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.991911   0.873563  0.690909  0.771574  0.721063  0.829694   

   Average Precision  
0           0.609665  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[02:48:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 2338.636 seconds
Cross-validation score: 0.8042120224537681
Test score: 0.8014354066985646
Best Hyperparameters: {'classifier__min_child_weight': 2, 'classifier__max_depth': 20, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0.0, 'classifier__colsample_bytree': 0.4}
0.010833338
0.025691502
0.02852505
0.03323617
0.03195603
0.0034405217
0.0072132587
0.005505239
0.0060301274
0.01139525
0.007756061
0.002924345
0.012392439
0.009180396
0.009184846
0.00250997
0.0048413803
0.006108761
0.021019638
0.012013073
0.02473127
0.006018019
0.004319867
0.0060917987
0.0034862955
0.0036104708
0.013881609
0.012834517
0.0032905035
0.002611803
0.0075748595
0.0019046013
0.004931105
0.011673628
0.0029034256
0.009715634
0.0037891364
0.006856654
0.005199047
0.0021113257
0.003939405
0.0047738506
0.0030921295
0.0037348636
0.009393518
0.0
0.002945641
0.0062420922
0.008987118
0.005596798
0.016664501
0.006182611
0.00605473
0.0056797774
0.014952118
0.0124517875
0.0
0.0
0.0
0.0031478642
0.003922637
0.005825829
0.0017275239
0.002989727
0.0041725948
0.00673609
0.0013173652
0.007362849
0.0042523597
0.0029404087
0.007647396
0.0055012736
0.0017986328
0.0063168393
0.003956315
0.0024058088
0.007386873
0.010557903
0.0042093582
0.0073865782
0.0059462036
0.003925703
0.005396584
0.0072053205
0.0037859462
0.006167343
0.0076191067
0.0072597773
0.0051683355
0.004556011
0.008285028
0.0
0.0030594645
0.0054540345
0.005164106
0.015404154
0.0022048722
0.004992521
0.005697645
0.00041233236
0.0039354265
0.0051961755
0.0050242944
0.002910047
0.003957717
0.006077809
0.0056916527
0.0030450616
0.0
0.0060234363
0.008471389
0.0017892708
0.00818221
0.0041455836
0.0061374544
0.0057625854
0.011997935
0.00518988
0.006316233
0.008596822
0.0045993025
0.004388654
0.0044684093
0.0034401787
0.0052451696
0.0029610517
0.004015628
0.004115075
0.008209113
0.007285782
0.007141164
0.014204314
0.0020615053
0.011853522
0.0033821901
0.009204375
0.0009777187
0.003899666
0.0043921415
0.008066688
0.0047112685
0.0055543096
0.0057293517
0.0049296813
0.006583665
0.0066987993
0.007533287
0.0
0.0044419873
0.002071938
0.0082457345
0.0
0.011886781
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.990473    0.87013  0.609091  0.716578  0.647969  0.801435   

   Average Precision  
0           0.537718  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[03:32:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 2629.491 seconds
Cross-validation score: 0.8043586539120782
Test score: 0.8191489361702127
Best Hyperparameters: {'classifier__min_child_weight': 1, 'classifier__max_depth': 16, 'classifier__learning_rate': 0.35, 'classifier__gamma': 0.0, 'classifier__colsample_bytree': 1.0}
0.011876297
0.018861698
0.023071026
0.030363705
0.038634814
0.002836783
0.004308014
0.004155167
0.0040352936
0.028315919
0.005091539
0.0032763237
0.014093682
0.0066465
0.0053090323
0.0
0.0022778483
0.0
0.016700342
0.0056842314
0.016094172
0.0043051206
0.004309103
0.009468795
0.005738108
0.0043231314
0.005194076
0.0045939214
0.0125424815
0.010252549
0.00716475
0.004661274
0.0024321245
0.0110033685
0.0027889656
0.006723187
0.0
0.0059515145
0.0031661864
0.0036525333
0.0022985018
0.0
0.0
0.0
0.019743979
0.0014658625
0.006812769
0.0046411725
0.0
0.0059324005
0.0038058632
0.0085186595
0.0038735524
0.0061765676
0.0
0.0029649923
0.0
0.0
0.0
0.0022342636
0.001947405
0.0051026493
0.005185842
0.0
0.002824515
0.0004980388
0.0
0.008689544
0.014462424
0.0042204573
0.0038311705
0.001882235
0.005673537
0.0019850635
0.009365316
0.0066281296
0.0073184203
0.0023675796
0.008989419
0.00046881873
0.009642786
0.0032169197
0.005496871
0.003255129
0.0039662477
0.0011815906
0.0056790733
0.0
0.008183769
0.0010751568
0.013101031
0.0
0.001818955
0.0056406385
0.0034546703
0.1927743
0.003980083
0.003596186
0.003288977
0.00024061315
0.0046193637
0.010596022
0.0061634537
0.0
0.002058909
0.006163889
0.003843893
0.008203811
0.002194295
0.009458056
0.004315933
0.005835804
0.0032634272
0.006160182
0.0073529016
0.0026434392
0.008186107
0.0026659344
0.005930612
0.007572955
0.0070737363
0.0
0.0026284424
0.004464568
0.0
0.003043148
0.0033793699
0.0
0.00076182466
0.0061011426
0.0
0.010455138
0.017642181
0.0
0.00549936
0.006725637
0.0
0.0
0.0057844515
0.0
0.0063117943
0.0057990323
0.0042331754
0.0053671976
0.0029735558
0.0021305515
0.0015064543
0.0
0.0028133676
0.0012737932
0.005401913
0.0
0.001995461
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision  Recall    F1        F2      F0.5  Average Precision
0  0.991731   0.855556     0.7  0.77  0.726415  0.819149           0.604821

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[04:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 2382.969 seconds
Cross-validation score: 0.8205570658115047
Test score: 0.7555555555555556
Best Hyperparameters: {'classifier__min_child_weight': 2, 'classifier__max_depth': 20, 'classifier__learning_rate': 0.4, 'classifier__gamma': 0.3, 'classifier__colsample_bytree': 0.9}
0.013261649
0.024590692
0.02083528
0.022025723
0.040008076
0.003967788
0.01343389
0.0021965727
0.0049041985
0.018378684
0.002318568
0.0034490097
0.014729359
0.006028521
0.0026588924
0.0022458527
0.0024031578
0.0
0.016778471
0.0058771935
0.015048684
0.004105076
0.0073490585
0.003564527
0.0019009402
0.0027942176
0.014610999
0.016442623
0.014157933
0.0045382944
0.0035504024
0.006274187
0.004599155
0.009342546
0.0026970142
0.004913534
0.0069374405
0.006178753
0.0027614585
0.0
0.0048845327
0.00897725
0.0
0.0028927163
0.013028073
0.0
0.0067892694
0.01134611
0.00849266
0.010005391
0.005214713
0.0
0.0047220443
0.0069148233
0.0
0.008776069
0.0
0.0
0.0
0.0033719912
0.006447501
0.007149182
0.011420078
0.0
0.008192231
0.0027776917
0.0
0.002925771
0.014031197
0.0041276985
0.007481858
0.008126667
0.0029590272
0.011983539
0.001000785
0.004216456
0.0039582755
0.012343252
0.008846953
0.003471318
0.0038302457
0.0038260305
0.0076998253
0.0061736163
0.0046601463
0.008048124
0.0052968757
0.0
0.0061076484
0.005117385
0.0046554958
0.0
0.01420624
0.0010688237
0.00697964
0.0055927997
0.0022428196
0.010030771
0.0039786976
0.0
0.005830628
0.004783258
0.010296976
0.0
0.005135507
0.0021924358
0.0040140087
0.005756335
0.0069625927
0.0090345815
0.00481927
0.03259828
0.008583258
0.0078961225
0.021928947
0.0036232166
0.018849788
0.004004173
0.011329233
0.0023793066
0.008060051
0.0
0.00487901
0.0045519164
0.0047238115
0.0
0.0029098452
0.0045281816
0.00341182
0.003777292
0.0
0.008470174
0.0072987457
0.0
0.006055679
0.005062523
0.0
0.008747174
0.020465212
0.0039515556
0.0065784617
0.0042301225
0.0035842864
0.0020793108
0.0039409436
0.009980581
0.00735569
0.0
0.008307297
0.003274258
0.009996536
0.0
0.0055129086
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.989394        0.8  0.618182  0.697436  0.647619  0.755556   

   Average Precision  
0           0.502095  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[04:53:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 2479.176 seconds
Cross-validation score: 0.7997318369248145
Test score: 0.8116883116883118
Best Hyperparameters: {'classifier__min_child_weight': 1, 'classifier__max_depth': 16, 'classifier__learning_rate': 0.25, 'classifier__gamma': 0.1, 'classifier__colsample_bytree': 0.9}
0.011247816
0.026023256
0.02353506
0.0369819
0.03701765
0.0048608007
0.007316042
0.003453388
0.007588155
0.023302885
0.0035215165
0.0025496262
0.009723531
0.0066570477
0.003331809
0.0029909231
0.004657926
0.0
0.013412728
0.008951792
0.015876189
0.006036483
0.0056280433
0.00690044
0.002284664
0.0047520897
0.0073431856
0.008067728
0.00759255
0.016878864
0.0029931767
0.0048171566
0.004609499
0.012218897
0.007803762
0.0061522825
0.0067759026
0.004536822
0.003806731
0.0016096616
0.005282439
0.0017498218
0.0
0.0036441712
0.0154596465
0.0
0.0075909183
0.0067029805
0.0050006174
0.010766273
0.0063175554
0.0
0.0047539566
0.009458434
0.0
0.0050808354
0.0
0.0
0.0
0.005555672
0.0045121154
0.005613836
0.0058109923
0.0
0.0051915213
0.0024993236
0.0
0.0044397907
0.012441376
0.0086614955
0.009921614
0.007119214
0.0022046657
0.0033441535
0.0050998325
0.0038438078
0.007369787
0.0071948944
0.0096483175
0.0093561495
0.0028575286
0.0042515746
0.009226747
0.007359501
0.00415632
0.010307526
0.008503941
0.0030788179
0.0101749115
0.0035333505
0.0048397104
0.0
0.006483188
0.012009526
0.005125848
0.004441855
0.033306386
0.006325156
0.0030072771
0.0
0.0039928956
0.0030800393
0.014222148
0.0
0.003273822
0.013214286
0.0044850972
0.005986652
0.00061868044
0.004440354
0.0015744908
0.0008653241
0.0057083364
0.0047556604
0.0030465582
0.005398748
0.009219587
0.0031160482
0.008005998
0.00374671
0.0066869
0.010864257
0.0044000717
0.005402705
0.0
0.004479047
0.0057215574
0.006052695
0.0
0.0048168884
0.0
0.016219577
0.0070649968
0.007259685
0.004590637
0.0059845247
0.0005896655
0.0040797424
0.005563871
0.025621222
0.006042919
0.0032418699
0.0044950224
0.007823379
0.006221091
0.0056329616
0.0035913468
0.0
0.003649082
0.001815123
0.0051839678
0.0
0.013720343
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.991372   0.852273  0.681818  0.757576  0.710227  0.811688   

   Average Precision  
0           0.587387  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\metrics\_plot\precision_recall_curve.py:125: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots()
C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[05:31:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 2298.654 seconds
Cross-validation score: 0.8050481948073134
Test score: 0.8255813953488371
Best Hyperparameters: {'classifier__min_child_weight': 3, 'classifier__max_depth': 10, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0.5, 'classifier__colsample_bytree': 0.7}
0.012380048
0.020673757
0.023223586
0.020341864
0.025554359
0.004160489
0.008590376
0.0045822174
0.0070059034
0.021447435
0.0038453229
0.0060045966
0.011572357
0.0084585
0.0017465951
0.0056430805
0.0036253373
0.00373619
0.044729933
0.012715083
0.013489425
0.011099201
0.0043512303
0.005915737
0.004022156
0.0026670867
0.0058351485
0.012437471
0.013089441
0.0010448591
0.0047688456
0.0016488183
0.0050402195
0.009209761
0.0039024374
0.0063325684
0.0049726153
0.0034719598
0.0037255203
0.0018388245
0.0030116704
0.00778583
0.0036833999
0.001981961
0.016310237
0.0
0.0054720333
0.006488819
0.0025912356
0.0051059965
0.00859541
0.0049864054
0.0070149554
0.006490814
0.0
0.016042344
0.0
0.0
0.0
0.003988224
0.003751726
0.0055572824
0.009430999
0.0049957866
0.0032568166
0.0022629995
0.0
0.0058647078
0.009760374
0.0022165095
0.0055622905
0.00934524
0.0047343145
0.006682765
0.004222033
0.003066524
0.004570692
0.007787046
0.011036136
0.0030417652
0.0048829196
0.0055287182
0.00431919
0.005547112
0.0044291094
0.011237721
0.004214035
0.0039693536
0.005670247
0.0049044224
0.0054308507
0.0
0.005786769
0.0075320294
0.005340014
0.0078122024
0.010410163
0.009011828
0.006645952
0.01493773
0.0060897754
0.003519432
0.0056232307
0.0
0.0030150886
0.011547374
0.0053702607
0.008886861
0.0040863617
0.008004551
0.005376979
0.0033073265
0.0074399826
0.004109899
0.0028337426
0.0069953827
0.0119561525
0.005252276
0.013011191
0.004483607
0.0032565072
0.002750948
0.0030490763
0.0043496764
0.0027083373
0.004522888
0.0048655975
0.0
0.0027814952
0.0082852505
0.0
0.009843883
0.010478556
0.017217554
0.0055913893
0.009321055
0.002404908
0.0066162227
0.00415695
0.01327031
0.0061795656
0.00408782
0.0037579974
0.0041068136
0.003222369
0.004975743
0.0028241083
0.0
0.005193009
0.015267368
0.0062961294
0.0
0.0045029684
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.991372     0.8875  0.645455  0.747368  0.682692  0.825581   

   Average Precision  
0           0.579852  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[06:10:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 2309.889 seconds
Cross-validation score: 0.8158888860580428
Test score: 0.8195020746887965
Best Hyperparameters: {'classifier__min_child_weight': 3, 'classifier__max_depth': 8, 'classifier__learning_rate': 0.55, 'classifier__gamma': 0.1, 'classifier__colsample_bytree': 1.0}
0.009012999
0.027805174
0.025472282
0.033926737
0.04729853
0.0022358738
0.005942071
0.0044873827
0.012335327
0.023874413
0.010941397
0.0020491416
0.028969882
0.008008835
0.002201361
0.0
0.0012673808
0.0
0.015637536
0.0062088114
0.022109529
0.002852468
0.0044598463
0.0007310174
0.003412019
0.0038158025
0.009855093
0.016979711
0.0062094363
0.0018381655
0.010094442
0.0009350573
0.0015273013
0.013880099
0.0043561854
0.017208805
0.0043937857
0.0016906572
0.006055022
0.0028555368
0.0031371203
0.0
0.0
0.0
0.009063318
0.0
0.0023784766
0.016904593
0.0
0.0017376385
0.014310024
0.0
0.008505941
0.0105195455
0.0
0.013978913
0.0
0.0
0.0
0.0021440056
0.0027021968
0.0068747853
0.0
0.0
0.012475806
0.0
0.0
0.0064769187
0.019708473
0.002183688
0.011135576
0.0014769542
0.0031494638
0.004627955
0.011874999
0.0037270188
0.0111779915
0.006158748
0.0058426885
0.0107291015
0.0136940405
0.003685747
0.0041728783
0.009359221
0.0032393883
0.032384105
0.014348708
0.0
0.0054354924
0.0072647496
0.0
0.0
0.00508464
0.005686388
0.007050396
0.0
0.0017204781
0.003212361
0.005655551
0.0
0.007056393
0.0017545763
0.0073516546
0.0
0.008806871
0.0043014884
0.005290649
0.009218479
0.0
0.0024861575
0.0036125502
0.010657487
0.005463823
0.0043277317
0.00052400306
0.0012356293
0.015316885
0.0015561454
0.025422238
0.0022044387
0.0041247667
0.0
0.0023280624
0.0030695766
0.0
0.0072576446
0.0044002202
0.0
0.0
0.007687381
0.0
0.014864287
0.0075862207
0.0
0.014981009
0.009887655
0.0
0.00084445986
0.013888361
0.0
0.006258956
0.008252913
0.0056075165
0.006789836
0.0036160187
0.010078305
0.00273086
0.0
0.00072157534
0.007607957
0.007741572
0.0
0.0051564095
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.991911   0.849462  0.718182  0.778325  0.741088  0.819502   

   Average Precision  
0           0.615641  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[06:53:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 2560.020 seconds
Cross-validation score: 0.8026670671703586
Test score: 0.8179723502304148
Best Hyperparameters: {'classifier__min_child_weight': 9, 'classifier__max_depth': 10, 'classifier__learning_rate': 0.35, 'classifier__gamma': 0.1, 'classifier__colsample_bytree': 1.0}
0.005487835
0.028778834
0.02102389
0.024802914
0.044787753
0.0036129039
0.0067680795
0.0037044922
0.0105655845
0.016256262
0.0
0.0039378367
0.014934776
0.013198268
0.0046072113
0.0
0.0041308687
0.0
0.02497877
0.008051906
0.026477112
0.013521731
0.008681753
0.0059240325
0.0026549336
0.003583452
0.005861302
0.011235817
0.0057652756
0.004942177
0.010340864
0.012992806
0.008125069
0.0102693075
0.0026629397
0.008437457
0.0
0.0021685085
0.0042849295
0.004481421
0.0051995628
0.0
0.0
0.0
0.0
0.0
0.0044310517
0.0063498747
0.0
0.00667495
0.010264271
0.0
0.013387027
0.017624347
0.0
0.009635126
0.0
0.0
0.0
0.003286803
0.0030296764
0.0043297573
0.002437888
0.0
0.0022699218
0.010863381
0.0
0.007389089
0.014159067
0.00085355795
0.0063973754
0.004955181
0.0
0.0024712165
0.011047958
0.0045948727
0.008211501
0.009435984
0.0047739767
0.0
0.0033473782
0.0020006339
0.0039424417
0.010049668
0.0058170287
0.044834197
0.006310331
0.004529762
0.02451042
0.0062329955
0.0069325157
0.0
0.004285574
0.016207686
0.007790527
0.0
0.0036754718
0.007623218
0.010029456
0.0059452895
0.0055807917
0.006840208
0.0038932434
0.0
0.0043721143
0.008537471
0.004400015
0.0070025483
0.0
0.01268116
0.00663881
0.00992236
0.0076787425
0.0048963446
0.0
0.0056844126
0.01724831
0.005199758
0.004099004
0.0045521287
0.0022445915
0.0
0.0033440932
0.0046541505
0.0
0.0039462056
0.0036832974
0.0
0.0025966347
0.011579526
0.0
0.014995862
0.005456221
0.0
0.0086609125
0.0072763097
0.0
0.0038271842
0.0031727084
0.0
0.006253279
0.0042657643
0.0061329384
0.007353432
0.0029421246
0.008538704
0.009335933
0.0
0.010061664
0.004702832
0.0034100267
0.0
0.0021611343
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.991192   0.876543  0.645455  0.743455  0.681382  0.817972   

   Average Precision  
0           0.572779  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[07:38:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 2729.006 seconds
Cross-validation score: 0.8130190407972536
Test score: 0.8091787439613527
Best Hyperparameters: {'classifier__min_child_weight': 1, 'classifier__max_depth': 20, 'classifier__learning_rate': 0.4, 'classifier__gamma': 0.9, 'classifier__colsample_bytree': 0.8}
0.008810815
0.01867
0.017983261
0.021330807
0.04317619
0.0041820207
0.01164744
0.0044367188
0.0047095264
0.017149255
0.0071199764
0.004859748
0.00946001
0.008253766
0.0029238756
0.0
0.0045860624
0.0
0.030569468
0.0070353025
0.02041391
0.01892381
0.0065305517
0.00647752
0.005935614
0.0059778746
0.008299314
0.008788595
0.010472042
0.008667548
0.011906478
0.0030369274
0.0037555618
0.0076641194
0.005886147
0.006639245
0.0032469297
0.007767661
0.005280964
0.010298141
0.0059304037
0.00291042
0.0
0.0
0.009458568
0.0
0.0072939023
0.0045329444
0.0036624714
0.0047298903
0.025119485
0.0
0.006364119
0.00895425
0.0
0.011280785
0.0
0.0
0.0
0.0054972363
0.0055656615
0.005658286
0.0064494344
0.0
0.0040690172
0.004449676
0.0
0.003183791
0.012522449
0.0016054303
0.008684365
0.004474149
0.018379038
0.013153711
0.0
0.0034544508
0.014060301
0.0078451075
0.00963301
0.010306065
0.007102609
0.0085242875
0.0077085663
0.008491829
0.005700556
0.0074809426
0.009653176
0.005936646
0.0062348563
0.006444599
0.0050289645
0.0
0.005066636
0.015465676
0.007012258
0.003331957
0.0046623154
0.0051922775
0.0030631097
0.0
0.007779586
0.008423514
0.007777362
0.0
0.0060553486
0.005615931
0.0050613186
0.0077981516
0.003028275
0.005479412
0.0035014453
0.0
0.006054479
0.009083543
0.0056799008
0.007894892
0.018743163
0.0
0.01128677
0.005672712
0.0056353644
0.0
0.0030420718
0.005394472
0.0
0.0
0.008017569
0.0
0.0
0.005030288
0.0
0.0087548345
0.0045099366
0.0025702198
0.0034027807
0.0076370547
0.0
0.0
0.0055980617
0.0
0.0059079453
0.007065023
0.0040948554
0.010648695
0.008164064
0.005341248
0.004498173
0.0
0.013461109
0.0027714956
0.0040230574
0.0
0.005293031
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall       F1        F2      F0.5  \
0  0.990653   0.881579  0.609091  0.72043  0.649225  0.809179   

   Average Precision  
0           0.544691  

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

--------------------------------------------------------------------
[08:19:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 2467.151 seconds
Cross-validation score: 0.808488353634646
Test score: 0.7555555555555556
Best Hyperparameters: {'classifier__min_child_weight': 4, 'classifier__max_depth': 18, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0.4, 'classifier__colsample_bytree': 0.3}
0.008656274
0.023824748
0.031179933
0.029539423
0.02823872
0.0022751985
0.0038857437
0.003182707
0.0055736196
0.00920295
0.0074998247
0.005110441
0.011594411
0.008674544
0.003727495
0.005592718
0.0057021566
0.0034210219
0.015609886
0.012010266
0.024482386
0.006917751
0.0045291274
0.0056428113
0.0041832426
0.0041681915
0.014232225
0.016676191
0.0034073938
0.0027696285
0.0026952554
0.0063221054
0.0050426247
0.0097694015
0.0050692228
0.0048330645
0.007777132
0.002834323
0.0061343266
0.0023216684
0.0029908298
0.003574915
0.0
0.004473171
0.006905409
0.0
0.0058923047
0.004253279
0.0
0.0049954583
0.0074311295
0.0
0.0080763735
0.0075343424
0.0
0.009844251
0.0
0.0
0.0
0.0059514204
0.006377494
0.0039103967
0.004743549
0.01729912
0.0045073847
0.014431982
0.014526756
0.008071515
0.005054243
0.001893797
0.009802148
0.007807828
0.005677531
0.0038601677
0.0072090807
0.011401447
0.00611424
0.015467558
0.0038589812
0.0040684566
0.0031435103
0.004390223
0.0055339704
0.005982549
0.00391302
0.015165378
0.004685772
0.0040146434
0.0039309254
0.00475071
0.008719179
0.005738372
0.005029615
0.0077208304
0.0064175446
0.008616828
0.008544453
0.009773731
0.0066338014
0.00084217906
0.003148487
0.016139477
0.0032923429
0.0006484361
0.0030028562
0.0050651794
0.0060221925
0.0045881057
0.0005398109
0.0061216233
0.0032740652
0.0033204756
0.0048094513
0.0049643335
0.0045217713
0.0056873243
0.010950824
0.00549974
0.0057824645
0.0051229093
0.0039952565
0.00780157
0.0038004334
0.0031712353
0.0034608105
0.0041372427
0.0042034886
0.008094906
0.00309414
0.0049264627
0.003815214
0.0075612483
0.0073314314
0.01432096
0.0065962896
0.009491258
0.0033667781
0.008144585
0.005505602
0.0063034235
0.0042669564
0.0058667087
0.005349586
0.0024990204
0.0050643333
0.0040806914
0.016148163
0.0
0.005111212
0.003930254
0.0037797953
0.0
0.006415139
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.989394        0.8  0.618182  0.697436  0.647619  0.755556   

   Average Precision  
0           0.502095  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[08:59:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 2378.921 seconds
Cross-validation score: 0.8228934159205373
Test score: 0.7594936708860759
Best Hyperparameters: {'classifier__min_child_weight': 4, 'classifier__max_depth': 8, 'classifier__learning_rate': 0.45, 'classifier__gamma': 0.2, 'classifier__colsample_bytree': 0.7}
0.010152786
0.027716484
0.024908448
0.020503078
0.038126532
0.003505882
0.011532842
0.0034775464
0.0033136646
0.022046817
0.008062768
0.0049136747
0.013106319
0.007802836
0.0016319485
0.0016418771
0.002361628
0.0
0.029155621
0.012578904
0.022155153
0.0017112016
0.0030223918
0.004085967
0.001705842
0.0046674376
0.004952858
0.013363996
0.012110458
0.0016155782
0.007936373
0.0
0.0054869796
0.009457908
0.0056245117
0.0067601684
0.018006997
0.0028541584
0.006917695
0.0027624946
0.006299575
0.007797868
0.0070142755
0.0022046103
0.009422273
0.0
0.0058623715
0.00688399
0.011265067
0.007285092
0.015336258
0.0
0.0063837306
0.012624559
0.0
0.016524145
0.0
0.0
0.0
0.0034048064
0.0065208906
0.006338273
0.0
0.0
0.022755116
0.0020210766
0.0
0.009767365
0.017831203
0.0037349851
0.005263827
0.0025204935
0.0021152534
0.0053916043
0.0033657008
0.002280538
0.006326093
0.008088602
0.0078026317
0.015968451
0.0028893282
0.004289055
0.004624639
0.011255324
0.0032446715
0.002679889
0.0018513845
0.0
0.0065441662
0.006289076
0.005300468
0.0
0.0015980871
0.0047702976
0.0026033209
0.0056897774
0.0032871463
0.002906339
0.00861217
0.0
0.0014665818
0.003381054
0.005341547
0.0
0.0060087834
0.0033239513
0.00661385
0.017815877
0.0
0.01678369
0.00035704992
0.0
0.010538331
0.0014975754
0.0
0.0034766635
0.013355274
0.0034850962
0.014563061
0.0070637297
0.003758824
0.0
0.005921484
0.0039639366
0.0020752887
0.0
0.006260969
0.0
0.005462866
0.008844032
0.0010146593
0.0044844802
0.00608476
0.028513713
0.0036794322
0.0025204287
0.0012982945
0.010421367
0.0022492998
0.0
0.0048866565
0.00331839
0.0041381815
0.0018733005
0.0019138271
0.0013550938
0.0019651887
0.0
0.0037879837
0.03809789
0.005372276
0.0
0.01509157
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.989754   0.791209  0.654545  0.716418  0.677966  0.759494   

   Average Precision  
0           0.524713  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[09:38:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 2335.577 seconds
Cross-validation score: 0.8183918537261737
Test score: 0.7701421800947867
Best Hyperparameters: {'classifier__min_child_weight': 3, 'classifier__max_depth': 6, 'classifier__learning_rate': 0.15, 'classifier__gamma': 0.8, 'classifier__colsample_bytree': 0.9}
0.008233023
0.023323629
0.025566678
0.024128633
0.035532963
0.003816292
0.006786971
0.0033050657
0.007155537
0.012265655
0.0025307764
0.005055425
0.009047088
0.0091299545
0.008837181
0.0
0.0036173256
0.0
0.010512877
0.006488591
0.025119487
0.0075458386
0.006242787
0.007813279
0.0033278014
0.003285282
0.0049616103
0.00467337
0.007940962
0.00440156
0.0152364075
0.002801472
0.0038820647
0.010478927
0.0034810093
0.008436201
0.00814425
0.0041063847
0.007993581
0.0012176025
0.0039697695
0.008992642
0.0
0.0
0.008921341
0.0
0.0039049434
0.0049220566
0.0
0.006902258
0.006860022
0.0
0.008079597
0.009107118
0.0
0.011799554
0.0
0.0
0.0
0.003501907
0.009703914
0.004485993
0.0033144269
0.0
0.011437842
0.0034271963
0.0
0.008137273
0.018464398
0.0030808088
0.004494274
0.0044580344
0.0050494485
0.005642733
0.005548469
0.0052293683
0.007964139
0.009485997
0.008327263
0.0030338618
0.0033491806
0.004146076
0.005111455
0.0075085596
0.0063258135
0.006558905
0.003732377
0.0039197826
0.00591539
0.00441586
0.001966875
0.0
0.007385546
0.010364667
0.0050697476
0.017575853
0.008983546
0.0064805336
0.008375013
0.01085741
0.007881906
0.0071173455
0.0064538484
0.0
0.0034677961
0.002169341
0.006025304
0.007821663
0.0
0.007831407
0.011773814
0.0
0.009275474
0.005916361
0.0038078376
0.00439868
0.011689649
0.004756247
0.009055012
0.007564545
0.012883397
0.01590212
0.0034970276
0.0050735986
0.0067562256
0.0068816566
0.0078038326
0.0
0.0022830314
0.0037356985
0.0
0.008601311
0.0068868725
0.007752909
0.0054735206
0.008368197
0.0
0.0149115985
0.0056866645
0.01788227
0.0057322294
0.0051487302
0.0076670875
0.002073596
0.004318608
0.005754319
0.0039112163
0.0
0.017194413
0.0035243179
0.00744793
0.0
0.007128529
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.989574   0.833333  0.590909  0.691489  0.627413  0.770142   

   Average Precision  
0           0.500513  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[10:17:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 2375.008 seconds
Cross-validation score: 0.8078667116433877
Test score: 0.8149779735682818
Best Hyperparameters: {'classifier__min_child_weight': 5, 'classifier__max_depth': 18, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0.2, 'classifier__colsample_bytree': 0.4}
0.010857323
0.024605704
0.029680159
0.02687071
0.041670457
0.003612283
0.004153611
0.0027728064
0.008411378
0.010393756
0.003895015
0.003508153
0.014080356
0.007988613
0.0036433472
0.0074268407
0.0057381024
0.004746991
0.022818776
0.016499491
0.022907676
0.0090784505
0.0034805208
0.0063412874
0.003491146
0.0033752227
0.018236062
0.014929686
0.004430189
0.0032593866
0.004270799
0.008537144
0.0047553657
0.012761368
0.0026925409
0.006868316
0.0051069837
0.0031397664
0.0033657637
0.0036541556
0.004776791
0.0055369954
0.0030958764
0.0036106787
0.007690225
0.0
0.006080361
0.0032032575
0.0
0.0062946826
0.0028361422
0.0
0.0062057744
0.008732832
0.0
0.008160874
0.0
0.0
0.0
0.004789347
0.0043404535
0.0049791825
0.0
0.0077071283
0.005135813
0.006446861
0.0060735582
0.0071093044
0.006964732
0.0032835577
0.004336098
0.0051000416
0.0048072683
0.0056983763
0.0042465334
0.0036971415
0.006456309
0.006067641
0.008119128
0.0062112096
0.008845748
0.0040997765
0.005760795
0.007055663
0.004044565
0.0045534316
0.009820701
0.0019330614
0.0060987887
0.0036172655
0.0106869
0.0
0.006698487
0.0040170825
0.006297478
0.0099615045
0.0025847475
0.014983683
0.008331213
0.004211716
0.0050952425
0.01781186
0.006340223
0.0037524546
0.0067445626
0.004763452
0.0055705854
0.004877491
0.0033242
0.0056134374
0.005002354
0.0083444575
0.009456505
0.003144638
0.0050536725
0.0045049326
0.013438674
0.005876499
0.0044299425
0.0042477166
0.0033606642
0.005896478
0.004913766
0.0046730717
0.0037232835
0.0058275354
0.00498984
0.004542282
0.006135492
0.004164898
0.01026367
0.011449023
0.005572
0.011530807
0.00454688
0.0071767885
0.003371302
0.003651672
0.0054304996
0.0041470425
0.004571301
0.005290642
0.00510631
0.0046198117
0.0035281053
0.002755561
0.00631558
0.0
0.0035378684
0.006497474
0.004319477
0.0042057578
0.0070396173
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.991372   0.860465  0.672727  0.755102  0.703422  0.814978   

   Average Precision  
0            0.58533  

--------------------------------------------------------------------
