[04:14:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 11403.837 seconds
Cross-validation score: 0.7757145444535565
Test score: 0.7812499999999999
Best Hyperparameters: {'classifier__min_child_weight': 10, 'classifier__max_depth': 20, 'classifier__learning_rate': 0.3, 'classifier__gamma': 0.6, 'classifier__colsample_bytree': 0.4}
0.011394889
0.032656018
0.0261843
0.011768988
0.01651382
0.009361308
0.006273642
0.0036932079
0.005455474
0.011123369
0.0029002905
0.0
0.014173302
0.012430672
0.008337721
0.0066977395
0.0026501494
0.001635374
0.0039611883
0.0043424126
0.027145745
0.02105507
0.0072234552
0.006488641
0.0030079654
0.0005656126
0.005507935
0.011643245
0.019282022
0.004660468
0.0072060893
0.0
0.004334715
0.021058232
0.0031839868
0.0060477834
0.0038617977
0.0048512826
0.004074394
0.0019643784
0.0047528534
0.0035840475
0.004370053
0.0066354778
0.005917627
0.0
0.006761605
0.007615574
0.0007816571
0.0033125312
0.0021004921
0.005310455
0.006511141
0.004644664
0.030035824
0.0060764705
0.0
0.0
0.0
0.0039894814
0.006348294
0.004234702
0.011677206
0.004162355
0.0033892943
0.003021842
0.0040498325
0.008821727
0.004181151
0.0033271878
0.005766601
0.004091618
0.0059095114
0.0067672585
0.012533272
0.0022771272
0.0068433653
0.003354898
0.004059941
0.0
0.0064162933
0.0041234964
0.0052174167
0.0013304468
0.0033052217
0.007829696
0.0075446703
0.0
0.005330884
0.0043584094
0.007344044
0.0070293196
0.0022643993
0.0047841994
0.002791785
0.008522181
0.009437146
0.007059303
0.0204676
0.0014383844
0.007622768
0.0049246224
0.007035564
0.020550162
0.004949322
0.004656116
0.0027538117
0.0
0.02660623
0.006428052
0.009589115
0.010388721
0.003602425
0.0020647799
0.002776435
0.0044127284
0.0179679
0.001349985
0.0074015246
0.004054816
0.0060469676
0.010354931
0.0024599223
0.002722963
0.003414618
0.0038273232
0.0040414697
0.000974644
0.0011803102
0.006455345
0.0072954977
0.007116917
0.009234051
0.0040659113
0.008187795
0.014511984
0.010574524
0.001733677
0.0041819997
0.0057961326
0.002307924
0.003910649
0.0049303197
0.0010852449
0.004070317
0.005880993
0.0040278225
0.0
0.0050301356
0.0059738494
0.0083839595
0.002696078
0.009861958
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2     F0.5  \
0  0.997591   0.847458  0.595238  0.699301  0.632911  0.78125   

   Average Precision  
0           0.506344  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[07:11:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 10645.227 seconds
Cross-validation score: 0.8024635238998099
Test score: 0.6866197183098592
Best Hyperparameters: {'classifier__min_child_weight': 8, 'classifier__max_depth': 6, 'classifier__learning_rate': 0.15, 'classifier__gamma': 0.0, 'classifier__colsample_bytree': 0.6}
0.008330777
0.03162562
0.020698024
0.013030562
0.015371437
0.0064038807
0.0064802202
0.007551145
0.008831705
0.004262059
0.0
0.0035604883
0.009695109
0.012489432
0.006752067
0.0148933735
0.00067091855
0.0
0.006491136
0.002618051
0.018837098
0.02491297
0.0044596256
0.009030034
0.0035794731
0.0020917575
0.0061061797
0.00497325
0.0012371732
0.014517672
0.0132202115
0.0054617887
0.005335124
0.010357815
0.0027209155
0.0058793556
0.0034508388
0.008989463
0.0037835124
0.013439852
0.0041391165
0.0041274303
0.0
0.0032154012
0.0024638057
0.0066430005
0.008501841
0.007043508
0.0
0.00906312
0.020452106
0.0067001926
0.0089876205
0.0055009136
0.0
0.0062876106
0.0
0.0
0.0
0.0070315883
0.010251627
0.0036698035
0.0055902796
0.0
0.007184748
0.006414495
0.009269344
0.00391229
0.0104001695
0.0042214766
0.005562358
0.0032133257
0.0056025884
0.004908656
0.008590589
0.004557989
0.006669254
0.0057316134
0.0033586596
0.0026882808
0.0071083046
0.0035379922
0.0049626287
0.0
0.0029904249
0.005401155
0.009388203
0.0036728324
0.005134457
0.006759334
0.007436654
0.0
0.0060172263
0.005192723
0.0064811483
0.006895513
0.007839301
0.003936059
0.0063145147
0.0059118755
0.008687406
0.0076322183
0.0060806624
0.0
0.006886018
0.008650464
0.0031033396
0.0039019117
0.008068355
0.0
0.012664136
0.008991787
0.0062713693
0.0039507947
0.0051986407
0.006286606
0.0065505495
0.010323631
0.008295489
0.004389902
0.004543229
0.002185858
0.0068181152
0.006350566
0.0046199244
0.01447108
0.004418402
0.0
0.005548573
0.0058135595
0.0038424537
0.0046197525
0.0076362994
0.011315218
0.027296161
0.008021829
0.011561641
0.008162057
0.0052524614
0.0027719208
0.00303344
0.006644099
0.00406704
0.005497477
0.005946872
0.008350226
0.00690556
0.0021938332
0.0057652374
0.008404017
0.005232166
0.0
0.0077023627
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall       F1        F2     F0.5  \
0  0.996862       0.78  0.464286  0.58209  0.505181  0.68662   

   Average Precision  
0           0.364664  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[10:12:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 10837.444 seconds
Cross-validation score: 0.7871390751605445
Test score: 0.7770270270270271
Best Hyperparameters: {'classifier__min_child_weight': 5, 'classifier__max_depth': 6, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0.0, 'classifier__colsample_bytree': 0.8}
0.008012398
0.02808484
0.023111546
0.0145934345
0.012760392
0.0040567946
0.004159175
0.0067713195
0.007297424
0.007867958
0.0026758478
0.008564101
0.0084668165
0.011850099
0.0074734846
0.012205152
0.0030444905
0.0
0.003890468
0.0019619633
0.020562125
0.024998084
0.0036575014
0.010710203
0.0034382367
0.0038980069
0.0072637247
0.008326687
0.012440373
0.0066599944
0.0076812296
0.00912969
0.0038656245
0.010787149
0.004183627
0.0032254988
0.0033789861
0.006924956
0.0032330381
0.0022060361
0.004299033
0.0
0.0
0.0012431025
0.014639569
0.0006188134
0.009178559
0.006651371
0.004299652
0.010595894
0.012586925
0.0
0.008038658
0.0074766036
0.008003434
0.0113894185
0.0
0.0
0.0
0.0046442137
0.0035926586
0.0032033606
0.010093584
0.006803029
0.00555395
0.0031137639
0.0052862866
0.0059417277
0.007674497
0.0040038535
0.0022414278
0.0045320317
0.016298499
0.009555855
0.00395433
0.037117213
0.009306975
0.0042684274
0.0032660998
0.0
0.0029393292
0.002331807
0.005047411
0.03070989
0.0024103476
0.0047447
0.0037904086
0.0
0.00380113
0.0034213169
0.006258782
0.0
0.009635179
0.0069434606
0.010239434
0.0031845164
0.005861213
0.0044434406
0.003461777
0.003121149
0.009721056
0.007466954
0.0039380863
0.010623602
0.011239447
0.0033503883
0.0021315073
0.0021418636
0.005478562
0.004456328
0.0031723387
0.012497768
0.006449471
0.0021661143
0.0054539894
0.0067193354
0.0095293885
0.0
0.007926053
0.010193359
0.0048432844
0.00016216202
0.0032353464
0.004813793
0.0
0.006936648
0.005410729
0.0
0.004420069
0.0071397517
0.0
0.006627532
0.005510531
0.004412071
0.008310972
0.0066028936
0.010054913
0.00990741
0.005592543
0.0028940376
0.002636339
0.004558327
0.0028961326
0.008203046
0.003218756
0.007167542
0.00541545
0.015461293
0.003914772
0.006288308
0.006836704
0.0
0.006769093
0.009867388
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1       F2      F0.5  \
0  0.997479   0.867925  0.547619  0.671533  0.59126  0.777027   

   Average Precision  
0           0.477421  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[13:17:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 11141.904 seconds
Cross-validation score: 0.7791285555013246
Test score: 0.8283132530120482
Best Hyperparameters: {'classifier__min_child_weight': 2, 'classifier__max_depth': 20, 'classifier__learning_rate': 0.15, 'classifier__gamma': 0.3, 'classifier__colsample_bytree': 0.7}
0.010903118
0.025603117
0.02117749
0.01786809
0.0122522395
0.0063302484
0.004332794
0.011592001
0.006254765
0.0036288046
0.010647647
0.006711169
0.009932854
0.009065213
0.008526023
0.011764847
0.0040333653
0.014782319
0.0037160928
0.0048073856
0.019130973
0.015755137
0.004556232
0.008819332
0.00553051
0.00289961
0.0047495877
0.007139103
0.006862604
0.009966502
0.00865356
0.0048155556
0.0066698594
0.0057227476
0.003636861
0.0034650278
0.0024119413
0.004999597
0.0029831354
0.0047225845
0.0074530775
0.0025456743
0.00312775
0.0023937623
0.006406799
0.0
0.0045841015
0.0048517548
0.009041124
0.007759332
0.0069168536
0.0032268122
0.00531899
0.006465002
0.0
0.0074164234
0.0
0.0
0.0
0.003095811
0.0056501566
0.003543812
0.008395854
0.004378189
0.0064442675
0.0045025283
0.003935319
0.0071743084
0.008749255
0.007977477
0.0057781865
0.012444337
0.0065535335
0.012034159
0.0065604956
0.011182947
0.009378977
0.0038147345
0.0035132535
0.0073627164
0.0019382773
0.0029251084
0.0058760634
0.0052480865
0.0037677898
0.00507032
0.007436566
0.0
0.003416461
0.0060187085
0.006730966
0.0021277631
0.0045917085
0.012246995
0.013107703
0.0054348144
0.008313743
0.004265447
0.0046014576
0.0022991498
0.0051852884
0.01140353
0.008955305
0.001471801
0.0071865264
0.00399719
0.004590928
0.005412104
0.0038667237
0.007163592
0.011190725
0.012655556
0.00861064
0.0041784616
0.004929609
0.0025408145
0.0077392547
0.009518102
0.007962473
0.0047615203
0.004218043
0.0031966206
0.0037370466
0.0029265105
0.002201262
0.0026446935
0.0069486327
0.00333644
0.0048416555
0.00787533
0.015688388
0.0041611274
0.008205079
0.008899618
0.009679626
0.019874169
0.020564243
0.0039785192
0.0050587757
0.0
0.004323135
0.004379096
0.003964643
0.004114688
0.0043169083
0.005332716
0.004796057
0.00949867
0.006371111
0.0015126221
0.0047336984
0.0
0.006534769
0.005950943
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997983   0.887097  0.654762  0.753425  0.690955  0.828313   

   Average Precision  
0           0.582462  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[16:15:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 10638.069 seconds
Cross-validation score: 0.7696344947484308
Test score: 0.7904411764705882
Best Hyperparameters: {'classifier__min_child_weight': 6, 'classifier__max_depth': 6, 'classifier__learning_rate': 0.15, 'classifier__gamma': 0.7, 'classifier__colsample_bytree': 0.4}
0.01122446
0.02711602
0.024827352
0.012310051
0.012675926
0.009827979
0.005116411
0.0037837853
0.005897281
0.0056569097
0.003192577
0.0026545832
0.011619803
0.008865633
0.010526595
0.012783577
0.006193362
0.005460208
0.004336574
0.004012048
0.022984121
0.024890153
0.0068690428
0.009801233
0.004238811
0.0037845355
0.00592521
0.0070193736
0.006022867
0.010879188
0.008268923
0.010109649
0.008415393
0.00644036
0.0037587686
0.0031778247
0.0047296165
0.0052327393
0.004097114
0.0032611066
0.005079197
0.0018582708
0.005148825
0.0036783738
0.008914131
0.0
0.008290151
0.004878606
0.0037944952
0.0069793467
0.0084158555
0.008619107
0.0066162883
0.005989524
0.0
0.0065575885
0.0
0.0
0.0
0.007584806
0.004724695
0.0028289526
0.0059637753
0.006141779
0.008519773
0.0057734787
0.0070288777
0.004333029
0.0065387054
0.004439534
0.0046458524
0.006840334
0.0070621427
0.010833276
0.0045827106
0.01544168
0.0072090095
0.0019769054
0.005795368
0.0044912673
0.004495418
0.0029574237
0.0064005847
0.0
0.0042844717
0.0043954607
0.009767423
0.007744847
0.0026635446
0.0060586785
0.0043124147
0.0014939491
0.004436781
0.0077732205
0.0061759776
0.0051053544
0.010667108
0.0059580915
0.004801991
0.0
0.0066808714
0.0071265157
0.008209871
0.0053116637
0.006592614
0.0042175064
0.0028811349
0.002864698
0.013057104
0.0035574806
0.011378457
0.013563831
0.006247767
0.0027325533
0.007767733
0.0038265064
0.0048155477
0.0023698704
0.008145309
0.0038736644
0.0069441297
0.009022575
0.0032686286
0.004766192
0.0032390286
0.0
0.0038976735
0.0026096136
0.008477452
0.008568476
0.010345057
0.006072476
0.011223096
0.004275711
0.009328003
0.011659637
0.0073662074
0.00545812
0.0069784615
0.0067710546
0.0051856907
0.0031101794
0.0043403623
0.008628132
0.0045994655
0.010612584
0.008441605
0.0043967757
0.007410771
0.009309606
0.005288428
0.0
0.006157306
0.0019712646
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997479   0.914894  0.511905  0.656489  0.561358  0.790441   

   Average Precision  
0           0.470636  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[19:20:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 11140.966 seconds
Cross-validation score: 0.7707197252713044
Test score: 0.7971014492753623
Best Hyperparameters: {'classifier__min_child_weight': 8, 'classifier__max_depth': 14, 'classifier__learning_rate': 0.15, 'classifier__gamma': 0.2, 'classifier__colsample_bytree': 0.8}
0.008552146
0.0293587
0.020540154
0.013316554
0.017264916
0.004701843
0.0060070986
0.009329789
0.004956688
0.004870969
0.0032712426
0.004903599
0.011448122
0.014405856
0.008691705
0.045891162
0.0030751736
0.0
0.004811769
0.0045881667
0.025403172
0.017541066
0.0042777243
0.007902939
0.007875078
0.001576945
0.0017381478
0.006954025
0.007173446
0.008684083
0.009979099
0.004237549
0.0046097892
0.006298208
0.0032695467
0.004849132
0.0
0.005658643
0.0038091608
0.01091005
0.004123709
0.0
0.0
0.0037447785
0.0075802812
0.0
0.0100051565
0.005215211
0.0037711842
0.0066120024
0.0059109037
0.0
0.008719153
0.0059897513
0.020352878
0.010252884
0.0
0.0
0.0
0.004214461
0.0013844746
0.0033864537
0.006379105
0.006830195
0.008229897
0.0027296671
0.0062766853
0.007223736
0.006565107
0.0054389513
0.0045407605
0.0035003247
0.020645855
0.00690989
0.003943138
0.0
0.0066452655
0.0024507733
0.0049050525
0.00352825
0.0040259333
0.004574867
0.00400353
0.0
0.004850439
0.010576491
0.009172161
0.0
0.004638639
0.0096634235
0.007512542
0.0
0.0057135043
0.006134049
0.008943023
0.0037187182
0.004379356
0.0070236367
0.003076268
0.024090363
0.0054084184
0.006025431
0.008067346
0.0022835832
0.0063853865
0.0
0.0032987758
0.0046761306
0.004891499
0.004425957
0.009001867
0.0051456583
0.006428015
0.0038919891
0.00844106
0.0064860294
0.008246095
0.005138014
0.008552232
0.004114408
0.004689668
0.008907051
0.0044989767
0.0036679036
0.0
0.0053749066
0.0039963913
0.009080009
0.002100287
0.008992474
0.0
0.010878276
0.007687552
0.0014754104
0.014523986
0.0057708714
0.010570319
0.0033541343
0.007392922
0.0037504
0.0037897672
0.0067111533
0.0044703614
0.0048278123
0.0061485
0.0063907974
0.011389998
0.0038157152
0.0041536256
0.0059867753
0.00808217
0.0019986364
0.0065788324
0.0052002054
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision   Recall        F1        F2      F0.5  \
0  0.997535   0.916667  0.52381  0.666667  0.572917  0.797101   

   Average Precision  
0             0.4824  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[22:21:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 10846.720 seconds
Cross-validation score: 0.7640409708384688
Test score: 0.8
Best Hyperparameters: {'classifier__min_child_weight': 1, 'classifier__max_depth': 12, 'classifier__learning_rate': 0.3, 'classifier__gamma': 0.6, 'classifier__colsample_bytree': 0.8}
0.010156208
0.025247669
0.019959312
0.014194694
0.010512167
0.005474098
0.0048515596
0.0068074735
0.0036697173
0.003856274
0.013522794
0.0056708106
0.014217061
0.007500638
0.0054485234
0.00985546
0.0014590517
0.0
0.0076229754
0.0036924076
0.021133365
0.016847944
0.0058593955
0.0038006408
0.0051754005
0.0069762594
0.004201447
0.00493868
0.010298985
0.007423561
0.021644711
0.006175662
0.007527441
0.0064252303
0.008074868
0.0030314126
0.014320789
0.006793198
0.0034373535
0.0066900547
0.0050540017
0.0022076163
0.0024272797
0.0
0.004901709
0.005584126
0.006504282
0.005974023
0.0014850742
0.010349455
0.0067611285
0.0
0.0028021364
0.006020961
0.0052102455
0.0044266214
0.0
0.0
0.0
0.004263726
0.004351659
0.008026583
0.0064519094
0.007728574
0.0051545026
0.004298281
0.003910537
0.0046714004
0.0057582064
0.0061978116
0.006059255
0.0
0.023979155
0.010099144
0.011081679
0.015517671
0.012867399
0.008535729
0.005604279
0.0032993834
0.0039723334
0.004207982
0.006555199
0.004389269
0.004243124
0.0023845672
0.0050724735
0.0
0.005629636
0.004835812
0.004176497
0.0
0.003738211
0.014918855
0.0074857147
0.0045002275
0.008038399
0.002997025
0.0045540286
0.0
0.0
0.006266632
0.0097029265
0.0047744415
0.0042020087
0.007912011
0.0035257672
0.003046975
0.0074371
0.010950756
0.0076551433
0.011102746
0.005154622
0.0047529615
0.0071400674
0.010926552
0.012376386
0.003464652
0.006636943
0.009883928
0.006207151
0.008557722
0.0031304325
0.0049016573
0.0044217827
0.00209884
0.006283349
0.0
0.002291105
0.011966005
0.0
0.004635257
0.0056812675
0.002810567
0.013513653
0.012492048
0.02283863
0.004256468
0.005793926
0.005870983
0.004220934
0.0037082175
0.005264528
0.00418903
0.0053626066
0.005167486
0.00589905
0.017927783
0.0038356527
0.002264555
0.007716136
0.0
0.0044749673
0.0015453957
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2  F0.5  Average Precision
0  0.997647   0.888889  0.571429  0.695652  0.615385   0.8           0.509954

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\metrics\_plot\precision_recall_curve.py:125: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots()
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[01:33:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 11490.883 seconds
Cross-validation score: 0.7601420385766747
Test score: 0.7670454545454545
Best Hyperparameters: {'classifier__min_child_weight': 5, 'classifier__max_depth': 8, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0.4, 'classifier__colsample_bytree': 0.9}
0.008721775
0.033922702
0.02173513
0.013362366
0.016587451
0.00680647
0.005452405
0.00904111
0.0076446324
0.009250477
0.0018174244
0.0011725009
0.00841153
0.011972087
0.009015282
0.008041722
0.002411032
0.0
0.0038672315
0.0050774305
0.01766651
0.017839314
0.0061283875
0.013770111
0.008166734
0.0045008264
0.00361475
0.008406116
0.0077289073
0.0047382573
0.011122153
0.004032645
0.004208491
0.013427616
0.0081225075
0.0048948256
0.005083398
0.0070041036
0.003732269
0.009795498
0.0018215387
0.006157231
0.0017772727
0.0008889088
0.008643605
0.0
0.009897864
0.005728821
0.0012437376
0.006017648
0.012496396
0.0
0.010850313
0.0071265595
0.012371653
0.0047857147
0.0
0.0
0.0
0.005193674
0.0031828727
0.0050680223
0.009985491
0.010638076
0.0049781143
0.0030451554
0.0055172266
0.009263151
0.0060139415
0.003703918
0.0042542946
0.00603497
0.0
0.015518815
0.005478133
0.0025711074
0.0047591594
0.005643484
0.0032357306
0.0029024146
0.004956454
0.004314487
0.003870822
0.0027744006
0.005880926
0.0057100113
0.0054635913
0.0
0.012197292
0.0064248713
0.005171583
0.017437533
0.0069003585
0.010473552
0.013326413
0.006399979
0.006315909
0.0054785693
0.0036278928
0.0016678888
0.0057553886
0.007855198
0.0057834797
0.00328809
0.009155199
0.0037017027
0.0022853215
0.006892301
0.00786476
0.004646007
0.010942048
0.012956043
0.005425183
0.0039916695
0.0047474634
0.003723333
0.0040302225
0.0011070883
0.008999238
0.004398917
0.0057869526
0.012753033
0.0018729426
0.002724728
0.0044897003
0.006905439
0.0045540263
0.0
0.0015215252
0.008072603
0.0
0.0057916897
0.0072060423
0.009108429
0.014666083
0.012266802
0.0
0.0043332325
0.0052104113
0.0074803918
0.0050656702
0.005173144
0.003798128
0.0038782493
0.0070171426
0.0076751807
0.006831707
0.005134225
0.005441088
0.00318165
0.009015573
0.0
0.009694499
0.012319386
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997591    0.80597  0.642857  0.715232  0.669975  0.767045   

   Average Precision  
0           0.519805  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[04:41:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 11304.496 seconds
Cross-validation score: 0.7712397052950749
Test score: 0.7922535211267605
Best Hyperparameters: {'classifier__min_child_weight': 7, 'classifier__max_depth': 20, 'classifier__learning_rate': 0.15, 'classifier__gamma': 0.4, 'classifier__colsample_bytree': 0.8}
0.00866346
0.028688606
0.022178503
0.010935721
0.016797155
0.003602112
0.004254129
0.008936703
0.0072647478
0.0039773905
0.0
0.00571839
0.0115158325
0.016019251
0.007352457
0.018488294
0.0017598252
0.0
0.006174722
0.0037565765
0.019970525
0.019682888
0.006258026
0.012632636
0.0058275904
0.0042570815
0.007956191
0.009195308
0.011117922
0.0071669924
0.015318671
0.0033636799
0.0031953105
0.014537082
0.0023380232
0.0041886554
0.0036566765
0.007246623
0.0038378844
0.00997139
0.0035168985
0.003421323
0.0036040982
0.00437369
0.008877399
0.0
0.007543457
0.008113093
0.0047960556
0.0066655716
0.01104062
0.0
0.009708141
0.005989095
0.0
0.004383314
0.0
0.0
0.0
0.004298153
0.0033566114
0.0031705976
0.014618564
0.009318558
0.0065474436
0.011003871
0.0067484844
0.0076951147
0.0052086925
0.008954085
0.004468006
0.005905989
0.015043965
0.011765336
0.0026108383
0.0023707033
0.0056354487
0.0028521896
0.004017662
0.0
0.0066606686
0.005168011
0.00376236
0.0074597714
0.0027178167
0.0075841467
0.005846851
0.0
0.0076131085
0.011100702
0.0053660925
0.0054140193
0.0060210037
0.0057428884
0.0049371915
0.0028498457
0.008979977
0.0040070373
0.0076987706
0.0039435322
0.0066098515
0.005790597
0.005088178
0.019716855
0.0056592394
0.0046438933
0.0039980845
0.0053392453
0.0050733997
0.0051324195
0.009147831
0.006467319
0.0072946018
0.0036976852
0.0015809656
0.010906078
0.0074324333
0.0025256365
0.0077572917
0.006266253
0.0049116267
0.0
0.004850426
0.004262627
0.0
0.0016236984
0.0027486598
0.00733129
0.0080808215
0.003801098
0.0
0.0059171813
0.006657915
0.010294463
0.011812386
0.0076602995
0.011003027
0.005681043
0.007187523
0.009820948
0.0030514444
0.004999375
0.00394133
0.003644157
0.0047192355
0.0057457886
0.006333741
0.00676892
0.0039113546
0.0024204596
0.0069108265
0.004288793
0.007607338
0.003584494
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997535        0.9  0.535714  0.671642  0.582902  0.792254   

   Average Precision  
0           0.484328  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[07:56:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 11690.794 seconds
Cross-validation score: 0.7710724446323186
Test score: 0.7649253731343283
Best Hyperparameters: {'classifier__min_child_weight': 1, 'classifier__max_depth': 16, 'classifier__learning_rate': 0.35, 'classifier__gamma': 0.8, 'classifier__colsample_bytree': 0.6}
0.008485807
0.02720303
0.01985291
0.014099367
0.014982786
0.004998258
0.006677035
0.004354665
0.0048569804
0.0030426795
0.0073379753
0.004839447
0.008189296
0.0073865666
0.005795295
0.01846993
0.003970616
0.004478623
0.008380196
0.0036790324
0.01608974
0.026606698
0.004789602
0.01036549
0.0035035473
0.007882461
0.00642593
0.004865226
0.0047430587
0.0040896093
0.0055938545
0.0037070706
0.003615069
0.007798282
0.0017639942
0.006568233
0.005088929
0.0038043254
0.0039260904
0.006048725
0.005415464
0.0028101625
0.003914815
0.0048732697
0.0063578156
0.0
0.008465252
0.0119930655
6.590761e-05
0.0050715585
0.01761063
0.0
0.0061754067
0.0040289024
0.0
0.006537421
0.0
0.0
0.0
0.003922768
0.0051723416
0.0028858024
0.008905634
0.0058140764
0.009857899
0.010800361
0.0077521605
0.0052820486
0.008135471
0.004394456
0.0062147607
0.0070846877
0.01633924
0.0048056287
0.0054767313
0.009643577
0.0067439536
0.010087094
0.0030379503
0.0
0.004139797
0.003992548
0.0044079795
0.0051881587
0.007133313
0.0085985465
0.00494488
0.0067722644
0.006491248
0.0044680056
0.0043211076
0.003397661
0.0055868058
0.0128976535
0.004736206
0.005584788
0.007430287
0.004676365
0.007676325
0.0
0.011303673
0.008360149
0.009053338
0.0
0.0034420867
0.004915631
0.005484805
0.005409727
0.004282232
0.019255927
0.007673492
0.009209974
0.00829699
0.0030062017
0.0036170543
0.006984043
0.0058439705
0.005325624
0.007024928
0.007109017
0.007260611
0.0033401914
0.0053320066
0.00524327
0.0
0.006079
0.0050165006
0.00494457
0.0050930423
0.007353157
0.018404815
0.006484883
0.009102186
0.0073451116
0.0046243067
0.0076148263
0.020325992
0.0038618315
0.0038027386
0.0028205612
0.0060371957
0.0042566527
0.00436632
0.01078273
0.004882651
0.0072661084
0.004114233
0.0026205094
0.004556861
0.007053454
0.009501721
0.0
0.0037467382
0.0046897093
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0   0.99731   0.891304  0.488095  0.630769  0.536649  0.764925   

   Average Precision  
0           0.437451  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[10:56:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 10811.360 seconds
Cross-validation score: 0.7843760428393578
Test score: 0.7692307692307693
Best Hyperparameters: {'classifier__min_child_weight': 9, 'classifier__max_depth': 14, 'classifier__learning_rate': 0.15, 'classifier__gamma': 0.6, 'classifier__colsample_bytree': 0.3}
0.009172983
0.030756317
0.027986322
0.015636735
0.016190711
0.009075261
0.010742995
0.007413636
0.0054709953
0.006060384
0.0033431407
0.0020075927
0.011624589
0.01652136
0.007819389
0.0069083953
0.014973909
0.0025364102
0.0073972493
0.005783656
0.022107115
0.022306757
0.005574102
0.010168255
0.001730444
0.007439351
0.0094780335
0.007878558
0.0026233164
0.0042574927
0.014973187
0.0063693114
0.004449894
0.008137139
0.0058699287
0.0059159542
0.0072491295
0.0053579663
0.005998192
0.006227308
0.0039613876
0.0017958975
0.0084736915
0.0032755742
0.005641067
0.0
0.010955358
0.0074899234
0.0
0.008923766
0.0062489524
0.0
0.0061573475
0.0058781207
0.0037864163
0.0062284768
0.0
0.0
0.0
0.007821619
0.0035804356
0.0030159608
0.0057946267
0.0041672145
0.0073146224
0.006172847
0.0048136767
0.006534469
0.00634324
0.0061629214
0.0047902055
0.0057210424
0.008654304
0.012126107
0.005897898
0.006285646
0.006305693
0.005045746
0.0026417195
0.0044313115
0.00384659
0.0043072067
0.0042475658
0.0
0.0034155536
0.005179407
0.0059942147
0.0032679664
0.0015223315
0.0057590073
0.008958523
0.0017338997
0.0059099616
0.006253014
0.0023990169
0.00986001
0.008558506
0.0076832287
0.009239774
0.0062996214
0.006977988
0.0105719725
0.00656126
0.0087191025
0.00696399
0.0028833607
0.0026776448
0.0035381091
0.007179455
0.0057278634
0.0065954775
0.011972864
0.0060396986
0.0040480983
0.0030052331
0.002759517
0.008917418
0.00579524
0.006540928
0.0039924644
0.004394759
0.0076935897
0.0056509417
0.005641001
0.0
0.0
0.0032026619
0.0031175334
0.0
0.006638869
0.008973082
0.007594058
0.008145865
0.0051749824
0.007526738
0.01253611
0.010716836
0.0053500705
0.0072639347
0.008205604
0.002728564
0.005610936
0.0054294392
0.0032652079
0.0075958227
0.005216986
0.0074659805
0.0046229577
0.0060109827
0.003832762
0.0070004906
0.0064401245
0.005434418
0.0016447913
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997479   0.842105  0.571429  0.680851  0.610687  0.769231   

   Average Precision  
0            0.48322  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[13:38:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 9720.313 seconds
Cross-validation score: 0.7697479968093388
Test score: 0.7738095238095238
Best Hyperparameters: {'classifier__min_child_weight': 1, 'classifier__max_depth': 6, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0.3, 'classifier__colsample_bytree': 0.6}
0.011033965
0.03501337
0.026822366
0.01995387
0.008541921
0.00956443
0.0042367997
0.0063918997
0.004595211
0.0035417818
0.010674126
0.00966765
0.0064194575
0.0090165585
0.005312098
0.013943432
0.003130363
0.0
0.002471592
0.0048997262
0.021389209
0.016562358
0.004765543
0.012793844
0.0041278647
0.0040473803
0.008529448
0.009178069
0.00875047
0.008438313
0.00566918
0.0047786366
0.0038112393
0.00703852
0.004247358
0.004301103
0.004131008
0.0076088174
0.0031483637
0.0068565356
0.0048817373
0.0023919442
0.00535442
0.0034715552
0.00837148
0.002264598
0.011890373
0.008864727
0.0039045785
0.0066715707
0.004560182
0.0
0.006664993
0.0049656485
0.0
0.008321906
0.0
0.0
0.0
0.0058494904
0.004771932
0.003144699
0.008666821
0.004594567
0.007414538
0.0115925055
0.007872136
0.0062702596
0.0061010295
0.0031706218
0.006045027
0.0028421632
0.0016875053
0.013544289
0.010586988
0.006516789
0.009615666
0.006776571
0.0040174974
0.0026259643
0.0041682916
0.0032474184
0.0034823336
0.0038675515
0.006295047
0.008002668
0.0063858167
0.0
0.009223995
0.0023706497
0.01056106
0.005864414
0.0065158117
0.01021955
0.006448484
0.004539865
0.006159734
0.0035659126
0.006707907
0.009040779
0.008577796
0.01277428
0.0067246393
0.0
0.010467164
0.005535662
0.0041441177
0.0032388251
0.007712619
0.0058092885
0.012157603
0.024793407
0.0048344876
0.0052149137
0.006436749
0.007210329
0.006143645
0.0
0.0017045755
0.0076177637
0.004708735
0.018410303
0.0028474384
0.004684547
0.004634763
0.0025128
0.003962395
0.0
0.011707733
0.0075219087
0.0009935012
0.0035629272
0.0065864376
0.006888613
0.012568198
0.0037656252
0.005981601
0.004520754
0.0040281583
0.0057389587
0.007669676
0.002462566
0.0049054837
0.0029505978
0.0056197643
0.0058678137
0.0034113955
0.004969681
0.008235899
0.0049709463
0.0064729485
0.0017256917
0.0056563346
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2     F0.5  \
0  0.997591   0.825397  0.619048  0.707483  0.651629  0.77381   

   Average Precision  
0           0.512753  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[16:38:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 10786.679 seconds
Cross-validation score: 0.7704816416684832
Test score: 0.744047619047619
Best Hyperparameters: {'classifier__min_child_weight': 6, 'classifier__max_depth': 6, 'classifier__learning_rate': 0.15, 'classifier__gamma': 0.5, 'classifier__colsample_bytree': 0.5}
0.008418859
0.028709143
0.02521097
0.011564638
0.013033231
0.0046068
0.009055067
0.0057177707
0.0058736303
0.0032228676
0.003154826
0.0038583262
0.010605628
0.0108897975
0.0063004796
0.014407721
0.004079282
0.00090287655
0.005045449
0.002321937
0.018354004
0.01678887
0.00516247
0.009165449
0.002806852
0.0076979524
0.004523931
0.006987333
0.007237625
0.007210231
0.00866512
0.006475111
0.0040626274
0.013170912
0.0043283426
0.0053629396
0.0069444985
0.006398444
0.003503207
0.0048956815
0.0037945127
0.006806849
0.008361961
0.0015030445
0.0066477205
0.0
0.0073058563
0.003553007
0.0
0.010083234
0.005422286
0.013681936
0.00863857
0.010196311
0.009852819
0.0066097444
0.0
0.0
0.0
0.006156155
0.004098695
0.003838005
0.003504935
0.00875644
0.006160009
0.0057824394
0.007417253
0.005400919
0.005427329
0.0026761852
0.0053963857
0.010384036
0.015369539
0.009167303
0.0052404557
0.009412986
0.006378538
0.0025184741
0.0065953275
0.002822617
0.0037664082
0.0028276686
0.0057450673
0.009479478
0.004446291
0.008097778
0.0040461505
0.0
0.007740819
0.002015599
0.0060926536
0.0
0.0064140903
0.009250769
0.008965265
0.00528463
0.0072170217
0.0049841455
0.0074225445
0.008607425
0.0060901213
0.009423256
0.007209358
0.0022474576
0.010789576
0.0038717152
0.0050214203
0.0016426059
0.0071191187
0.007850642
0.009227686
0.010036519
0.0035696998
0.0044444567
0.004068587
0.005082141
0.008304178
0.0059989844
0.010672846
0.006149063
0.0062313355
0.020508103
0.00414153
0.0034523478
0.0068330024
0.0034468565
0.0046056346
0.002575305
0.0068246876
0.011032837
0.005454194
0.0062943953
0.0063184174
0.0070408965
0.010644181
0.0071691447
0.0099817645
0.0021403278
0.0059139766
0.0018416829
0.004190438
0.0020020616
0.004853819
0.0032005727
0.006570548
0.005839472
0.0070650866
0.002245063
0.0042667645
0.0052753147
0.005151484
0.0
0.006490889
0.0074918475
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997367   0.793651  0.595238  0.680272  0.626566  0.744048   

   Average Precision  
0           0.474316  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[19:39:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 10847.597 seconds
Cross-validation score: 0.7731039028728282
Test score: 0.7172131147540983
Best Hyperparameters: {'classifier__min_child_weight': 2, 'classifier__max_depth': 14, 'classifier__learning_rate': 0.3, 'classifier__gamma': 0.2, 'classifier__colsample_bytree': 0.4}
0.011736978
0.027301624
0.02372291
0.015398151
0.007343129
0.006693881
0.006624434
0.0041539297
0.0018071899
0.0053014574
0.005380467
0.0010619138
0.011058429
0.009866237
0.0037832835
0.0090601845
0.0048037544
0.005756182
0.0064238003
0.002645744
0.014625926
0.018432342
0.0050844764
0.0051563117
0.0033998187
0.0036343206
0.0077457856
0.006900317
0.015082742
0.0010949634
0.010983903
0.0071750428
0.0023417822
0.020583265
0.0069641843
0.008093062
0.0021419066
0.0045148423
0.0034682078
0.0040390305
0.0043112724
0.0036203184
0.0040551666
0.002893796
0.0052476004
0.018555524
0.007905741
0.009213631
0.009536711
0.0041243527
0.009331545
0.0
0.007822681
0.00419431
0.0
0.009106531
0.0
0.0
0.0
0.0054432643
0.00214414
0.0052445545
0.0037886542
0.004642665
0.0055414755
0.011033105
0.0034518684
0.0028502757
0.0062502786
0.0027627964
0.0068679475
0.0057296865
0.0049776323
0.0052785473
0.006077757
0.016022239
0.0131675545
0.0039342702
0.0035333948
0.0041085067
0.0028541281
0.0026146306
0.005465389
0.010456871
0.0032688356
0.006511579
0.0073242127
0.0020175711
0.0063999454
0.005846755
0.0031516347
0.0032586202
0.0011322477
0.0064697154
0.0048204795
0.019300291
0.0066263974
0.0034212861
0.0038673442
0.0
0.010243514
0.004292974
0.0058121164
0.0025949501
0.006187894
0.0026704706
0.0033527305
0.0022591152
0.0043887673
0.0054188883
0.0065395306
0.022025477
0.004948441
0.0029976266
0.0035335904
0.006635699
0.009212
0.008417177
0.004350004
0.0021316502
0.0064625065
0.0054979417
0.0019607565
0.0027475953
0.0026579695
0.0062204893
0.0064031263
0.004002238
0.006605488
0.015846897
0.0077555985
0.004920253
0.007124323
0.008404028
0.012469225
0.008967418
0.022776479
0.008892058
0.003639374
0.0109812785
0.002881878
0.0031701047
0.0041347593
0.0031209842
0.0052736886
0.005644879
0.0056448854
0.0017109434
0.004950674
0.0075970786
0.006961183
0.0
0.009697273
0.017900378
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.996974      0.875  0.416667  0.564516  0.465426  0.717213   

   Average Precision  
0           0.367329  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[22:48:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 11351.903 seconds
Cross-validation score: 0.7624000099024577
Test score: 0.8
Best Hyperparameters: {'classifier__min_child_weight': 4, 'classifier__max_depth': 12, 'classifier__learning_rate': 0.15, 'classifier__gamma': 0.4, 'classifier__colsample_bytree': 0.8}
0.009457152
0.025779989
0.021965215
0.013481857
0.009601468
0.0052531897
0.0048264004
0.010023888
0.005725126
0.007749229
0.0070856554
0.0017272242
0.011460452
0.012480712
0.008060437
0.0067587076
0.0066088266
0.0010698873
0.004843551
0.0037546803
0.016596125
0.02586492
0.0042446726
0.013373862
0.0069939853
0.0040420997
0.0042366297
0.00850031
0.009002457
0.010165796
0.0066472823
0.004361883
0.0047128974
0.0071465387
0.0069837663
0.0043153306
0.0033459738
0.007443494
0.0047190404
0.010639253
0.0046473453
0.008003747
0.0
0.0080332
0.00581804
0.0054292274
0.009401622
0.005123589
0.0
0.004752178
0.015542471
0.0
0.0048719165
0.00732436
0.0
0.0063330666
0.0
0.0
0.0
0.003281233
0.0047173765
0.0037301353
0.0059226914
0.009225783
0.0069754366
0.0050800997
0.0046600723
0.007945258
0.005392115
0.00392085
0.00912261
0.0059119537
0.010095147
0.0040225196
0.009783335
0.006286364
0.005707255
0.0037553054
0.0041193995
0.0017159999
0.0052438104
0.00337988
0.0051904893
0.006738157
0.002775132
0.006782086
0.0066378517
0.0
0.008403862
0.005646322
0.0037423607
0.0
0.0069531207
0.004219532
0.0065225656
0.0053971354
0.007597547
0.0037963197
0.005412081
0.00259969
0.009475674
0.006495567
0.006549337
0.021613482
0.00604391
0.0071162726
0.0023186188
0.00682147
0.0051556514
0.008540675
0.006654429
0.00947132
0.004849423
0.005050044
0.0028326493
0.0056809764
0.010339837
0.005118716
0.009900655
0.006150949
0.0038429303
0.032972112
0.0033544004
0.0050451523
0.0047324537
0.004568582
0.0041807606
0.0042604515
0.005828411
0.006701849
0.0
0.00523818
0.007434578
0.006075286
0.009313749
0.008382936
0.008234667
0.002805917
0.0056834477
0.0039400347
0.003523109
0.0026625714
0.003009786
0.003002907
0.006556876
0.0039968444
0.0064416383
0.013736594
0.0017143034
0.008680016
0.0046055214
0.0029473947
0.006719661
0.008887618
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2  F0.5  Average Precision
0  0.997647   0.888889  0.571429  0.695652  0.615385   0.8           0.509954

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[01:42:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 10495.872 seconds
Cross-validation score: 0.776160384357292
Test score: 0.7862903225806451
Best Hyperparameters: {'classifier__min_child_weight': 1, 'classifier__max_depth': 14, 'classifier__learning_rate': 0.35, 'classifier__gamma': 0.4, 'classifier__colsample_bytree': 1.0}
0.010562644
0.03228785
0.021504529
0.020500666
0.016580284
0.0051186914
0.004236448
0.0068637417
0.0075694253
0.004708518
0.005126213
0.00945569
0.0105773145
0.013625227
0.011946308
0.0
0.0053509935
0.0
0.0055940533
0.003725061
0.014974964
0.03245792
0.0055260994
0.008376616
0.012647827
0.0025850143
0.0068368157
0.0060315146
0.0044682543
0.007599329
0.015560953
0.0015120759
0.0031381636
0.010413944
0.008089113
0.00540685
0.0045204475
0.0070023113
0.0063493964
0.0030932527
0.0058428305
0.0
0.0
0.0
0.012407919
0.0049780686
0.0042861947
0.0075500133
0.0014914803
0.004934208
0.0044641453
0.0
0.007027655
0.007234697
0.0
0.0046774913
0.0
0.0
0.0
0.003144331
0.0047631585
0.0048901583
0.011710462
0.0063432334
0.009174198
0.0061344183
0.0045172484
0.010962453
0.0053293556
0.009753729
0.0070504425
0.040812735
0.0069224536
0.0072473017
0.005848104
0.016316045
0.007394768
0.0077906693
0.008105251
0.008187696
0.003704369
0.004133305
0.0057784864
0.0037868654
0.004447695
0.014216713
0.007014187
0.0
0.0056444257
0.0053232033
0.004890678
0.0
0.002914104
0.008415329
0.0048163733
0.0043829903
0.007374629
0.002997858
0.0021690961
0.0062057134
0.004502795
0.007461439
0.0030895283
0.004370929
0.014196618
0.008665735
0.00653941
0.006262775
0.009807553
0.007867731
0.0043126587
0.0049335766
0.005189704
0.0040884176
0.008828148
0.0077378633
0.0051094787
0.005754804
0.007928878
0.0060993857
0.0045062522
0.0
0.0031436826
0.0075379913
0.0
0.0016537573
0.004645751
0.0
0.0
0.011423997
0.0
0.004635982
0.009099689
0.0
0.0035280338
0.0066482252
0.0
0.004538943
0.005457707
0.0
0.009470167
0.00627303
0.0026894412
0.0041543487
0.007316382
0.0116942385
0.006183491
0.00801501
0.0072713248
0.001897392
0.007647665
0.0
0.006316527
0.004070048
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall     F1        F2     F0.5  Average Precision
0  0.997367    0.95122  0.464286  0.624  0.517241  0.78629           0.444159

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[04:34:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 10281.375 seconds
Cross-validation score: 0.7824942174655617
Test score: 0.8012820512820511
Best Hyperparameters: {'classifier__min_child_weight': 5, 'classifier__max_depth': 6, 'classifier__learning_rate': 0.15, 'classifier__gamma': 0.5, 'classifier__colsample_bytree': 0.6}
0.008775284
0.031192822
0.022342568
0.014805318
0.010245455
0.0061607254
0.006841723
0.008548511
0.007882346
0.0037813582
0.0022944498
0.0033872419
0.009435794
0.011441118
0.004892494
0.010356676
0.0024549498
0.0026649588
0.0073602176
0.0030773655
0.01595536
0.0252842
0.0049484684
0.011412774
0.0036941022
0.0035979545
0.0063439026
0.006142164
0.013960532
0.008273383
0.013689399
0.0070296247
0.0076960977
0.012420675
0.0052581
0.0045617865
0.004494046
0.006507091
0.002672115
0.005902469
0.0040054545
0.0032393956
0.003955466
0.010756097
0.006791263
0.0
0.008889851
0.00522079
0.012288977
0.0056599355
0.0077355956
0.0
0.0068601146
0.006073392
0.0
0.005575302
0.0
0.0
0.0
0.00532042
0.0032277268
0.0038595456
0.0008580913
0.0
0.008860944
0.006247689
0.008103466
0.0034247888
0.0066623124
0.005054188
0.008016801
0.0062030237
0.0068214857
0.011429743
0.0060866587
0.005083119
0.0072187944
0.0031525514
0.003961916
0.0
0.0073128315
0.0035988728
0.0049301907
0.0
0.0024295414
0.006264394
0.007536424
0.0
0.003936778
0.008219895
0.004640038
0.0027005272
0.005790627
0.009238742
0.01076136
0.012437266
0.0050254916
0.005199299
0.0074642766
0.002850161
0.012069659
0.008313203
0.006801709
0.0012870253
0.0058832658
0.007304371
0.0025815344
0.0034987514
0.012346194
0.004075091
0.01414869
0.009492286
0.0051715425
0.003620022
0.005625309
0.002866123
0.005424337
0.0022067185
0.009096876
0.0031648309
0.0055759735
0.015102053
0.004928746
0.003824518
0.0040929713
0.0028728398
0.003782986
0.0032361932
0.014835978
0.0059582866
0.017985947
0.0063293884
0.0061446214
0.009619688
0.012943004
0.008195982
0.009312152
0.0046204375
0.0064370236
0.0
0.0037948533
0.0035128102
0.0030936012
0.0029429619
0.005275392
0.0055326987
0.008291079
0.0
0.00455697
0.0070694173
0.006998203
0.013298477
0.0069344738
0.0031554655
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall       F1        F2      F0.5  \
0  0.997703   0.877193  0.595238  0.70922  0.636132  0.801282   

   Average Precision  
0           0.524044  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[07:27:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 10364.076 seconds
Cross-validation score: 0.7834012062613833
Test score: 0.745967741935484
Best Hyperparameters: {'classifier__min_child_weight': 3, 'classifier__max_depth': 20, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0.3, 'classifier__colsample_bytree': 0.3}
0.013888967
0.02889806
0.030279208
0.013925244
0.014039371
0.003823161
0.005260291
0.005965783
0.008581014
0.006496276
0.0058305725
0.0015555418
0.011636707
0.012698463
0.0077553676
0.00871623
0.010071287
0.004278629
0.008354326
0.004098062
0.01844606
0.01436483
0.008474036
0.007818599
0.0026166975
0.0068989424
0.005762499
0.008639152
0.008402014
0.0043455884
0.011229577
0.008726612
0.0035348807
0.008282283
0.0036361204
0.0043790066
0.0051902863
0.0054932926
0.0047903135
0.0045424537
0.0039500473
0.003564318
0.0012002155
0.0068254843
0.006162369
0.0
0.012250943
0.0035852822
0.0
0.0036295198
0.0069818655
0.0
0.006953223
0.0068433774
0.0
0.0049185357
0.0
0.0
0.0
0.007276626
0.0033576477
0.0031726714
0.0023634625
0.005768971
0.0051557994
0.011370037
0.0039031287
0.00597841
0.0051703644
0.0043874606
0.0036878334
0.009680073
0.016398445
0.008395368
0.011117616
0.0070864917
0.0064157182
0.007014552
0.0034211238
0.0013184487
0.001956054
0.0051085437
0.003956971
0.002408133
0.00316582
0.007890676
0.008385153
0.013205704
0.0047103874
0.0063323933
0.0054815873
0.0
0.006860135
0.0053346627
0.012044767
0.011496446
0.008380616
0.0037738536
0.008419041
0.006231593
0.009832399
0.008792214
0.0074698804
0.008949511
0.0063413167
0.003717142
0.006409455
0.002012207
0.0055907113
0.005831322
0.010114245
0.021340122
0.004282857
0.0032970584
0.002668227
0.0028761402
0.0055444874
0.0050990004
0.0061895
0.012181522
0.00506053
0.0048378757
0.0026977959
0.0038261334
0.0041953563
0.0033028577
0.004795355
0.0053207986
0.0062110685
0.00985979
0.005349643
0.0057489322
0.008045975
0.007404165
0.010138737
0.007845871
0.009384901
0.0069296956
0.007853862
0.0075587616
0.0029386396
0.0063245357
0.005043749
0.0033840295
0.005329785
0.0037552908
0.0057733394
0.0034881332
0.0031712088
0.0023189264
0.0038593865
0.0
0.0072806682
0.0062510544
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall     F1        F2      F0.5  Average Precision
0  0.997142   0.902439  0.440476  0.592  0.490716  0.745968           0.400136

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[10:09:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 9721.542 seconds
Cross-validation score: 0.7801174673696171
Test score: 0.7394366197183099
Best Hyperparameters: {'classifier__min_child_weight': 2, 'classifier__max_depth': 20, 'classifier__learning_rate': 0.25, 'classifier__gamma': 0.2, 'classifier__colsample_bytree': 0.3}
0.015009497
0.028539374
0.023723872
0.013689145
0.018864503
0.006727575
0.0038034187
0.004520342
0.0026451768
0.0032645133
0.0044639637
0.00062787556
0.00794376
0.015072746
0.0074370215
0.011980231
0.0063022943
0.0024956258
0.0069877226
0.0055297404
0.015663618
0.0138021745
0.009395605
0.009313236
0.0032924612
0.008007286
0.0070397626
0.01074947
0.009075905
0.01090289
0.0101757925
0.00266303
0.0035578397
0.0046259393
0.0029021092
0.0056186765
0.004167157
0.005622707
0.002456022
0.0034112683
0.0037290643
0.0037020366
0.0044844
0.009002939
0.009250255
0.0
0.011138024
0.0066876374
0.003425799
0.0039482126
0.008283715
0.008549423
0.0096438
0.0054564974
0.0
0.0075711817
0.0
0.0
0.0
0.004087048
0.0015671254
0.0029753363
0.003940767
0.0065695927
0.0038001488
0.008132287
0.0039761546
0.005092145
0.0048380173
0.00527823
0.004607451
0.014996012
0.0114817
0.006086616
0.0075538894
0.016794406
0.007010185
0.0042514717
0.0025255347
0.010985039
0.003029952
0.0037261879
0.005550657
0.003700681
0.0035260736
0.006990039
0.005829092
0.014759946
0.008059496
0.005008557
0.005618636
0.0
0.0047203396
0.004380483
0.004458751
0.0072464016
0.013583602
0.0063623716
0.007126207
0.0
0.012193207
0.0065488773
0.007952461
0.0019295
0.010117092
0.0041509843
0.005092526
0.0018003301
0.0049701515
0.0059736646
0.006202283
0.01778507
0.0044973586
0.0044425945
0.004584337
0.0054148873
0.008291975
0.0067451536
0.005165677
0.0046820384
0.007417108
0.0064320895
0.002200496
0.0016599676
0.0029598754
0.0023287686
0.005000922
0.0016950819
0.009393035
0.01367515
0.0048838216
0.00232986
0.0061494117
0.0051593035
0.0107608
0.009302294
0.017301466
0.009845401
0.0064597502
0.003088215
0.0025727812
0.0031076758
0.003767527
0.0034761126
0.0059087304
0.0066240365
0.006896637
0.0036896165
0.0041858293
0.0043097823
0.006385603
0.0010873434
0.0039909887
0.010243403
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision  Recall        F1        F2      F0.5  \
0  0.997198       0.84     0.5  0.626866  0.544041  0.739437   

   Average Precision  
0           0.422353  

--------------------------------------------------------------------
