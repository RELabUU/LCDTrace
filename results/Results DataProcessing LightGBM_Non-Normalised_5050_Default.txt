C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 10.451 seconds
Cross-validation score: 0.7717251719037508
Test score: 0.743006993006993
Best Hyperparameters: {}
2395.9404703378677
20962.2374868989
26282.989256739616
49751.95000499487
8330.906965076923
118.91160154342651
71.20884644985199
129.13514924049377
575.8187955617905
252.84856569766998
56.484978914260864
90.03326505422592
2584.4649937152863
1204.8591232299805
130.0284299850464
0.0
131.24469202756882
0.0
10142.142073869705
133.86429888010025
3412.331430196762
32.61728048324585
483.11081659793854
17.33736002445221
11.713410139083862
57.19896078109741
431.05192244052887
1514.3916043043137
375.8181389570236
123.63467049598694
93.59718179702759
132.30844843387604
16.046080231666565
1022.8858914375305
5.181009888648987
385.1670432090759
949.1328010559082
72.68918430805206
55.459620118141174
1260.6709973216057
67.2072029709816
0.0
0.0
0.0
47.17800045013428
0.0
301.6375960111618
197.13818788528442
26.283970713615417
940.5431494116783
153.80129885673523
19.88719940185547
198.14130318164825
357.0252974629402
0.0
226.889319896698
0.0
0.0
0.0
129.2831470966339
115.1887875199318
72.70059984922409
19.7888400554657
10.415479898452759
16.74991011619568
6.308133006095886
100.38999938964844
367.0076479911804
636.2016245126724
79.8758716583252
94.15251260995865
271.3084216117859
225.27946203947067
131.23089414834976
101.11751139163971
191.66714894771576
59.71770238876343
5.812686920166016
185.36951965093613
712.3796342611313
22.945579767227173
39.60286545753479
66.94871747493744
949.7444726228714
220.57716935873032
68.98960900306702
109.72222584486008
1059.4110525846481
66.37575608491898
97.78855955600739
81.45012032985687
108.2969970703125
269.40023732185364
98.50755190849304
407.09266090393066
27.311789512634277
20.574150323867798
61.517770290374756
456.0604819059372
82.43681252002716
48.486146569252014
128.54443991184235
48.459411680698395
35.78420174121857
104.56076687574387
1008.2851892709732
1713.7705236077309
282.77898490428925
0.0
256.8983789086342
334.2525427341461
283.8588192462921
182.64251589775085
233.92789214849472
56.984310269355774
337.65054082870483
3985.5579007864
209.02823668718338
669.5668808817863
0.8470460176467896
89.74382543563843
0.0
79.11708682775497
89.90780586004257
0.0
308.1293275356293
107.42166018486023
0.0
152.3686225414276
445.416512131691
0.0
553.6725684404373
268.5469628572464
0.0
102.58739852905273
159.2135278582573
0.0
127.76512217521667
160.63091784715652
0.0
295.68772196769714
134.5732103586197
214.81621050834656
16.967576801776886
32.75707691907883
25.933930277824402
183.06990367174149
0.0
30.521770238876343
50.80297017097473
158.0304719209671
0.0
335.3589410185814
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.987057   0.643939  0.772727  0.702479  0.743007  0.666144   

   Average Precision  
0           0.502084  

--------------------------------------------------------------------

C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 12.153 seconds
Cross-validation score: 0.7631143628291243
Test score: 0.8131487889273356
Best Hyperparameters: {}
846.4291536211967
40135.173645853996
10353.114556610584
14357.394447028637
20710.019045174122
63.13214689493179
125.49512851238251
276.71162420511246
342.1902939081192
194.56696891784668
61.19905924797058
135.9853471517563
9135.835067510605
636.38789665699
174.7521054148674
0.0
539.7101314663887
0.0
18620.542238235474
84.89262408018112
6946.244053483009
15.416130065917969
431.8952257633209
29.084813237190247
16.93839955329895
36.87701952457428
258.231205701828
1970.0288671255112
658.1132135391235
183.41987347602844
3507.43279671669
38.07979965209961
42.93408012390137
583.0117498636246
14.485270023345947
81.87956154346466
2337.3965933322906
130.68943428993225
68.0165503025055
987.0531364679337
109.93903017044067
0.0
0.0
0.0
5.254050016403198
0.0
116.74713039398193
864.8294374346733
34.0803108215332
586.6642647981644
559.3279476165771
0.0
177.40777415037155
606.2517128586769
0.0
482.6687114238739
0.0
0.0
0.0
76.73737013339996
91.17796403169632
91.22217166423798
101.9273989200592
48.843480587005615
38.46693968772888
105.1831887960434
44.20303988456726
109.46298921108246
509.08393263816833
32.19774055480957
675.0156626701355
123.73966121673584
198.03189837932587
162.15997141599655
78.81465649604797
96.6573896408081
296.127170085907
45.48022961616516
133.01663744449615
640.5718677639961
40.42704492807388
53.653303027153015
229.47375643253326
799.1513098478317
82.34928059577942
39.62946927547455
47.52764481306076
752.177613735199
46.67259979248047
233.79846620559692
102.42040014266968
35.546409606933594
401.28478264808655
209.48300170898438
510.920792222023
0.0
60.77565097808838
212.85115015506744
915.2166690826416
85.45422899723053
15.016851544380188
108.20220172405243
60.06337070465088
0.9504879713058472
8.360067129135132
898.5081117153168
674.8473869562149
220.35388791561127
24.350388407707214
529.6374545097351
284.33375120162964
41.10970264673233
352.70157784223557
119.57896727323532
164.33579909801483
75.63706016540527
298.7887915968895
182.9186528325081
24.608140349388123
61.03390038013458
67.60779976844788
0.0
137.5369228720665
169.22864270210266
0.0
237.75184613466263
60.6488493680954
0.0
230.02106046676636
253.56850600242615
0.0
1756.1417845487595
177.69106566905975
0.0
147.0924225449562
106.42672711610794
0.0
87.6575722694397
107.00640988349915
0.0
87.468998670578
335.54284381866455
380.8555815219879
258.9710623025894
62.22504925727844
32.38960087299347
112.689299762249
0.0
268.4698044061661
73.11534011363983
262.89634078741074
108.9453010559082
1164.6439262628555
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2     F0.5  \
0  0.989214   0.681159  0.854545  0.758065  0.813149  0.70997   

   Average Precision  
0           0.584958  

--------------------------------------------------------------------

C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 11.777 seconds
Cross-validation score: 0.7459485437472918
Test score: 0.7535460992907801
Best Hyperparameters: {}
2937.098721265793
25120.641160547733
21626.614480495453
46751.021929979324
6528.837220132351
134.13514924049377
118.40890979766846
34.20910948514938
797.3815584182739
559.0074899196625
224.51308274269104
46.304908871650696
4852.362575888634
353.335247695446
22.331512928009033
0.0
148.2620295882225
0.0
9614.20521724224
140.80551546812057
6720.624093651772
4.537160038948059
404.2516531944275
30.401209354400635
67.11510992050171
90.11566972732544
151.59404212236404
2989.55986058712
110.37064933776855
47.70026099681854
537.7198605537415
324.4054710865021
38.23620104789734
466.4239137172699
41.26327908039093
138.57557010650635
1287.591069817543
34.73353087902069
126.06548964977264
668.1750146746635
66.82946074008942
0.0
0.0
0.0
125.86079919338226
0.0
176.67760699987411
580.4227821826935
5.063109874725342
281.09060883522034
66.51526117324829
5.437020182609558
141.65999346971512
630.2266659140587
0.0
450.5402697920799
0.0
0.0
0.0
111.51074492931366
194.626331448555
210.84392058849335
26.26457989215851
5.278889894485474
26.85967892408371
226.04577112197876
43.68920135498047
202.3455035686493
406.82958847284317
28.75239497423172
411.2332878112793
27.32349991798401
165.59929645061493
178.01332807540894
30.71734046936035
15.960800290107727
285.24102318286896
5.7156901359558105
171.2962898015976
931.5198130607605
89.29088878631592
83.04219818115234
129.91734540462494
1024.4778615236282
117.11423510313034
72.62645983695984
44.14646017551422
530.0385473966599
78.21413087844849
182.27449345588684
216.60701763629913
63.53520202636719
289.0909257531166
94.94356226921082
224.9914709329605
0.0
74.4120591878891
141.535728931427
1284.2001951932907
49.545610189437866
59.058950424194336
128.79350900650024
58.18431067466736
0.0
66.5485207438469
851.5536221265793
1012.8914203047752
234.60754370689392
35.618210792541504
192.4324586391449
669.9869105815887
63.99711203575134
95.54869467020035
126.16625213623047
107.23067092895508
93.1935430765152
4282.88322198391
240.18481731414795
206.00980615615845
39.41701900959015
131.4558503627777
0.0
46.620609998703
192.35309952497482
0.0
260.9826120734215
66.37402606010437
0.0
222.12751960754395
215.5029383301735
0.0
164.26457846164703
182.7720606327057
0.0
58.000879883766174
22.364099740982056
0.0
47.49907040596008
294.7722667455673
0.0
253.64025956392288
105.28026086091995
176.51251363754272
76.25057059526443
72.264289021492
35.789119243621826
204.36253648996353
0.0
241.56569492816925
22.58236002922058
397.7876217365265
41.43673062324524
739.4113916158676
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2     F0.5  \
0  0.988495   0.685484  0.772727  0.726496  0.753546  0.70132   

   Average Precision  
0           0.534186  

--------------------------------------------------------------------

C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 13.102 seconds
Cross-validation score: 0.757883584724256
Test score: 0.8235294117647057
Best Hyperparameters: {}
3877.3011340498924
24153.007923841476
21622.898787796497
50118.63556367159
7222.138963222504
109.21563935279846
52.581723153591156
48.15318012237549
447.57045662403107
172.68845307826996
117.01965379714966
49.885962426662445
3064.513647735119
327.1129179596901
76.10496008396149
0.0
568.2717550992966
0.0
8789.737800955772
185.48412823677063
3835.304009437561
77.30330073833466
527.106254696846
4.509339809417725
60.449118971824646
62.20476335287094
633.7921789884567
2625.13403570652
184.5579912662506
34.65734100341797
86.05980676412582
7.73130989074707
5.732833087444305
700.0581549406052
17.958070039749146
379.09545850753784
1375.578730583191
29.617987275123596
42.07287037372589
748.3113186359406
43.65358340740204
0.0
0.0
0.0
211.18143236637115
0.0
132.7437761425972
840.4266575574875
0.0
216.9793425798416
521.4876179695129
53.17857885360718
92.75501930713654
453.7538121342659
0.0
433.5747472047806
0.0
0.0
0.0
141.3489196896553
378.49989128112793
74.31713938713074
20.32679009437561
17.854509830474854
50.581884264945984
127.70826387405396
0.0
179.5763465166092
759.2149970531464
89.98546028137207
108.14066964387894
151.6395299434662
200.08529806137085
87.57463723421097
165.486750125885
124.99855995178223
165.85324048995972
70.83037853240967
221.6941865682602
1357.369869709015
19.913400292396545
120.56086301803589
113.57735621929169
1253.5803505182266
74.1765746474266
3.3176788687705994
31.06674087047577
869.9484703540802
37.098220229148865
204.12281787395477
200.29813933372498
0.0
250.53567349910736
14.991550087928772
150.60881221294403
15.19886028766632
35.360408782958984
24.89393973350525
770.100614964962
9.528970003128052
18.338409662246704
62.29975515604019
275.7388561964035
0.0
18.09401100873947
1019.2459850311279
1395.1231644749641
541.4699053764343
24.46810883283615
583.5719228982925
362.98166942596436
11.69985020160675
173.33214616775513
436.1210768222809
170.24254834651947
237.33154261112213
3716.6603014469147
196.56863141059875
365.9674959182739
168.10046076774597
18.52690017223358
0.0
62.78092294931412
232.56438314914703
0.0
188.01302206516266
150.83162528276443
0.0
31.58517038822174
76.50629091262817
0.0
334.88188195228577
78.7525919675827
0.0
75.57838940620422
44.58101963996887
0.0
467.39827412366867
124.6480712890625
0.0
158.06423139572144
225.38812911510468
276.90767908096313
83.30246323347092
51.76215660572052
27.67748326063156
306.771262049675
0.0
215.62764048576355
88.8253481388092
184.41077947616577
0.0
725.0236131548882
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.987597   0.632258  0.890909  0.739623  0.823529  0.671233   

   Average Precision  
0           0.565442  

--------------------------------------------------------------------

C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 15.265 seconds
Cross-validation score: 0.7797644066134924
Test score: 0.7469244288224954
Best Hyperparameters: {}
3266.4444173574448
21454.49590945244
26589.222634017467
44079.72305738926
6618.191200017929
86.32379603385925
44.56679576635361
95.7984647154808
1381.752336204052
193.34352976083755
72.32669645547867
86.02622497081757
4490.606806278229
658.393221616745
540.7145493030548
0.0
322.52616477012634
0.0
12801.288431167603
233.99768334627151
2543.768637239933
36.10393977165222
494.6296606659889
15.825214385986328
56.86410975456238
67.7419273853302
217.71980166435242
3136.94502222538
282.60505455732346
31.668039441108704
151.01210021972656
2.0708999633789062
6.3567399978637695
580.4271838068962
18.264660120010376
120.95121771097183
919.7363240122795
18.255208909511566
160.39226162433624
777.939713716507
47.91592490673065
0.0
0.0
0.0
66.57100868225098
0.0
339.2682684659958
170.22197902202606
5.957159996032715
218.98565298318863
466.6784541606903
54.23251974582672
104.12243449687958
223.0380136370659
0.0
333.7980922460556
0.0
0.0
0.0
28.19662708044052
128.3856202363968
180.53202587366104
66.50981950759888
32.5944904088974
82.11289823055267
41.25810098648071
1.0670900344848633
331.35641664266586
569.0164543390274
33.874040603637695
155.4839444756508
104.92380517721176
73.59220945835114
105.35427057743073
161.1535805463791
77.19106006622314
173.51102924346924
77.5713005065918
109.74838501214981
435.0679202079773
6.778519988059998
19.613680005073547
74.04999154806137
1118.97177785635
137.40353256464005
23.558599829673767
19.54306298494339
685.8888948559761
38.88893985748291
196.15579187870026
219.8970400094986
0.0
136.17063975334167
28.314690113067627
401.3702344894409
48.90686047077179
143.9324208498001
42.416900634765625
374.06310683488846
41.22594118118286
29.1948401927948
95.96007657051086
88.0244311094284
0.0
3.0433420538902283
833.0828957557678
1309.057878613472
1245.2535862922668
27.16054058074951
233.688081741333
217.3191800713539
47.9104266166687
88.1157717704773
113.18322265148163
31.047470092773438
196.81154000759125
5658.783263802528
160.06586581468582
923.9296381473541
6.846669912338257
132.04411435127258
0.0
262.1332165002823
193.37270468473434
0.0
199.72473013401031
231.756902217865
0.0
39.34231090545654
187.2865601181984
0.0
1037.9032606482506
124.98576855659485
0.0
43.814896523952484
80.77273315191269
0.0
250.81047141551971
229.68979966640472
0.0
131.72740077972412
398.69406789541245
118.31602454185486
70.14924764633179
94.03922253847122
21.096975207328796
362.1190565228462
0.0
105.55897057056427
94.84890174865723
160.1636574268341
6.092430114746094
923.216335773468
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.987597   0.658915  0.772727  0.711297  0.746924  0.678914   

   Average Precision  
0           0.513655  

--------------------------------------------------------------------

C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 15.807 seconds
Cross-validation score: 0.7491660651563673
Test score: 0.7839721254355402
Best Hyperparameters: {}
2305.0724922418594
26893.339510142803
22807.84476363659
44968.45270746946
3207.9736192822456
86.56086027622223
44.21407997608185
69.01975560188293
501.1466369628906
343.7025125026703
147.1442250609398
231.28833651542664
5119.18100976944
864.9319489002228
157.00763154029846
0.0
350.0007452368736
0.0
10438.488350868225
324.88925528526306
5495.673472344875
49.78642928600311
966.1534312963486
43.376760482788086
107.76674008369446
56.55354297161102
85.56051516532898
3209.644697189331
364.3957388997078
70.02624034881592
928.6389631032944
109.03988218307495
10.847630143165588
656.7696977257729
34.4016575217247
101.806569814682
1576.0324391126633
100.26923245191574
154.74795019626617
402.803991317749
111.0815794467926
0.0
0.0
0.0
110.80191910266876
0.0
170.28526031970978
506.6071007847786
0.984620988368988
140.97564089298248
48.87692242860794
67.02639770507812
129.36406779289246
712.0185899734497
0.0
314.4869174361229
0.0
0.0
0.0
88.31149125099182
62.49903529882431
56.1142338514328
119.08587074279785
80.63349199295044
30.52303981781006
164.322371840477
10.482339859008789
181.6926236152649
556.1048287153244
42.5079699754715
164.0382118821144
96.3325822353363
159.59561133384705
225.17007303237915
24.189469933509827
38.32711100578308
154.36941993236542
145.2262133359909
136.58910143375397
1282.276024222374
51.623817443847656
93.54835891723633
133.03830873966217
612.9211710691452
47.97064006328583
30.79264998435974
35.17208015918732
1022.8960592746735
6.550443947315216
161.80053102970123
130.6382433772087
0.0
93.70142316818237
102.58194273710251
192.7362184524536
2.389509916305542
32.02229976654053
43.28894400596619
816.4597515463829
16.911680221557617
65.98875081539154
106.77872085571289
5.407870054244995
0.8673449754714966
2.5702099800109863
1367.150357246399
675.1865672469139
132.734423995018
160.17320382595062
867.4076900482178
215.46202886104584
29.4072003364563
75.48334956169128
146.01524889469147
88.89517903327942
113.77506226301193
4246.997987508774
183.23555254936218
1631.0495783090591
139.98607051372528
137.82033848762512
0.0
40.54412031173706
317.2156174182892
0.0
283.8696982860565
176.77647149562836
0.0
7.086186110973358
256.0184072256088
0.0
547.3866782188416
89.06989872455597
0.0
171.31435722112656
93.46183973550797
0.0
336.764687538147
90.44859862327576
0.0
115.15480077266693
296.98626267910004
214.87637662887573
58.03608059883118
144.28447198867798
124.45118832588196
165.7074432373047
0.0
108.49193167686462
73.60343188047409
280.0174582004547
6.928490161895752
580.957910656929
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.988495   0.671642  0.818182  0.737705  0.783972  0.696594   

   Average Precision  
0            0.55312  

--------------------------------------------------------------------

C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 17.058 seconds
Cross-validation score: 0.7704619379024106
Test score: 0.7522123893805309
Best Hyperparameters: {}
847.9283755421638
30509.215353250504
20704.67882835865
44207.47504448891
5788.581966936588
150.27124792337418
323.88258624076843
118.31551563739777
317.33583766222
847.015702188015
169.70343095064163
104.89634990692139
3558.1580371260643
790.7590237855911
49.117942452430725
0.0
827.2917550802231
0.0
12354.560939669609
607.2607577443123
4583.760159730911
29.02465069293976
121.48012810945511
31.164339542388916
127.37925094366074
129.8302611708641
204.97127252817154
1534.100794017315
682.1232935190201
64.96360003948212
335.6888473033905
300.80835223197937
43.02783942222595
848.425883948803
20.342600226402283
38.69659960269928
1641.6195584535599
36.87069910764694
53.364744782447815
623.6375671029091
55.75491100549698
0.0
0.0
0.0
99.57341599464417
0.0
182.89259034395218
550.3215990066528
22.241600036621094
658.0882104039192
76.62408065795898
0.0
67.20513343811035
318.0530461668968
0.0
247.45996993780136
0.0
0.0
0.0
167.80051749944687
78.71619611978531
50.8224858045578
27.100950002670288
65.11391890048981
15.111129641532898
55.05630111694336
6.922489881515503
157.78305041790009
569.8234996795654
13.78062391281128
214.66621392965317
101.92012143135071
174.0315819978714
72.52562046051025
684.8037665486336
71.02509677410126
240.12995862960815
4.79109001159668
232.8706882596016
307.7750107049942
27.32347971200943
72.7840405702591
53.14742869138718
1577.3926274776459
180.97607105970383
40.63760948181152
45.04494535923004
900.4662422537804
9.306023061275482
253.4558800458908
134.49305498600006
312.11199951171875
245.8516411781311
78.96581453084946
166.8489911556244
9.6636803150177
114.99807703495026
86.29178643226624
437.12939685583115
46.06140065193176
33.81045323610306
188.2596994638443
77.42871820926666
0.0
69.87955033779144
838.9496254324913
866.0028669834137
518.5124008059502
52.93294012546539
203.8972121477127
322.59678906202316
213.42381191253662
48.37133985757828
75.59069257974625
102.99240016937256
158.31893771886826
4678.488374471664
30.61003053188324
783.5274541378021
5.202620029449463
135.58412063121796
0.0
97.66097033023834
229.76935160160065
0.0
159.33826678991318
359.295389354229
0.0
233.22644233703613
60.77555900812149
0.0
487.6158863902092
119.03106123209
0.0
25.70631992816925
73.40766060352325
0.0
124.60583186149597
354.70150113105774
0.0
363.99664640426636
216.28853398561478
143.79260778427124
110.95891952514648
58.77186357975006
139.0565903186798
367.079165995121
0.0
341.51861023902893
69.44076263904572
217.1972804069519
0.0
372.1212152838707
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.988316       0.68  0.772727  0.723404  0.752212  0.696721   

   Average Precision  
0           0.529949  

--------------------------------------------------------------------

C:\Python39\lib\site-packages\sklearn\metrics\_plot\precision_recall_curve.py:125: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots()
C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 13.530 seconds
Cross-validation score: 0.7577184526204144
Test score: 0.7610619469026548
Best Hyperparameters: {}
2804.5793103575706
30870.747501850128
17163.713378190994
17850.38971453905
6531.301793754101
97.28921568393707
80.61691164970398
45.59890019893646
393.838968873024
109.29327374696732
112.91987985372543
35.73923945426941
4727.817313969135
551.0794229507446
62.51374047994614
0.0
455.4594863653183
0.0
10019.738680243492
227.4408816099167
36337.236054599285
49.94331133365631
398.88916885852814
10.21930992603302
99.62346124649048
41.49548077583313
41.95343899726868
352.1975883245468
880.83639138937
186.632542014122
53.75036931037903
5.39247989654541
2.111920118331909
518.3446565270424
28.665172338485718
139.22905504703522
1282.255319595337
173.43943732976913
48.622079968452454
909.6131963729858
111.23744958639145
0.0
0.0
0.0
72.40426087379456
0.0
222.42384034395218
1549.7625340223312
15.074899673461914
608.7554309368134
162.20905995368958
0.0
91.93834817409515
665.3620485067368
0.0
582.0795778632164
0.0
0.0
0.0
128.96108162403107
213.93066120147705
82.51343417167664
116.53493815660477
82.56038230657578
73.46572995185852
172.3178632259369
12.365699768066406
97.93973183631897
286.22045040130615
52.24102848768234
90.25596272945404
56.499380588531494
63.99430549144745
185.21503192186356
386.5690379142761
67.67118847370148
329.24139100313187
10.856579899787903
66.66782313585281
541.1116429567337
44.39876985549927
104.29201823472977
93.79273343086243
819.2321094274521
97.0942690372467
0.9210699796676636
170.62867444753647
767.3453651666641
8.718650102615356
8.379240036010742
417.87222123146057
0.0
373.097803235054
164.82319974899292
82.81012976169586
2.4504199028015137
42.94604188203812
91.10551518201828
493.38495057821274
45.681188106536865
106.48751080036163
214.98854410648346
99.11963021755219
0.0
26.46542376279831
525.6000856757164
1470.9750868082047
237.8551452755928
7.543359756469727
162.72579097747803
350.9483026266098
59.18217879533768
8.919907093048096
114.33118796348572
80.81103086471558
106.40311908721924
4962.327237725258
56.2692391872406
333.3063871860504
30.066100120544434
74.33085858821869
0.0
118.43246901035309
138.65638780593872
0.0
158.23649883270264
188.88933688402176
0.0
106.00188136100769
265.60356748104095
0.0
472.7853727340698
498.7606204152107
0.0
37.559109568595886
101.02128159999847
0.0
133.7161915898323
146.57585114240646
0.0
170.50407952070236
258.22733145952225
355.9450458884239
69.69168138504028
162.16672086715698
76.25771403312683
55.59654116630554
0.0
65.93097031116486
8.187820196151733
187.01945012807846
0.0
629.6726024150848
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.988675      0.688  0.781818  0.731915  0.761062  0.704918   

   Average Precision  
0           0.542205  

--------------------------------------------------------------------

C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 13.992 seconds
Cross-validation score: 0.7634716341357082
Test score: 0.7525951557093425
Best Hyperparameters: {}
2527.977649629116
18900.17480790615
30055.04478162527
45426.17677283287
3620.4370326399803
82.7388476729393
192.8217523097992
137.7686324119568
599.0338510274887
302.58294278383255
226.65819215774536
133.52826684713364
2914.0026761889458
529.4523881673813
51.39093995094299
0.0
347.96713531017303
0.0
12718.625245213509
115.05400538444519
5323.328133106232
68.41910946369171
243.11616426706314
55.90173810720444
242.79791051149368
52.271759152412415
725.9425801634789
1259.91481423378
57.293179750442505
221.51932775974274
34.25833988189697
231.41151309013367
18.547500014305115
1108.076858997345
13.474477052688599
95.31059980392456
847.7662636041641
70.87440896034241
70.47313958406448
585.5969997644424
122.6465699672699
0.0
0.0
0.0
366.90402007102966
0.0
317.2630786895752
669.2717118263245
27.263399124145508
546.3445507287979
174.985669195652
6.17903995513916
81.32223898172379
344.7636221051216
0.0
316.45339274406433
0.0
0.0
0.0
158.48086160421371
100.00955456495285
107.01833891868591
20.800609707832336
118.93477249145508
18.568819880485535
272.2255504131317
5.353725075721741
110.80277079343796
2679.8294714689255
82.6836998462677
61.73974007368088
42.07238119840622
197.79728138446808
33.69203054904938
3.5799219608306885
26.02895975112915
214.65797126293182
83.7989935874939
261.53893065452576
648.7163074016571
11.266772150993347
103.42628222703934
149.9500206708908
1123.304038822651
57.987795531749725
27.73810166120529
16.584779024124146
1050.1940949559212
38.13848131895065
92.86088037490845
282.28080600500107
0.0
73.90941309928894
1.6028499603271484
634.3052077293396
0.0
122.43438863754272
0.0
337.69573801755905
22.849609971046448
28.18842923641205
76.0432801246643
74.51640790700912
0.0
83.89925986528397
1012.6288279294968
2001.0594701170921
415.26330173015594
29.613860487937927
242.26717960834503
373.57421684265137
307.88045144081116
364.0875144600868
188.0167634487152
11.238900184631348
33.63491940498352
5235.55301129818
416.53898841142654
661.8082947731018
95.20147204399109
90.24580156803131
0.0
110.54844915866852
162.95922201871872
0.0
291.7168143391609
209.31799066066742
0.0
50.30820095539093
97.94560110569
0.0
181.13044768571854
103.51891100406647
0.0
15.107449889183044
175.87251925468445
0.0
203.83095264434814
196.15976881980896
0.0
92.88748186826706
305.4483155012131
109.13425487279892
63.10348057746887
76.53405565023422
35.616844832897186
420.8295922279358
0.0
154.89928996562958
13.860844254493713
256.1791524887085
28.179640293121338
515.0944162607193
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2    F0.5  \
0  0.986698   0.630435  0.790909  0.701613  0.752595  0.6571   

   Average Precision  
0           0.502751  

--------------------------------------------------------------------

C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 14.443 seconds
Cross-validation score: 0.7519718452146853
Test score: 0.768566493955095
Best Hyperparameters: {}
2847.49595952034
21223.115777492523
26109.307393491268
40544.017551362514
9086.488209843636
63.06795221567154
279.27511674165726
39.90006446838379
569.9391096830368
292.49193090200424
190.893257021904
228.32131254673004
4856.199645757675
1412.6865481734276
41.86288905143738
0.0
517.6682020425797
0.0
13929.884551882744
111.75987780094147
3921.2289073467255
81.51205557584763
201.7980055809021
22.69164276123047
142.32416093349457
48.33069294691086
136.04635483026505
2693.799669802189
91.89708113670349
141.9418967962265
373.306322991848
2.391010046005249
6.909695148468018
486.2346591949463
27.308956027030945
185.09322267770767
1292.0768964886665
116.02577531337738
47.668099999427795
1262.590306699276
33.490699768066406
0.0
0.0
0.0
121.29600214958191
0.0
361.82550567388535
525.6507501006126
0.0
544.5065144300461
19.79775631427765
0.0
93.28459185361862
331.3313197493553
0.0
490.42344427108765
0.0
0.0
0.0
65.47980570793152
234.90024894475937
91.39406955242157
10.598260045051575
24.13081532716751
19.23087990283966
61.76701021194458
0.0
439.1575074195862
862.4997732639313
53.039043724536896
280.3258159160614
34.653249740600586
152.0871386528015
137.4628678560257
468.6593642234802
128.22180211544037
346.27095794677734
92.00875973701477
153.89107358455658
791.4002022743225
24.87632966041565
69.41776263713837
64.41097855567932
1535.474901854992
133.90318608283997
49.052224934101105
123.90693080425262
800.6320479512215
14.651594161987305
161.4268810749054
71.93925952911377
245.29110717773438
358.9462791085243
4.072809934616089
372.662682056427
2.8554999828338623
63.85110020637512
57.4087119102478
210.37083047628403
28.658620834350586
17.630730032920837
123.12270760536194
38.42423069477081
9.886169910430908
51.52262932062149
713.9856493473053
1720.9969280958176
221.53267467021942
0.0
243.5107502937317
590.55124604702
40.75502121448517
117.91996490955353
163.33219456672668
30.5230495929718
216.33501517772675
3646.788453578949
211.77658998966217
794.4490892887115
5.1022650599479675
24.37555581331253
0.0
117.42722260951996
182.89977151155472
0.0
143.6460698246956
122.28164148330688
0.0
33.13924449682236
53.67755889892578
0.0
726.501131772995
124.35120463371277
0.0
48.87590944766998
398.34152323007584
0.0
188.44570702314377
111.58201146125793
0.0
283.03383922576904
150.07322269678116
395.9738970398903
136.0021337866783
23.74780011177063
53.82584095001221
187.45363187789917
0.0
285.9214938879013
30.499960899353027
187.38356113433838
11.484780311584473
306.22193694114685
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.987237   0.640288  0.809091  0.714859  0.768566  0.668168   

   Average Precision  
0           0.521826  

--------------------------------------------------------------------

C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 14.382 seconds
Cross-validation score: 0.7621996962308213
Test score: 0.7804459691252145
Best Hyperparameters: {}
2095.5947890877724
24781.977776050568
23852.9944293499
49015.67858308554
6980.750965893269
156.62701708078384
9.010860204696655
96.7421692609787
310.49426370859146
334.10108798742294
114.1829309463501
28.407110035419464
4436.192861974239
1397.9303275346756
97.39968329668045
0.0
916.5869646072388
0.0
8272.680657148361
123.12704730033875
5822.724074661732
114.15576469898224
225.90531760454178
38.148673474788666
142.91207242012024
80.12903702259064
699.6847919225693
2679.056087255478
480.0719368457794
119.27732253074646
186.6826581954956
8.396901845932007
12.436370134353638
852.3835784196854
4.682672083377838
111.14048981666565
1064.058799803257
66.46184957027435
154.68302261829376
1663.1308761835098
64.91624802350998
0.0
0.0
0.0
44.68219029903412
0.0
106.92770320177078
209.44517254829407
43.08153009414673
326.09877717494965
121.99224078655243
177.90627014636993
182.2872463464737
391.56521195173264
0.0
197.2843828201294
0.0
0.0
0.0
82.77241456508636
150.11279547214508
272.76204603910446
13.47081995010376
22.799343585968018
115.02094727754593
24.79493999481201
0.0
133.0939005613327
360.13073086738586
25.839541137218475
121.15430253744125
82.60080814361572
19.75131094455719
204.67141675949097
50.8413952589035
119.91585874557495
107.83242976665497
63.12449073791504
43.75036174058914
867.455115377903
32.27412033081055
234.91037887334824
102.16216915845871
843.6712988615036
123.10830199718475
27.25681972503662
87.03782665729523
756.9257164001465
21.70476984977722
151.40733885765076
168.85898196697235
0.0
236.40858727693558
48.23480033874512
436.01126873493195
5.916760087013245
65.55040943622589
33.68092495203018
576.0151092410088
13.566346228122711
15.591789841651917
134.9670488834381
103.29241013526917
0.0
13.207649946212769
574.2656494379044
1392.7084398269653
723.515825510025
69.62984049320221
368.45908510684967
410.06704157590866
46.781320095062256
88.55203747749329
166.0861855149269
81.42129921913147
125.72349715232849
2643.073731958866
121.9426052570343
725.4604034423828
38.53924036026001
139.7145749926567
0.0
301.16665267944336
76.9183042049408
0.0
237.8417100906372
74.60523545742035
0.0
49.7765611410141
147.28875768184662
0.0
877.1343383789062
274.12544482946396
0.0
35.822179555892944
156.23182141780853
0.0
413.36134028434753
108.05166047811508
0.0
181.87356531620026
43.42918074131012
220.18523186445236
8.781562983989716
164.42718076705933
23.601289868354797
69.80674415826797
0.0
40.204014122486115
4.912010073661804
328.67974799871445
11.788399696350098
242.5753791332245
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.987237   0.636364  0.827273  0.719368  0.780446  0.667155   

   Average Precision  
0           0.529862  

--------------------------------------------------------------------

C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 13.864 seconds
Cross-validation score: 0.7698622272000372
Test score: 0.7731958762886598
Best Hyperparameters: {}
2275.2847839593887
19893.266330122948
25684.320067048073
44499.880017995834
3258.3305789232254
229.43435263633728
98.74310779571533
31.91301953792572
952.4897672533989
229.85147494077682
329.71153008937836
70.83053159713745
5243.2868765592575
724.037663757801
79.62142825126648
0.0
727.872853577137
0.0
15488.33099347353
339.59946846961975
5924.589162111282
105.4249894618988
324.8909434080124
120.22916024923325
68.4449412226677
20.763470828533173
211.83714091777802
1396.1366713047028
349.9643774032593
78.13484728336334
482.3210942745209
66.27321791648865
15.4270099401474
657.9070112109184
31.642769694328308
89.0682692527771
1372.480468571186
62.603912591934204
38.27366262674332
1438.4556859135628
49.52787810564041
0.0
0.0
0.0
26.957175731658936
0.0
230.18908643722534
338.5483160018921
9.908419847488403
464.06861782073975
167.8286416530609
1.5689599514007568
99.58726906776428
455.5529181957245
0.0
272.5334426164627
0.0
0.0
0.0
50.262507021427155
60.48662042617798
100.88471758365631
2.4696000814437866
72.80425930023193
33.18696904182434
7.153379917144775
5.761699795722961
140.35953813791275
1584.4005821943283
23.870140194892883
63.14206671714783
164.41295099258423
223.8004967570305
65.79448080062866
74.833780169487
158.46806848049164
163.33683061599731
12.124709606170654
235.11635613441467
1483.2567631602287
35.517229080200195
98.54861855506897
79.31612545251846
1710.3672057390213
59.80495023727417
23.63874042034149
39.86331421136856
827.153715968132
0.0
174.23957192897797
256.61452853679657
0.0
256.3056084513664
270.6816098690033
48.39899533987045
3.809390068054199
100.92178785800934
20.631969928741455
381.63850528001785
86.23147964477539
50.16920334100723
103.9869396686554
50.9149295091629
1.5549099445343018
178.4077678322792
781.210117816925
755.0203616023064
183.29091930389404
0.0
487.9998268485069
723.0015480518341
115.03602886199951
81.19327211380005
129.8916893005371
188.13415932655334
108.62887895107269
3855.5975691080093
418.08035296201706
374.84728956222534
151.07251000404358
128.74748826026917
0.0
39.544138848781586
324.2692571878433
0.0
305.7738371491432
539.0744990110397
0.0
198.1950169801712
70.75173962116241
0.0
252.95525443553925
251.46098709106445
0.0
56.18221998214722
95.26256054639816
0.0
114.5755203962326
430.0706602334976
0.0
87.14814984798431
279.9564675092697
189.9377639889717
73.35064828395844
19.191749811172485
30.81862998008728
114.55176198482513
0.0
576.2089084386826
81.95861423015594
284.30978095531464
0.0
634.6229600906372
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.987057   0.633803  0.818182  0.714286  0.773196  0.663717   

   Average Precision  
0           0.522161  

--------------------------------------------------------------------

C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 16.283 seconds
Cross-validation score: 0.7720990701860341
Test score: 0.7381370826010546
Best Hyperparameters: {}
3273.4010447859764
42406.37470692396
11480.095575928688
11480.384423673153
29271.887859284878
422.65097469091415
92.82030087709427
57.44825506210327
308.4597715139389
152.35315245389938
215.44695204496384
169.99046057462692
3813.0828546881676
916.0176019668579
105.91921865940094
0.0
483.999471783638
0.0
8343.86178970337
243.07253432273865
10066.769512951374
15.314069747924805
223.79089605808258
86.4636817574501
65.7614096403122
157.62579894065857
265.86097407341003
5122.139730453491
1265.8605214357376
52.091620326042175
454.4606727361679
278.2602840065956
39.39261704683304
550.5794481039047
19.675933957099915
303.5931891798973
994.909318447113
34.32363665103912
69.91144770383835
149.2322991490364
98.31137210130692
0.0
0.0
0.0
10.3644357919693
0.0
472.3494375348091
665.4993314743042
47.37220001220703
327.27733862400055
180.79603695869446
7.1542298793792725
50.61795765161514
1111.1168454885483
0.0
435.3904073238373
0.0
0.0
0.0
113.62041103839874
84.66418927907944
133.36476510763168
104.73316895961761
64.55077910423279
12.157320022583008
34.50209528207779
17.178060173988342
206.54236817359924
459.0356911420822
286.4864755868912
510.2505922317505
489.11879098415375
110.28636944293976
11.254674911499023
142.78796964883804
30.95279186964035
166.66891932487488
57.06117022037506
115.55510246753693
776.3412243127823
104.83892220258713
103.30328404903412
62.255900621414185
628.1789820194244
72.0841925740242
44.845089077949524
29.885769844055176
568.5488950014114
7.633039951324463
69.8168625831604
59.74696600437164
0.0
130.9959478378296
197.5679208636284
451.5897978544235
4.626020073890686
267.8985007405281
66.0411227941513
503.33458775281906
14.659918785095215
1.9712249636650085
122.59223419427872
102.08657121658325
11.981499671936035
22.474050402641296
1185.9682976603508
676.410996556282
280.9103578925133
124.21838986873627
266.24599158763885
526.3424849510193
76.62145066261292
251.19563126564026
217.94480901956558
49.0602508187294
89.38513731956482
1641.4926792383194
93.20953691005707
188.926442861557
6.4331430196762085
107.50790536403656
0.0
48.788714945316315
358.3643955588341
0.0
376.9789505600929
125.18750321865082
1.4230200052261353
22.07178008556366
343.24178951978683
0.0
3187.7620342969894
394.1149372458458
0.0
78.00387120246887
25.907587230205536
0.0
58.949159383773804
74.53189742565155
0.0
184.40310376882553
457.7119873762131
230.07392138242722
48.18079972267151
94.14065885543823
31.08899974822998
120.22264015674591
0.0
125.6318638920784
92.32880115509033
311.30748784542084
11.813400268554688
1195.9992163181305
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.987237   0.651163  0.763636  0.702929  0.738137  0.670927   

   Average Precision  
0           0.501925  

--------------------------------------------------------------------

C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 16.107 seconds
Cross-validation score: 0.7705723843586625
Test score: 0.7443082311733801
Best Hyperparameters: {}
2371.4888773560524
20776.28486120701
30913.29018610716
48309.777416586876
6550.882464706898
133.72149181365967
239.36821109056473
99.16614079475403
242.42028445005417
192.3480908870697
83.21075302362442
203.1212615966797
2934.2604516148567
654.2048662900925
40.05979943275452
0.0
397.112586081028
0.0
5663.950101613998
67.44116872549057
4663.743499994278
24.60421061515808
539.4568037986755
23.136979818344116
76.41870886087418
79.41566979885101
166.48689073324203
4231.640617787838
97.42336690425873
59.249268770217896
1423.035585284233
537.3800659179688
10.631979703903198
493.50625759363174
32.876116156578064
49.81762307882309
986.2038877606392
56.78692030906677
62.88130700588226
733.2802819013596
51.009899497032166
0.0
0.0
0.0
104.39771044254303
0.0
76.57279062271118
1044.6989607810974
0.0
352.140359044075
193.61497128009796
20.365050315856934
87.78753560781479
629.5243890285492
0.0
239.95117270946503
0.0
0.0
0.0
98.08718401193619
62.72973930835724
232.19210767745972
8.901900172233582
7.855749845504761
48.519020318984985
49.06632977724075
2.7008700370788574
324.50135242938995
571.3453867435455
6.986119747161865
483.1154963374138
133.9879913330078
171.42332458496094
143.49281126260757
45.480979442596436
10.883008241653442
49.16136968135834
72.22672033309937
141.02288687229156
707.6361728310585
5.698390007019043
63.63593232631683
106.45609819889069
1165.7654075622559
217.72684341669083
70.65800094604492
134.90752679109573
493.3824088573456
21.674729824066162
123.39362168312073
160.85468125343323
0.0
233.91184997558594
12.437710285186768
93.02740895748138
2.5029119849205017
24.56873482465744
99.31313008069992
922.4556780457497
12.242239952087402
42.98895967006683
45.705819606781006
169.84613966941833
0.0
39.59780025482178
1605.5311142206192
698.7789843082428
280.54966431856155
68.4999008178711
315.02112221717834
366.6762165427208
32.22350990772247
182.02930492162704
37.18389040231705
50.30566930770874
115.81751787662506
4274.825149774551
251.92803418636322
1230.0436985492706
244.92308580875397
78.28218960762024
0.0
143.2119621038437
96.62470358610153
0.0
152.8973725438118
210.79664880037308
0.0
10.051780223846436
167.73377323150635
0.0
525.9083179235458
375.3429888486862
0.0
141.95049268007278
127.1977870464325
0.0
38.80822569131851
91.9852727651596
0.0
119.64074242115021
141.36810958385468
392.3724402189255
363.4926573038101
141.229936003685
19.72859537601471
188.12877810001373
0.0
92.33756214380264
21.118969202041626
128.9578211903572
8.498720169067383
62.40363693237305
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.987237   0.648855  0.772727  0.705394  0.744308  0.670347   

   Average Precision  
0           0.505882  

--------------------------------------------------------------------

C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 14.533 seconds
Cross-validation score: 0.7645146654644324
Test score: 0.7604895104895105
Best Hyperparameters: {}
1500.422397851944
30998.923475027084
21034.071180403233
15708.113037228584
23287.47313004732
296.9130231142044
30.464058995246887
10.835785865783691
299.31910276412964
200.7193888425827
351.0016578435898
63.29064965248108
2895.304496705532
1461.4487652778625
152.61611783504486
0.0
443.44136613607407
0.0
9319.500979363918
147.17150217294693
15985.189067363739
39.5599347949028
250.2355875968933
39.04679101705551
145.5151349902153
48.60154891014099
118.57287120819092
3948.8971868157387
175.07740849256516
91.56577932834625
18.239106833934784
171.0586395263672
17.906350255012512
619.5779576897621
77.63093256950378
533.1250720620155
1899.3680226802826
19.41680383682251
79.46588230133057
1128.8570434451103
92.9869087934494
0.0
0.0
0.0
243.4787130355835
0.0
183.60736083984375
689.8673691749573
4.604169845581055
305.7970817089081
333.5979838371277
0.0
153.33210784196854
407.12607222795486
0.0
813.3115661740303
0.0
0.0
0.0
88.9185870885849
184.51073628664017
80.73508268594742
216.56360125541687
111.60384899377823
91.13656914234161
905.8175727128983
51.3972202539444
203.24735844135284
1413.6734988689423
82.12274920940399
46.67282277345657
72.78839993476868
112.39656621217728
186.49941396713257
267.1240530014038
165.36429965496063
107.07182908058167
25.215190172195435
223.48152577877045
1040.7242625951767
86.49187642335892
39.05241882801056
45.15837335586548
986.5283263325691
83.10448133945465
8.512649893760681
95.30220091342926
607.8335820436478
85.11576163768768
111.39175063371658
269.23773968219757
219.84840029478073
223.04416239261627
94.48510026931763
155.0696278810501
4.699479937553406
24.31502938270569
19.41091024875641
589.8728921413422
6.336960077285767
85.65256798267365
260.689390540123
647.0969338417053
15.963800430297852
38.0189505815506
1326.9161630272865
778.0359001755714
391.98546212911606
7.478280067443848
706.5694460868835
478.8588217496872
68.93152022361755
156.10400837659836
117.38263088464737
20.75169086456299
63.89188063144684
1053.9054371714592
708.6639442443848
165.58355712890625
41.37208032608032
174.1315724849701
0.0
94.73077094554901
85.60342472791672
0.0
260.9115413427353
176.61027014255524
0.0
295.2163474559784
291.85889995098114
0.0
568.2750393152237
363.24327743053436
0.0
53.50643992424011
80.66992038488388
0.0
92.99773979187012
205.06583976745605
0.0
138.1937299966812
239.69501614570618
337.6014613509178
133.27012467384338
138.69066208600998
81.15666145086288
226.2712361216545
0.0
229.97468042373657
13.825700044631958
177.24574333429337
15.817299842834473
304.06114435195923
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1       F2      F0.5  \
0  0.987776   0.659091  0.790909  0.719008  0.76049  0.681818   

   Average Precision  
0           0.525415  

--------------------------------------------------------------------

C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 15.373 seconds
Cross-validation score: 0.7705174972285651
Test score: 0.7321428571428572
Best Hyperparameters: {}
2048.474842965603
27392.455464184284
18037.49935168028
20254.726910591125
21128.87801748514
169.09183049201965
26.547988951206207
32.18672513961792
559.6611502170563
215.60714083909988
190.82157057523727
57.434909641742706
4747.44215887785
493.1716439127922
117.14767920970917
0.0
364.97003197669983
0.0
17624.537369847298
131.70698022842407
14562.326168894768
221.15441715717316
194.4769805073738
36.37644290924072
37.143411695957184
42.79093390703201
448.4163172841072
1657.2453181743622
184.75542271137238
26.57047975063324
1087.5066732764244
0.0
68.1150284409523
474.2422360777855
18.677224278450012
283.17177534103394
1648.310087442398
140.09337973594666
177.70273053646088
828.0803754925728
71.61093580722809
0.0
0.0
0.0
42.68972909450531
0.0
101.18801313638687
1047.8421697616577
36.388139128685
278.72899824380875
294.57445734739304
4.010859966278076
174.29779386520386
521.7952555418015
0.8127409815788269
426.76204907894135
0.0
0.0
0.0
194.00446611642838
233.51961278915405
95.20969259738922
10.15512990951538
34.776960253715515
0.0
7.617400050163269
6.979608774185181
588.8206496834755
444.6584020256996
1.7870299816131592
238.70815068483353
91.77957248687744
39.16148924827576
62.88531905412674
113.79920172691345
55.935103476047516
228.53606569766998
13.8610200881958
85.33347117900848
640.81744992733
20.86476594209671
193.8495774269104
234.7687582373619
1540.2819076180458
86.3755356669426
13.745635271072388
42.9583797454834
608.17023229599
65.58671939373016
141.74009066820145
69.45169574022293
0.0
133.27839523553848
39.95439910888672
212.57219874858856
1.1780799627304077
81.2212598323822
18.135342240333557
328.5432481765747
23.205355763435364
158.62967270612717
98.22717368602753
68.85846990346909
146.48019790649414
89.9810283780098
1154.252334177494
735.159451842308
319.4880884885788
19.325250387191772
228.47616654634476
467.88341093063354
22.241510033607483
178.08851051330566
136.43907183408737
55.93420958518982
194.95888471603394
2226.406521320343
303.6555641889572
774.828271150589
8.683449983596802
51.83297944068909
0.0
189.57014632225037
204.15183359384537
0.0
205.85627675056458
70.75004607439041
0.0
90.85113608837128
171.23817086219788
0.0
1256.4125804901123
128.7657579779625
0.0
39.110441505908966
126.40162253379822
0.0
119.16592824459076
214.73842895030975
0.0
74.89477616548538
63.4624388217926
228.7750688791275
83.50187039375305
99.25525492429733
76.0802869796753
172.6802418231964
0.0
185.68233013153076
64.3299013376236
361.82088458538055
29.46569299697876
777.6869035959244
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.988136   0.683333  0.745455  0.713043  0.732143  0.694915   

   Average Precision  
0           0.514427  

--------------------------------------------------------------------

C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 16.953 seconds
Cross-validation score: 0.7562331840737031
Test score: 0.7746478873239437
Best Hyperparameters: {}
3440.9286648631096
26457.36645334959
23970.342846035957
41303.36089146137
11096.800370514393
116.40262633562088
76.1839908361435
94.37358206510544
291.8142312169075
932.433448433876
183.31912302970886
132.52189141511917
3476.4711253643036
1214.5282537937164
76.69671034812927
0.0
163.62401568889618
0.0
5784.217271387577
164.33525282144547
9191.283898413181
24.75001358985901
585.0745936632156
6.101860165596008
40.86235237121582
88.85222977399826
106.83519911766052
1096.2436769008636
83.65725713968277
180.76322585344315
473.2044485807419
220.6357774734497
21.59586864709854
288.9328780770302
87.97711080312729
41.25007873773575
1573.0853744745255
174.75527811050415
125.14078724384308
1004.7152774333954
62.41221642494202
0.0
0.0
0.0
157.64520609378815
0.0
455.4904370903969
261.62246465682983
44.1994788646698
279.8567002415657
275.25655376911163
1.1894899606704712
220.53766214847565
649.4275915026665
0.0
434.632184445858
0.0
0.0
0.0
135.0153689980507
42.49427008628845
119.01756542921066
125.00797545909882
18.770030975341797
12.181459665298462
11.689599990844727
52.00857925415039
283.6101471185684
766.5801907777786
22.248395264148712
340.7454744577408
37.48447895050049
42.747330367565155
247.58690357208252
638.7617865800858
375.7411594390869
535.2415471076965
7.677919864654541
41.879857420921326
708.448882997036
24.836860418319702
54.47950994968414
84.00809979438782
903.3943997621536
49.81426274776459
16.176769495010376
22.05076014995575
741.3472470641136
28.86925983428955
105.27149707078934
88.07089751958847
0.0
90.56857532262802
123.1933326125145
155.04506796598434
20.021599173545837
29.610539436340332
68.24954974651337
454.2164912223816
14.056540131568909
18.69251012802124
114.20138120651245
98.22593057155609
1.7248799800872803
62.62510573863983
1402.162778556347
845.0783342123032
240.64385390281677
0.0
365.57083362340927
309.31555914878845
9.365789890289307
97.07537388801575
246.53838747739792
231.94715130329132
43.28019607067108
3549.180669784546
197.07080727815628
385.2140466570854
21.298512399196625
87.65772515535355
0.0
95.14201563596725
88.8952208161354
0.0
185.8948700428009
189.21758711338043
0.0
25.625059723854065
146.8440375328064
0.0
1628.5841681957245
142.8918412923813
0.0
66.24917685985565
329.35359394550323
0.0
101.04214054346085
190.84101915359497
0.0
96.57591259479523
153.64465308189392
291.3455581665039
129.07910823822021
15.374574899673462
19.138259768486023
412.91320264339447
0.0
111.41002875566483
25.208280324935913
161.1492270231247
65.904949426651
427.46085023880005
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision  Recall        F1        F2      F0.5  \
0  0.988855     0.6875     0.8  0.739496  0.774648  0.707395   

   Average Precision  
0           0.553955  

--------------------------------------------------------------------

C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 17.360 seconds
Cross-validation score: 0.7673153588183622
Test score: 0.7972270363951472
Best Hyperparameters: {}
1685.7637794613838
23210.491552710533
27350.206257522106
44922.59465402365
2762.348489046097
162.32684618234634
63.844910860061646
56.55045831203461
868.3074501156807
410.37676441669464
108.93218153715134
153.23046910762787
3955.326402425766
1014.9276873469353
36.467237412929535
0.0
692.0372349023819
0.0
14674.12608385086
43.25887989997864
4677.127810239792
30.935530185699463
454.4979908466339
53.7810697555542
19.602141201496124
137.06485295295715
92.07754224538803
1737.3596469163895
251.2518658041954
199.90644824504852
99.15308046340942
284.6996011734009
14.140219986438751
741.0530946850777
12.078431963920593
140.83543241024017
1262.4729649424553
122.81806063652039
91.10255122184753
571.1868806481361
45.88896304368973
0.0
0.0
0.0
153.36071276664734
0.0
301.6855528354645
163.92943286895752
23.439459800720215
547.6030812263489
122.04776340723038
8.522970199584961
290.269610285759
418.6805031299591
0.0
547.8946208953857
0.0
0.0
0.0
42.09367698431015
199.88152772188187
114.0045462846756
17.533860087394714
23.688429474830627
33.06358075141907
23.33084011077881
0.0
193.11815083026886
563.3458711504936
7.787529945373535
42.557371497154236
248.5883002281189
100.61949342489243
184.7968189716339
85.79944884777069
52.39099955558777
230.2511715888977
22.149619340896606
56.082299530506134
705.5379017591476
31.13780426979065
104.29254937171936
99.55767917633057
1003.1541532874107
422.6277272105217
32.11620670557022
3.9825299978256226
752.9952035546303
319.61516666412354
176.37829661369324
227.59197175502777
444.70779728889465
229.29896068572998
17.43800950050354
399.1038291454315
0.0
37.39470064640045
93.98411047458649
630.0442760586739
53.08673107624054
72.48952913284302
111.6334976553917
209.81680065393448
2.4088399410247803
55.565900444984436
985.9501829743385
1372.5428175926208
476.4806841611862
130.6335290670395
629.6783484220505
322.1142832040787
203.22009360790253
96.19033205509186
162.7432854771614
54.819159269332886
174.44003468751907
2413.068850159645
33.43614608049393
1769.7348893880844
33.192989468574524
63.042616188526154
0.0
135.26762574911118
151.58387517929077
0.0
225.7725064754486
114.6290191411972
0.0
3.585900068283081
220.05160588026047
0.0
677.4981229305267
236.8458104133606
0.0
43.74837386608124
447.82155179977417
0.0
245.88957476615906
241.8037635087967
0.0
63.51811981201172
83.08914601802826
177.7954249382019
194.53279078006744
147.3157515525818
82.05426532030106
458.006671667099
0.0
142.10112363100052
24.26196014881134
403.767553627491
4.128220081329346
468.98055601119995
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.988675   0.671533  0.836364  0.744939  0.797227  0.699088   

   Average Precision  
0           0.564881  

--------------------------------------------------------------------

C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 16.521 seconds
Cross-validation score: 0.7663534069933972
Test score: 0.7512953367875647
Best Hyperparameters: {}
1674.9056023955345
34943.127144396305
13630.927477359772
43484.068820118904
10730.83792155981
177.68892741203308
303.4215692281723
46.15056365728378
494.6938009262085
282.0092958211899
187.88221895694733
65.07273054122925
5214.57974922657
677.4789089560509
81.17029893398285
0.0
446.4894246459007
0.0
9030.69071918726
198.60854107141495
6304.408682703972
22.39717960357666
196.06278091669083
40.949932277202606
197.32175767421722
116.32638710737228
41.41635036468506
1158.5906980633736
205.38413655757904
33.640854835510254
1373.817118883133
21.912240386009216
65.23134100437164
1296.72776979208
14.530416190624237
402.42395251989365
1861.8454983830452
114.8409121632576
97.6959280371666
275.86220943927765
60.789999186992645
0.0
0.0
0.0
96.1345716714859
0.0
345.4595376253128
532.3295855522156
61.32178997993469
519.7377795577049
324.7383018732071
0.0
145.0190989971161
146.94890373945236
0.0
384.63606745004654
0.0
0.0
0.0
127.87395423650742
202.83561527729034
300.6859695315361
41.140960693359375
26.666109919548035
44.762990951538086
123.7593994140625
0.0
183.12309730052948
275.24207681417465
1.4028500318527222
17.710469961166382
71.67890787124634
148.86130940914154
273.13488656282425
118.88760817050934
347.2266901731491
281.3252876996994
52.15163004398346
102.8129625916481
607.4520815610886
34.433069944381714
65.30598032474518
120.59606009721756
1591.68058937788
115.49933737516403
34.385377168655396
31.042412281036377
603.5384991765022
11.6700998544693
126.75644946098328
241.1864993572235
0.0
346.28416085243225
104.14570987224579
521.4241890907288
9.233650207519531
23.62395989894867
40.8283908367157
816.8296175003052
15.165090203285217
26.046949863433838
137.05097448825836
73.7531099319458
0.0
15.44884991645813
664.0813504457474
718.0137300491333
812.0593667030334
17.448092460632324
255.38459372520447
237.12748628854752
39.94651538133621
116.63795065879822
41.41478890180588
57.126500606536865
54.997328996658325
3323.0391488075256
47.946716248989105
291.7696455717087
82.11660015583038
33.75014531612396
0.0
18.132992804050446
374.3416277170181
0.0
231.75231981277466
127.60017114877701
0.0
15.02793002128601
66.16366320848465
0.0
465.3637316226959
379.4322194457054
0.0
23.554269909858704
431.2050533890724
0.0
323.74296885728836
125.56468015909195
0.0
207.775160074234
440.3238773345947
126.4428540468216
81.10130095481873
100.76334714889526
43.86782389879227
146.95326602458954
0.0
70.55439043045044
105.43262773752213
195.23596996068954
0.0
823.9631613492966
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.986518   0.625899  0.790909  0.698795  0.751295  0.653153   

   Average Precision  
0           0.499164  

--------------------------------------------------------------------

C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 17.711 seconds
Cross-validation score: 0.7827683653463361
Test score: 0.7407407407407408
Best Hyperparameters: {}
2755.248919546604
26810.411907434464
18913.399393200874
46908.11470609903
7065.457924246788
143.71756780147552
87.46915006637573
62.13812702894211
261.13654416799545
174.1134962439537
101.99008733034134
24.745113909244537
3691.753474831581
1243.4022215604782
111.79626929759979
0.0
245.76862341165543
0.0
9050.270874679089
883.0633848905563
4999.9433081150055
58.86032056808472
256.1092448234558
14.230829298496246
147.60122072696686
21.217252254486084
173.60234159231186
5328.764474630356
619.5353830456734
108.12287902832031
200.97469973564148
52.39170968532562
5.460805952548981
950.3892920613289
15.17887932062149
220.3612266778946
632.2180600166321
42.47536087036133
118.81298094987869
578.5331752300262
52.99106568098068
0.0
0.0
0.0
214.86695098876953
0.0
161.3025353550911
876.3810279369354
0.0
347.91963171958923
149.36017966270447
18.04674005508423
40.13860076665878
362.5751419663429
0.0
160.8691154718399
0.0
0.0
0.0
97.40282171964645
779.4844323992729
98.97858965396881
141.73880410194397
89.73100018501282
18.398531317710876
456.12089455127716
8.2608802318573
229.09044283628464
261.5158075094223
38.1031996011734
269.6459941267967
56.56281489133835
56.242240607738495
9.428579926490784
53.316548347473145
247.20795023441315
151.83033221960068
39.03169256448746
593.7706953883171
1251.460135936737
19.925859928131104
64.45770162343979
43.719219863414764
1133.7387169003487
244.04779589176178
59.927284836769104
51.983569264411926
798.9856660366058
10.15218997001648
112.49073994159698
99.5819890499115
0.0
264.47681272029877
93.32914805412292
283.30908930301666
0.0
27.650861620903015
117.39505755901337
473.61476373672485
11.370820045471191
66.97095447778702
176.604223549366
224.52304428815842
0.0
18.30759024620056
311.6450830101967
742.7747887372971
176.19397401809692
2.8903799057006836
684.4534094333649
785.0026146173477
123.1880019903183
207.0688169002533
222.76473504304886
150.4077501296997
86.67845058441162
4165.408499717712
225.64206957817078
127.23415994644165
68.20874083042145
217.77669709920883
0.0
97.64347094297409
90.70321899652481
0.0
239.9797008037567
388.11625015735626
0.0
127.69442933797836
134.009570479393
0.0
463.88520431518555
94.83779174089432
0.0
109.05619955062866
130.07643204927444
0.0
78.09883987903595
97.34190142154694
0.0
114.26919692754745
369.5673415660858
99.18585520982742
285.2660074830055
252.8945443034172
245.58610898256302
778.1624861359596
0.0
256.92255556583405
77.14306116104126
272.96829402446747
27.546682119369507
287.79387509822845
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.987597   0.661417  0.763636  0.708861  0.740741  0.679612   

   Average Precision  
0           0.509756  

--------------------------------------------------------------------

C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 16.765 seconds
Cross-validation score: 0.7593675582729922
Test score: 0.7772020725388601
Best Hyperparameters: {}
2197.815194070339
26732.873284220695
21604.966895341873
37279.65230423212
16814.351732313633
177.7114878296852
138.50628972053528
64.94822931289673
491.4942899942398
626.5602730512619
312.6772105693817
148.8245785832405
6149.262440979481
423.6502291560173
245.03355836868286
0.0
450.4730703830719
0.0
7424.708807349205
865.4552602767944
4090.474223434925
7.554140090942383
539.007672727108
98.30711781978607
89.02914881706238
9.050731003284454
335.09842574596405
1342.526937007904
492.0624191761017
67.69033819437027
832.1859911680222
275.9359562397003
31.756211757659912
374.4418348670006
8.390727996826172
150.37133073806763
1533.348599076271
94.1360228061676
57.54994910955429
606.2275751233101
71.41016256809235
0.0
0.0
0.0
22.999709367752075
1.1310100555419922
96.03603100776672
263.95285218954086
157.19919967651367
709.335798740387
150.33831864595413
167.373379945755
102.58101123571396
298.4557731151581
0.0
323.886610686779
0.0
0.0
0.0
66.87710320949554
316.8932711482048
78.80669927597046
24.41304910182953
51.36504876613617
11.580080151557922
267.11144840717316
12.490449905395508
199.09659934043884
341.0187628865242
61.358840227127075
8.840745985507965
234.65412485599518
146.89669036865234
361.06592440605164
59.08417081832886
94.43179082870483
140.1554684638977
68.00187039375305
116.29342597723007
1437.9126496315002
13.438419938087463
70.35007953643799
77.37283945083618
1222.4212048053741
260.7096058130264
24.158058166503906
93.32101792097092
377.7394065260887
115.3245752453804
17.92838203907013
470.87790751457214
0.0
236.57161140441895
188.87116920948029
290.57105815410614
0.0
43.17179989814758
5.760329961776733
480.6016685962677
57.05292010307312
35.77439022064209
111.37103700637817
88.81941044330597
0.0
101.47554105520248
1294.0692901611328
1071.1358858942986
625.535129904747
87.91419422626495
302.3737168312073
483.3455773591995
112.92788934707642
57.16340470314026
254.28069180250168
50.49212050437927
195.528060734272
2130.930569291115
104.49127012491226
395.98866844177246
62.80475056171417
79.38069313764572
0.0
189.70503544807434
181.748861849308
0.0
350.6629737019539
162.4500229358673
0.0
166.3755178451538
186.4767507314682
0.0
1719.7154030799866
281.52694976329803
0.0
61.8320626616478
136.73530745506287
0.0
592.1755018234253
236.78217786550522
0.0
147.80121475458145
150.91781187057495
148.62480241060257
63.49222433567047
41.36049050092697
41.08039516210556
133.2737289071083
0.0
125.50330865383148
121.61608469486237
293.8628832101822
4.693209886550903
1304.6255675554276
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.987597   0.647482  0.818182  0.722892  0.777202  0.675676   

   Average Precision  
0           0.533353  

--------------------------------------------------------------------

C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 16.550 seconds
Cross-validation score: 0.7622260803999497
Test score: 0.7391304347826088
Best Hyperparameters: {}
2013.4119850993156
28153.17610168457
21714.84398895502
35329.6839710474
6701.149411559105
297.42538142204285
88.36296480894089
52.13552129268646
282.2722444534302
354.19784212112427
160.40855515003204
168.67522531747818
5805.2692784667015
453.63683915138245
10.519430041313171
0.0
486.3336945772171
0.0
16858.83231317997
288.56273448467255
6902.245359659195
31.59311068058014
299.2734895348549
11.571300029754639
103.45827955007553
12.383909702301025
224.23847675323486
1464.512680053711
827.0094635486603
18.321571052074432
312.2723300457001
201.86534070968628
15.271290063858032
743.2040401101112
13.722667872905731
179.48458868265152
1844.0416804552078
199.71705794334412
94.4936797618866
777.2143820524216
64.35616135597229
0.0
0.0
0.0
78.00148069858551
0.0
316.8615175485611
454.3497468829155
0.8477410078048706
218.38412445783615
226.00342309474945
4.2268500328063965
161.71474832296371
416.96526139974594
0.0
291.47938299179077
0.0
0.0
0.0
151.16737693548203
167.16460198163986
170.24369275569916
52.8281888961792
13.009384334087372
37.04288959503174
15.954629898071289
27.848800659179688
311.1741442680359
551.0339877605438
1.6601200103759766
167.63436222076416
192.4075276851654
353.05706852674484
84.91151469945908
95.69518101215363
96.83165299892426
89.87015342712402
23.535640001296997
119.53753924369812
1514.871003985405
70.80833029747009
11.4275461435318
174.011494576931
1023.0067656040192
126.3051587343216
64.7748293876648
46.558160841464996
1430.481756567955
56.373765885829926
68.04601740837097
136.13094997406006
6.505980014801025
61.65339320898056
208.1254607439041
182.66424119472504
0.0
189.60071229934692
37.3217191696167
248.49321341514587
3.5245001316070557
133.78840053081512
63.05370777845383
149.46481347084045
4.725289821624756
45.8115119934082
553.6326216459274
1181.6864871382713
321.758669257164
0.0
958.7459272742271
408.1855174899101
5.8035629987716675
283.42580258846283
164.9021418094635
174.58138346672058
51.23690044879913
2440.7504844665527
162.14135509729385
1092.9853134155273
48.1541109085083
176.46630930900574
0.0
63.83668214082718
67.57117974758148
0.0
372.904590010643
66.27088129520416
0.0
157.4219532608986
202.80311888456345
0.0
1867.981124162674
29.31743037700653
0.0
45.11855697631836
133.12647145986557
0.0
201.53113782405853
182.7370501756668
0.0
216.02239990234375
76.52571839094162
386.3173926472664
43.42836058139801
41.42496681213379
12.329169988632202
257.53922486305237
0.0
364.8134334087372
103.79837846755981
193.1225088238716
0.0
625.6406183242798
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1       F2      F0.5  \
0  0.986518    0.62963  0.772727  0.693878  0.73913  0.653846   

   Average Precision  
0           0.491026  

--------------------------------------------------------------------

C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 16.725 seconds
Cross-validation score: 0.7644467844876542
Test score: 0.75993091537133
Best Hyperparameters: {}
1392.5174250006676
22952.383972883224
26668.555531144142
45187.32875949144
7817.324533045292
105.70284068584442
85.43209159374237
206.48702120780945
350.2193618416786
82.53974097967148
138.48090028762817
193.91823029518127
5906.49252396822
1038.7303783893585
125.15545791387558
0.0
415.5565893650055
0.0
5957.881053507328
1057.5463287234306
5404.08430236578
100.96936976909637
222.9714126586914
56.99270153045654
228.6325935125351
43.61736536026001
95.9595456123352
5610.838542699814
119.85559749603271
102.09767431020737
166.33711391687393
151.477801322937
30.95131254196167
401.98568391799927
4.83004504442215
459.44863760471344
953.2272529602051
130.0128024816513
155.48921436071396
137.6724841594696
73.13950550556183
0.0
0.0
0.0
155.76880979537964
0.0
172.24062621593475
284.49742794036865
24.222990036010742
531.8645549416542
170.9615684747696
16.586669921875
76.98508805036545
718.2797926664352
0.0
217.4239993095398
0.0
0.0
0.0
330.0907026529312
395.35310328006744
46.37215495109558
36.33214974403381
4.826789855957031
12.348940253257751
35.61539125442505
2.0892200469970703
237.3844078183174
1367.2925417423248
5.948850035667419
154.28649985790253
109.71183741092682
152.6477073431015
153.44467771053314
185.42175579071045
39.58558964729309
363.81210219860077
25.80502998828888
105.8719909787178
437.4805076122284
28.93595004081726
41.27450346946716
76.22353959083557
824.5208778977394
83.57343989610672
69.07925915718079
34.48673057556152
846.2932237386703
0.0
292.52286887168884
161.32639002799988
0.0
264.8665238022804
87.6626296043396
46.95821928977966
6.739570140838623
72.28716945648193
37.27015173435211
1159.1183724403381
37.64535081386566
97.07710534334183
94.397829413414
91.8829128742218
4.210509777069092
63.3232399225235
937.7497964501381
658.084147632122
323.408207654953
1.1638400554656982
213.07416152954102
162.84977054595947
42.20706069469452
508.0902283191681
159.465072453022
118.94344276189804
31.32120978832245
3496.372235894203
261.55408173799515
1391.3721535801888
186.5950552225113
94.36450958251953
0.0
23.81212228536606
178.27896505594254
0.0
189.22095865011215
207.0385099053383
0.0
139.13842010498047
207.17940938472748
0.0
708.9902957677841
207.37524050474167
0.0
39.387149930000305
256.4923024177551
0.0
90.1800594329834
43.35300898551941
0.0
148.90224158763885
171.9728130698204
174.35656487941742
18.884270071983337
240.5853077173233
66.34543055295944
246.994166970253
0.0
125.72428953647614
77.35349881649017
288.9876352548599
32.5059700012207
266.0903558731079
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision  Recall        F1        F2      F0.5  \
0  0.986878   0.633094     0.8  0.706827  0.759931  0.660661   

   Average Precision  
0            0.51043  

--------------------------------------------------------------------

C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 16.058 seconds
Cross-validation score: 0.7883851860984157
Test score: 0.7394366197183099
Best Hyperparameters: {}
2436.411073446274
24833.70473062992
21652.161142647266
28982.668037831783
5444.8163251280785
333.3691909313202
51.48711049556732
134.71534538269043
1805.5428435206413
161.5851554274559
235.65019011497498
93.33194983005524
7835.653338611126
819.611859202385
55.844220757484436
0.0
304.8590560555458
0.0
12212.19241309166
360.55946457386017
18798.240564763546
76.58899056911469
146.06554234027863
11.420977115631104
202.99837684631348
48.58279836177826
276.2770844697952
1036.658117055893
293.9609000682831
32.33006978034973
102.47743940353394
60.84515964984894
17.756987690925598
778.365696310997
26.615049839019775
278.3145655989647
1733.931193292141
57.629560470581055
145.46945917606354
734.383131980896
54.20199012756348
0.0
0.0
0.0
116.56242728233337
0.0
189.71255791187286
1280.0742683410645
8.328380227088928
978.4104713201523
5.304020047187805
122.01491355895996
49.716857850551605
386.91270488500595
0.0
543.3128690719604
0.0
0.0
0.0
112.93374860286713
243.6294628381729
73.76792013645172
3.7918899059295654
28.80635803937912
15.127593040466309
9.48458981513977
5.3260698318481445
164.5313020348549
793.0104213356972
5.734469890594482
171.97162556648254
116.70765233039856
72.1976009607315
177.4116291999817
37.13521981239319
96.41701823472977
156.98801016807556
22.0904198884964
71.84303021430969
682.1337994933128
15.367397904396057
53.03811573982239
134.07291626930237
961.7368392944336
61.2854700088501
66.46912384033203
74.48065912723541
873.39819419384
3.6850199699401855
217.4219629764557
264.54341864585876
645.6339874267578
266.79605811834335
27.38557004928589
98.27434015274048
52.430970668792725
28.334819555282593
151.87806129455566
585.2444522380829
1.935629963874817
22.207759737968445
86.04286921024323
381.34725338220596
0.0
41.48093634843826
1448.059835612774
1110.6111431121826
945.2316301465034
7.53794002532959
442.3322318792343
144.3368844985962
55.55795097351074
150.4849300980568
112.24079948663712
34.07049036026001
88.78765976428986
4109.49936401844
41.40616524219513
171.27893114089966
42.75379812717438
64.77149474620819
0.0
118.30571246147156
174.30715322494507
0.0
263.8519147634506
50.58745038509369
0.0
59.65200853347778
230.54090815782547
0.0
326.5070458650589
223.71002388000488
0.0
142.46028816699982
162.85354948043823
0.0
257.7648561000824
194.2714336514473
0.0
332.36374604701996
198.90265691280365
296.1849846839905
143.13946932554245
201.0074518918991
19.18139934539795
75.0223678946495
0.0
56.582043409347534
85.96594965457916
188.19872510433197
11.344000101089478
916.2875396609306
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.987417    0.65625  0.763636  0.705882  0.739437  0.675241   

   Average Precision  
0            0.50581  

--------------------------------------------------------------------

C:\Python39\lib\site-packages\sklearn\model_selection\_search.py:285: UserWarning: The total space of parameters 1 is smaller than n_iter=100. Running 1 iterations. For exhaustive searches, use GridSearchCV.
  warnings.warn(

Elapsed time to compute best fit: 16.179 seconds
Cross-validation score: 0.7559278895396833
Test score: 0.7368421052631579
Best Hyperparameters: {}
2790.41780847311
24213.17216026783
21791.41094172001
40231.67659878731
9363.92169868946
220.6388099193573
142.21061968803406
15.990993738174438
490.78428852558136
131.65535145998
571.3462033867836
64.25900113582611
4287.257996201515
446.47757399082184
213.7769677042961
0.0
753.5909463763237
0.0
12269.601063728333
198.42203027009964
3782.855497956276
44.79922914505005
396.5215300321579
64.06536054611206
49.8108224272728
20.793647170066833
171.87751942873
4602.423613905907
1420.0308029651642
63.05939120054245
38.5754691362381
14.346966743469238
8.77908992767334
1416.4581884741783
2.3812999725341797
294.42692708969116
1542.8952540159225
49.02153378725052
100.25758773088455
734.6389420032501
44.146748304367065
0.0
0.0
0.0
88.9943876862526
0.0
114.6993179321289
547.4735387563705
4.618159770965576
365.72732388973236
589.1524277329445
143.06790697574615
51.96097534894943
694.2890730500221
0.0
538.6192882061005
0.0
0.0
0.0
48.50137758255005
69.06225979328156
95.31809586286545
9.119279861450195
8.048809885978699
76.85978275537491
51.72872042655945
31.347169637680054
734.1394683122635
275.76734590530396
57.17363953590393
225.10253769159317
99.88078951835632
172.859659075737
8.278020143508911
26.496910572052002
270.7943900823593
103.36440998315811
50.71565097570419
404.1975395679474
1000.419670343399
27.311083436012268
78.74679970741272
109.82218730449677
808.035287797451
182.78281831741333
42.95641803741455
118.07809430360794
568.1712605953217
98.38362163305283
120.90197026729584
145.5244870185852
0.0
358.75484269857407
53.100669503211975
236.91462635993958
12.918480396270752
24.109359741210938
24.853360056877136
387.67680644989014
21.469890117645264
33.6380233168602
240.68502008914948
69.18065893650055
1.0002399682998657
27.413035452365875
959.3177291750908
973.0467542409897
405.1270581483841
0.0
588.762995839119
183.0737944841385
1488.0242134332657
95.81811058521271
67.60712027549744
121.07894706726074
56.80870985984802
3614.289041161537
122.79505997896194
509.30875647068024
43.9825673699379
124.16192930936813
0.0
310.5503893494606
163.74764454364777
0.0
175.08345979452133
203.29229992628098
0.0
131.95352464914322
150.05032289028168
0.0
822.2521688938141
223.26036047935486
0.0
153.2360115647316
52.337459325790405
0.0
195.8827093243599
243.06087589263916
0.0
97.82552933692932
122.33268874883652
179.75209307670593
27.261799812316895
74.69207316637039
38.876180768013
674.0514267086983
0.0
285.7401080131531
86.56903088092804
100.48819363117218
8.594859838485718
586.3943381905556
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall   F1        F2      F0.5  Average Precision
0  0.987057   0.646154  0.763636  0.7  0.736842  0.666667             0.4981