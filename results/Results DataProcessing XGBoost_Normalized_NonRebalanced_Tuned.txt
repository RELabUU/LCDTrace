[12:34:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 2813.583 seconds
Cross-validation score: 0.814257529069797
Test score: 0.7847533632286996
Best Hyperparameters: {'classifier__min_child_weight': 2, 'classifier__max_depth': 20, 'classifier__learning_rate': 0.4, 'classifier__gamma': 0.0, 'classifier__colsample_bytree': 0.4}
0.015802069
0.021309245
0.02623326
0.023890357
0.02723099
0.002688243
0.0040120953
0.0035009268
0.003864319
0.008825699
0.012229064
0.004232762
0.014189898
0.0055626333
0.0013949357
0.00888483
0.0035457243
0.0035855619
0.023658326
0.004955007
0.019936057
0.009043341
0.005793494
0.0028907584
0.0022315183
0.0024658719
0.015690822
0.009831074
0.0045473594
0.003185128
0.016052624
0.0027652576
0.0036927524
0.012380315
0.003214511
0.010037305
0.0051702503
0.0031908643
0.00561881
0.00029178872
0.0034299865
0.0028276537
0.0029311108
0.0048096133
0.0016506199
0.0
0.0070268265
0.00661324
0.0
0.009261156
0.012686594
0.0015051741
0.0024205092
0.004021888
0.0
0.012172431
0.0
0.0
0.0
0.0027211392
0.0046139727
0.0043935506
0.003003429
0.0
0.0030561343
0.010146887
0.006826964
0.0038972127
0.0070501426
0.0014106829
0.005724882
0.005417523
0.007334435
0.0038512275
0.0078641465
0.00051464164
0.0061304704
0.007648238
0.005726315
0.0067329267
0.008059279
0.0038321065
0.0050828583
0.0042279195
0.0029113432
0.0037776686
0.007688009
0.0022190264
0.010631016
0.003039772
0.008292499
0.030727256
0.002568401
0.0037409477
0.0059954952
0.014150027
0.0022931378
0.0009896219
0.005836238
0.008766544
0.009517656
0.018398343
0.010856466
0.01978524
0.004858479
0.0068992274
0.0041701365
0.004911988
0.0
0.003611468
0.005170031
0.007862373
0.012833176
0.0046057403
0.0053679734
0.0023336117
0.018574445
0.0048244577
0.0118130315
0.0044165426
0.0027803173
0.0052879914
0.0035083566
0.0026815042
0.0029305418
0.007198715
0.0077567217
0.004880913
0.0050081667
0.002264128
0.007217815
0.011363062
0.0047563403
0.015657999
0.0019721335
0.007380208
0.0010956797
0.007934515
0.0031865102
0.00034118383
0.0054739965
0.005120381
0.0036156669
0.002725645
0.0053418404
0.0067126597
0.019478815
0.0
0.0017410067
0.00978104
0.0045078276
0.0
0.0016112721
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.990293   0.833333  0.636364  0.721649  0.667939  0.784753   

   Average Precision  
0           0.537493  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[13:26:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 3076.465 seconds
Cross-validation score: 0.8182918185504106
Test score: 0.7692307692307692
Best Hyperparameters: {'classifier__min_child_weight': 2, 'classifier__max_depth': 20, 'classifier__learning_rate': 0.3, 'classifier__gamma': 0.8, 'classifier__colsample_bytree': 0.7}
0.008226182
0.017077824
0.021512164
0.019513989
0.026321445
0.01082263
0.0034354809
0.0035184664
0.0032953161
0.023213957
0.015503407
0.0049442914
0.009987277
0.007814899
0.0
0.004086475
0.0026905956
0.0008903471
0.020349002
0.0067199823
0.02396771
0.004434416
0.0041910945
0.009031543
0.0050694495
0.00443192
0.0052698744
0.015010863
0.0068225893
0.012844093
0.0041541127
0.0018671834
0.0032553894
0.0088874195
0.0025557831
0.007932562
0.0023052287
0.005071783
0.0035425078
0.0070056096
0.002922678
0.0
0.0
0.0
0.01712319
0.0
0.009874643
0.006875651
0.0
0.0069993995
0.0064899
0.0
0.0060438225
0.009533374
0.0
0.0067016915
0.0
0.0
0.0
0.0020683357
0.0036018211
0.0045267865
0.0
0.008824689
0.01001512
0.003452653
0.0
0.0037444395
0.0070573012
0.002134285
0.008329286
0.00534854
0.0069136624
0.0039577447
0.0048349523
0.0046539134
0.004685615
0.005062103
0.007918952
0.0
0.0019552493
0.0049390336
0.0070598675
0.0037224176
0.0037010503
0.005838857
0.017955126
0.0
0.004025792
0.005196855
0.0054479917
0.0
0.004548271
0.0078475475
0.005485472
0.0026762958
0.013264535
0.02361293
0.004198714
0.0042225597
0.01144258
0.004767476
0.0077120913
0.0
0.0034014888
0.0060002995
0.0037915364
0.0034837243
0.0027331607
0.0035018984
0.015299939
0.0
0.006626279
0.0074891485
0.0048182467
0.009473068
0.017478034
0.0028570467
0.011892025
0.008227078
0.003855794
0.0
0.004861683
0.0044294307
0.0032032346
0.0030241902
0.003913321
0.0
0.0
0.0043475167
0.0
0.011674837
0.0070503093
0.0055825007
0.0086560575
0.010597974
0.05542285
0.0075624734
0.008525731
0.01647581
0.00727278
0.005828259
0.00512512
0.003970215
0.005008768
0.008215239
0.0061571505
0.0
0.0046917866
0.0066019217
0.009283158
0.0
0.0046988013
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.989754   0.819277  0.618182  0.704663  0.650096  0.769231   

   Average Precision  
0           0.514012  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[14:16:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 3000.991 seconds
Cross-validation score: 0.8156966356362705
Test score: 0.7805429864253394
Best Hyperparameters: {'classifier__min_child_weight': 5, 'classifier__max_depth': 8, 'classifier__learning_rate': 0.15, 'classifier__gamma': 0.6, 'classifier__colsample_bytree': 0.4}
0.011367049
0.023704285
0.027608346
0.028371107
0.027421601
0.005047536
0.0041449764
0.0033857478
0.0084684575
0.0073764976
0.004059679
0.0026888396
0.011053254
0.0064470028
0.009051687
0.0029538455
0.005890603
0.0057125064
0.019001756
0.010603701
0.026067704
0.0070344307
0.0044300584
0.00586978
0.005139621
0.0039650076
0.013158062
0.011800205
0.00670408
0.008191597
0.0035210156
0.0030370296
0.0052494374
0.009710851
0.0037232346
0.004914683
0.005780565
0.0032674205
0.0048907823
0.0020025515
0.0039141537
0.0049824063
0.0035489334
0.0036762923
0.008728193
0.0
0.0046045016
0.004139625
0.0
0.0048899194
0.007024044
0.008874465
0.007139529
0.008420432
0.0
0.009443922
0.0
0.0
0.0
0.0058504646
0.0040454813
0.0038836708
0.007304659
0.0
0.009146398
0.005106429
0.0
0.008317108
0.0061153676
0.0051278025
0.009429816
0.0051141237
0.0068984404
0.006122341
0.008144986
0.0027276382
0.006970843
0.007294648
0.0048720273
0.005057071
0.010104275
0.005572907
0.0045518167
0.006275235
0.004421599
0.011924298
0.004028535
0.006644143
0.007815139
0.0043317107
0.0061214315
0.00845997
0.0036387867
0.0064212643
0.004128046
0.017795239
0.006740728
0.0057456107
0.009488259
0.0
0.006754656
0.003974431
0.008016813
0.0043998254
0.005788585
0.008207922
0.0052861394
0.007646698
0.0
0.0062547154
0.00664156
0.0050793653
0.008097509
0.0049068374
0.0055293553
0.0045158365
0.008761397
0.00490024
0.0051837
0.003685736
0.0025199
0.005931772
0.0029308328
0.004475145
0.0052326987
0.008287543
0.004810721
0.010850272
0.008169715
0.003794432
0.0032072603
0.02110385
0.0072645354
0.013047519
0.0047178157
0.005721246
0.0020006516
0.008404869
0.005035018
0.0071159992
0.0050996593
0.0070350524
0.0054747537
0.0036123414
0.004794461
0.0034211348
0.008219018
0.0
0.0062418897
0.003718773
0.0049020424
0.0
0.0052864105
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.990113   0.831325  0.627273  0.715026  0.659656  0.780543   

   Average Precision  
0           0.528838  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[15:08:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 3123.301 seconds
Cross-validation score: 0.8048935082263335
Test score: 0.7872340425531914
Best Hyperparameters: {'classifier__min_child_weight': 2, 'classifier__max_depth': 6, 'classifier__learning_rate': 0.25, 'classifier__gamma': 0.3, 'classifier__colsample_bytree': 0.8}
0.009659265
0.026776148
0.026700467
0.026333742
0.033523303
0.0059550093
0.0043531405
0.0029355627
0.0058674654
0.013832309
0.0026225836
0.0033008324
0.01127075
0.006717145
0.008130892
0.0014814199
0.0030861292
0.0012042812
0.025264375
0.0046725227
0.013356133
0.0074181766
0.005667458
0.0020233213
0.006727653
0.0021757742
0.0064522414
0.009445168
0.006880827
0.005630596
0.0022011918
0.0015845511
0.0033475608
0.011539826
0.00328226
0.005320515
0.008985278
0.0023822777
0.005025664
0.002630169
0.0048162476
0.007926158
0.0
0.0024863721
0.010904176
0.0
0.0036872982
0.005593795
0.0043096016
0.0057443213
0.004516707
0.0
0.0022801564
0.009136644
0.0
0.004665529
0.0
0.0
0.0
0.0028420766
0.0035999739
0.0077510313
0.0055509354
0.009639966
0.0017750177
0.006542099
0.007638943
0.0055066096
0.0027815627
0.0
0.009445479
0.017144062
0.0021841023
0.0028906097
0.0009381261
0.00043410054
0.006497485
0.007029712
0.011486615
0.0016784236
0.003255105
0.004980001
0.0046906923
0.0039379746
0.00226872
0.0031165606
0.0026416057
0.0
0.0018981062
0.0051538856
0.010754766
0.0
0.0065686833
0.010670245
0.0055224523
0.0
0.0088307215
0.0054612583
0.008552786
0.011912003
0.00764223
0.005189779
0.0055358517
0.0
0.0049916105
0.00942029
0.008619508
0.005843819
0.0056272196
0.011687005
0.0070197494
0.0
0.010946157
0.006101283
0.009805331
0.008145905
0.02506925
0.007582351
0.01002868
0.003932103
0.0052234353
0.008063464
0.004069858
0.0043443358
0.006075719
0.0
0.003924109
0.0
0.0016929792
0.0054720026
0.0
0.01328204
0.004831172
0.04130151
0.006214024
0.0127487425
0.01862015
0.012973208
0.0060008634
0.0
0.0037498602
0.006518315
0.005026847
0.0016372313
0.0038830747
0.0016946797
0.024355793
0.0
0.009740909
0.003755537
0.013171311
0.0
0.0030371733
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall    F1        F2      F0.5  Average Precision
0  0.990653   0.822222  0.672727  0.74  0.698113  0.787234           0.559603

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[15:56:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 2876.775 seconds
Cross-validation score: 0.8148733592464676
Test score: 0.8023255813953487
Best Hyperparameters: {'classifier__min_child_weight': 4, 'classifier__max_depth': 14, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0.7, 'classifier__colsample_bytree': 0.6}
0.012375905
0.019927649
0.023319162
0.01942298
0.031271182
0.0049174195
0.00433301
0.0031006117
0.0071630585
0.021313425
0.0039869766
0.003665612
0.011588799
0.009298362
0.0040732035
0.0
0.0048894687
0.0035181192
0.028062467
0.012225455
0.016411496
0.011204879
0.005236079
0.0024683294
0.007319072
0.005271543
0.011136409
0.010413241
0.007558572
0.0056566265
0.005105092
0.0046686037
0.0029860544
0.00907258
0.0040815915
0.0035774675
0.009973763
0.0038065917
0.0036729274
0.0016821022
0.004363092
0.0054203332
0.0
0.002493987
0.0064849043
0.0
0.0050175814
0.006505927
0.0030110416
0.0063477154
0.0051264376
0.0
0.0055964743
0.0077366894
0.0
0.01842593
0.0
0.0
0.0
0.004902855
0.003135742
0.0050296527
0.011978041
0.0
0.008688375
0.0032755309
0.0
0.0038208428
0.0073573105
0.0045727235
0.0032251454
0.0029284626
0.01124449
0.0027274513
0.009535459
0.0044116587
0.006113185
0.007370636
0.009002977
0.008764365
0.0030981111
0.0046569463
0.0045686415
0.0040630978
0.0040641134
0.0051712175
0.003568936
0.0032150156
0.011393766
0.0075032013
0.008835175
0.0
0.0044659106
0.008787885
0.00933439
0.004530309
0.022109453
0.0053774533
0.013065395
0.013015177
0.00461381
0.007912938
0.006064094
0.0
0.011000108
0.0076215705
0.005723388
0.0059326235
0.0024138608
0.0047963983
0.00501551
0.0
0.008484696
0.004112211
0.00602224
0.008666688
0.011466869
0.008547197
0.007305075
0.0063219727
0.005806039
0.0019184629
0.0039278255
0.0046915477
0.0042001214
0.0051713516
0.005690144
0.0
0.0074564596
0.0071783205
0.0
0.01146023
0.0073227067
0.015735168
0.006408723
0.009800259
0.006815175
0.0076122233
0.006757922
0.0
0.004935937
0.004677527
0.005082488
0.0026370909
0.0035567873
0.004240956
0.004421125
0.0
0.012980891
0.007830134
0.0049357624
0.0
0.009532312
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.990653     0.8625  0.627273  0.726316  0.663462  0.802326   

   Average Precision  
0           0.548393  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[16:47:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 3050.127 seconds
Cross-validation score: 0.811511959850541
Test score: 0.8255813953488371
Best Hyperparameters: {'classifier__min_child_weight': 3, 'classifier__max_depth': 16, 'classifier__learning_rate': 0.25, 'classifier__gamma': 0.0, 'classifier__colsample_bytree': 0.9}
0.010851955
0.02437576
0.02165087
0.029148031
0.052602135
0.0039278106
0.0073091076
0.004814929
0.010384364
0.01234078
0.0030923751
0.0038247148
0.010916934
0.01054749
0.0022266156
0.0
0.0038744346
0.0
0.011385338
0.006618699
0.015425917
0.015028172
0.00804468
0.0017344635
0.0033098792
0.0037408846
0.011247376
0.015195955
0.008417662
0.0
0.01020022
0.0058136503
0.0032398647
0.010011279
0.003762438
0.00610879
0.012122796
0.0055217003
0.0060099475
0.0028136503
0.004592181
0.007109769
0.0008414135
0.0021439309
0.012732262
0.0
0.0030665384
0.006662175
0.0
0.00213308
0.014051776
0.0
0.004773844
0.009792396
0.0
0.012289873
0.0
0.0
0.0
0.0032461435
0.0054085758
0.0073048477
0.0025049527
0.002454419
0.0061648646
0.004323948
0.0
0.0053128554
0.009567357
0.0035042195
0.011009785
0.0041793576
0.007299229
0.005809353
0.0036145763
0.004684351
0.007984831
0.009759478
0.013392752
0.010363484
0.004421156
0.0051375804
0.006833627
0.0068604113
0.0052127335
0.005900628
0.00733307
0.0031200415
0.0015196302
0.0030395077
0.006683906
0.0
0.0033493994
0.0046078614
0.006742271
0.0020596064
0.026594052
0.005073196
0.007662197
0.0013368513
0.0040699695
0.006331661
0.016027376
0.0
0.005583841
0.004189724
0.007566546
0.0063350787
0.0
0.009611407
0.0034434912
0.0
0.0104855355
0.0040197195
0.007935066
0.004066908
0.015516304
0.005963436
0.008533591
0.006681547
0.0051377905
0.0
0.004124011
0.0052869283
0.0028275766
0.00555338
0.00658429
0.0
0.0025218462
0.0057165613
0.003286562
0.012978948
0.008432367
0.008518394
0.009350415
0.009423394
0.0
0.009619747
0.008509421
0.0056457887
0.0044841277
0.004980708
0.005121095
0.003424663
0.0032006488
0.0020028548
0.0029771964
0.0
0.013904931
0.0071971337
0.0072224415
0.0
0.0063975323
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.991372     0.8875  0.645455  0.747368  0.682692  0.825581   

   Average Precision  
0           0.579852  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[17:32:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 2748.359 seconds
Cross-validation score: 0.8092396400398341
Test score: 0.788888888888889
Best Hyperparameters: {'classifier__min_child_weight': 5, 'classifier__max_depth': 18, 'classifier__learning_rate': 0.35, 'classifier__gamma': 0.4, 'classifier__colsample_bytree': 0.7}
0.010508213
0.030959463
0.026518738
0.023894196
0.05893999
0.0026570132
0.0034965123
0.0032822606
0.002899028
0.011138947
0.012611404
0.003056807
0.01048402
0.008602743
0.0032735984
0.0
0.003338229
0.0
0.029664204
0.006727206
0.012733511
0.013737637
0.004426276
0.01004465
0.005023296
0.0036322754
0.0058795176
0.021941932
0.0068972018
0.0043374435
0.009027243
0.0035287805
0.005237733
0.011877486
0.0016435427
0.0049645193
0.009159311
0.0025930544
0.003027494
0.00787249
0.0031961296
0.003262024
0.0011957942
0.0015534296
0.0052858125
0.0
0.0035326604
0.0063111004
0.0027268815
0.0076662973
0.012863585
0.0
0.0046569197
0.010150786
0.0
0.0075556017
0.0
0.0
0.0
0.002566215
0.0064111063
0.006224528
0.0
0.0017728889
0.0
0.00783765
0.004659847
0.0076444694
0.011981666
0.0
0.0068270857
0.0058248183
0.001779075
0.011107347
0.0074688517
0.0012946635
0.009907118
0.009224505
0.01905581
0.002985207
0.0074196076
0.005111657
0.0077923615
0.01484914
0.004426801
0.0
0.0027295228
0.0
0.0055700727
0.0087696
0.0
0.0
0.0025910342
0.004563614
0.009047133
0.0
0.0030240486
0.0050333724
0.005290633
0.0017733503
0.0053754025
0.009597128
0.006646593
0.0
0.008444588
0.013451886
0.007845332
0.0026069232
0.0
0.005549354
0.006250516
0.0
0.006094537
0.006028861
0.0023231183
0.0019535404
0.013331682
0.0052202432
0.0031940644
0.010004095
0.0063529825
0.0026463522
0.002992822
0.004521055
0.0057991464
0.0054368638
0.008531157
0.0
0.0072946167
0.0060195024
0.0023600715
0.01352945
0.011556966
0.011257876
0.0048333257
0.0075086327
0.021700697
0.009973817
0.0062731616
0.0
0.0051011457
0.0037275183
0.0041170917
0.002924154
0.0053492477
0.0022913623
0.0066114073
0.0
0.010155035
0.012385881
0.0064212712
0.0
0.0062496574
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1       F2      F0.5  \
0  0.990473   0.835294  0.645455  0.728205  0.67619  0.788889   

   Average Precision  
0           0.546155  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\sklearn\metrics\_plot\precision_recall_curve.py:125: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots()
C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[18:19:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 2820.776 seconds
Cross-validation score: 0.8133241311304966
Test score: 0.8128078817733991
Best Hyperparameters: {'classifier__min_child_weight': 1, 'classifier__max_depth': 18, 'classifier__learning_rate': 0.25, 'classifier__gamma': 0.0, 'classifier__colsample_bytree': 0.8}
0.013668871
0.024094045
0.026710426
0.02995366
0.04348303
0.0040726704
0.0047915317
0.0056798784
0.003516222
0.007725352
0.008238757
0.0035785963
0.015270295
0.0075233732
0.0020560785
0.002709351
0.004846509
0.0017069501
0.028820997
0.005785462
0.016266834
0.004967125
0.0050766696
0.009023599
0.010267925
0.0045782505
0.011707746
0.012304958
0.006223596
0.00784574
0.005830133
0.0044531934
0.0033034743
0.009488382
0.0041172635
0.0062457374
0.0036309918
0.0087174345
0.005613169
0.0024847272
0.00444605
0.008540428
0.00706136
0.005044955
0.0047384943
0.0
0.0077473177
0.008241473
0.002705147
0.0093837185
0.0053090956
0.009510556
0.0027506289
0.0072560934
0.0
0.008850511
0.0
0.0
0.0
0.0035862222
0.0068406938
0.004895654
0.013448664
0.0012699799
0.004861752
0.007541453
0.00068115216
0.0036574285
0.01020135
0.0060356483
0.013023927
0.0038034138
0.00575301
0.0052132416
0.008349075
0.009869073
0.0056154267
0.011540295
0.0066648526
0.0069459016
0.0027937854
0.005030039
0.007201478
0.003161639
0.0049209706
0.011562213
0.002604181
0.008692699
0.0060474062
0.004811317
0.004858551
0.0
0.0066074007
0.010181216
0.0039223297
0.0004156746
0.0051523806
0.0044500465
0.0066168867
0.00031976745
0.010774996
0.005058453
0.0059509925
0.0
0.002565594
0.0074380655
0.0057718097
0.008070364
0.0
0.0055996673
0.0067147017
0.0023853416
0.013338273
0.005408855
0.0069406345
0.004861464
0.017762793
0.0033197843
0.010762452
0.0026756271
0.0034253548
0.0024245002
0.0024994297
0.0042019323
0.0047343182
0.0041988366
0.0034272524
0.0041752914
0.002806897
0.0065483376
0.0
0.014005528
0.0040565957
0.010154835
0.004067292
0.0044971933
0.0007533839
0.008814459
0.0023605858
0.0004311953
0.004173553
0.0053550056
0.0032016903
0.0061976556
0.0049527064
0.006573362
0.005546071
0.0
0.008739133
0.00061990216
0.007392604
0.0
0.017152242
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision  Recall        F1        F2      F0.5  \
0  0.990653   0.891892     0.6  0.717391  0.642023  0.812808   

   Average Precision  
0           0.543045  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[19:08:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 2893.275 seconds
Cross-validation score: 0.8181930376447537
Test score: 0.7579185520361992
Best Hyperparameters: {'classifier__min_child_weight': 10, 'classifier__max_depth': 20, 'classifier__learning_rate': 0.45, 'classifier__gamma': 0.2, 'classifier__colsample_bytree': 0.5}
0.007001803
0.029528726
0.025886156
0.021863613
0.031833477
0.0054060793
0.005412773
0.0064031687
0.008389911
0.016638415
0.0
0.008807266
0.014350812
0.013392406
0.004661425
0.0
0.0038166398
0.0
0.04505394
0.0037813296
0.017381303
0.004258949
0.003231218
0.011277709
0.00400184
0.005388718
0.008420665
0.0120293265
0.0033699854
0.0005119023
0.0
0.0
0.0032959066
0.016999623
0.0033588754
0.006108839
0.018576628
0.0048285974
0.0073405886
0.004366429
0.0026076422
0.009211034
0.0010217511
0.0025515894
0.0069966908
0.0
0.0066166245
0.004071217
0.0
0.007917932
0.020445438
0.0
0.0055679255
0.0045218966
0.0
0.00897556
0.0
0.0
0.0
0.005021843
0.003747279
0.0032509502
0.0
0.0
0.0023254682
0.010994798
0.0
0.012773928
0.006132681
0.0072131925
0.005131188
0.009246272
0.006145602
0.0
0.008594054
0.0
0.027501982
0.013101605
0.016569309
0.009195582
0.0035580806
0.003018072
0.005288814
0.015118552
0.003437897
0.009605832
0.0013444542
0.0
0.002619613
0.015687738
0.004363744
0.0
0.0027457788
0.01713919
0.00432268
0.008075007
0.0030158584
0.0048407344
0.0038998036
0.0
0.008372933
0.0034849965
0.0063637327
0.0
0.004889194
0.008246321
0.00472461
0.0055942805
0.0
0.0115374345
0.0
0.0015386629
0.011658693
0.006732332
0.0055168555
0.0040591476
0.013779941
0.0030972047
0.0040022107
0.003198854
0.0095190955
0.006446257
0.0025470536
0.0032900942
0.002228809
0.0040471423
0.00717266
0.00063158514
0.0
0.008102535
0.004610757
0.008109447
0.0066379737
0.02843756
0.001290258
0.015288486
0.0013257142
0.011486296
0.0029880751
0.0012099926
0.0038384332
0.0010710164
0.0042724293
0.0034859353
0.0017604056
0.0026817347
0.00824776
0.0
0.004589507
0.0039272504
0.009512013
0.0
0.0019383559
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.989394   0.807229  0.609091  0.694301  0.640535  0.757919   

   Average Precision  
0           0.499405  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[20:00:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 3156.181 seconds
Cross-validation score: 0.8208297113176439
Test score: 0.7467532467532467
Best Hyperparameters: {'classifier__min_child_weight': 2, 'classifier__max_depth': 18, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0.3, 'classifier__colsample_bytree': 0.6}
0.0119527085
0.020861316
0.023214217
0.021800235
0.03263546
0.0039420947
0.004857193
0.004725506
0.0049722074
0.015031428
0.006693743
0.0025907692
0.012026483
0.007472898
0.017242119
0.0036727223
0.0029323755
0.0028686675
0.024576422
0.008685138
0.016985817
0.008717684
0.003997841
0.007031325
0.0028607938
0.0020795846
0.0062000067
0.01777234
0.0069340756
0.0040415917
0.0073748035
0.0032057553
0.005479936
0.010279075
0.00555544
0.0036550588
0.009969497
0.0034029633
0.005198101
0.0026332773
0.0032180252
0.0071624103
0.0040862835
0.0016260532
0.011305251
0.0
0.0069952155
0.00492257
0.0035316977
0.008496646
0.0039452147
0.007502134
0.0045763683
0.006740774
0.0
0.015430463
0.0
0.0
0.0
0.0044780276
0.0047169942
0.0057322835
0.010252859
0.0
0.003870972
0.005614818
0.009837345
0.0043982
0.006990827
0.002493989
0.004419356
0.0022772239
0.005836549
0.0043754554
0.011365506
0.0034042387
0.005497626
0.013259859
0.006033468
0.0049811923
0.004589023
0.00419069
0.005411504
0.0114804115
0.003893461
0.005484604
0.007780987
0.0015442047
0.007637789
0.002283534
0.012415779
0.0
0.006090778
0.0057202224
0.0066866074
0.013387165
0.0061680446
0.0066452846
0.0056897015
0.0
0.005046354
0.009139337
0.009914725
0.0
0.0042712046
0.0051734396
0.005127197
0.008056049
0.007155619
0.0051332396
0.0038513152
0.0073730354
0.009210333
0.0059741274
0.0033697095
0.011907854
0.012080909
0.0040977257
0.009117803
0.0059518903
0.0067541366
0.00869139
0.0041081654
0.0042973724
0.0027946078
0.0037683381
0.00395943
0.0017136337
0.007658368
0.0053671324
0.0050321035
0.013750698
0.008088708
0.016780896
0.0067440392
0.005759921
0.0024035955
0.004754242
0.0037002503
0.008485799
0.0056686252
0.0074780015
0.004326262
0.004227252
0.0045144656
0.002484367
0.0034840573
0.0
0.0022901855
0.0036106312
0.0033176816
0.004211018
0.0052183853
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall       F1        F2      F0.5  \
0  0.989214   0.784091  0.627273  0.69697  0.653409  0.746753   

   Average Precision  
0           0.499209  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[20:52:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 3106.452 seconds
Cross-validation score: 0.802910608364025
Test score: 0.8419689119170983
Best Hyperparameters: {'classifier__min_child_weight': 1, 'classifier__max_depth': 16, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0.1, 'classifier__colsample_bytree': 0.5}
0.009145286
0.02572447
0.025314769
0.030352633
0.032216225
0.005877871
0.0034953766
0.0053515835
0.004679056
0.007030607
0.0060351663
0.004359223
0.0104267495
0.0107918475
0.010730094
0.0077398494
0.0033679989
0.0029676124
0.021917164
0.009810625
0.013973485
0.011354522
0.0047085104
0.005574969
0.0044163372
0.006046883
0.011894108
0.009534819
0.009187925
0.006964759
0.0051580747
0.001992552
0.0038229849
0.01332065
0.0029429574
0.004520185
0.010609981
0.0040073292
0.0043905424
0.003441177
0.004879623
0.0073167286
0.0020089697
0.006484129
0.0059564114
0.0
0.006140955
0.0052471687
0.0
0.008661747
0.0067237294
0.0
0.0038527015
0.006325701
0.0
0.00977359
0.0
0.0
0.0
0.004329064
0.004649758
0.0065752654
0.0035394726
0.0056802365
0.0037142641
0.0029402866
0.0
0.005772995
0.00401547
0.0067255134
0.009625419
0.0086613195
0.0020243048
0.0023171008
0.008159711
0.004787406
0.009074101
0.008621664
0.0076742615
0.00538932
0.005268582
0.0028294572
0.0054549365
0.0053598154
0.003554755
0.0064553353
0.0054322607
0.001891996
0.005577353
0.004332625
0.015016573
0.0
0.0060527558
0.0033683986
0.005833629
0.007822158
0.012108491
0.0029925073
0.009322521
0.001688733
0.0055125933
0.01195887
0.012812548
0.007964934
0.004959369
0.0067153573
0.0044702357
0.004666256
0.0045426553
0.009123907
0.0033883187
0.001643316
0.00930016
0.005154482
0.011407222
0.007074792
0.01256844
0.0036300095
0.00754754
0.004487841
0.004564697
0.005386769
0.0060106493
0.004614015
0.0021038742
0.00576253
0.011352022
0.0038465261
0.0018002496
0.0074827746
0.0038633447
0.012546148
0.009363864
0.014602014
0.0031419552
0.0067764344
0.0052621905
0.006178437
0.00688475
0.0011496962
0.004312676
0.0051533584
0.005468253
0.0056948448
0.006956676
0.0048193457
0.0050764703
0.0
0.0056970143
0.0035614928
0.010896897
0.0
0.0075329584
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.991192   0.942029  0.590909  0.726257  0.638507  0.841969   

   Average Precision  
0           0.564743  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[21:45:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 3169.321 seconds
Cross-validation score: 0.8066879186809512
Test score: 0.7906976744186046
Best Hyperparameters: {'classifier__min_child_weight': 3, 'classifier__max_depth': 12, 'classifier__learning_rate': 0.15, 'classifier__gamma': 0.2, 'classifier__colsample_bytree': 0.4}
0.01115749
0.02091157
0.029399756
0.029660184
0.033256643
0.0030882622
0.0061015477
0.0042154947
0.004935473
0.013782011
0.009933569
0.002845919
0.012571195
0.006541235
0.008208771
0.0032494084
0.0043504825
0.0042564753
0.018546222
0.018534612
0.018404817
0.009212105
0.006040706
0.0046725837
0.0053339633
0.004683081
0.014233388
0.014467984
0.006300804
0.0062129754
0.004098904
0.0077356803
0.0050969063
0.010454689
0.0044325283
0.0074471137
0.004601197
0.004168451
0.0056662047
0.0069922893
0.002745246
0.0071159927
0.003746105
0.002409414
0.00754206
0.0
0.004956172
0.0053300895
0.0026742038
0.0061022774
0.0054585678
0.0
0.0033956605
0.004134105
0.0
0.010381161
0.0
0.0
0.0
0.00420498
0.006048569
0.0028682097
0.004304639
0.008549785
0.005249248
0.009791014
0.0
0.0056409314
0.007524414
0.000980616
0.0040146457
0.005497969
0.0038310334
0.002323229
0.0040285317
0.004495774
0.007977354
0.007276619
0.0063366233
0.0064145927
0.005193782
0.0037960925
0.0061537437
0.0052885357
0.0038288157
0.010200482
0.0057691024
0.0018821694
0.0059959064
0.0040571433
0.008039535
0.0
0.0047976645
0.005350537
0.006517103
0.008166848
0.0031969757
0.004008275
0.0075873598
0.0016354704
0.007114099
0.010602441
0.0062626367
0.009999704
0.0056750416
0.007836915
0.0062201596
0.006870873
0.014278163
0.007584892
0.007877602
0.0016213591
0.006331217
0.0040853783
0.0044532362
0.0065135946
0.011111096
0.0066497074
0.0045346012
0.0066021215
0.0084897075
0.006484544
0.0026516418
0.003640667
0.0030981533
0.003106854
0.006168675
0.003632428
0.0083821835
0.00568487
0.0025110093
0.017311718
0.006440139
0.00899594
0.0031949596
0.008042004
0.00893243
0.008601575
0.00749594
0.010145489
0.0037505045
0.0039958153
0.0039575323
0.0026295925
0.0048705125
0.0043298765
0.007902348
0.0
0.004379219
0.006935624
0.0074265026
0.0
0.0039685722
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.990293       0.85  0.618182  0.715789  0.653846  0.790698   

   Average Precision  
0           0.533004  

--------------------------------------------------------------------

C:\Users\Randell\AppData\Local\Programs\Python\Python39\lib\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[22:31:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 2785.200 seconds
Cross-validation score: 0.8222487818617614
Test score: 0.7458563535911603
Best Hyperparameters: {'classifier__min_child_weight': 2, 'classifier__max_depth': 10, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0.2, 'classifier__colsample_bytree': 0.4}
0.006872763
0.021638246
0.030360008
0.030517798
0.030550757
0.0043116044
0.0060479445
0.0044634333
0.004311961
0.011728682
0.007992615
0.00299654
0.01212462
0.009500882
0.0047934484
0.011019822
0.006100105
0.006678097
0.017794447
0.010371351
0.019240763
0.012364347
0.0043549137
0.0073463484
0.004658727
0.004256892
0.0139593035
0.013929691
0.0053487816
0.006747692
0.0049703047
0.0025895436
0.004550426
0.012792013
0.003404931
0.008514227
0.009960557
0.0059436327
0.0039942185
0.004251176
0.003010211
0.004866173
0.0027628806
0.0033446774
0.008029073
0.0
0.005341075
0.010443289
0.0028545698
0.0051070913
0.0049761175
0.0
0.0040070605
0.005440978
0.0
0.012964732
0.0
0.0
0.0
0.005157391
0.005111567
0.0064120204
0.004562152
0.0024066821
0.006445931
0.0077354717
0.0
0.0056464756
0.0075711883
0.0043586125
0.0044210344
0.0060446095
0.004260803
0.005155761
0.0063257525
0.0017494714
0.009493798
0.009031624
0.005272195
0.0068528377
0.0037094264
0.00446608
0.005721414
0.0064476426
0.0025766247
0.013594658
0.0065434477
0.0020239705
0.0048956075
0.006174343
0.015439083
0.0
0.0040586
0.007638194
0.0043806396
0.01081158
0.0036655138
0.011565597
0.006931484
0.0025074498
0.0039820606
0.0139110815
0.008341527
0.0065097786
0.0049658525
0.004935919
0.005027834
0.0024509628
0.0
0.005977932
0.0061876434
0.0031141378
0.006973374
0.0069571123
0.009247313
0.006200773
0.01567531
0.0057453834
0.0041809543
0.004410851
0.0041187806
0.0058531673
0.005160424
0.0037848994
0.0049468363
0.0027037836
0.006636609
0.0038838952
0.0023421077
0.007296785
0.0015858873
0.012251788
0.0039300867
0.013779367
0.0059820767
0.009220278
0.0025132769
0.009197701
0.0038389233
0.0062531773
0.0044988897
0.0035689268
0.0054305983
0.0030672508
0.0029649057
0.004125835
0.0057853274
0.0
0.006357916
0.0025719323
0.0073839705
0.00437556
0.0061249863
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.988316   0.857143  0.490909  0.624277  0.536779  0.745856   

   Average Precision  
0           0.430846  