[01:15:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 8471.333 seconds
Cross-validation score: 0.7833620933188874
Test score: 0.7072368421052632
Best Hyperparameters: {'classifier__min_child_weight': 7, 'classifier__max_depth': 18, 'classifier__learning_rate': 0.3, 'classifier__gamma': 0.0, 'classifier__colsample_bytree': 0.9}
0.007280717
0.041686777
0.027852166
0.016497051
0.0097696
0.008066642
0.0072750985
0.0058377245
0.009053997
0.0052577625
0.0
0.0008380786
0.01325456
0.015686767
0.008522397
1.23353075e-05
0.0042417995
0.0
0.0039154734
0.006982486
0.019714026
0.019385207
0.0018829379
0.016075797
0.0071822857
0.0055115162
0.0054344647
0.012059351
0.005032682
0.0065225535
0.016567206
0.0025064505
0.008061099
0.01148023
0.008216956
0.010091164
0.004260234
0.006304669
0.0034403026
0.002983664
0.0029863904
0.0
0.0
0.0
0.011646357
0.0
0.0096064145
0.008492519
0.004817133
0.004780336
0.007941851
0.0
0.006396848
0.0063579427
0.0
0.0067542796
0.0
0.0
0.0
0.00470965
0.0032146005
0.0048274617
0.026641622
0.03159824
0.005600339
0.0026895527
0.0064514335
0.006600603
0.0077827326
0.007269003
0.005267
0.008981432
0.0018002382
0.005544709
0.0030364662
0.0021451407
0.007405022
0.002119441
0.002199579
0.016000902
0.0022789245
0.0039604567
0.0067560608
0.0027440842
0.0027554578
0.006047348
0.007851798
0.0
0.0040737814
0.017750403
0.0040655434
0.0
0.007194573
0.005251771
0.005092194
0.003031294
0.010239344
0.004479904
0.007846874
0.0
0.00231075
0.0089451475
0.0076454524
0.0
0.01154059
0.0065744463
0.0053150975
0.0024590506
0.003988714
0.006344783
0.009619004
0.015205679
0.01210565
0.004802991
0.005122083
0.004756283
0.004515786
0.0038312734
0.0070496625
0.0013630628
0.0048938245
0.0
0.003679075
0.0031767476
0.001746894
0.0055703986
0.0062010684
0.0033030862
0.006076161
0.00892386
0.0
0.005325724
0.008853717
0.0
0.0064760223
0.0108267795
0.0
0.011610628
0.0074279676
0.0
0.0037930233
0.0030838938
0.0050542
0.0045008534
0.009878763
0.008974399
0.013412941
0.0
0.008669705
0.008537716
0.0047513493
0.006113277
0.00781315
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0   0.99703   0.781818  0.511905  0.618705  0.549872  0.707237   

   Average Precision  
0           0.402514  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[03:36:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 8487.585 seconds
Cross-validation score: 0.7713465721923385
Test score: 0.8390410958904111
Best Hyperparameters: {'classifier__min_child_weight': 5, 'classifier__max_depth': 8, 'classifier__learning_rate': 0.15, 'classifier__gamma': 0.2, 'classifier__colsample_bytree': 0.7}
0.008659615
0.027166463
0.019998204
0.01599541
0.012194455
0.006677474
0.008719269
0.0105691925
0.005321285
0.003933833
0.0058335057
0.0061221616
0.007665669
0.010816731
0.0058671813
0.010296229
0.0031497402
0.0
0.0033860877
0.0032017056
0.018626852
0.023607137
0.0043178746
0.007835155
0.0054748273
0.00466907
0.0035874234
0.007808039
0.010245838
0.0
0.0076840003
0.008172436
0.0025573263
0.010299102
0.0031651645
0.0040567475
0.0041189273
0.0070580235
0.003734847
0.0021538557
0.004933972
0.0060220207
0.0
0.006324531
0.007429609
0.0
0.0062525435
0.006301261
0.0044228495
0.006294318
0.004147327
0.024468364
0.0048656557
0.007547121
0.0
0.004762815
0.0
0.0
0.0
0.003625743
0.0027981857
0.0033655146
0.0025090326
0.0032378144
0.005843345
0.014696473
0.0064968653
0.0038377594
0.005270373
0.0051374254
0.0088407
0.006757487
0.0045006964
0.009864647
0.004183752
0.0028133658
0.0058123874
0.0035733823
0.0038489348
0.0029396547
0.0034114704
0.0034665663
0.0036343012
0.034489293
0.00461747
0.0063893716
0.0044810195
0.0
0.0042949715
0.0068292413
0.0057950784
0.019567188
0.0056455988
0.004979184
0.006087744
0.007867933
0.004746701
0.003470558
0.003990019
0.0031238107
0.003583337
0.0087936595
0.006967843
0.008642824
0.008890946
0.0064323624
0.0028806177
0.0046907132
0.0077151977
0.006510943
0.0074704452
0.008539853
0.0045850794
0.0028169677
0.010431665
0.0051339706
0.006830943
0.017504323
0.0077451267
0.00550214
0.003808135
0.013665755
0.004595222
0.0037565294
0.0043252963
0.0035167574
0.003594735
0.0023901109
0.010350477
0.008353519
0.0032890541
0.004825668
0.009341835
0.0039251666
0.013363758
0.008307967
0.015221788
0.0055929204
0.0059478753
0.0027295088
0.003252475
0.0038524587
0.0036241973
0.0063758073
0.005512086
0.0068212724
0.0049963384
0.011411903
0.0051633236
0.0022095668
0.005502146
0.0
0.005913984
0.0074330885
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997871   0.942308  0.583333  0.720588  0.631443  0.839041   

   Average Precision  
0           0.551641  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[06:05:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 8905.164 seconds
Cross-validation score: 0.7888632196344991
Test score: 0.7730263157894737
Best Hyperparameters: {'classifier__min_child_weight': 4, 'classifier__max_depth': 14, 'classifier__learning_rate': 0.25, 'classifier__gamma': 0.7, 'classifier__colsample_bytree': 0.5}
0.009267083
0.030386182
0.024932817
0.015979929
0.014383674
0.005627799
0.0024471704
0.009954823
0.006700904
0.0035406773
0.0033662103
0.006689563
0.01011042
0.009662398
0.008000495
0.011350679
0.0058014644
0.0
0.0039021382
0.0026939765
0.018405084
0.026484935
0.0045649293
0.005641298
0.0070522283
0.003145235
0.0069024996
0.005225219
0.0070872344
0.00816151
0.009409502
0.0038857798
0.0038316317
0.008572823
0.0028735916
0.009131308
0.00992278
0.0061683487
0.003381446
0.0020549786
0.004020428
0.0047310316
0.0037626396
0.003622359
0.008551021
0.0
0.008549721
0.0058645364
0.0
0.003662977
0.003383457
0.0021347764
0.01108649
0.0059375074
0.0066836705
0.007301248
0.0
0.0
0.0
0.005389522
0.0028129236
0.0023311444
0.008191555
0.004844307
0.00791511
0.00846587
0.0051911795
0.005770018
0.0051445523
0.0073150815
0.003500169
0.0040105428
0.020719146
0.012399428
0.0065341764
0.014706156
0.0061146743
0.0045513567
0.006137
0.0042354115
0.0033348876
0.005381102
0.0054010046
0.0
0.0033676787
0.008532642
0.008615528
0.0
0.003431299
0.011154243
0.009556885
0.0041886815
0.0031863884
0.008096155
0.007681417
0.004360985
0.009532974
0.005406518
0.0067852098
0.0015299448
0.004205636
0.0067232344
0.00688748
0.0
0.011499213
0.005569316
0.0032413946
0.0043153567
0.008968718
0.004871361
0.004685186
0.014169811
0.005310694
0.0040783803
0.005568762
0.008051151
0.01100295
0.009304687
0.007890927
0.0050054844
0.0034662208
0.006476662
0.002521789
0.005439092
0.0022915332
0.0024787767
0.0081697665
0.0
0.0045558256
0.0077023674
0.003912939
0.0032425635
0.008338313
0.0070065684
0.011449644
0.011116657
0.012756935
0.006937171
0.005639925
0.00484632
0.0020076246
0.006670534
0.00527823
0.0028542785
0.0038908168
0.0056704013
0.0040555447
0.003526368
0.0064010387
0.0052347276
0.007467041
0.017814726
0.003767162
0.003847201
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997479   0.854545  0.559524  0.676259  0.601023  0.773026   

   Average Precision  
0           0.480212  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[08:31:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 8778.735 seconds
Cross-validation score: 0.792540098301723
Test score: 0.75
Best Hyperparameters: {'classifier__min_child_weight': 1, 'classifier__max_depth': 20, 'classifier__learning_rate': 0.3, 'classifier__gamma': 0.8, 'classifier__colsample_bytree': 0.8}
0.009911005
0.020556346
0.020919744
0.012127352
0.008803631
0.005405917
0.005710495
0.0060160737
0.0041575036
0.0049362876
0.0044472185
0.0048464173
0.0065203183
0.010626481
0.012673164
0.007977356
0.004096777
0.0
0.0034917109
0.004362802
0.0146500645
0.027261578
0.0068282667
0.005931465
0.0032619855
0.006950049
0.0028810445
0.009333834
0.005634864
0.011239546
0.01394568
0.006381712
0.0052353656
0.005159614
0.0027694006
0.0095984265
0.0
0.0070278323
0.0038550983
0.0061233584
0.0030150195
0.004122751
0.0
0.00170939
0.0072191088
0.0
0.006425826
0.0074262717
0.0
0.008480155
0.0069710747
0.0
0.010873093
0.005395158
0.009617228
0.004568674
0.0
0.0
0.0
0.005621084
0.005127277
0.005170313
0.026184829
0.004944749
0.006208305
0.011158731
0.0025585075
0.0030380613
0.005391498
0.013967152
0.008220165
0.01021963
0.0118747465
0.00773131
0.0055621904
0.0035131737
0.00497126
0.0057282187
0.0047390885
0.0036956628
0.0043079276
0.0027448086
0.0056377095
0.0
0.0042935894
0.0061307326
0.0045631295
0.017315116
0.0060794335
0.004450208
0.005646702
0.0
0.008246462
0.0064697377
0.0063682883
0.006169201
0.0057024453
0.0035479686
0.0026389991
0.006084649
0.0026658364
0.0054087425
0.0034673791
0.0
0.006122437
0.0044882386
0.003642453
0.004994865
0.0012339844
0.0073533463
0.010950664
0.006346652
0.005441023
0.00510683
0.0038195192
0.0032489756
0.005181956
0.048706528
0.005747439
0.0059747687
0.0014141081
0.0
0.004339241
0.004437447
0.0
0.0022700334
0.0055993935
0.0076180315
0.0022393093
0.006309049
0.0
0.0056108553
0.003476571
0.0
0.01854195
0.014346248
0.039554052
0.009530279
0.006521758
0.0
0.0036584672
0.0029324833
0.003854359
0.0044010463
0.008514594
0.005988236
0.005411469
0.005154566
0.007048903
0.003428532
0.015009342
0.0
0.00411677
0.009268742
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2  F0.5  Average Precision
0  0.997367   0.813559  0.571429  0.671329  0.607595  0.75           0.466908

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[10:57:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 8782.198 seconds
Cross-validation score: 0.7948640499193699
Test score: 0.7922535211267605
Best Hyperparameters: {'classifier__min_child_weight': 2, 'classifier__max_depth': 14, 'classifier__learning_rate': 0.25, 'classifier__gamma': 0.0, 'classifier__colsample_bytree': 0.8}
0.007938858
0.02728556
0.021699
0.019632893
0.008276821
0.004383785
0.006262849
0.0063729235
0.006221864
0.0063332017
0.0016690494
0.008996018
0.010703477
0.01090881
0.010421402
0.008261508
0.0034632266
0.0
0.0055566835
0.004219075
0.014707587
0.022475082
0.0051948708
0.014616059
0.005119604
0.0058341026
0.0028383685
0.00885157
0.011222005
0.008821832
0.0121699665
0.0043460433
0.006348771
0.006167463
0.003964015
0.004623367
0.0045457226
0.0060708136
0.002016189
0.00202092
0.00471135
0.0022291255
0.0017754184
0.0028513237
0.011712816
0.0
0.008337629
0.007305721
0.009809153
0.0025614402
0.007012096
0.02950512
0.0040847887
0.008394362
0.0
0.0022523724
0.0
0.0
0.0
0.0031493974
0.0044046217
0.0026841986
0.0076547693
0.006007907
0.0065341424
0.010007716
0.0058824616
0.0034935935
0.0048267483
0.0018914855
0.0026126516
0.012111226
0.011403521
0.006137095
0.009407351
0.007315768
0.009899423
0.005023412
0.0029150497
0.003172876
0.0033072599
0.0032495253
0.0028434375
0.0
0.005126824
0.008532221
0.0052333823
0.0040632193
0.006511507
0.0056921137
0.0056829844
0.008178762
0.0028176156
0.008398092
0.0056402865
0.005106657
0.006809599
0.0032903212
0.006122226
0.00053978915
0.008969519
0.005249224
0.005464004
0.0
0.008359197
0.005338476
0.0021344344
0.015044447
0.011089564
0.009110286
0.007713852
0.01530359
0.007902492
0.0030830568
0.0034869649
0.0048057176
0.0058518965
0.0048435386
0.011449652
0.005646938
0.0060370336
0.022491943
0.0016543568
0.0059037725
0.0024453753
0.005935445
0.0050770096
3.6516343e-05
0.014938271
0.0054957788
0.0
0.007784696
0.009390235
0.0019196548
0.01730517
0.0070958524
0.011541704
0.0032505048
0.0051971604
0.0
0.001515181
0.0038512163
0.0034183648
0.004130028
0.0019093517
0.006813324
0.0062161293
0.0040428285
0.0047091655
0.006983687
0.0052311905
0.0
0.006348584
0.01369834
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997535        0.9  0.535714  0.671642  0.582902  0.792254   

   Average Precision  
0           0.484328  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[13:25:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 8849.157 seconds
Cross-validation score: 0.8019391457514597
Test score: 0.7203389830508474
Best Hyperparameters: {'classifier__min_child_weight': 1, 'classifier__max_depth': 20, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0.9, 'classifier__colsample_bytree': 0.5}
0.008120919
0.023514811
0.018032162
0.017383799
0.008927863
0.005672109
0.0053574364
0.005429776
0.005449633
0.005608084
0.015621999
0.004046272
0.008642891
0.0058761686
0.005289851
0.0051340126
0.00545163
0.0035363666
0.006747632
0.00352791
0.0151685765
0.013810962
0.0042875037
0.006549168
0.004191674
0.0083327945
0.006688347
0.0070507512
0.008058984
0.010191552
0.009225887
0.005237431
0.0033497529
0.0044301623
0.0055313986
0.0055114087
0.00482814
0.0065040356
0.0035944947
0.0041592354
0.0047926917
0.0034317859
0.0046958243
0.005055696
0.008372895
0.0
0.009641276
0.0092977425
0.029070832
0.006787802
0.0062382235
0.005575943
0.0075477366
0.0069863135
0.0
0.005171539
0.0
0.0
0.0
0.0038539148
0.0035345478
0.003203887
0.005344896
0.0070084124
0.006708481
0.005565426
0.0036724769
0.0053867735
0.00633327
0.005585586
0.0032804382
0.009123563
0.00519516
0.009436166
0.0058067446
0.011478691
0.007854993
0.004413842
0.006421233
0.0076520415
0.0026268775
0.0041885064
0.0048002214
0.0011871302
0.0059993733
0.0060324264
0.008747208
0.0
0.00563819
0.0050849933
0.006383583
0.0073074265
0.0047461824
0.005961659
0.007560609
0.009732187
0.006097948
0.0047298647
0.0041691326
0.006644769
0.01182818
0.005541466
0.0058183447
0.013171469
0.004766523
0.0042938264
0.004858555
0.0041051917
0.005083208
0.008358911
0.0065968456
0.010856336
0.006033001
0.005045703
0.006582057
0.005483057
0.0050561056
0.0038223518
0.0066352445
0.003572831
0.0066993125
0.007472482
0.0032078698
0.0038808074
0.0044664973
0.0064687887
0.0051666065
0.00096947054
0.0024297752
0.009171631
0.0066075795
0.0035380994
0.011924332
0.006898285
0.01255273
0.0072833393
0.011699775
0.012675442
0.0048735333
0.009504536
0.0042952816
0.0038479497
0.0035771597
0.0049550394
0.003074346
0.008485777
0.004544049
0.004289021
0.00451046
0.009246076
0.0066641285
0.0
0.008904124
0.017367808
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.996974   0.894737  0.404762  0.557377  0.454545  0.720339   

   Average Precision  
0           0.364957  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[15:56:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 9052.973 seconds
Cross-validation score: 0.7931839833283132
Test score: 0.7291666666666666
Best Hyperparameters: {'classifier__min_child_weight': 8, 'classifier__max_depth': 18, 'classifier__learning_rate': 0.35, 'classifier__gamma': 0.7, 'classifier__colsample_bytree': 0.5}
0.008284535
0.035476897
0.02491553
0.01811944
0.017181536
0.0055334577
0.0026817282
0.0049653645
0.0073106773
0.018058864
0.00070555875
0.0010075531
0.012680965
0.009899891
0.008143806
0.00569666
0.0032231298
0.0
0.008880161
0.0047936053
0.035560165
0.017545352
0.007547204
0.009273629
0.0011422806
0.0041447477
0.005030844
0.011074738
0.0137063945
0.0
0.015168367
0.0062723
0.0067974427
0.0073798243
0.0028280586
0.0045936345
0.010286351
0.006783309
0.003091234
0.0052728453
0.0060669426
0.004596323
0.0025946267
0.0067503396
0.0054350467
0.0
0.011638738
0.006455244
0.0023693813
0.0019338117
0.0060998234
0.0
0.012132478
0.005534406
0.0
0.0046736365
0.0
0.0
0.0
0.0037775852
0.0016203533
0.0023232559
0.0054006204
0.00085476605
0.0044292533
0.008413177
0.0062473686
0.004644809
0.0045716274
0.0037724613
0.0064379014
0.0036305727
0.0060919602
0.0127722435
0.015696328
0.009719562
0.0114408
0.0055141407
0.004461535
0.0015637918
0.006059798
0.003983571
0.0036757493
0.0
0.0048524374
0.004157785
0.004330465
0.0029811226
0.0069675767
0.0040464327
0.0065092854
0.013431612
0.0039386945
0.0059131393
0.009348065
0.0039563514
0.0050908416
0.007310306
0.0037179587
0.0
0.004364074
0.009018049
0.007354635
0.007683486
0.016041417
0.0027335493
0.0030704415
0.014598093
0.005950813
0.007872164
0.009918754
0.008034051
0.011676582
0.0035209688
0.0033979972
0.008190242
0.0049995286
0.0023295686
0.012633513
0.013514654
0.0029775293
0.0055260723
0.0047530066
0.0040314314
0.0037550824
0.0013552413
0.0021599203
0.0
0.012614274
0.0055603404
0.0075190593
0.008089176
0.0065752184
0.006918368
0.01783158
0.011599377
0.0015277783
0.006520251
0.004332792
0.0
0.0050741313
0.0048109996
0.0030166097
0.0049952595
0.004575926
0.004063551
0.006282505
0.0
0.0061471043
0.0014050222
0.002726685
0.0
0.015358956
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision  Recall        F1        F2      F0.5  \
0  0.997142   0.823529     0.5  0.622222  0.542636  0.729167   

   Average Precision  
0           0.414118  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\sklearn\metrics\_plot\precision_recall_curve.py:125: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  fig, ax = plt.subplots()
C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[18:35:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 9555.235 seconds
Cross-validation score: 0.7758640096480294
Test score: 0.7954545454545454
Best Hyperparameters: {'classifier__min_child_weight': 1, 'classifier__max_depth': 18, 'classifier__learning_rate': 0.2, 'classifier__gamma': 0.1, 'classifier__colsample_bytree': 1.0}
0.010662721
0.0334784
0.025855303
0.01855153
0.01557516
0.0052173035
0.0036888137
0.0069871377
0.0041657262
0.0083979815
0.011509899
0.0043396973
0.012709492
0.013545602
0.00847265
0.0
0.004852821
0.0
0.003561966
0.0035012064
0.021724613
0.03039302
0.005345357
0.010553884
0.010349866
0.0022486884
0.0034232994
0.004641242
0.005657762
0.009200083
0.006920764
0.007038082
0.004618556
0.0066845324
0.008672367
0.0062299776
0.0038761224
0.0053592864
0.0039962204
0.003763977
0.007885281
0.0
0.0
0.0
0.008075459
0.003423384
0.0056774733
0.007769872
0.0026160409
0.007556661
0.0032056666
0.0
0.007760429
0.0063643996
0.016554521
0.007276045
0.0
0.0
0.0
0.0024485488
0.0049513844
0.003364952
0.009299683
0.0040698242
0.008503384
0.005644128
0.006405566
0.007614109
0.0032530364
0.007875717
0.0025643941
0.0070368666
0.022156538
0.004444739
0.009066614
0.020279432
0.011760698
0.008122428
0.0058053983
0.010857694
0.0060838703
0.0066424552
0.0069099413
0.002811693
0.0048656277
0.005567668
0.0067601027
0.001767828
0.0036384263
0.0052199312
0.0070621497
0.001498494
0.0039549265
0.0097473245
0.0069912123
0.008976327
0.009525259
0.0019366124
0.01753617
0.008354921
0.0056620734
0.006698148
0.015385418
0.00053405826
0.007008964
0.006643796
0.0035918467
0.0041982047
0.006822632
0.0067696385
0.010287608
0.0046241744
0.004725254
0.0053482214
0.0039775497
0.0053007184
0.006606176
0.005485456
0.008855455
0.01118275
0.0036699995
0.0
0.0021820583
0.0057882587
0.0
0.00426146
0.0045357356
0.0
0.0
0.0071154083
0.0
0.0070302733
0.0070595066
0.0
0.00720003
0.0070276074
0.0
0.0054183262
0.0041444604
0.0
0.0053339466
0.0068274057
0.003926095
0.0045708064
0.003927388
0.0027872287
0.0032821135
0.0020122887
0.0047056735
0.010964706
0.008229823
0.0
0.009792047
0.007186779
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall   F1     F2      F0.5  Average Precision
0  0.997647      0.875  0.583333  0.7  0.625  0.795455           0.512378

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[21:00:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 8701.661 seconds
Cross-validation score: 0.783932590006719
Test score: 0.76171875
Best Hyperparameters: {'classifier__min_child_weight': 4, 'classifier__max_depth': 6, 'classifier__learning_rate': 0.35, 'classifier__gamma': 0.7, 'classifier__colsample_bytree': 0.7}
0.011269675
0.029801797
0.02574557
0.014747313
0.017809259
0.006181701
0.0057095285
0.004752855
0.0036842944
0.0046562925
0.005374431
0.0007868106
0.007973659
0.010414925
0.006153122
0.009378512
0.00200522
0.0
0.0034910596
0.0027774938
0.022358058
0.014212754
0.0030105903
0.010183511
0.0035900832
0.0024995392
0.011707173
0.009117629
0.0085839275
0.0
0.022764785
0.0
0.0097674215
0.0059144543
0.004015669
0.0037866675
0.0019324839
0.013840982
0.0080237575
0.011305044
0.002966615
0.0050904993
0.0
0.0025808779
0.0037516123
0.0
0.0077879294
0.0066975397
0.0
0.00423064
0.015591424
0.006414808
0.0019731906
0.014355064
0.0
0.003901417
0.0
0.0
0.0
0.0033502327
0.0037229098
0.0036576318
0.0074347635
0.0021422508
0.0051061125
0.0051018684
0.009049897
0.007182082
0.0032917876
0.0
0.008468512
0.0018898941
0.0073820674
0.0049308506
0.008653131
0.0064831465
0.008727652
0.003943157
0.002408642
0.0047184457
0.0028128498
0.002078424
0.004322472
0.007709517
0.007049428
0.0039683026
0.007401487
0.0
0.008456736
0.0075407326
0.00750262
0.007556408
0.0043258937
0.0028804943
0.010729005
0.010247979
0.015401738
0.0037269602
0.0051030996
0.006152131
0.03552583
0.0075275754
0.011125472
0.0049651354
0.014996142
0.0025100636
0.0026587371
0.003026494
0.010713052
0.016137363
0.0074399244
0.0
0.008164224
0.0030578107
0.010298577
0.0054227584
0.005641616
0.002060013
0.0063559865
0.0029716475
0.011146674
0.0
0.0041775308
0.002330968
0.0
0.005576284
0.0031992323
0.0
0.013239378
0.008561042
0.0
0.004575738
0.010903674
0.011484257
0.011650758
0.007692075
0.0013262336
0.0035972581
0.003513329
0.006272337
0.005431077
0.0034474828
0.0037253706
0.004532121
0.0021471868
0.008487532
0.0115773985
0.0024994987
0.006590915
0.012679544
0.010242268
0.0
0.011513486
0.0
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997254   0.906977  0.464286  0.614173  0.514512  0.761719   

   Average Precision  
0           0.423618  

--------------------------------------------------------------------

C:\Users\rande\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\LocalCache\local-packages\Python39\site-packages\xgboost\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].
  warnings.warn(label_encoder_deprecation_msg, UserWarning)

[23:19:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.
Elapsed time to compute best fit: 8317.616 seconds
Cross-validation score: 0.7797773688077398
Test score: 0.8079268292682927
Best Hyperparameters: {'classifier__min_child_weight': 2, 'classifier__max_depth': 16, 'classifier__learning_rate': 0.45, 'classifier__gamma': 0.4, 'classifier__colsample_bytree': 0.6}
0.009758768
0.025759475
0.02778052
0.014424488
0.011993156
0.0062806117
0.008311411
0.011548687
0.008090448
0.003054337
0.0010921025
0.0070762835
0.006543261
0.009955922
0.015955992
0.004376853
0.004629742
0.024283566
0.00510208
0.004564748
0.012032983
0.024015214
0.004828665
0.006929593
0.0024970404
0.007994252
0.0028304402
0.007585186
0.0037487375
0.027347779
0.0038038946
0.0019854356
0.004209145
0.0062674936
0.002800589
0.0037639544
0.004568157
0.0069930456
0.0032865824
0.0026050145
0.00558655
0.0030194952
0.0023961097
0.0068631503
0.009113732
0.0049455813
0.016389033
0.004932618
0.0064986995
0.003522556
0.0053115697
0.0
0.009678731
0.0044790828
0.0
0.0068842364
0.0
0.0
0.0
0.0013762007
0.004735412
0.0019313358
0.0047079544
0.008627047
0.005963182
0.0025350763
0.007913424
0.0017283757
0.006774509
0.0059871683
0.0042722244
0.0013100986
0.0
0.0092383195
0.0055636973
0.008583561
0.0061831074
0.0029272938
0.0035466175
0.0
0.0018483074
0.002252513
0.005974837
0.0055878754
0.0011862387
0.0074071847
0.0063700504
0.0
0.0060655894
0.004845312
0.011053055
0.0035991035
0.005135713
0.006625034
0.0018131342
0.009080468
0.0042558415
0.0060809376
0.0022376098
0.0016362576
0.010882165
0.0066245208
0.0054039024
0.007223228
0.011058713
0.009033774
0.004959057
0.0031903384
0.0038966255
0.006630957
0.006685875
0.03319112
0.005917607
0.0031829851
0.0029993006
0.0025571196
0.005003441
0.0
0.007762157
0.0019735987
0.005450731
0.011908733
0.002606448
0.005719168
0.0021110591
0.004471198
0.0071377964
0.0
0.005320358
0.011065989
0.009888116
0.004025701
0.006449188
0.007067168
0.010488549
0.012517164
0.035743017
0.0063418467
0.007624193
0.010543912
0.007515703
0.0014870072
0.0026848407
0.0033743286
0.01055461
0.0038202615
0.0075811953
0.0
0.01731549
0.0011651159
0.0053683086
0.0
0.00472544
0.0024944735
Legend
Recall -  measures the fraction of relevant links that are retrieved
Precision - measures the fraction of retrieved links that are relevant
F-measure - measures the harmonic mean of recall and precision
F2-measure - favors recall
F0.5-measure - favors precision
Average Precision - summarizes a precision-recall curve as the weighted mean of precisions achieved at each threshold

   Accuracy  Precision    Recall        F1        F2      F0.5  \
0  0.997815   0.868852  0.630952  0.731034  0.667506  0.807927   

   Average Precision  
0           0.549942  

--------------------------------------------------------------------
